ProjectName,methodName,methodBody
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AbstractWgsMetricsCollector.java, abstract wgs metrics collector,"  (  collect wgs metrics collect wgs metrics final int coverage cap final  interval list intervals )  {  if  ( coverage cap  <  =  0 )   {  throw new  illegal argument exception ( "" coverage cap must be positive . "" )  ;   }  this . collect wgs metrics = collect wgs metrics ;  unfiltered depth histogram array = new long[coverage cap  +  1] ;  high quality depth histogram array = new long[coverage cap  +  1] ;  unfiltered baseq histogram array = new long[ byte . max   value] ;  this . coverage cap = coverage cap ;  this . intervals = intervals ;  this . using stop after = collect wgs metrics . stop   after  >  0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AbstractWgsMetricsCollector.java,add baseq histogram,protected void   ( final  metrics file <  collect wgs metrics .  wgs metrics  integer >  file )  {  file . add histogram ( get unfiltered baseq histogram (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AdapterUtility.java, adapter utility,public   ( final  list <  string >  adapter sequence )  {  adapter kmers = prepare adapter sequences ( adapter sequence )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AdapterUtility.java,is adapter sequence,public boolean   ( final byte[] read )  {  if  ( read . length  <  adapter   match   length )  return false ;  for  (  final byte[] adapter : adapter kmers )   {  int errors = 0 ;  for  ( int i = 0 ;  i  <  adapter . length ;   +  + i )   {  if  ( read[i]  !  =  adapter[i] &&  +  + errors  >  max   adapter   errors )   {  break ;   }   }  if  ( errors  <  =  max   adapter   errors )  return true ;   }  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AdapterUtility.java,prepare adapter sequences,private static byte[][]   ( final  list <  string >  adapter sequence )  {  final  set <  string >  kmers = new  hash set <  >  (  )  ;  for  (  final  string seq : adapter sequence )   {  for  ( int i = 0 ;  i  <  =  seq . length (  )   -  adapter   match   length ;   +  + i )   {  final  string kmer = seq . substring ( i i  +  adapter   match   length )  . to upper case (  )  ;  int ns = 0 ;  for  (  final char ch : kmer . to char array (  )  )  if  ( ch  =  =  'n' )   +  + ns ;  if  ( ns  <  =  max   adapter   errors )   {  kmers . add ( kmer )  ;  kmers . add (  sequence util . reverse complement ( kmer )  )  ;   }   }   }  final byte[][] adapter kmers = new byte[kmers . size (  ) ][] ;  int i = 0 ;  for  (  final  string kmer : kmers )   {  adapter kmers[i +  + ] =  string util . string to bytes ( kmer )  ;   }  return adapter kmers ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AlignmentSummaryMetricsCollector.java, alignment summary metrics collector,public   ( final  set <  metric accumulation level >  accumulation levels final  list < sam read group record >  sam rg records final boolean do ref metrics final  list <  string >  adapter sequence final int max insert size final  set <  pair orientation >  expected orientations final boolean is bisulfite sequenced )  {  this . do ref metrics = do ref metrics ;  this . adapter utility = new  adapter utility ( adapter sequence )  ;  this . max insert size = max insert size ;  this . expected orientations = expected orientations ;  this . is bisulfite sequenced = is bisulfite sequenced ;  setup ( accumulation levels sam rg records )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AlignmentSummaryMetricsCollector.java, group alignment summary metrics per unit metric collector,public   ( final  string sample final  string library final  string read group )  {  this . sample = sample ;  this . library = library ;  this . read group = read group ;  unpaired collector = new  individual alignment summary metrics collector (  alignment summary metrics .  category . unpaired sample library read group )  ;  first of pair collector = new  individual alignment summary metrics collector (  alignment summary metrics .  category . first   of   pair sample library read group )  ;  second of pair collector = new  individual alignment summary metrics collector (  alignment summary metrics .  category . second   of   pair sample library read group )  ;  pair collector = new  individual alignment summary metrics collector (  alignment summary metrics .  category . pair sample library read group )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AlignmentSummaryMetricsCollector.java, individual alignment summary metrics collector,public   ( final  alignment summary metrics .  category pairing category final  string sample final  string library final  string read group )  {  metrics = new  alignment summary metrics (  )  ;  metrics . category = pairing category ;  metrics . sample = sample ;  metrics . library = library ;  metrics . read   group = read group ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AlignmentSummaryMetricsCollector.java,accept record,public void   ( final sam record and reference args )  {  final sam record rec = args . get sam record (  )  ;  final  reference sequence ref = args . get reference sequence (  )  ;  if  ( rec . get read paired flag (  )  )   {  if  ( rec . get first of pair flag (  )  )   {  first of pair collector . add record ( rec ref )  ;   }  else  {  second of pair collector . add record ( rec ref )  ;   }  pair collector . add record ( rec ref )  ;   }  else  {  unpaired collector . add record ( rec ref )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AlignmentSummaryMetricsCollector.java,add metrics to file,@ override public void   ( final  metrics file <  alignment summary metrics  comparable <  ?  >  >  file )  {  if  ( first of pair collector . get metrics (  )  . total   reads  >  0 )   {  pair collector . get metrics (  )  . bad   cycles = first of pair
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AlignmentSummaryMetricsCollector.java,add record,public void   ( final sam record record final  reference sequence ref )  {  if  ( record . get not primary alignment flag (  )  )   {  return ;   }  collect read data ( record )  ;  collect quality data ( record ref )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AlignmentSummaryMetricsCollector.java,collect quality data,private void   ( final sam record record final  reference sequence reference )  {  if  ( record . get read unmapped flag (  )  || record . get read fails vendor quality check flag (  )  ||  ! do ref metrics )   {  final byte[] read bases = record . get read bases (  )  ;  for  ( int i = 0 ;  i  <  read bases . length ;  i +  +  )   {  if  (  sequence util . is no call ( read bases[i] )  )   {  bad cycle histogram . increment (  coord math . get cycle ( record . get read negative strand flag (  )  read bases . length i )  )  ;   }   }   }  else if  (  ! record . get read fails vendor quality check flag (  )  )   {  final boolean high quality mapping = is high quality mapping ( record )  ;  if  ( high quality mapping &&  ! record . get supplementary alignment flag (  )  )  metrics . pf   hq   aligned   reads +  +  ;  final byte[] read bases = record . get read bases (  )  ;  final byte[] ref bases = reference . get bases (  )  ;  final byte[] qualities = record . get base qualities (  )  ;  final int ref length = ref bases . length ;  long mismatch count = 0 ;  long hq mismatch count = 0 ;  for  (  final  alignment block alignment block : record . get alignment blocks (  )  )   {  final int read index = alignment block . get read start (  )   -  1 ;  final int ref index = alignment block . get reference start (  )   -  1 ;  final int length = alignment block . get length (  )  ;  for  ( int i = 0 ;  i  <  length && ref index  +  i  <  ref length ;   +  + i )   {  final int read base index = read index  +  i ;  boolean mismatch =  !  sequence util . bases equal ( read bases[read base index] ref bases[ref index  +  i] )  ;  final boolean bisulfite match = is bisulfite sequenced &&  sequence util . bisulfite bases equal ( record . get read negative strand flag (  )  read bases[read base index] ref bases[read base index] )  ;  final boolean bisulfite base = mismatch && bisulfite match ;  mismatch = mismatch &&  ! bisulfite match ;  if  ( mismatch )  mismatch count +  +  ;  metrics . pf   aligned   bases +  +  ;  if  (  ! bisulfite base )  non bisulfite aligned bases +  +  ;  if  ( high quality mapping )   {  metrics . pf   hq   aligned   bases +  +  ;  if  (  ! bisulfite base )  hq non bisulfite aligned bases +  +  ;  if  ( qualities[read base index]  >  =  base   quality   threshold )  metrics . pf   hq   aligned   q20   bases +  +  ;  if  ( mismatch )  hq mismatch count +  +  ;   }  if  ( mismatch ||  sequence util . is no call ( read bases[read base index] )  )   {  bad cycle histogram . increment (  coord math . get cycle ( record . get read negative strand flag (  )  read bases . length i )  )  ;   }   }   }  mismatch histogram . increment ( mismatch count )  ;  hq mismatch histogram . increment ( hq mismatch count )  ;  for  (  final  cigar element elem : record . get cigar (  )  . get cigar elements (  )  )   {  final  cigar operator op = elem . get operator (  )  ;  if  ( op  =  =   cigar operator . insertion || op  =  =   cigar operator . deletion )   +  + this . indels ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AlignmentSummaryMetricsCollector.java,collect read data,private void   ( final sam record record )  {  if  ( record . get supplementary alignment flag (  )  )  return ;  metrics . total   reads +  +  ;  read length histogram . increment ( record . get read bases (  )  . length )  ;  if  (  ! record . get read fails vendor quality check flag (  )  )   {  metrics . pf   reads +  +  ;  if  ( is noise read ( record )  )  metrics . pf   noise   reads +  +  ;  if  ( record . get read unmapped flag (  )  )   {  final byte[] read bases = record . get read bases (  )  ;  if  (  !  ( record instanceof bam record )  )   string util . to upper case ( read bases )  ;  if  ( adapter utility . is adapter sequence ( read bases )  )   {  this . adapter reads +  +  ;   }   }  else if  ( do ref metrics )   {  metrics . pf   reads   aligned +  +  ;  if  ( record . get read paired flag (  )  &&  ! record . get proper pair flag (  )  )  metrics . pf   reads   improper   pairs +  +  ;  if  (  ! record . get read negative strand flag (  )  )  num positive strand +  +  ;  if  ( record . get read paired flag (  )  &&  ! record . get mate unmapped flag (  )  )   {  metrics . reads   aligned   in   pairs +  +  ;  final  integer mate mq = record . get integer attribute ( sam tag . mq . to string (  )  )  ;  if  ( mate mq  =  =  null || mate mq  >  =  mapping   quality   threshold && record . get mapping quality (  )   >  =  mapping   quality   threshold )   {   +  + this . chimeras denominator ;  if  (  chimera util . is chimeric ( record max insert size expected orientations )  )   {   +  + this . chimeras ;   }   }   }  else  {  if  ( record . get mapping quality (  )   >  =  mapping   quality   threshold )   {   +  + this . chimeras denominator ;  if  ( record . get attribute ( sam tag . sa . to string (  )  )   !  =  null )   +  + this . chimeras ;   }   }   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AlignmentSummaryMetricsCollector.java,finish,@ override public void   (  )  {  unpaired collector . on complete (  )  ;  first of pair collector . on complete (  )  ;  second of pair collector . on complete (  )  ;  pair collector . on complete (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AlignmentSummaryMetricsCollector.java,get metrics,public  alignment summary metrics   (  )  {  return this . metrics ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AlignmentSummaryMetricsCollector.java,is high quality mapping,private boolean   ( final sam record record )  {  return  ! record . get read fails vendor quality check flag (  )  && record . get mapping quality (  )   >  =  mapping   quality   threshold ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AlignmentSummaryMetricsCollector.java,is noise read,private boolean   ( final sam record record )  {  final  object noise attribute = record . get attribute (  reserved tag constants . xn )  ;  return  ( noise attribute  !  =  null && noise attribute . equals ( 1 )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AlignmentSummaryMetricsCollector.java,make child collector,@ override protected  per unit metric collector <  alignment summary metrics  comparable <  ?  >  sam record and reference >    (  string sample  string library  string read group )  {  return new  group alignment summary metrics per unit metric collector
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\AlignmentSummaryMetricsCollector.java,on complete,public void   (  )  {  if  ( metrics . total   reads  >  0 )   {  metrics . pct   pf   reads =  ( double ) metrics . pf   reads  /   ( double ) metrics . total   reads ;  metrics . pct   adapter = this . adapter reads  /   ( double ) metrics . pf   reads ;  metrics . mean   read   length = read length histogram . get mean (  )  ;  metrics . bad   cycles = 0 ;  for  (  final  histogram .  bin <  integer >  cycle bin : bad cycle histogram . values (  )  )   {  final double bad cycle percentage = cycle bin . get value (  )   /  metrics . total   reads ;  if  ( bad cycle percentage  >  =  0 . 8 )   {  metrics . bad   cycles +  +  ;   }   }  if  ( do ref metrics )   {  if  ( metrics . pf   reads  >  0 )  metrics . pct   pf   reads   aligned =  ( double ) metrics . pf   reads   aligned  /   ( double ) metrics . pf   reads ;  if  ( metrics . pf   reads   aligned  >  0 )  metrics . pct   reads   aligned   in   pairs =  ( double ) metrics . reads   aligned   in   pairs  /   ( double ) metrics . pf   reads   aligned ;  if  ( metrics . pf   reads   aligned  >  0 )  metrics . pct   pf   reads   improper   pairs =  ( double ) metrics . pf   reads   improper   pairs  /   ( double ) metrics . pf   reads   aligned ;  if  ( metrics . pf   reads   aligned  >  0 )  metrics . strand   balance = num positive strand  /   ( double ) metrics . pf   reads   aligned ;  if  ( this . chimeras denominator  >  0 )  metrics . pct   chimeras = this . chimeras  /   ( double ) this . chimeras denominator ;  if  ( non bisulfite aligned bases  >  0 )  metrics . pf   mismatch   rate = mismatch histogram . get sum (  )   /   ( double ) non bisulfite aligned bases ;  metrics . pf   hq   median   mismatches = hq mismatch histogram . get median (  )  ;  if  ( hq non bisulfite aligned bases  >  0 )  metrics . pf   hq   error   rate = hq mismatch histogram . get sum (  )   /   ( double ) hq non bisulfite aligned bases ;  if  ( metrics . pf   aligned   bases  >  0 )  metrics . pf   indel   rate = this . indels  /   ( double ) metrics . pf   aligned   bases ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ContextAccumulator.java, context accumulator,"public   ( final  set <  string >  contexts final boolean expected tandem reads )  {  this . expected tandem reads = expected tandem reads ;  this . artifact map = new  hash map <  >  (  )  ;  for  (  final  string context : contexts )   {  if  (  ( context . length (  )  & 1 )   =  =  0 )  throw new  picard exception ( "" contexts cannot have an even number of bases: ""  +  context )  ;  final  alignment accumulator[] accumulators = new  alignment accumulator[ transition .  base . values (  )  . length] ;  for  ( int i = 0 ;  i  <   transition .  base . values (  )  . length ;  i +  +  )   {  accumulators[i] = new  alignment accumulator (  )  ;   }  this . artifact map . put ( context accumulators )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ContextAccumulator.java,calculate metrics,"public  list map <  transition  detail pair >    ( final  string sample alias final  string library )  {  final  list map <  transition  detail pair >  detail metrics map = new  list map <  >  (  )  ;  for  (  final  string context : new  tree set <  >  ( artifact map . key set (  )  )  )   {  if  (  ( context . length (  )  & 1 )   =  =  0 )  throw new  picard exception ( "" contexts cannot have an even number of bases: ""  +  context  +  "" .   this should never happen here ! "" )  ;  final char ref base = context . char at ( context . length (  )   /  2 )  ;  for  (  final  transition .  base alt base :  transition .  base . values (  )  )   {  final  transition transition =  transition . transition of ( ref base  ( char ) alt base . base )  ;  final  pre adapter detail metrics pre adapter detail metrics = new  pre adapter detail metrics (  )  ;  final  bait bias detail metrics bait bias detail metrics = new  bait bias detail metrics (  )  ;  pre adapter detail metrics . sample   alias = sample alias ;  pre adapter detail metrics . library = library ;  pre adapter detail metrics . context = context ;  pre adapter detail metrics . ref   base = transition . ref (  )  ;  pre adapter detail metrics . alt   base = transition . call (  )  ;  bait bias detail metrics . sample   alias = sample alias ;  bait bias detail metrics . library = library ;  bait bias detail metrics . context = context ;  bait bias detail metrics . ref   base = transition . ref (  )  ;  bait bias detail metrics . alt   base = transition . call (  )  ;  final  alignment accumulator[] accumulators = artifact map . get ( context )  ;  final  alignment accumulator[] reverse comp accumulators = artifact map . get (  sequence util . reverse complement ( context )  )  ;  final  alignment accumulator fwd ref alignments = accumulators[ transition . base index map[transition . ref (  ) ]] ;  final  alignment accumulator fwd alt alignments = accumulators[ transition . base index map[transition . call (  ) ]] ;  final  alignment accumulator rev ref alignments = reverse comp accumulators[ transition . base index map[transition . complement (  )  . ref (  ) ]] ;  final  alignment accumulator rev alt alignments = reverse comp accumulators[ transition . base index map[transition . complement (  )  . call (  ) ]] ;  if  ( expected tandem reads )   {  pre adapter detail metrics . pro   ref   bases = fwd ref alignments . r1   pos  +  fwd ref alignments . r2   pos  +  rev ref alignments . r1   neg +  rev ref alignments . r2   neg ;  pre adapter detail metrics . pro   alt   bases = fwd alt alignments . r1   pos  +  fwd alt alignments . r2   pos  +  rev alt alignments . r1   neg +  rev alt alignments . r2   neg ;  pre adapter detail metrics . con   ref   bases = fwd ref alignments . r1   neg  +  fwd ref alignments . r2   neg  +  rev ref alignments . r1   pos +  rev ref alignments . r2   pos ;  pre adapter detail metrics . con   alt   bases = fwd alt alignments . r1   neg  +  fwd alt alignments . r2   neg  +  rev alt alignments . r1   pos +  rev alt alignments . r2   pos ;   }  else  {  pre adapter detail metrics . pro   ref   bases = fwd ref alignments . r1   pos  +  fwd ref alignments . r2   neg  +  rev ref alignments . r1   neg +  rev ref alignments . r2   pos ;  pre adapter detail metrics . pro   alt   bases = fwd alt alignments . r1   pos  +  fwd alt alignments . r2   neg  +  rev alt alignments . r1   neg +  rev alt alignments . r2   pos ;  pre adapter detail metrics . con   ref   bases = fwd ref alignments . r1   neg  +  fwd ref alignments . r2   pos  +  rev ref alignments . r1   pos +  rev ref alignments . r2   neg ;  pre adapter detail metrics . con   alt   bases = fwd alt alignments . r1   neg  +  fwd alt alignments . r2   pos  +  rev alt alignments . r1   pos +  rev alt alignments . r2   neg ;   }  bait bias detail metrics . fwd   cxt   ref   bases = fwd ref alignments . r1   pos  +  fwd ref alignments . r1   neg  +  fwd ref alignments . r2   pos +  fwd ref alignments . r2   neg ;  bait bias detail metrics . fwd   cxt   alt   bases = fwd alt alignments . r1   pos  +  fwd alt alignments . r1   neg  +  fwd alt alignments . r2   pos +  fwd alt alignments . r2   neg ;  bait bias detail metrics . rev   cxt   ref   bases = rev ref alignments . r1   pos  +  rev ref alignments . r1   neg  +  rev ref alignments . r2   pos +  rev ref alignments . r2   neg ;  bait bias detail metrics . rev   cxt   alt   bases = rev alt alignments . r1   pos  +  rev alt alignments . r1   neg  +  rev alt alignments . r2   pos +  rev alt alignments . r2   neg ;  pre adapter detail metrics . calculate derived statistics (  )  ;  bait bias detail metrics . calculate derived statistics (  )  ;  detail metrics map . add ( transition new  detail pair ( pre adapter detail metrics bait bias detail metrics )  )  ;   }   }  return detail metrics map ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ContextAccumulator.java,count record,private void   ( final sam record rec )  {  final boolean is negative strand = rec . get read negative strand flag (  )  ;  final boolean is read two = rec . get read paired flag (  )  && rec . get second of pair flag (  )  ;  if  ( is read two )   {  if  ( is negative strand )  this . r2   neg +  +  ;  else this . r2   pos +  +  ;   }  else  {  if  ( is negative strand )  this . r1   neg +  +  ;  else this . r1   pos +  +  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ContextAccumulator.java,fill half records,public void   ( final  context accumulator full context accumulator final int context size )  {  final  string padding =  string util . repeat charn times ( 'n' context size )  ;  for  (   map .  entry <  string  alignment accumulator[] >  full context : full context accumulator . artifact map . entry set (  )  )   {  final  string full context key = full context . get key (  )  ;  final char central base = full context key . char at ( context size )  ;  final  string leading context key = full context key . substring ( 0 context size )   +  central base  +  padding ;  final  string trailing context key = padding  +  central base  +  full context key . substring ( context size  +  1 full context key . length (  )  )  ;  final  alignment accumulator[] trailing alignment accumulators = this . artifact map . get ( trailing context key )  ;  final  alignment accumulator[] leading alignment accumulators = this . artifact map . get ( leading context key )  ;  final  alignment accumulator[] full alignment accumulators = full context . get value (  )  ;  for  ( int i = 0 ;  i  <  full alignment accumulators . length ;  i +  +  )   {  trailing alignment accumulators[i] . merge ( full alignment accumulators[i] )  ;  leading alignment accumulators[i] . merge ( full alignment accumulators[i] )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ContextAccumulator.java,fill zero records,public void   ( final  context accumulator full context accumulator final int context size )  {  final  string padding =  string util . repeat charn times ( 'n' context size )  ;  for  (   map .  entry <  string  alignment accumulator[] >  full context : full context accumulator . artifact map . entry set (  )  )   {  final  string full context key = full context . get key (  )  ;  final char central base = full context key . char at ( context size )  ;  final  string zero context key = padding  +  central base  +  padding ;  final  alignment accumulator[] zero alignment accumulators = this . artifact map . get ( zero context key )  ;  final  alignment accumulator[] full alignment accumulators = full context . get value (  )  ;  for  ( int i = 0 ;  i  <  full alignment accumulators . length ;  i +  +  )   {  zero alignment accumulators[i] . merge ( full alignment accumulators[i] )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ContextAccumulator.java,merge,private void   ( final  alignment accumulator other )  {  this . r1   pos = this . r1   pos  +  other . r1   pos ;  this . r2   pos = this . r2   pos  +  other . r2   pos ;  this . r1   neg = this . r1   neg  +  other . r1   neg ;  this . r2   neg = this . r2   neg  +  other . r2   neg ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ConvertSequencingArtifactToOxoG.java,do work,@ override protected int   (  )  {  if  ( output   base  =  =  null )   {  output   base = input   base ;   }  final  file pre   adapter   in = new  file ( input   base  +   sequencing artifact metrics . pre   adapter   details   ext )  ;  final  file bai
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ConvertSequencingArtifactToOxoG.java,is oxog,private boolean   ( final  transition t )  {  return t . equals (  transition .  ctoa )  || t . equals (  transition .  gtot )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ArtifactCounter.java, artifact counter,public   ( final  string sample alias final  string library final int context size final boolean expected tandem reads )  {  this . sample alias = sample alias ;  this . library = library ;  this . context size = context size ;  final  hash set <  string >  full contexts = new  hash set <  >  (  )  ;  for  (  final byte[] kmer :  sequence util . generate all kmers ( 2 * context size  +  1 )  )   {  full contexts . add (  string util . bytes to string ( kmer )  )  ;   }  final  set <  string >  zero contexts = new  hash set <  >  (  )  ;  final  string padding =  string util . repeat charn times ( 'n' context size )  ;  for  (  final  string context : full contexts )   {  final char central base = context . char at ( context size )  ;  final  string leading = context . substring ( 0 context size )   +  central base  +  padding ;  final  string trailing = padding  +  central base  +  context . substring ( context size  +  1 context . length (  )  )  ;  final  string zero = padding  +  central base  +  padding ;  context map . put ( context new  ref context ( context leading trailing zero )  )  ;  leading contexts . add ( leading )  ;  trailing contexts . add ( trailing )  ;  zero contexts . add ( zero )  ;   }  final  set <  string >  half contexts = new  hash set <  >  ( leading contexts )  ;  half contexts . add all ( trailing contexts )  ;  this . full context accumulator = new  context accumulator ( full contexts expected tandem reads )  ;  this . half context accumulator = new  context accumulator ( half contexts expected tandem reads )  ;  this . zero context accumulator = new  context accumulator ( zero contexts expected tandem reads )  ;  pre adapter summary metrics list = new  array list <  pre adapter summary metrics >  (  )  ;  pre adapter detail metrics list = new  array list <  pre adapter detail metrics >  (  )  ;  bait bias summary metrics list = new  array list <  bait bias summary metrics >  (  )  ;  bait bias detail metrics list = new  array list <  bait bias detail metrics >  (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ArtifactCounter.java, ref context,public   ( final  string ref final  string leading final  string trailing final  string zero )  {  this . ref = ref ;  this . leading = leading ;  this . trailing = trailing ;  this . zero = zero ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ArtifactCounter.java,count record,public void   ( final  string ref context final char called base final sam record rec )  {  this . full context accumulator . count record ( ref context called base rec )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ArtifactCounter.java,finish,public void   (  )  {  final  list map <  transition  detail pair >  all detail metrics = get detail metrics (  )  ;  final  map <  transition  summary pair >  all summary metrics = get summary metrics (  )  ;  for  (  final  transition transition :  transition . alt values (  )  )   {  final  summary pair summary = all summary metrics . get ( transition )  ;  final  list <  detail pair >  details = all detail metrics . get ( transition )  ;  pre adapter summary metrics list . add ( summary . pre adapter metrics )  ;  bait bias summary metrics list . add ( summary . bait bias metrics )  ;  for  (  final  detail pair detail : details )   {  pre adapter detail metrics list . add ( detail . pre adapter metrics )  ;  bait bias detail metrics list . add ( detail . bait bias metrics )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ArtifactCounter.java,get bait bias detail metrics,public  list <  bait bias detail metrics >    (  )  {  return bait bias detail metrics list ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ArtifactCounter.java,get bait bias summary metrics,public  list <  bait bias summary metrics >    (  )  {  return bait bias summary metrics list ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ArtifactCounter.java,get detail metrics,private  list map <  transition  detail pair >    (  )  {  return this . full context accumulator . calculate metrics ( this . sample alias this . library )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ArtifactCounter.java,get pre adapter detail metrics,public  list <  pre adapter detail metrics >    (  )  {  return pre adapter detail metrics list ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ArtifactCounter.java,get pre adapter summary metrics,public  list <  pre adapter summary metrics >    (  )  {  return pre adapter summary metrics list ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ArtifactCounter.java,get summary metrics,"private  map <  transition  summary pair >    (  )  {  final  map <  transition  summary pair >  summary metrics map = new  enum map <  transition  summary pair >  (  transition . class )  ;  final  list map <  transition  detail pair >  full metrics = this . full context accumulator . calculate metrics ( sample alias library )  ;  this . half context accumulator . fill half records ( this . full context accumulator context size )  ;  final  list map <  transition  detail pair >  half metrics = this . half context accumulator . calculate metrics ( sample alias library )  ;  this . zero context accumulator . fill zero records ( this . full context accumulator context size )  ;  final  list map <  transition  detail pair >  zero metrics = this . zero context accumulator . calculate metrics ( sample alias library )  ;  for  (  final  transition transition :  transition . alt values (  )  )   {  final  list <  detail pair >  full metrics for transition = full metrics . get ( transition )  ;  final  list <  detail pair >  zero metrics for transition = zero metrics . get ( transition )  ;  if  ( zero metrics for transition . size (  )   !  =  1 )   {  throw new  picard exception ( "" should have exactly one context - free metric pair for transition: ""  +  transition )  ;   }  final  list <  detail pair >  leading metrics for transition = new  array list <  detail pair >  (  )  ;  final  list <  detail pair >  trailing metrics for transition = new  array list <  detail pair >  (  )  ;  for  (  final  detail pair metrics : half metrics . get ( transition )  )   {  if  (  ! metrics . pre adapter metrics . context . equals ( metrics . bait bias metrics . context )  )   {  throw new  picard exception ( "" input detail metrics are not matched up properly  -  contexts differ . "" )  ;   }  final boolean is leading = leading contexts . contains ( metrics . pre adapter metrics . context )  ;  final boolean is trailing = trailing contexts . contains ( metrics . pre adapter metrics . context )  ;  if  ( is leading )  leading metrics for transition . add ( metrics )  ;  if  ( is trailing )  trailing metrics for transition . add ( metrics )  ;   }  final  detail pair total metric = zero metrics for transition . get ( 0 )  ;  final  detail pair worst full metric = get worst metrics ( full metrics for transition )  ;  final  detail pair worst leading metric = get worst metrics ( leading metrics for transition )  ;  final  detail pair worst trailing metric = get worst metrics ( trailing metrics for transition )  ;  final  pre adapter summary metrics pre adapter summary metrics = new  pre adapter summary metrics (  )  ;  final  bait bias summary metrics bait bias summary metrics = new  bait bias summary metrics (  )  ;  pre adapter summary metrics . sample   alias = this . sample alias ;  pre adapter summary metrics . library = this . library ;  pre adapter summary metrics . ref   base = transition . ref (  )  ;  pre adapter summary metrics . alt   base = transition . call (  )  ;  pre adapter summary metrics . total   qscore = total metric . pre adapter metrics . qscore ;  pre adapter summary metrics . worst   cxt = worst full metric . pre adapter metrics . context ;  pre adapter summary metrics . worst   cxt   qscore = worst full metric . pre adapter metrics . qscore ;  pre adapter summary metrics . worst   pre   cxt = worst leading metric . pre adapter metrics . context ;  pre adapter summary metrics . worst   pre   cxt   qscore = worst leading metric . pre adapter metrics . qscore ;  pre adapter summary metrics . worst   post   cxt = worst trailing metric . pre adapter metrics . context ;  pre adapter summary metrics . worst   post   cxt   qscore = worst trailing metric . pre adapter metrics . qscore ;  pre adapter summary metrics . infer artifact name (  )  ;  bait bias summary metrics . sample   alias = this . sample alias ;  bait bias summary metrics . library = this . library ;  bait bias summary metrics . ref   base = transition . ref (  )  ;  bait bias summary metrics . alt   base = transition . call (  )  ;  bait bias summary metrics . total   qscore = total metric . bait bias metrics . qscore ;  bait bias summary metrics . worst   cxt = worst full metric . bait bias metrics . context ;  bait bias summary metrics . worst   cxt   qscore = worst full metric . bait bias metrics . qscore ;  bait bias summary metrics . worst   pre   cxt = worst leading metric . bait bias metrics . context ;  bait bias summary metrics . worst   pre   cxt   qscore = worst leading metric . bait bias metrics . qscore ;  bait bias summary metrics . worst   post   cxt = worst trailing metric . bait bias metrics . context ;  bait bias summary metrics . worst   post   cxt   qscore = worst trailing metric . bait bias metrics . qscore ;  bait bias summary metrics . infer artifact name (  )  ;  summary metrics map . put ( transition new  summary pair ( pre adapter summary metrics bait bias summary metrics )  )  ;   }  return summary metrics map ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ArtifactCounter.java,get worst metrics,private  detail pair   ( final  list <  detail pair >  metrics )  {   pre adapter detail metrics worst pre adapter metrics = null ;   bait bias detail metrics worst bait bias metrics = null ;  for  (  final  detail pair m : metrics )   {  if  ( worst pre adapter metrics  =  =  null || m . pre adapter metrics . compare to ( worst pre adapter metrics )   <  0 )  worst pre adapter metrics = m . pre adapter metrics ;  if  ( worst bait bias metrics  =  =  null || m . bait bias metrics . compare to ( worst bait bias metrics )   <  0 )  worst bait bias metrics = m . bait bias metrics ;   }  return new  detail pair ( worst pre adapter metrics worst bait bias metrics )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\CollectSequencingArtifactMetrics.java,accept read,@ override protected void   ( final sam record rec final  reference sequence ref )  {  if  ( record filter . filter out ( rec )  )  return ;  final  string library =  ( rec . get read group (  )   =  =  null )   ?  unknown   library : get or else ( rec . 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\CollectSequencingArtifactMetrics.java,custom command line validation,"@ override protected  string[]   (  )  {  final  list <  string >  messages = new  array list <  >  (  )  ;  final int context full length = 2 * context   size  +  1 ;  if  ( context   size  <  0 )  messages . add ( ""context   size cannot be negative"" )  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\CollectSequencingArtifactMetrics.java,finish,@ override protected void   (  )  {  final  metrics file <  pre adapter summary metrics  integer >  pre adapter summary metrics file = get metrics file (  )  ;  final  metrics file <  pre adapter detail metrics  integer >  pre adapter detail metrics file 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\CollectSequencingArtifactMetrics.java,get ref context,private  string   ( final  reference sequence ref final int context start index final int context full length )  {  if  ( current ref index  !  =  ref . get contig index (  )  )   {  current ref string = new  string ( ref . get bases (  )  )  . to upper case (  )  ;  current ref index = ref . get contig index (  )  ;   }  return current ref string . substring ( context start index context start index  +  context full length )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\CollectSequencingArtifactMetrics.java,requires reference,@ override protected boolean   (  )  {  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\CollectSequencingArtifactMetrics.java,setup,"@ override protected void   ( final sam file header header final  file sam file )  {  final  string outext =  ( null  !  =  file   extension )   ?  file   extension : """" ;  pre adapter summary out = new  file ( output  +   sequencing artifact metrics . pr"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\CollectSequencingArtifactMetrics.java,uses no ref reads,@ override protected boolean   (  )  {  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\ErrorSummaryMetrics.java,calculate derived fields,@ override public void   (  )  {  final double total = ref   count  +  alt   count ;  this . substitution   rate =  ( total  =  =  0 )   ?  0 : alt   count  /  total ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\SequencingArtifactMetrics.java, detail pair,  ( final  pre adapter detail metrics pre adapter metrics final  bait bias detail metrics bait bias metrics )  {  this . pre adapter metrics = pre adapter metrics ;  this . bait bias metrics = bait bias metrics ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\SequencingArtifactMetrics.java, summary pair,  ( final  pre adapter summary metrics pre adapter metrics final  bait bias summary metrics bait bias metrics )  {  this . pre adapter metrics = pre adapter metrics ;  this . bait bias metrics = bait bias metrics ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\SequencingArtifactMetrics.java,calculate derived statistics,public void   (  )  {  this . fwd   error   rate = min   error ;  final long fwd bases = this . fwd   cxt   ref   bases  +  this . fwd   cxt   alt   bases ;  if  ( fwd bases  >  0 )   {  final double fwd err = this . fwd   cxt   alt   bases  /   ( double ) fwd bases ;  this . fwd   error   rate =  math . max ( min   error fwd err )  ;   }  this . rev   error   rate = min   error ;  final long rev bases = this . rev   cxt   ref   bases  +  this . rev   cxt   alt   bases ;  if  ( rev bases  >  0 )   {  final double rev err = this . rev   cxt   alt   bases  /   ( double ) rev bases ;  this . rev   error   rate =  math . max ( min   error rev err )  ;   }  this . error   rate =  math . max ( min   error this . fwd   error   rate  -  this . rev   error   rate )  ;  this . qscore =  quality util . get phred score from error probability ( this . error   rate )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\SequencingArtifactMetrics.java,compare to,public int   ( final  bait bias detail metrics o )  {  int retval =  double . compare ( qscore o . qscore )  ;  if  ( retval  !  =  0 )  return retval ;  retval = ref   base  -  o . ref   base ;  if  ( retval  !  =  0 )  return retval ;  retval = alt   base  -  o . alt   base ;  if  ( retval  !  =  0 )  return retval ;  retval = context . compare to ( o . context )  ;  return retval ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\SequencingArtifactMetrics.java,infer artifact name,"public void   (  )  {  if  ( this . ref   base  =  =  'g' && this . alt   base  =  =  't' )  this . artifact   name = "" gref"" ;  else if  ( this . ref   base  =  =  'c' && this . alt   base  =  =  'a' )  this . artifact   name = "" cref"" ;  else this . artifact   name = ""na"" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\Transition.java, base,private   ( final char base )  {  this . base =  ( byte ) base ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\Transition.java, transition,  ( final char ref final char call )  {  this . ref = ref ;  this . call = call ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\Transition.java,alt values,public static  transition[]   (  )  {  return alt   values ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\Transition.java,call,public char   (  )  {  return this . call ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\Transition.java,complement,public  transition   (  )  {  return transition of (  ( char )  sequence util . complement (  ( byte ) this . ref )   ( char )  sequence util . complement (  ( byte ) this . call )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\Transition.java,ref,public char   (  )  {  return this . ref ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\Transition.java,to string,"@ override public  string   (  )  {  return this . ref  +  "" > ""  +  this . call ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\artifacts\Transition.java,transition of,"public static  transition   ( final char ref final char call )  {  try  {  return transition index map[base index map[ref]][base index map[call]] ;   }  catch  (   index out of bounds exception e )   {  throw new  illegal argument exception (  string . format ( "" base params should be one of  { a  c  t  g }  but ref = %s and call = %s"" ref call )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\ChimeraUtil.java,is chimeric,public static boolean   ( final sam record r1 final sam record r2 final int max insert size final  set <  pair orientation >  expected orientations )  {  return is mapped pair ( r1 )  &&  (  math . abs ( r1 . get inferred insert size (  )  )   >  max insert size ||  ! r1 . get reference index (  )  . equals ( r2 . get reference index (  )  )  ||  ! matches expected orientations ( r1 expected orientations )  || r2 . get attribute ( sam tag . sa . to string (  )  )   !  =  null )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\ChimeraUtil.java,is mapped pair,private static boolean   ( final sam record rec )  {  return rec . get read paired flag (  )  &&  ! rec . get read unmapped flag (  )  &&  ! rec . get mate unmapped flag (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\ChimeraUtil.java,matches expected orientations,private static boolean   ( final sam record rec final  set <  pair orientation >  expected orientations )  {  return expected orientations . contains (  sam pair util . get pair orientation ( rec )  )  && rec . get attribute ( sam tag . sa . to string (  )  )   =  =  null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectAlignmentSummaryMetrics.java,accept read,@ override protected void   ( final sam record rec final  reference sequence ref )  {  collector . accept record ( rec ref )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectAlignmentSummaryMetrics.java,finish,@ override protected void   (  )  {  collector . finish (  )  ;  final  metrics file <  alignment summary metrics  comparable <  ?  >  >  file = get metrics file (  )  ;  collector . add all levels to file ( file )  ;  file . write ( output )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectAlignmentSummaryMetrics.java,get reference file,@ override public  file   (  )  {  return reference   sequence ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectAlignmentSummaryMetrics.java,main,public static void   ( final  string[] argv )  {  new  collect alignment summary metrics (  )  . instance main with exit ( argv )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectAlignmentSummaryMetrics.java,make reference argument collection,@ override protected  reference argument collection   (  )  {  return new  collect alignment ref arg collection (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectAlignmentSummaryMetrics.java,setup,"@ override protected void   ( final sam file header header final  file sam file )  {  io util . assert file is writable ( output )  ;  if  ( header . get sequence dictionary (  )  . is empty (  )  )   {  log . warn ( input . get absolute file (  )   +  "" "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectAlignmentSummaryMetrics.java,test do work,protected final int   (  )  {  return do work (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectGcBiasMetrics.java,accept read,@ override protected void   ( final sam record rec final  reference sequence ref )  {  multi collector . accept record ( rec ref )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectGcBiasMetrics.java,finish,@ override protected void   (  )  {  multi collector . finish (  )  ;  write results to files (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectGcBiasMetrics.java,main,public static void   ( final  string[] args )  {   system . exit ( new  collect gc bias metrics (  )  . instance main ( args )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectGcBiasMetrics.java,setup,@ override protected void   ( final sam file header header final  file sam file )  {  io util . assert file is writable ( chart   output )  ;  io util . assert file is writable ( summary   output )  ;  io util . assert file is readable ( reference   seque
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectGcBiasMetrics.java,write results to files,private void   (  )  {  final  metrics file <  gc bias metrics  integer >  file = get metrics file (  )  ;  final  metrics file <  gc bias detail metrics  ?  >  detail metrics file = get metrics file (  )  ;  final  metrics file <  gc bias summary metrics  ?  >  summary metrics file = get metrics file (  )  ;  multi collector . add all levels to file ( file )  ;  final  list <  gc bias metrics >  gc bias metrics list = file . get metrics (  )  ;  for  (  final  gc bias metrics gcbm : gc bias metrics list )   {  final  list <  gc bias detail metrics >  gc detail list = gcbm . details . get metrics (  )  ;  for  (  final  gc bias detail metrics d : gc detail list )   {  detail metrics file . add metric ( d )  ;   }  summary metrics file . add metric ( gcbm . summary )  ;   }  detail metrics file . write ( output )  ;  summary metrics file . write ( summary   output )  ;  final  number format fmt =  number format . get integer instance (  )  ;  fmt . set grouping used ( true )  ;  r executor . execute from classpath ( r   script output . get absolute path (  )  summary   output . get absolute path (  )  chart   output . get absolute path (  )   string . value of ( scan   window   size )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectBaseDistributionByCycle.java,accept read,@ override protected void   ( final sam record rec final  reference sequence ref )  {  if  (  ( pf   reads   only )  &&  ( rec . get read fails vendor quality check flag (  )  )  )   {  return ;   }  if  (  ( aligned   reads   only )  &&  ( rec . get read
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectBaseDistributionByCycle.java,add record,void   ( final sam record rec )  {  final byte[] bases = rec . get read bases (  )  ;  if  ( bases  =  =  null )   {  return ;   }  final int length = bases . length ;  final boolean rc = rec . get read negative strand flag (  )  ;  ensure arrays big enough ( length  +  1 )  ;  if  (  ( rec . get read paired flag (  )  )  &&  ( rec . get second of pair flag (  )  )  )   {  seen second end = true ;  for  ( int i = 0 ;  i  <  length ;  i +  +  )   {  final int cycle = rc  ?  length  -  i : i  +  1 ;  second read totals by cycle[base to int ( bases[i] ) ][cycle] +  = 1 ;  second read counts by cycle[cycle] +  = 1 ;   }   }  else  {  for  ( int i = 0 ;  i  <  length ;  i +  +  )   {  final int cycle = rc  ?  length  -  i : i  +  1 ;  first read totals by cycle[base to int ( bases[i] ) ][cycle] +  = 1 ;  first read counts by cycle[cycle] +  = 1 ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectBaseDistributionByCycle.java,add to metrics file,public void   ( final  metrics file <  base distribution by cycle metrics  ?  >  metrics )  {  int first read length = 0 ;  for  ( int i = 0 ;  i  <  max length so far ;  i +  +  )   {  if  ( 0  !  =  first read counts by cycle[i] )   {  final  base distribution by cycle metrics metric = new  base distribution by cycle metrics (  )  ;  metric . read   end = 1 ;  metric . cycle = i ;  metric . pct   a =  ( 100 . 0 * first read totals by cycle[0][i]  /  first read counts by cycle[i] )  ;  metric . pct   c =  ( 100 . 0 * first read totals by cycle[1][i]  /  first read counts by cycle[i] )  ;  metric . pct   g =  ( 100 . 0 * first read totals by cycle[2][i]  /  first read counts by cycle[i] )  ;  metric . pct   t =  ( 100 . 0 * first read totals by cycle[3][i]  /  first read counts by cycle[i] )  ;  metric . pct   n =  ( 100 . 0 * first read totals by cycle[4][i]  /  first read counts by cycle[i] )  ;  metrics . add metric ( metric )  ;  first read length = i ;   }   }  if  ( seen second end )   {  for  ( int i = 0 ;  i  <  max length so far ;  i +  +  )   {  if  ( 0  !  =  second read counts by cycle[i] )   {  final  base distribution by cycle metrics metric = new  base distribution by cycle metrics (  )  ;  metric . read   end = 2 ;  metric . cycle =  ( i  +  first read length )  ;  metric . pct   a =  ( 100 . 0 * second read totals by cycle[0][i]  /  second read counts by cycle[i] )  ;  metric . pct   c =  ( 100 . 0 * second read totals by cycle[1][i]  /  second read counts by cycle[i] )  ;  metric . pct   g =  ( 100 . 0 * second read totals by cycle[2][i]  /  second read counts by cycle[i] )  ;  metric . pct   t =  ( 100 . 0 * second read totals by cycle[3][i]  /  second read counts by cycle[i] )  ;  metric . pct   n =  ( 100 . 0 * second read totals by cycle[4][i]  /  second read counts by cycle[i] )  ;  metrics . add metric ( metric )  ;   }   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectBaseDistributionByCycle.java,base to int,private int   ( final byte base )  {  switch  ( base )   {  case 'a': case 'a': return 0 ;  case 'c': case 'c': return 1 ;  case 'g': case 'g': return 2 ;  case 't': case 't': return 3 ;   }  return 4 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectBaseDistributionByCycle.java,ensure arrays big enough,private void   ( final int length )  {  if  ( length  >  max length so far )   {  for  ( int i = 0 ;  i  <  5 ;  i +  +  )   {  first read totals by cycle[i] =  arrays . copy of ( first read totals by cycle[i] length )  ;  second read totals by cycle[i] =  arrays . copy of ( second read totals by cycle[i] length )  ;   }  first read counts by cycle =  arrays . copy of ( first read counts by cycle length )  ;  second read counts by cycle =  arrays . copy of ( second read counts by cycle length )  ;  max length so far = length ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectBaseDistributionByCycle.java,finish,@ override protected void   (  )  {  final  metrics file <  base distribution by cycle metrics  ?  >  metrics = get metrics file (  )  ;  hist . add to metrics file ( metrics )  ;  metrics . write ( output )  ;  if  ( hist . is empty (  )  )   {  log . wa
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectBaseDistributionByCycle.java,is empty,boolean   (  )  {  return max length so far  =  =  0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectBaseDistributionByCycle.java,main,public static void   (  string[] args )  {   system . exit ( new  collect base distribution by cycle (  )  . instance main ( args )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectBaseDistributionByCycle.java,setup,@ override protected void   ( final sam file header header final  file sam file )  {  io util . assert file is writable ( chart   output )  ;  final  list < sam read group record >  read groups = header . get read groups (  )  ;  if  ( read groups . size 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectInsertSizeMetrics.java,accept read,@ override protected void   ( final sam record record final  reference sequence ref )  {  multi collector . accept record ( record ref )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectInsertSizeMetrics.java,custom command line validation,"@ override protected  string[]   (  )  {  if  ( minimum   pct  <  0 || minimum   pct  >  0 . 5 )   {  return new  string[] { ""minimum   pct was set to ""  +  minimum   pct  +  "" .   it must be between 0 and 0 . 5 so all data categories don't get discarded "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectInsertSizeMetrics.java,finish,@ override protected void   (  )  {  multi collector . finish (  )  ;  final  metrics file <  insert size metrics  integer >  file = get metrics file (  )  ;  multi collector . add all levels to file ( file )  ;  if  ( file . get num histograms (  )   =  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectInsertSizeMetrics.java,main,public static void   ( final  string[] argv )  {  new  collect insert size metrics (  )  . instance main with exit ( argv )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectInsertSizeMetrics.java,setup,@ override protected void   ( final sam file header header final  file sam file )  {  io util . assert file is writable ( output )  ;  io util . assert file is writable (  histogram   file )  ;  multi collector = new  insert size metrics collector ( metri
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectInsertSizeMetrics.java,uses no ref reads,@ override protected boolean   (  )  {  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectJumpingLibraryMetrics.java,do work,"protected int   (  )  {  for  (   file f : input )   {  io util . assert file is readable ( f )  ;   }  io util . assert file is writable ( output )  ;   histogram <  integer >  innie histogram = new  histogram <  integer >  (  )  ;   histogram <  integer >  outie histogram = new  histogram <  integer >  (  )  ;  int fragments = 0 ;  int innies = 0 ;  int outies = 0 ;  int innie dupes = 0 ;  int outie dupes = 0 ;  int cross chrom pairs = 0 ;  int super sized = 0 ;  int tandem pairs = 0 ;  double chimera size minimum =  math . max ( get outie mode (  )   ( double ) chimera   kb   min )  ;  for  (   file f : input )   {   sam reader reader =  sam reader factory . make default (  )  . open ( f )  ;  if  ( reader . get file header (  )  . get sort order (  )   !  =  sam file header .  sort order . coordinate )   {  throw new  picard exception ( ""sam file must ""  +  f . get name (  )   +  "" must be sorted in coordintate order"" )  ;   }  for  (  sam record sam : reader )   {  if  (  ! sam . get first of pair flag (  )  )   {  continue ;   }  if  ( sam . get read unmapped flag (  )  )   {  if  (  ! sam . get mate unmapped flag (  )  )   {  fragments +  +  ;  continue ;   }  if  ( sam . get reference index (  )   =  =  sam record . no   alignment   reference   index )   {  break ;   }  continue ;   }  if  ( sam . get mate unmapped flag (  )  )   {  fragments +  +  ;  continue ;   }  if  (  ( sam . get attribute ( sam tag . mq . name (  )  )   !  =  null && sam . get integer attribute ( sam tag . mq . name (  )  )   <  minimum   mapping   quality )  || sam . get mapping quality (  )   <  minimum   mapping   quality )   {  continue ;   }  final int abs insert size =  math . abs ( sam . get inferred insert size (  )  )  ;  if  ( abs insert size  >  chimera size minimum )   {  super sized +  +  ;   }  else if  ( sam . get mate negative strand flag (  )   =  =  sam . get read negative strand flag (  )  )   {  tandem pairs +  +  ;   }  else if  (  ! sam . get mate reference index (  )  . equals ( sam . get reference index (  )  )  )   {  cross chrom pairs +  +  ;   }  else  {  final  pair orientation pair orientation =  sam pair util . get pair orientation ( sam )  ;  if  ( pair orientation  =  =   pair orientation . rf )   {  outie histogram . increment ( abs insert size )  ;  outies +  +  ;  if  ( sam . get duplicate read flag (  )  )   {  outie dupes +  +  ;   }   }  else if  ( pair orientation  =  =   pair orientation . fr )   {  innie histogram . increment ( abs insert size )  ;  innies +  +  ;  if  ( sam . get duplicate read flag (  )  )   {  innie dupes +  +  ;   }   }  else  {  throw new  illegal state exception ( "" this should never happen"" )  ;   }   }   }   closer util . close ( reader )  ;   }   metrics file <  jumping library metrics  integer >  metrics file = get metrics file (  )  ;   jumping library metrics metrics = new  jumping library metrics (  )  ;  metrics . jump   pairs = outies ;  metrics . jump   duplicate   pairs = outie dupes ;  metrics . jump   duplicate   pct = outies  !  =  0  ?  outie dupes  /   ( double ) outies : 0 ;  metrics . jump   library   size =  ( outies  >  0 && outie dupes  >  0 )   ?   duplication metrics . estimate library size ( outies outies  -  outie dupes )  : 0 ;  outie histogram . trim by tail limit ( tail   limit )  ;  metrics . jump   mean   insert   size = outie histogram . get mean (  )  ;  metrics . jump   stdev   insert   size = outie histogram . get standard deviation (  )  ;  metrics . nonjump   pairs = innies ;  metrics . nonjump   duplicate   pairs = innie dupes ;  metrics . nonjump   duplicate   pct = innies  !  =  0  ?  innie dupes  /   ( double ) innies : 0 ;  metrics . nonjump   library   size =  ( innies  >  0 && innie dupes  >  0 )   ?   duplication metrics . estimate library size ( innies innies  -  innie dupes )  : 0 ;  innie histogram . trim by tail limit ( tail   limit )  ;  metrics . nonjump   mean   insert   size = innie histogram . get mean (  )  ;  metrics . nonjump   stdev   insert   size = innie histogram . get standard deviation (  )  ;  metrics . chimeric   pairs = cross chrom pairs  +  super sized  +  tandem pairs ;  metrics . fragments = fragments ;  double total pairs = outies  +  innies  +  metrics . chimeric   pairs ;  metrics . pct   jumps = total pairs  !  =  0  ?  outies  /  total pairs : 0 ;  metrics . pct   nonjumps = total pairs  !  =  0  ?  innies  /  total pairs : 0 ;  metrics . pct   chimeras = total pairs  !  =  0  ?  metrics . chimeric   pairs  /  total pairs : 0 ;  metrics file . add metric ( metrics )  ;  metrics file . write ( output )  ;  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectJumpingLibraryMetrics.java,get outie mode,private double   (  )  {  int sample per file = sample   for   mode  /  input . size (  )  ;   histogram <  integer >  histo = new  histogram <  integer >  (  )  ;  for  (   file f : input )   {   sam reader reader =  sam reader factory . make default (  )  . open ( f )  ;  int sampled = 0 ;  for  (  iterator < sam record >  it = reader . iterator (  )  ;  it . has next (  )  && sampled  <  sample per file ;   )   {  sam record sam = it . next (  )  ;  if  (  ! sam . get first of pair flag (  )  )   {  continue ;   }  if  ( sam . get read unmapped flag (  )  && sam . get reference index (  )   =  =  sam record . no   alignment   reference   index )   {  break ;   }  else if  ( sam . get read unmapped flag (  )  || sam . get mate unmapped flag (  )  )   {  continue ;   }  else if  (  ( sam . get attribute ( sam tag . mq . name (  )  )   =  =  null || sam . get integer attribute ( sam tag . mq . name (  )  )   >  =  minimum   mapping   quality )  && sam . get mapping quality (  )   >  =  minimum   mapping   quality && sam . get mate negative strand flag (  )   !  =  sam . get read negative strand flag (  )  && sam . get mate reference index (  )  . equals ( sam . get reference index (  )  )  &&  sam pair util . get pair orientation ( sam )   =  =   pair orientation . rf )   {  histo . increment (  math . abs ( sam . get inferred insert size (  )  )  )  ;  sampled +  +  ;   }   }   closer util . close ( reader )  ;   }  return histo . size (  )   >  0  ?  histo . get mode (  )  : 0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectJumpingLibraryMetrics.java,main,public static void   (  string[] args )  {   system . exit ( new  collect jumping library metrics (  )  . instance main ( args )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectMultipleMetrics.java,custom command line validation,"@ override protected  string[]   (  )  {  if  ( program . is empty (  )  )   {  return new  string[] { "" no programs specified with program"" }  ;   }  programs to run = new  linked hash set <  >  ( program )  ;  return super . custom command line validati"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectMultipleMetrics.java,do work,"@ override public int   (  )  {  if  ( output . ends with ( "" . "" )  )   {  output = output . substring ( 0 output . length (  )   -  1 )  ;   }  final  list <  single pass sam program >  programs = new  array list <  >  (  )  ;  for  (  final  program in"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectMultipleMetrics.java,main,public static void   ( final  string[] args )  {  new  collect multiple metrics (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectMultipleMetrics.java,make instance,@ override public  single pass sam program   ( final  string outbase final  string outext final  file input final  file reference final  set <  metric accumulation level >  metric accumulation level final  file db snp final  file intervals )  {  final  co
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectMultipleMetrics.java,needs reference sequence,@ override public boolean   (  )  {  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectMultipleMetrics.java,set programs to run,public void   ( final  collection <  program interface >  programs to run )  {  this . programs to run . clear (  )  ;  this . programs to run . add all ( programs to run )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectMultipleMetrics.java,supports metric accumulation level,@ override public boolean   (  )  {  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectOxoGMetrics.java, calculator,  ( final  string library final  string context )  {  this . library = library ;  this . context = context ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectOxoGMetrics.java,accept,"void   ( final  sam locus iterator .  locus info info final byte ref base )  {  final  counts counts = compute allele fraction ( info ref base )  ;  if  ( counts . total (  )   >  0 )   {  this . sites +  +  ;  if  ( ref base  =  =  'c' )   {  this . ref ccontrola +  = counts . controla ;  this . ref coxidateda +  = counts . oxidateda ;  this . ref ccontrolc +  = counts . controlc ;  this . ref coxidatedc +  = counts . oxidatedc ;   }  else if  ( ref base  =  =  'g' )   {  this . ref gcontrola +  = counts . controla ;  this . ref goxidateda +  = counts . oxidateda ;  this . ref gcontrolc +  = counts . controlc ;  this . ref goxidatedc +  = counts . oxidatedc ;   }  else  {  throw new  illegal state exception ( "" reference bases other than g and c not supported . "" )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectOxoGMetrics.java,compute allele fraction,private  counts   ( final  sam locus iterator .  locus info info final byte ref base )  {  final  counts counts = new  counts (  )  ;  final byte alt base =  ( ref base  =  =  'c' )   ?   ( byte ) 'a' :  ( byte ) 't' ;  for  (  final  sam locus iterator .  record and offset rec : info . get record and offsets (  )  )   {  final byte qual ;  final sam record samrec = rec . get record (  )  ;  if  ( use   oq )   {  final byte[] oqs = samrec . get original base qualities (  )  ;  if  ( oqs  !  =  null )  qual = oqs[rec . get offset (  ) ] ;  else qual = rec . get base quality (  )  ;   }  else  {  qual = rec . get base quality (  )  ;   }  if  ( qual  <  minimum   quality   score )  continue ;  if  (  ! this . library . equals (  optional . of nullable ( samrec . get read group (  )  . get library (  )  )  . or else ( unknown   library )  )  )  continue ;  final byte base = rec . get read base (  )  ;  final byte base as read = samrec . get read negative strand flag (  )   ?   sequence util . complement ( base )  : base ;  final int read = samrec . get read paired flag (  )  && samrec . get second of pair flag (  )   ?  2 : 1 ;  if  ( base  =  =  ref base )   {  if  ( base as read  =  =  'g' && read  =  =  1 )   +  + counts . oxidatedc ;  else if  ( base as read  =  =  'g' && read  =  =  2 )   +  + counts . controlc ;  else if  ( base as read  =  =  'c' && read  =  =  1 )   +  + counts . controlc ;  else if  ( base as read  =  =  'c' && read  =  =  2 )   +  + counts . oxidatedc ;   }  else if  ( base  =  =  alt base )   {  if  ( base as read  =  =  't' && read  =  =  1 )   +  + counts . oxidateda ;  else if  ( base as read  =  =  't' && read  =  =  2 )   +  + counts . controla ;  else if  ( base as read  =  =  'a' && read  =  =  1 )   +  + counts . controla ;  else if  ( base as read  =  =  'a' && read  =  =  2 )   +  + counts . oxidateda ;   }   }  return counts ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectOxoGMetrics.java,custom command line validation,@ override protected  string[]   (  )  {  final int size = 1  +  2 * context   size ;  final  list <  string >  messages = new  array list <  >  (  )  ;  for  (  final  string ctx : contexts )   {  if  ( ctx . length (  )   !  =  size )   {  messages . ad
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectOxoGMetrics.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  if  ( intervals  !  =  null )  io util . assert file is readable ( intervals )  ;  io util . assert file is readable ( ref
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectOxoGMetrics.java,finish, cpcg metrics   (  )  {  final  cpcg metrics m = new  cpcg metrics (  )  ;  m . library = this . library ;  m . context = this . context ;  m . total   sites = this . sites ;  m . total   bases = this . ref ccontrolc  +  this . ref coxidatedc  +  this . ref ccontrola +  this . ref coxidateda +  this . ref gcontrolc +  this . ref goxidatedc +  this . ref gcontrola +  this . ref goxidateda ;  m . ref   oxo   bases = this . ref coxidatedc  +  ref goxidatedc ;  m . ref   nonoxo   bases = this . ref ccontrolc  +  this . ref gcontrolc ;  m . ref   total   bases = m . ref   oxo   bases  +  m . ref   nonoxo   bases ;  m . alt   nonoxo   bases = this . ref ccontrola  +  this . ref gcontrola ;  m . alt   oxo   bases = this . ref coxidateda  +  this . ref goxidateda ;  m . oxidation   error   rate =  math . max ( m . alt   oxo   bases  -  m . alt   nonoxo   bases 1 )   /   ( double ) m . total   bases ;  m . oxidation   q =  - 10 *  math . log10 ( m . oxidation   error   rate )  ;  m . c   ref   ref   bases = this . ref ccontrolc  +  this . ref coxidatedc ;  m . g   ref   ref   bases = this . ref gcontrolc  +  this . ref goxidatedc ;  m . c   ref   alt   bases = this . ref ccontrola  +  this . ref coxidateda ;  m . g   ref   alt   bases = this . ref gcontrola  +  this . ref goxidateda ;  final double c ref error rate = m . c   ref   alt   bases  /   ( double )  ( m . c   ref   alt   bases  +  m . c   ref   ref   bases )  ;  final double g ref error rate = m . g   ref   alt   bases  /   ( double )  ( m . g   ref   alt   bases  +  m . g   ref   ref   bases )  ;  m . c   ref   oxo   error   rate =  math . max ( c ref error rate  -  g ref error rate 1e - 10 )  ;  m . g   ref   oxo   error   rate =  math . max ( g ref error rate  -  c ref error rate 1e - 10 )  ;  m . c   ref   oxo   q =  - 10 *  math . log10 ( m . c   ref   oxo   error   rate )  ;  m . g   ref   oxo   q =  - 10 *  math . log10 ( m . g   ref   oxo   error   rate )  ;  return m ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectOxoGMetrics.java,make context strings,"private  set <  string >    ( final int context size )  {  final  set <  string >  contexts = new  hash set <  >  (  )  ;  for  (  final byte[] kmer :  sequence util . generate all kmers ( 2 * context size  +  1 )  )   {  if  ( kmer[context size]  =  =  'c' )   {  contexts . add (  string util . bytes to string ( kmer )  )  ;   }   }  log . info ( "" generated ""  +  contexts . size (  )   +  "" context strings . "" )  ;  return contexts ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectOxoGMetrics.java,requires reference,@ override protected boolean   (  )  {  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectOxoGMetrics.java,total,int   (  )  {  return controlc  +  oxidatedc  +  controla +  oxidateda ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectRawWgsMetrics.java, collect raw wgs metrics,public   (  )  {  minimum   mapping   quality = 0 ;  minimum   base   quality = 3 ;  coverage   cap = 100000 ;  locus   accumulation   cap = 200000 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectRawWgsMetrics.java, raw wgs metrics,public   ( final  interval list intervals final  histogram <  integer >  high quality depth histogram final  histogram <  integer >  unfiltered depth histogram final double pct excluded by mapq final double pct excluded by dupes final double pct excluded by pairing final double pct excluded by baseq final double pct excluded by overlap final double pct excluded by capping final double pct total final int coverage cap final  histogram <  integer >  unfiltered baseq histogram final int sample size )  {  super ( intervals high quality depth histogram unfiltered depth histogram pct excluded by mapq pct excluded by dupes pct excluded by pairing pct excluded by baseq pct excluded by overlap pct excluded by capping pct total coverage cap unfiltered baseq histogram sample size )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectRawWgsMetrics.java,generate wgs metrics,@ override protected  wgs metrics   ( final  interval list intervals final  histogram <  integer >  high quality depth histogram final  histogram <  integer >  unfiltered depth histogram final double pct excluded by mapq final double pct excluded by dupes
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectQualityYieldMetrics.java, quality yield metrics collector,public   ( final boolean use original qualities final boolean include secondary alignments final boolean include supplemental alignments )  {  this . use original qualities = use original qualities ;  this . include secondary alignments = include secondary alignments ;  this . include supplemental alignments = include supplemental alignments ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectQualityYieldMetrics.java,accept read,@ override protected void   ( final sam record rec final  reference sequence ref )  {  this . collector . accept record ( rec ref )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectQualityYieldMetrics.java,accept record,public void   ( final sam record rec final  reference sequence ref )  {  if  (  ! this . include secondary alignments && rec . get not primary alignment flag (  )  )  return ;  if  (  ! this . include supplemental alignments && rec . get supplementary alignment flag (  )  )  return ;  final int length = rec . get read length (  )  ;  metrics . total   reads +  +  ;  metrics . total   bases +  = length ;  final boolean is pf read =  ! rec . get read fails vendor quality check flag (  )  ;  if  ( is pf read )   {  metrics . pf   reads +  +  ;  metrics . pf   bases +  = length ;   }  final byte[] quals ;  if  ( this . use original qualities )   {  byte[] tmp = rec . get original base qualities (  )  ;  if  ( tmp  =  =  null )  tmp = rec . get base qualities (  )  ;  quals = tmp ;   }  else  {  quals = rec . get base qualities (  )  ;   }  for  (  final int qual : quals )   {  metrics . q20   equivalent   yield +  = qual ;  if  ( qual  >  =  30 )   {  metrics . q20   bases +  +  ;  metrics . q30   bases +  +  ;   }  else if  ( qual  >  =  20 )   {  metrics . q20   bases +  +  ;   }  if  ( is pf read )   {  metrics . pf   q20   equivalent   yield +  = qual ;  if  ( qual  >  =  30 )   {  metrics . pf   q20   bases +  +  ;  metrics . pf   q30   bases +  +  ;   }  else if  ( qual  >  =  20 )   {  metrics . pf   q20   bases +  +  ;   }   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectQualityYieldMetrics.java,add metrics to file,public void   ( final  metrics file <  quality yield metrics  integer >  metrics file )  {  metrics file . add metric ( metrics )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectQualityYieldMetrics.java,finish,public void   (  )  {  metrics . read   length = metrics . total   reads  =  =  0  ?  0 :  ( int )  ( metrics . total   bases  /  metrics . total   reads )  ;  metrics . q20   equivalent   yield = metrics . q20   equivalent   yield  /  20 ;  metrics . pf   q20   equivalent   yield = metrics . pf   q20   equivalent   yield  /  20 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectQualityYieldMetrics.java,setup,@ override protected void   ( final sam file header header final  file sam file )  {  io util . assert file is writable ( output )  ;  this . collector = new  quality yield metrics collector ( use   original   qualities include   secondary   alignments in
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectQualityYieldMetrics.java,uses no ref reads,@ override protected boolean   (  )  {  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectRnaSeqMetrics.java,accept read,@ override protected void   ( final sam record rec final  reference sequence ref seq )  {  collector . accept record ( rec ref seq )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectRnaSeqMetrics.java,custom command line validation,"@ override protected  string[]   (  )  {  if  ( ribosomal   intervals  =  =  null && rrna   fragment   percentage  =  =  0 )   {  throw new  picard exception ( "" must use a ribosomal   intervals file if rrna   fragment   percentage  =  0 . 0"" )  ;   }  re"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectRnaSeqMetrics.java,finish,@ override protected void   (  )  {  collector . finish (  )  ;  final  metrics file <  rna seq metrics  integer >  file = get metrics file (  )  ;  collector . add all levels to file ( file )  ;  file . write ( output )  ;  boolean at least one histogram
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectRnaSeqMetrics.java,main,public static void   ( final  string[] argv )  {  new  collect rna seq metrics (  )  . instance main with exit ( argv )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectRnaSeqMetrics.java,setup,@ override protected void   ( final sam file header header final  file sam file )  {  if  ( chart   output  !  =  null )  io util . assert file is writable ( chart   output )  ;  final  overlap detector <  gene >  gene overlap detector =  gene annotation 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CompareMetrics.java,do work,@ override protected int   (  )  {  io util . assert files are readable ( metrics files )  ;  final  metrics file <  ?   ?  >  metricsa = new  metrics file (  )  ;  final  metrics file <  ?   ?  >  metricsb = new  metrics file (  )  ;  try  {  metricsa . 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CompareMetrics.java,main,public static void   (  string[] argv )  {  new  compare metrics (  )  . instance main with exit ( argv )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectRrbsMetrics.java,assert io files,private void   ( final  file summary file final  file details file final  file plots file )  {  io util . assert file is readable ( input )  ;  io util . assert file is readable ( reference   sequence )  ;  io util . assert file is writable ( summary file )  ;  io util . assert file is writable ( details file )  ;  io util . assert file is writable ( plots file )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectRrbsMetrics.java,custom command line validation,"@ override protected  string[]   (  )  {  final  list <  string >  error msgs = new  array list <  string >  (  )  ;  if  ( max   mismatch   rate  <  0 || max   mismatch   rate  >  1 )   {  error msgs . add ( ""max   mismatch   rate must be in the range of"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectRrbsMetrics.java,do work,"@ override protected int   (  )  {  if  (  ! metrics   file   prefix . ends with ( "" . "" )  )   {  metrics   file   prefix = metrics   file   prefix  +  "" . "" ;   }  final  file summary   out = new  file ( metrics   file   prefix  +  summary   file   exte"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectRrbsMetrics.java,get reference file,@ override public  file   (  )  {  return reference ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectRrbsMetrics.java,is sequence filtered,private boolean   ( final  string sequence name )  {  return  ( sequence   names  !  =  null )  &&  (  ! sequence   names . is empty (  )  )  &&  (  ! sequence   names . contains ( sequence name )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectRrbsMetrics.java,main,public static void   ( final  string[] args )  {  new  collect rrbs metrics (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectRrbsMetrics.java,make reference argument collection,@ override protected  reference argument collection   (  )  {  return new  collect rrbs metrics reference argument collection (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java, wgs metrics,public   ( final  interval list intervals final  histogram <  integer >  high quality depth histogram final  histogram <  integer >  unfiltered depth histogram final double pct excluded by mapq final double pct excluded by dupes final double pct excluded by pairing final double pct excluded by baseq final double pct excluded by overlap final double pct excluded by capping final double pct exclude total final int coverage cap final  histogram <  integer >  unfiltered baseq histogram final int theoretical het sensitivity sample size )  {  this . intervals = intervals . uniqued (  )  ;  this . high quality depth histogram = high quality depth histogram ;  this . unfiltered depth histogram = unfiltered depth histogram ;  this . unfiltered baseq histogram = unfiltered baseq histogram ;  this . coverage cap = coverage cap ;  this . theoretical het sensitivity sample size = theoretical het sensitivity sample size ;  pct   exc   mapq = pct excluded by mapq ;  pct   exc   dupe = pct excluded by dupes ;  pct   exc   unpaired = pct excluded by pairing ;  pct   exc   baseq = pct excluded by baseq ;  pct   exc   overlap = pct excluded by overlap ;  pct   exc   capped = pct excluded by capping ;  pct   exc   total = pct exclude total ;  calculate derived fields (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java, wgs metrics collector,public   ( final  collect wgs metrics metrics final int coverage cap final  interval list intervals )  {  super ( metrics coverage cap intervals )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java,add info,@ override public void   ( final  abstract locus info <  sam locus iterator .  record and offset >  info final  reference sequence ref boolean reference basen )  {  if  ( reference basen )   {  return ;   }  final  hash set <  string >  read names = new  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java,calculate derived fields,"@ override public void   (  )  {  if  ( high quality depth histogram  =  =  null || unfiltered depth histogram  =  =  null )  throw new  picard exception ( "" depth histogram is required when deriving metrics . "" )  ;  if  ( unfiltered baseq histogram  !  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  io util . assert file is readable ( reference   sequence )  ;  intervals = interval arugment collection . get interval fil
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java,generate wgs metrics, wgs metrics   ( final  interval list intervals final  histogram <  integer >  high quality depth histogram final  histogram <  integer >  unfiltered depth histogram final long bases excluded by mapq final long bases excluded by dupes final long bases excluded by pairing final long bases excluded by baseq final long bases excluded by overlap final long bases excluded by capping final int coverage cap final  histogram <  integer >  unfiltered baseq histogram final int theoretical het sensitivity sample size )  {  final double total = high quality depth histogram . get sum (  )  ;  final double total with excludes = total  +  bases excluded by dupes  +  bases excluded by mapq +  bases excluded by pairing +  bases excluded by baseq +  bases excluded by overlap +  bases excluded by capping ;  final double pct excluded by mapq = total with excludes  =  =  0  ?  0 : bases excluded by mapq  /  total with excludes ;  final double pct excluded by dupes = total with excludes  =  =  0  ?  0 : bases excluded by dupes  /  total with excludes ;  final double pct excluded by pairing = total with excludes  =  =  0  ?  0 : bases excluded by pairing  /  total with excludes ;  final double pct excluded by baseq = total with excludes  =  =  0  ?  0 : bases excluded by baseq  /  total with excludes ;  final double pct excluded by overlap = total with excludes  =  =  0  ?  0 : bases excluded by overlap  /  total with excludes ;  final double pct excluded by capping = total with excludes  =  =  0  ?  0 : bases excluded by capping  /  total with excludes ;  final double pct total = total with excludes  =  =  0  ?  0 :  ( total with excludes  -  total )   /  total with excludes ;  return generate wgs metrics ( intervals high quality depth histogram unfiltered depth histogram pct excluded by mapq pct excluded by dupes pct excluded by pairing pct excluded by baseq pct excluded by overlap pct excluded by capping pct total coverage cap unfiltered baseq histogram theoretical het sensitivity sample size )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java,get bases excluded by,protected long   ( final  counting filter filter )  {  return filter . get filtered bases (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java,get collector,protected  abstract wgs metrics collector   ( final int coverage cap final  interval list intervals )  {  return use   fast   algorithm  ?  new  fast wgs metrics collector ( this coverage cap intervals )  : new  wgs metrics collector ( this coverage cap intervals )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java,get interval file,public  file   (  )  {  return intervals ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java,get intervals to examine,protected  interval list   (  )  {  final  interval list intervals ;  if  ( intervals  !  =  null )   {  io util . assert file is readable ( intervals )  ;  intervals =  interval list . from file ( intervals )  ;   }  else  {  intervals = new  interval list ( this . header )  ;  for  (  final sam sequence record rec : this . header . get sequence dictionary (  )  . get sequences (  )  )   {  final  interval interval = new  interval ( rec . get sequence name (  )  1 rec . get sequence length (  )  )  ;  intervals . add ( interval )  ;   }   }  return intervals ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java,get locus iterator,protected  abstract locus iterator   ( final  sam reader in )  {  if  ( use   fast   algorithm )   {  return  ( intervals  !  =  null )   ?  new  edge read iterator ( in  interval list . from file ( intervals )  )  : new  edge read iterator ( in )  ;   }   sam locus iterator iterator =  ( intervals  !  =  null )   ?  new  sam locus iterator ( in  interval list . from file ( intervals )  )  : new  sam locus iterator ( in )  ;  iterator . set max reads to accumulate per locus ( locus   accumulation   cap )  ;  iterator . set emit uncovered loci ( true )  ;  iterator . set quality score cutoff ( 0 )  ;  return iterator ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java,get sam file header,"protected sam file header   (  )  {  if  ( this . header  =  =  null )  throw new  illegal state exception ( ""get sam file header (  )  was called but this . header is null"" )  ;  return this . header ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java,get sam reader,protected  sam reader   (  )  {  final  sam reader in =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . open ( input )  ;  this . header = in . get file header (  )  ;  return in ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java,get wgs metrics processor,private  < t extends  abstract record and offset >  wgs metrics processor impl < t >    (  progress logger progress  reference sequence file walker ref walker  abstract locus iterator < t  abstract locus info < t >  >  iterator  abstract wgs metrics collector < t >  collector )  {  return new  wgs metrics processor impl <  >  ( iterator ref walker collector progress )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java,main,public static void   ( final  string[] args )  {  new  collect wgs metrics (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java,make interval argument collection,protected  interval argument collection   (  )  {  return new  collect wgs metrics interval argument collection (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java,merge,@ override public  mergeable metric base   ( final  mergeable metric base other )  {  final  wgs metrics other metric =  (  wgs metrics ) other ;  if  ( high quality depth histogram  =  =  null || other metric . high quality depth histogram  =  =  null ||
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetrics.java,requires reference,@ override protected boolean   (  )  {  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetricsWithNonZeroCoverage.java, wgs metrics with non zero coverage,public   ( final  interval list intervals final  histogram <  integer >  high quality depth histogram final  histogram <  integer >  unfiltered depth histogram final double pct excluded by mapq final double pct excluded by dupes final double pct excluded by pairing final double pct excluded by baseq final double pct excluded by overlap final double pct excluded by capping final double pct total final int coverage cap final  histogram <  integer >  unfiltered baseq histogram final int sample size )  {  super ( intervals high quality depth histogram unfiltered depth histogram pct excluded by mapq pct excluded by dupes pct excluded by pairing pct excluded by baseq pct excluded by overlap pct excluded by capping pct total coverage cap unfiltered baseq histogram sample size )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetricsWithNonZeroCoverage.java, wgs metrics with non zero coverage collector,public   ( final  collect wgs metrics with non zero coverage metrics final int coverage cap final  interval list intervals )  {  super ( metrics coverage cap intervals )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetricsWithNonZeroCoverage.java,add to metrics file,@ override public void   ( final  metrics file <  wgs metrics  integer >  file final boolean includebq histogram final  counting filter dupe filter final  counting filter mapq filter final  counting paired filter pair filter )  {  high quality depth histo
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetricsWithNonZeroCoverage.java,are histograms empty,public boolean   (  )  {  return  ( high quality depth histogram . is empty (  )  || high quality depth histogram non zero . is empty (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetricsWithNonZeroCoverage.java,do work,@ override protected int   (  )  {  io util . assert file is writable ( chart   output )  ;  io util . assert file is readable ( input )  ;  get sam reader (  )  ;  this . collector = new  wgs metrics with non zero coverage collector ( this coverage   cap
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetricsWithNonZeroCoverage.java,generate wgs metrics,@ override protected  wgs metrics   ( final  interval list intervals final  histogram <  integer >  high quality depth histogram final  histogram <  integer >  unfiltered depth histogram final double pct excluded by mapq final double pct excluded by dupes
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetricsWithNonZeroCoverage.java,get collector,@ override protected  wgs metrics collector   ( final int coverage cap final  interval list intervals )  {  assert  ( coverage cap  =  =  this . collector . coverage cap )  ;  return this . collector ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetricsWithNonZeroCoverage.java,get depth histogram,"protected  histogram <  integer >    (  )  {  return get histogram ( high quality depth histogram array ""coverage"" ""count   whole   genome"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetricsWithNonZeroCoverage.java,get depth histogram non zero,"private  histogram <  integer >    (  )  {  final  histogram <  integer >  depth histogram = new  histogram <  >  ( ""coverage"" ""count   non   zero   regions"" )  ;  for  ( int i = 1 ;  i  <  high quality depth histogram array . length ;   +  + i )   {  depth histogram . increment ( i high quality depth histogram array[i] )  ;   }  return depth histogram ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetricsWithNonZeroCoverage.java,get sam reader,@ override protected  sam reader   (  )  {  if  ( this . sam reader  =  =  null )   {  this . sam reader = super . get sam reader (  )  ;   }  return this . sam reader ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CollectWgsMetricsWithNonZeroCoverage.java,main,public static void   ( final  string[] args )  {  new  collect wgs metrics (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CounterManager.java, counter,private   ( int array length )  {  array = new int[array length] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CounterManager.java, counter manager,public   ( final int array length int read length )  {  this . array length = array length ;  this . read length = read length ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CounterManager.java,check index,"private void   ( int index )  {  if  (  ( index  -  offset )   <  0 ||  ( index  -  offset )   >  =  array . length )   {  throw new  array index out of bounds exception ( "" the requested index ""  +  index  +  "" is out of counter bounds .  "" +  "" possible cause of exception can be wrong read   length parameter  ( much smaller than actual read length ) "" )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CounterManager.java,check out of bounds,public void   ( int locus position )  {  if  ( locus position  -  offset  +  read length  >  =  array length )   {  if  ( locus position  -  offset  <  array length )   {  rebase ( locus position )  ;   }  else  {  clear (  )  ;  offset = locus position ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CounterManager.java,clear,public void   (  )  {  for  (   counter counter : arrays )   {  final int[] array = counter . array ;   arrays . fill ( array 0 )  ;   }  offset = 0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CounterManager.java,get,public int   ( int index )  {  check index ( index )  ;  return array[index  -  offset] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CounterManager.java,get offset,int   (  )  {  return offset ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CounterManager.java,increment,public void   ( int index )  {  check index ( index )  ;  array[index  -  offset] +  +  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CounterManager.java,new counter,public  counter   (  )  {  final  counter counter = new  counter ( array length )  ;  arrays . add ( counter )  ;  return counter ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CounterManager.java,rebase,"private void   ( int locus position )  {  if  ( locus position  <  offset )   {  throw new  illegal argument exception ( "" position in the reference sequence is lesser than offset . "" )  ;   }  for  (   counter counter : arrays )   {  final int[] array = counter . array ;  final int skip length = locus position  -  offset ;   system . arraycopy ( array skip length array 0 array length  -  skip length )  ;   arrays . fill ( array array length  -  skip length array length 0 )  ;   }  offset = locus position ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\CounterManager.java,set offset,void   ( int offset )  {  this . offset = offset ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\CollectTargetedPcrMetrics.java,get probe intervals,@ override protected  interval list   (  )  {  return  interval list . from file ( amplicon   intervals )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\CollectTargetedPcrMetrics.java,get probe set name,@ override protected  string   (  )  {  return custom   amplicon   set   name  !  =  null  ?  custom   amplicon   set   name :  collect targeted metrics . render probe name from file ( amplicon   intervals )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\CollectTargetedPcrMetrics.java,main,public static void   ( final  string[] argv )  {   system . exit ( new  collect targeted pcr metrics (  )  . instance main ( argv )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\CollectTargetedPcrMetrics.java,make collector,@ override protected  targeted pcr metrics collector   ( final  set <  metric accumulation level >  accumulation levels final  list < sam read group record >  sam rg records final  reference sequence file ref file final  file per target coverage final  fi
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\CollectTargetedMetrics.java,custom command line validation,"protected  string[]   (  )  {  if  ( per   target   coverage  !  =  null &&  ( metric   accumulation   level . size (  )   !  =  1 || metric   accumulation   level . iterator (  )  . next (  )   !  =   metric accumulation level . all   reads )  )   {  return new  string[] { ""per   target   coverage can be specified only when metric   accumulation   level is set ""  +  ""to all   reads . "" }  ;   }  if  ( per   target   coverage  !  =  null && reference   sequence  =  =  null )   {  return new  string[] { "" must supply reference   sequence when supplying per   target   coverage"" }  ;   }  return super . custom command line validation (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\CollectTargetedMetrics.java,do work,protected int   (  )  {  for  (  final  file target interval : target   intervals )  io util . assert file is readable ( target interval )  ;  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  if  ( per   target   coverage  !  =  null )  io util . assert file is writable ( per   target   coverage )  ;  final  sam reader reader =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . open ( input )  ;  final  interval list target intervals =  interval list . from files ( target   intervals )  ;   sequence util . assert sequence dictionaries equal ( reader . get file header (  )  . get sequence dictionary (  )  target intervals . get header (  )  . get sequence dictionary (  )  )  ;   sequence util . assert sequence dictionaries equal ( reader . get file header (  )  . get sequence dictionary (  )  get probe intervals (  )  . get header (  )  . get sequence dictionary (  )  )  ;   reference sequence file ref = null ;  if  ( reference   sequence  !  =  null )   {  io util . assert file is readable ( reference   sequence )  ;  ref =  reference sequence file factory . get reference sequence file ( reference   sequence )  ;   sequence util . assert sequence dictionaries equal ( reader . get file header (  )  . get sequence dictionary (  )  ref . get sequence dictionary (  )  input reference   sequence )  ;   }  final collector collector = make collector ( metric   accumulation   level reader . get file header (  )  . get read groups (  )  ref per   target   coverage per   base   coverage target intervals get probe intervals (  )  get probe set name (  )  near   distance )  ;  final  progress logger progress = new  progress logger ( log )  ;  for  (  final sam record record : reader )   {  collector . accept record ( record null )  ;  progress . record ( record )  ;   }  final  metrics file < metric  integer >  metrics = get metrics file (  )  ;  collector . finish (  )  ;  collector . add all levels to file ( metrics )  ;  metrics . write ( output )  ;   closer util . close ( reader )  ;  return 0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\CollectHsMetrics.java, collect hs metrics,public   (  )  {  minimum   mapping   quality = 20 ;  minimum   base   quality = 20 ;  clip   overlapping   reads = true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\CollectHsMetrics.java,get probe intervals,@ override protected  interval list   (  )  {  for  (  final  file file : bait   intervals )  io util . assert file is readable ( file )  ;  return  interval list . from files ( bait   intervals )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\CollectHsMetrics.java,get probe set name,@ override protected  string   (  )  {  if  ( bait   set   name  !  =  null )   {  return bait   set   name ;   }  else  {  final  sorted set <  string >  bait set names = new  tree set <  string >  (  )  ;  for  (  final  file file : bait   intervals )  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\CollectHsMetrics.java,main,public static void   ( final  string[] argv )  {   system . exit ( new  collect hs metrics (  )  . instance main ( argv )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\CollectHsMetrics.java,make collector,@ override protected  hs metric collector   ( final  set <  metric accumulation level >  accumulation levels final  list < sam read group record >  sam rg records final  reference sequence file ref file final  file per target coverage final  file per base
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\HsMetricCollector.java, hs metric collector,public   ( final  set <  metric accumulation level >  accumulation levels final  list < sam read group record >  sam rg records final  reference sequence file ref file final  file per target coverage final  file per base coverage final  interval list target intervals final  interval list probe intervals final  string probe set name final int near probe distance final int minimum mapping quality final int minimum base quality final boolean clip overlapping reads final boolean no side effects final int coverage cap final int sample size )  {  super ( accumulation levels sam rg records ref file per target coverage per base coverage target intervals probe intervals probe set name near probe distance minimum mapping quality minimum base quality clip overlapping reads no side effects coverage cap sample size )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\HsMetricCollector.java,calculate hs penalty,private double   ( final  long library size final  target metrics target metrics final int coverage goal )  {  if  ( library size  =  =  null )  return 0 ;  final double mean coverage = target metrics . on   target   from   pair   bases  /   ( double ) target metrics . target   territory ;  final double fold80 = target metrics . fold   80   base   penalty ;  final long pairs = target metrics . pf   selected   pairs ;  final long unique pairs = target metrics . pf   selected   unique   pairs ;  final double on target pct =  ( double ) target metrics . on   target   bases  /   ( double ) target metrics . pf   uq   bases   aligned ;  final double unique pair goal multiplier =  ( coverage goal  /  mean coverage )  * fold80 ;  double pair multiplier = unique pair goal multiplier ;  double increment = 1 ;  boolean going up = unique pair goal multiplier  >  =  1 ;  double final pair multiplier =  - 1 ;  for  ( int i = 0 ;  i  <  10000 ;   +  + i )   {  final double unique pair multiplier =  duplication metrics . estimate roi ( library size pair multiplier pairs unique pairs )  ;  if  (  math . abs ( unique pair multiplier  -  unique pair goal multiplier )   /  unique pair goal multiplier  <  =  0 . 001 )   {  final pair multiplier = pair multiplier ;  break ;   }  else if  (  ( unique pair multiplier  >  unique pair goal multiplier && going up )  ||  ( unique pair multiplier  <  unique pair goal multiplier &&  ! going up )  )   {  increment /  = 2 ;  going up =  ! going up ;   }  pair multiplier +  =  ( going up  ?  increment :  - increment )  ;   }  if  ( final pair multiplier  =  =   - 1 )   {  return  - 1 ;   }  else  {  final double unique fraction =  ( unique pairs * unique pair goal multiplier )   /   ( pairs * final pair multiplier )  ;  return  ( 1  /  unique fraction )  * fold80 *  ( 1  /  on target pct )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\HsMetricCollector.java,convert metric,"@ override public  hs metrics   ( final  target metrics target metrics )  {  final  hs metrics hs metrics = new  hs metrics (  )  ;   target metrics collector . reflective copy ( target metrics hs metrics new  string[] { ""probe   set"" ""probe   territory"" "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\InsertSizeMetricsCollector.java, insert size collector args,public   ( final int insert size final  sam pair util .  pair orientation po )  {  this . insert size = insert size ;  this . po = po ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\InsertSizeMetricsCollector.java, insert size metrics collector,public   ( final  set <  metric accumulation level >  accumulation levels final  list < sam read group record >  sam rg records final double minimum pct final  integer histogram width final double deviations final boolean include duplicates )  {  this . minimum pct = minimum pct ;  this . histogram width = histogram width ;  this . deviations = deviations ;  this . include duplicates = include duplicates ;  setup ( accumulation levels sam rg records )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\InsertSizeMetricsCollector.java, per unit insert size metrics collector,"public   ( final  string sample final  string library final  string read group )  {  this . sample = sample ;  this . library = library ;  this . read group = read group ;   string prefix = null ;  if  ( this . read group  !  =  null )   {  prefix = this . read group  +  "" . "" ;   }  else if  ( this . library  !  =  null )   {  prefix = this . library  +  "" . "" ;   }  else if  ( this . sample  !  =  null )   {  prefix = this . sample  +  "" . "" ;   }  else  {  prefix = "" all    reads . "" ;   }  histograms . put (  sam pair util .  pair orientation . fr new  histogram <  integer >  ( ""insert   size"" prefix  +  ""fr   count"" )  )  ;  histograms . put (  sam pair util .  pair orientation . tandem new  histogram <  integer >  ( ""insert   size"" prefix  +  ""tandem   count"" )  )  ;  histograms . put (  sam pair util .  pair orientation . rf new  histogram <  integer >  ( ""insert   size"" prefix  +  ""rf   count"" )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\InsertSizeMetricsCollector.java,accept record,public void   ( final  insert size collector args args )  {  histograms . get ( args . get pair orientation (  )  )  . increment ( args . get insert size (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\InsertSizeMetricsCollector.java,add metrics to file,public void   ( final  metrics file <  insert size metrics  integer >  file )  {  for  (  final  histogram <  integer >  h : this . histograms . values (  )  )   {  total inserts +  = h . get count (  )  ;   }  if  ( 0  =  =  total inserts )  return ;  for  (  final  map .  entry <  sam pair util .  pair orientation  histogram <  integer >  >  entry : histograms . entry set (  )  )   {  final  sam pair util .  pair orientation pair orientation = entry . get key (  )  ;  final  histogram <  integer >  histogram = entry . get value (  )  ;  final double total = histogram . get count (  )  ;  if  ( total  >  =  total inserts * minimum pct )   {  final  insert size metrics metrics = new  insert size metrics (  )  ;  metrics . sample = this . sample ;  metrics . library = this . library ;  metrics . read   group = this . read group ;  metrics . pair   orientation = pair orientation ;  if  (  ! histogram . is empty (  )  )   {  metrics . read   pairs =  ( long ) total ;  metrics . max   insert   size =  ( int ) histogram . get max (  )  ;  metrics . min   insert   size =  ( int ) histogram . get min (  )  ;  metrics . median   insert   size = histogram . get median (  )  ;  metrics . mode   insert   size = histogram . get mode (  )  ;  metrics . median   absolute   deviation = histogram . get median absolute deviation (  )  ;  final double median = histogram . get median (  )  ;  double covered = 0 ;  double low = median ;  double high = median ;  while  ( low  >  =  histogram . get min (  )   -  1 || high  <  =  histogram . get max (  )   +  1 )   {  final  histogram .  bin <  integer >  low bin = histogram . get (  ( int ) low )  ;  if  ( low bin  !  =  null )  covered +  = low bin . get value (  )  ;  if  ( low  !  =  high )   {  final  histogram .  bin <  integer >  high bin = histogram . get (  ( int ) high )  ;  if  ( high bin  !  =  null )  covered +  = high bin . get value (  )  ;   }  final double percent covered = covered  /  total ;  final int distance =  ( int )  ( high  -  low )   +  1 ;  if  ( percent covered  >  =  0 . 1 && metrics . width   of   10   percent  =  =  0 )  metrics . width   of   10   percent = distance ;  if  ( percent covered  >  =  0 . 2 && metrics . width   of   20   percent  =  =  0 )  metrics . width   of   20   percent = distance ;  if  ( percent covered  >  =  0 . 3 && metrics . width   of   30   percent  =  =  0 )  metrics . width   of   30   percent = distance ;  if  ( percent covered  >  =  0 . 4 && metrics . width   of   40   percent  =  =  0 )  metrics . width   of   40   percent = distance ;  if  ( percent covered  >  =  0 . 5 && metrics . width   of   50   percent  =  =  0 )  metrics . width   of   50   percent = distance ;  if  ( percent covered  >  =  0 . 6 && metrics . width   of   60   percent  =  =  0 )  metrics . width   of   60   percent = distance ;  if  ( percent covered  >  =  0 . 7 && metrics . width   of   70   percent  =  =  0 )  metrics . width   of   70   percent = distance ;  if  ( percent covered  >  =  0 . 8 && metrics . width   of   80   percent  =  =  0 )  metrics . width   of   80   percent = distance ;  if  ( percent covered  >  =  0 . 9 && metrics . width   of   90   percent  =  =  0 )  metrics . width   of   90   percent = distance ;  if  ( percent covered  >  =  0 . 95 && metrics . width   of   95   percent  =  =  0 )  metrics . width   of   95   percent = distance ;  if  ( percent covered  >  =  0 . 99 && metrics . width   of   99   percent  =  =  0 )  metrics . width   of   99   percent = distance ;   -  - low ;   +  + high ;   }   }  final  histogram <  integer >  trimmed histogram = histogram ;  trimmed histogram . trim by width ( get width to trim to ( metrics )  )  ;  if  (  ! trimmed histogram . is empty (  )  )   {  metrics . mean   insert   size = trimmed histogram . get mean (  )  ;  metrics . standard   deviation = trimmed histogram . get standard deviation (  )  ;   }  file . add histogram ( trimmed histogram )  ;  file . add metric ( metrics )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\InsertSizeMetricsCollector.java,get insert size,public int   (  )  {  return insert size ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\InsertSizeMetricsCollector.java,get pair orientation,public  sam pair util .  pair orientation   (  )  {  return po ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\InsertSizeMetricsCollector.java,get total inserts,public double   (  )  {  return total inserts ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\InsertSizeMetricsCollector.java,get width to trim to,private int   (  insert size metrics metrics )  {  if  ( histogram width  =  =  null )   {  return  ( int )  ( metrics . median   insert   size  +   ( deviations * metrics . median   absolute   deviation )  )  ;   }  else  {  return histogram width ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\InsertSizeMetricsCollector.java,make arg,@ override protected  insert size collector args   ( sam record sam record  reference sequence ref seq )  {  final int insert size =  math . abs ( sam record . get inferred insert size (  )  )  ;  final  sam pair util .  pair orientation orientation =  sa
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\InsertSizeMetricsCollector.java,make child collector,@ override protected  per unit metric collector <  insert size metrics  integer  insert size collector args >    ( final  string sample final  string library final  string read group )  {  return new  per unit insert size metrics collector ( sample librar
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\FastWgsMetricsCollector.java, fast wgs metrics collector,public   (  collect wgs metrics collect wgs metrics int coverage cap final  interval list intervals )  {  super ( collect wgs metrics coverage cap intervals )  ;  this . previous sequence index =  - 1 ;  this . counter manager = new  counter manager ( collect wgs metrics . read   length * array   size   per   read   length collect wgs metrics . read   length )  ;  this . pileup size = counter manager . new counter (  )  ;  this . unfiltered depth size = counter manager . new counter (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\FastWgsMetricsCollector.java,add info,@ override public void   ( final  abstract locus info <  edging record and offset >  info final  reference sequence ref boolean reference basen )  {  prepare collector ( info )  ;  for  (  final  edging record and offset record : info . get record and off
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\FastWgsMetricsCollector.java,exclude by quality,private int   ( final  set <  edging record and offset >  set for name int position )  {  int bsq = 0 ;  for  (   edging record and offset record and offset : set for name )   {  if  ( position  -  record and offset . get ref pos (  )   >  =  record and offset . get length (  )  || record and offset . get base quality ( position )   <  collect wgs metrics . minimum   base   quality )   {  bsq +  +  ;   }   }  return bsq ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\FastWgsMetricsCollector.java,prepare collector,private void   (  abstract locus info <  edging record and offset >  info )  {  if  ( reads names  =  =  null )   {  reads names = new  hash map <  >  (  )  ;   }  if  ( previous sequence index  !  =  info . get sequence index (  )  )   {  reads names . clear (  )  ;  counter manager . clear (  )  ;  previous sequence index = info . get sequence index (  )  ;   }  counter manager . check out of bounds ( info . get position (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\FastWgsMetricsCollector.java,process record,private void   ( int position  reference sequence ref  edging record and offset record  set <  edging record and offset >  records and offsets for name )  {  long processed loci = counter ;  reads names . put ( record . get read name (  )  records and offsets for name )  ;  final byte[] qualities = record . get base qualities (  )  ;  final byte[] bases = record . get record (  )  . get read bases (  )  ;  for  ( int i = 0 ;  i  <  record . get length (  )  ;  i +  +  )   {  final int index = i  +  position ;  if  ( is reference basen ( index ref )  )   {  continue ;   }  final byte quality = qualities[i  +  record . get offset (  ) ] ;  if  ( quality  <  =  2 )   {  bases excluded by baseq +  +  ;   }  else  {  if  ( unfiltered depth size . get ( index )   <  coverage cap )   {  unfiltered baseq histogram array[quality] +  +  ;  unfiltered depth size . increment ( index )  ;   }  if  ( quality  <  collect wgs metrics . minimum   base   quality ||  sequence util . is no call ( bases[i  +  record . get offset (  ) ] )  )   {  bases excluded by baseq +  +  ;   }  else  {  final int bsq = exclude by quality ( records and offsets for name index )  ;  if  ( records and offsets for name . size (  )   -  bsq  >  0 )   {  bases excluded by overlap +  +  ;   }  else  {  pileup size . increment ( index )  ;   }   }   }  if  ( is time to stop (  +  + processed loci )  )   {  break ;   }   }  records and offsets for name . add ( record )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\FastWgsMetricsCollector.java,remove record from map,private void   (  edging record and offset record  set <  edging record and offset >  records and offsets for name )  {  if  ( records and offsets for name . size (  )   =  =  1 )   {  reads names . remove ( record . get read name (  )  )  ;   }  else  {  records and offsets for name . remove ( record . get start (  )  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\TargetedPcrMetricsCollector.java, targeted pcr metrics collector,public   ( final  set <  metric accumulation level >  accumulation levels final  list < sam read group record >  sam rg records final  reference sequence file ref file final  file per target coverage final  file per base coverage final  interval list target intervals final  interval list probe intervals final  string probe set name final int near probe distance final int minimum mapping quality final int minimum base quality final boolean clip overlapping reads final boolean no side effects final int coverage cap final int sample size )  {  super ( accumulation levels sam rg records ref file per target coverage per base coverage target intervals probe intervals probe set name near probe distance minimum mapping quality minimum base quality clip overlapping reads no side effects coverage cap sample size )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\TargetedPcrMetricsCollector.java,convert metric,"@ override public  targeted pcr metrics   ( final  target metrics target metrics )  {  final  targeted pcr metrics pcr metrics = new  targeted pcr metrics (  )  ;   target metrics collector . reflective copy ( target metrics pcr metrics new  string[] { ""p"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\TargetMetricsCollector.java, coverage,public   ( final  interval i final int padding )  {  this . interval = i ;  this . depths = new int[interval . length (  )   +  2 * padding] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\TargetMetricsCollector.java, per unit target metric collector,public   ( final  string probe set name final  set <  interval >  coverage targets final  string sample final  string library final  string read group final long probe territory final long target territory final long genome size final  map <  interval  double >  interval to gc final int minimum mapping quality final int minimum base quality final boolean clip overlapping reads )  {  this . metrics . sample = sample ;  this . metrics . library = library ;  this . metrics . read   group = read group ;  this . metrics . probe   set = probe set name ;  metrics . probe   territory = probe territory ;  metrics . target   territory = target territory ;  metrics . genome   size = genome size ;  high quality coverage by target = new  linked hash map <  >  ( coverage targets . size (  )  * 2 0 . 5f )  ;  unfiltered coverage by target = new  linked hash map <  >  ( coverage targets . size (  )  * 2 0 . 5f )  ;  for  (  final  interval target : coverage targets )   {  high quality coverage by target . put ( target new  coverage ( target 0 )  )  ;  unfiltered coverage by target . put ( target new  coverage ( target 0 )  )  ;   }  this . mapq filter = new  counting mapq filter ( minimum mapping quality )  ;  this . minimum base quality = minimum base quality ;  this . interval to gc = interval to gc ;  this . clip overlapping reads = clip overlapping reads ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\TargetMetricsCollector.java, target metrics collector,public   ( final  set <  metric accumulation level >  accumulation levels final  list < sam read group record >  sam rg records final  reference sequence file ref file final  file per target coverage final  file per base coverage final  interval list target intervals final  interval list probe intervals final  string probe set name final int near probe distance final int minimum mapping quality final int minimum base quality final boolean clip overlapping reads final boolean no side effects final int coverage cap final int sample size )  {  this . per target coverage = per target coverage ;  this . per base coverage = per base coverage ;  this . probe set name = probe set name ;  this . near probe distance = near probe distance ;  this . all probes = probe intervals ;  this . all targets = target intervals ;  this . coverage cap = coverage cap ;  this . sample size = sample size ;  final  list <  interval >  unique baits = this . all probes . uniqued (  )  . get intervals (  )  ;  this . probe detector = new  overlap detector <  interval >  (  - this . near probe distance 0 )  ;  this . probe detector . add all ( unique baits unique baits )  ;  this . probe territory =  interval . count bases ( unique baits )  ;  final  list <  interval >  unique targets = this . all targets . uniqued (  )  . get intervals (  )  ;  target detector = new  overlap detector <  interval >  ( 0 0 )  ;  this . target detector . add all ( unique targets unique targets )  ;  this . target territory =  interval . count bases ( unique targets )  ;  int i = 0 ;  cov = new  coverage[unique targets . size (  ) ] ;  this . coverage by target for read = new  linked hash map <  interval  coverage >  ( unique targets . size (  )  * 2 0 . 5f )  ;  for  (  final  interval target : unique targets )   {  final  coverage coverage = new  coverage ( target 0 )  ;  this . coverage by target for read . put ( target coverage )  ;  cov[i +  + ] = coverage ;   }  long genome size accumulator = 0 ;  for  (  final sam sequence record seq : this . all probes . get header (  )  . get sequence dictionary (  )  . get sequences (  )  )   {  genome size accumulator +  = seq . get sequence length (  )  ;   }  this . genome size = genome size accumulator ;  if  ( ref file  !  =  null )   {  interval to gc = new  hash map <  interval  double >  (  )  ;  for  (  final  interval target : unique targets )   {  final  reference sequence rs = ref file . get subsequence at ( target . get contig (  )  target . get start (  )  target . get end (  )  )  ;  interval to gc . put ( target  sequence util . calculate gc ( rs . get bases (  )  )  )  ;   }   }  this . minimum mapping quality = minimum mapping quality ;  this . minimum base quality = minimum base quality ;  this . clip overlapping reads = clip overlapping reads ;  this . no side effects = no side effects ;  setup ( accumulation levels sam rg records )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\TargetMetricsCollector.java,accept record,public void   ( final sam record record )  {  if  ( record . get not primary alignment flag (  )  )  return ;  final boolean mapped in pair = record . get read paired flag (  )  &&  ! record . get read unmapped flag (  )  &&  ! record . get mate unmapped flag (  ) &&  ! record . get supplementary alignment flag (  )  ;  final byte[] base qualities = record . get base qualities (  )  ;  int bases aligned in record = 0 ;  if  (  ! record . get read unmapped flag (  )  )   {  for  (  final  alignment block block : record . get alignment blocks (  )  )   {  bases aligned in record +  = block . get length (  )  ;   }   }  if  (  ! record . get supplementary alignment flag (  )  )   {  this . metrics . total   reads +  +  ;  if  (  ! record . get read fails vendor quality check flag (  )  )   {  this . metrics . pf   reads +  +  ;  if  (  ! record . get duplicate read flag (  )  )   {  this . metrics . pf   unique   reads +  +  ;  if  (  ! record . get read unmapped flag (  )  )   {  this . metrics . pf   uq   reads   aligned +  +  ;   }   }   }   }  if  ( record . get read fails vendor quality check flag (  )  )  return ;  if  (  ! record . get supplementary alignment flag (  )  )  this . metrics . pf   bases +  = record . get read length (  )  ;  if  (  ! record . get read unmapped flag (  )  )   {  this . metrics . pf   bases   aligned +  = bases aligned in record ;  if  (  ! record . get duplicate read flag (  )  )   {  this . metrics . pf   uq   bases   aligned +  = bases aligned in record ;   }   }  if  ( record . get read unmapped flag (  )  )  return ;  final  interval read = new  interval ( record . get reference name (  )  record . get alignment start (  )  record . get alignment end (  )  )  ;  final  collection <  interval >  targets = target detector . get overlaps ( read )  ;  final  collection <  interval >  probes = probe detector . get overlaps ( read )  ;  if  (  ! record . get supplementary alignment flag (  )  && record . get read paired flag (  )  && record . get first of pair flag (  ) &&  ! record . get read unmapped flag (  ) &&  ! record . get mate unmapped flag (  ) &&  ! probes . is empty (  )  )   {   +  + this . metrics . pf   selected   pairs ;  if  (  ! record . get duplicate read flag (  )  )   +  + this . metrics . pf   selected   unique   pairs ;   }   {  final int mapped bases = bases aligned in record ;  int on bait bases = 0 ;  if  (  ! probes . is empty (  )  )   {  for  (  final  interval bait : probes )   {  for  (  final  alignment block block : record . get alignment blocks (  )  )   {  final int end =  coord math . get end ( block . get reference start (  )  block . get length (  )  )  ;  for  ( int pos = block . get reference start (  )  ;  pos  <  =  end ;   +  + pos )   {  if  ( pos  >  =  bait . get start (  )  && pos  <  =  bait . get end (  )  )   +  + on bait bases ;   }   }   }  this . metrics . on   probe   bases +  = on bait bases ;  this . metrics . near   probe   bases +  =  ( mapped bases  -  on bait bases )  ;   }  else  {  this . metrics . off   probe   bases +  = mapped bases ;   }   }  if  ( record . get duplicate read flag (  )  )   {  this . metrics . pct   exc   dupe +  = bases aligned in record ;  return ;   }  if  ( this . mapq filter . filter out ( record )  )  return ;  final sam record rec ;  if  ( clip overlapping reads )   {  final int num overlapping bases to clip = sam utils . get num overlapping aligned bases to clip ( record )  ;  rec = sam utils . clip overlapping aligned bases ( record num overlapping bases to clip no side effects )  ;  metrics . pct   exc   overlap +  = num overlapping bases to clip ;  if  ( rec . get read unmapped flag (  )  )  return ;   }  else  {  rec = record ;   }  final  set <  interval >  covered targets = new  hash set <  >  (  )  ;  for  (  final  alignment block block : rec . get alignment blocks (  )  )   {  final int length = block . get length (  )  ;  final int ref start = block . get reference start (  )  ;  final int read start = block . get read start (  )  ;  for  ( int offset = 0 ;  offset  <  length ;   +  + offset )   {  final int ref pos = ref start  +  offset ;  final int read pos = read start  +  offset ;  final int qual = base qualities[read pos  -  1] ;  if  ( qual  <  =  2 )   {  metrics . pct   exc   baseq +  +  ;  continue ;   }  boolean is on target = false ;  for  (  final  interval target : targets )   {  if  ( ref pos  >  =  target . get start (  )  && ref pos  <  =  target . get end (  )  )   {  final int target offset = ref pos  -  target . get start (  )  ;  if  ( qual  >  =  minimum base quality )   {   +  + metrics . on   target   bases ;  if  ( mapped in pair )   +  + metrics . on   target   from   pair   bases ;  final  coverage high quality coverage = high quality coverage by target . get ( target )  ;  high quality coverage . add base ( target offset )  ;  if  (  ! covered targets . contains ( target )  )   {  high quality coverage . increment read count (  )  ;  covered targets . add ( target )  ;  is on target = true ;   }   }  else  {  this . metrics . pct   exc   baseq +  +  ;   }  unfiltered coverage by target . get ( target )  . add base ( target offset )  ;  if  ( unfiltered coverage by target . get ( target )  . get depths (  ) [target offset]  <  =  coverage cap )   {  baseq histogram array[qual] +  +  ;   }   }   }  if  (  ! is on target )  this . metrics . pct   exc   off   target +  +  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\TargetMetricsCollector.java,add base,public void   ( final int offset final int depth )  {  if  ( offset  >  =  0 && offset  <  this . depths . length && this . depths[offset]  <   integer . max   value  -  depth )   {  this . depths[offset] +  = depth ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\TargetMetricsCollector.java,add metrics to file,@ override public void   ( final  metrics file < metric   type  integer >  hs metrics comparable metrics file )  {  hs metrics comparable metrics file . add metric ( convert metric ( this . metrics )  )  ;  hs metrics comparable metrics file . add histogr
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\TargetMetricsCollector.java,calculate gc metrics,"private void   (  )  {  if  ( this . interval to gc  !  =  null )   {  log . info ( "" calculating gc metrics"" )  ;  final  format util fmt = new  format util (  )  ;  final  print writer out ;  try  {  if  ( per target output  !  =  null )   {  out = new  print writer ( per target output )  ;  out . println ( ""chrom\tstart\tend\tlength\tname\t%gc\tmean   coverage\tnormalized   coverage\tmin   normalized   coverage\tmax   normalized   coverage\tmin   coverage\tmax   coverage\tpct   0x\tread   count"" )  ;   }  else  {  out = null ;   }   }  catch  (  final io exception ioe )   {  throw new  runtimeio exception ( ioe )  ;   }  final int bins = 101 ;  final long[] target bases by gc = new long[bins] ;  final long[] aligned bases by gc = new long[bins] ;  for  (  final  map .  entry <  interval  coverage >  entry : this . high quality coverage by target . entry set (  )  )   {  final  interval interval = entry . get key (  )  ;  final  coverage cov = entry . get value (  )  ;  if  ( interval . length (  )   <  =  0 )   {  log . warn ( ""interval of length zero found: ""  +  interval  +  "" skipped . "" )  ;  continue ;   }  final double gc double = this . interval to gc . get ( interval )  ;  final int gc =  ( int )  math . round ( gc double * 100 )  ;  target bases by gc[gc] +  = interval . length (  )  ;  aligned bases by gc[gc] +  = cov . get total (  )  ;  if  ( out  !  =  null )   {  final double coverage = cov . get total (  )   /   ( double ) interval . length (  )  ;  double min =  integer . max   value ;  double max =  integer . min   value ;  double target bases at0x = 0 . 0 ;  for  (  final int d : cov . get depths (  )  )   {  if  ( 0  =  =  d )  target bases at0x +  +  ;  if  ( d  <  min )  min = d ;  if  ( max  <  d )  max = d ;   }  out . println ( interval . get contig (  )   +  ""\t""  +  interval . get start (  )  +  ""\t"" +  interval . get end (  )  +  ""\t"" +  interval . length (  )  +  ""\t"" +  interval . get name (  )  +  ""\t"" +  fmt . format ( gc double )  +  ""\t"" +  fmt . format ( coverage )  +  ""\t"" +  fmt . format ( coverage  /  this . metrics . mean   target   coverage )  +  ""\t"" +  fmt . format ( min  /  this . metrics . mean   target   coverage )  +  ""\t"" +  fmt . format ( max  /  this . metrics . mean   target   coverage )  +  ""\t"" +  fmt . format ( min )  +  ""\t"" +  fmt . format ( max )  +  ""\t"" +  fmt . format ( target bases at0x  /  interval . length (  )  )  +  ""\t"" +  fmt . format ( cov . read count )  )  ;   }   }  if  ( out  !  =  null )  out . close (  )  ;  long total target = 0 ;  long total bases = 0 ;  for  ( int i = 0 ;  i  <  target bases by gc . length ;   +  + i )   {  total target +  = target bases by gc[i] ;  total bases +  = aligned bases by gc[i] ;   }  for  ( int i = 0 ;  i  <  target bases by gc . length ;   +  + i )   {  final double target pct = target bases by gc[i]  /   ( double ) total target ;  final double aligned pct = aligned bases by gc[i]  /   ( double ) total bases ;  double dropout =  ( aligned pct  -  target pct )  * 100d ;  if  ( dropout  <  0 )   {  dropout =  math . abs ( dropout )  ;  if  ( i  <  =  50 )  this . metrics . at   dropout +  = dropout ;  if  ( i  >  =  50 )  this . metrics . gc   dropout +  = dropout ;   }   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\TargetMetricsCollector.java,calculate target coverage metrics,"private void   (  )  {  final long[] high quality coverage histogram array = new long[coverage cap  +  1] ;  int zero coverage targets = 0 ;  long total coverage = 0 ;  long max depth = 0 ;  final int[] target bases depth =  { 0 1 2 10 20 30 40 50 100 }  ;  final int[] target bases = new int[target bases depth . length] ;  for  (  final  coverage c : this . high quality coverage by target . values (  )  )   {  if  (  ! c . has coverage (  )  )   {  zero coverage targets +  +  ;  high quality coverage histogram array[0] +  = c . interval . length (  )  ;  target bases[0] +  = c . interval . length (  )  ;  continue ;   }  for  (  final int depth : c . get depths (  )  )   {  total coverage +  = depth ;  high quality coverage histogram array[ math . min ( depth coverage cap ) ] +  +  ;  max depth =  math . max ( max depth depth )  ;  for  ( int i = 0 ;  i  <  target bases depth . length ;  i +  +  )   {  if  ( depth  >  =  target bases depth[i] )  target bases[i] +  +  ;  else break ;   }   }   }  if  ( target bases[0]  !  =  high quality coverage by target . key set (  )  . stream (  )  . map to int (  interval::length )  . sum (  )  )   {  throw new  picard exception ( ""the number of target bases with at least 0x coverage does not equal the number of target bases"" )  ;   }  for  ( int i = 0 ;  i  <  high quality coverage histogram array . length ;   +  + i )   {  high quality depth histogram . increment ( i high quality coverage histogram array[i] )  ;   }  metrics . mean   target   coverage =  ( double ) total coverage  /  metrics . target   territory ;  metrics . median   target   coverage = high quality depth histogram . get median (  )  ;  metrics . max   target   coverage = max depth ;  metrics . fold   80   base   penalty = metrics . mean   target   coverage  /  high quality depth histogram . get percentile ( 0 . 2 )  ;  metrics . zero   cvg   targets   pct = zero coverage targets  /   ( double ) all targets . get intervals (  )  . size (  )  ;  metrics . pct   target   bases   1x =  ( double ) target bases[1]  /   ( double ) target bases[0] ;  metrics . pct   target   bases   2x =  ( double ) target bases[2]  /   ( double ) target bases[0] ;  metrics . pct   target   bases   10x =  ( double ) target bases[3]  /   ( double ) target bases[0] ;  metrics . pct   target   bases   20x =  ( double ) target bases[4]  /   ( double ) target bases[0] ;  metrics . pct   target   bases   30x =  ( double ) target bases[5]  /   ( double ) target bases[0] ;  metrics . pct   target   bases   40x =  ( double ) target bases[6]  /   ( double ) target bases[0] ;  metrics . pct   target   bases   50x =  ( double ) target bases[7]  /   ( double ) target bases[0] ;  metrics . pct   target   bases   100x =  ( double ) target bases[8]  /   ( double ) target bases[0] ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\TargetMetricsCollector.java,calculate theoretical het sensitivity,"private void   (  )  {  final long[] unfiltered depth histogram array = new long[coverage cap  +  1] ;  for  (  final  coverage c : this . unfiltered coverage by target . values (  )  )   {  if  (  ! c . has coverage (  )  )   {  unfiltered depth histogram array[0] +  = c . interval . length (  )  ;  continue ;   }  for  (  final int depth : c . get depths (  )  )   {  unfiltered depth histogram array[ math . min ( depth coverage cap ) ] +  +  ;   }   }  if  (  long stream . of ( baseq histogram array )  . sum (  )   !  =   long stream . range closed ( 0 coverage cap )  . map ( i  -  >  i * unfiltered depth histogram array[ ( int ) i] )  . sum (  )  )   {  throw new  picard exception ( ""numbers of bases in the base quality histogram and the coverage histogram are not equal"" )  ;   }  for  ( int i = 0 ;  i  <  baseq histogram array . length ;   +  + i )   {  unfiltered baseq histogram . increment ( i baseq histogram array[i] )  ;   }  for  ( int i = 0 ;  i  <  unfiltered depth histogram array . length ;  i +  +  )   {  unfiltered depth histogram . increment ( i unfiltered depth histogram array[i] )  ;   }  final double[] depth double array =  theoretical sensitivity . normalize histogram ( unfiltered depth histogram )  ;  final double[] baseq double array =  theoretical sensitivity . normalize histogram ( unfiltered baseq histogram )  ;  metrics . het   snp   sensitivity =  theoretical sensitivity . hetsnp sensitivity ( depth double array baseq double array sample size log   odds   threshold )  ;  metrics . het   snp   q =  quality util . get phred score from error probability (  ( 1  -  metrics . het   snp   sensitivity )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasUtils.java,calculate all gcs,public static byte[]   ( final byte[] ref bases final int last window start final int window size )  {  final  calculate gc state state = new  gc bias utils (  )  . new  calculate gc state (  )  ;  final int ref length = ref bases . length ;  final byte[] gc = new byte[ref length  +  1] ;  for  ( int i = 1 ;  i  <  last window start ;   +  + i )   {  final int window end = i  +  window size ;  final int window gc = calculate gc ( ref bases i window end state )  ;  gc[i] =  ( byte ) window gc ;   }  return gc ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasUtils.java,calculate gc,public static int   ( final byte[] bases final int start index final int end index final  calculate gc state state )  {  if  ( state . init )   {  state . init = false ;  state . gc count = 0 ;  state . n count = 0 ;  for  ( int i = start index ;  i  <  end index ;   +  + i )   {  final byte base = bases[i] ;  if  (  sequence util . bases equal ( base  ( byte ) 'g' )  ||  sequence util . bases equal ( base  ( byte ) 'c' )  )   +  + state . gc count ;  else if  (  sequence util . bases equal ( base  ( byte ) 'n' )  )   +  + state . n count ;   }   }  else  {  final byte new base = bases[end index  -  1] ;  if  (  sequence util . bases equal ( new base  ( byte ) 'g' )  ||  sequence util . bases equal ( new base  ( byte ) 'c' )  )   +  + state . gc count ;  else if  ( new base  =  =  'n' )   +  + state . n count ;  if  (  sequence util . bases equal ( state . prior base  ( byte ) 'g' )  ||  sequence util . bases equal ( state . prior base  ( byte ) 'c' )  )   -  - state . gc count ;  else if  (  sequence util . bases equal ( state . prior base  ( byte ) 'n' )  )   -  - state . n count ;   }  state . prior base = bases[start index] ;  if  ( state . n count  >  4 )  return  - 1 ;  else return  ( state . gc count * 100 )   /   ( end index  -  start index )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasUtils.java,calculate ref windows by gc,public static int[]   ( final int windows final  file reference sequence final int window size )  {  final  reference sequence file ref file =  reference sequence file factory . get reference sequence file ( reference sequence )  ;   reference sequence ref ;  final int[] windows by gc = new int[windows] ;  while  (  ( ref = ref file . next sequence (  )  )   !  =  null )   {  final byte[] ref bases = ref . get bases (  )  ;   string util . to upper case ( ref bases )  ;  final int ref length = ref bases . length ;  final int last window start = ref length  -  window size ;  final  calculate gc state state = new  gc bias utils (  )  . new  calculate gc state (  )  ;  for  ( int i = 1 ;  i  <  last window start ;   +  + i )   {  final int window end = i  +  window size ;  final int gc bin = calculate gc ( ref bases i window end state )  ;  if  ( gc bin  !  =   - 1 )  windows by gc[gc bin] +  +  ;   }   }  return windows by gc ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\RnaSeqMetricsCollector.java, per unit rna seq metrics collector,public   ( final  string sample final  string library final  string read group final  long ribosomal bases initial value )  {  this ( new  rna seq metrics (  )  sample library read group ribosomal bases initial value )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\RnaSeqMetricsCollector.java, rna seq metrics collector,public   ( final  set <  metric accumulation level >  accumulation levels final  list < sam read group record >  sam rg records final  long ribosomal bases initial value  overlap detector <  gene >  gene overlap detector  overlap detector <  interval >  ribosomal sequence overlap detector final  hash set <  integer >  ignored sequence indices final int minimum length final  strand specificity strand specificity final double rrna fragment percentage boolean collect coverage statistics )  {  this . ribosomal initial value = ribosomal bases initial value ;  this . ignored sequence indices = ignored sequence indices ;  this . gene overlap detector = gene overlap detector ;  this . ribosomal sequence overlap detector = ribosomal sequence overlap detector ;  this . minimum length = minimum length ;  this . strand specificity = strand specificity ;  this . rrna fragment percentage = rrna fragment percentage ;  this . collect coverage statistics = collect coverage statistics ;  setup ( accumulation levels sam rg records )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\RnaSeqMetricsCollector.java,accept record,public void   ( sam record rec )  {  if  ( rec . get read fails vendor quality check flag (  )  )  return ;  if  (  ! rec . get not primary alignment flag (  )  )  this . metrics . pf   bases +  = rec . get read length (  )  ;  if  (  ! rec . get read unmapped flag (  )  &&  ! rec . get not primary alignment flag (  )  && ignored sequence indices . contains ( rec . get reference index (  )  )  )   {   +  + this . metrics . ignored   reads ;  return ;   }  if  ( rec . get not primary alignment flag (  )  || rec . get read unmapped flag (  )  )  return ;  final  interval read interval = new  interval ( rec . get reference name (  )  rec . get alignment start (  )  rec . get alignment end (  )  )  ;  final  interval fragment interval ;  if  (  ! rec . get read paired flag (  )  )   {  fragment interval = read interval ;   }  else if  ( rec . get mate unmapped flag (  )  || rec . get reference index (  )   !  =  rec . get mate reference index (  )  )   {  fragment interval = null ;   }  else  {  final int fragment start =  math . min ( rec . get alignment start (  )  rec . get mate alignment start (  )  )  ;  final int fragment end =  coord math . get end ( fragment start  math . abs ( rec . get inferred insert size (  )  )  )  ;  fragment interval = new  interval ( rec . get reference name (  )  fragment start fragment end )  ;   }  if  ( fragment interval  !  =  null )   {  final  collection <  interval >  overlapping ribosomal intervals = ribosomal sequence overlap detector . get overlaps ( fragment interval )  ;  int intersection length = 0 ;  for  (  final  interval overlapping interval : overlapping ribosomal intervals )   {  final int this intersection length = overlapping interval . get intersection length ( fragment interval )  ;  intersection length =  math . max ( intersection length this intersection length )  ;   }  if  ( intersection length  /   ( double ) fragment interval . length (  )   >  =  rrna fragment percentage )   {  metrics . ribosomal   bases +  = rec . get read length (  )  ;  metrics . pf   aligned   bases +  = get num aligned bases ( rec )  ;  return ;   }   }  final  collection <  gene >  overlapping genes = gene overlap detector . get overlaps ( read interval )  ;  final  list <  alignment block >  alignment blocks = rec . get alignment blocks (  )  ;  boolean overlaps exon = false ;  for  (  final  alignment block alignment block : alignment blocks )   {  final  locus function[] locus functions = new  locus function[alignment block . get length (  ) ] ;   arrays . fill ( locus functions 0 locus functions . length  locus function . intergenic )  ;  for  (  final  gene gene : overlapping genes )   {  for  (  final  gene .  transcript transcript : gene )   {  transcript . assign locus function for range ( alignment block . get reference start (  )  locus functions )  ;  if  ( collect coverage statistics )   {  int[] coverage = this . coverage by transcript . get ( transcript )  ;  if  ( coverage  =  =  null )   {  coverage = new int[transcript . length (  ) ] ;  this . coverage by transcript . put ( transcript coverage )  ;   }  transcript . add coverage counts ( alignment block . get reference start (  )   coord math . get end ( alignment block . get reference start (  )  alignment block . get length (  )  )  coverage )  ;   }   }   }  for  (  final  locus function locus function : locus functions )   {   +  + metrics . pf   aligned   bases ;  switch  ( locus function )   {  case intergenic:  +  + metrics . intergenic   bases ;  break ;  case intronic:  +  + metrics . intronic   bases ;  break ;  case utr:  +  + metrics . utr   bases ;  overlaps exon = true ;  break ;  case coding:  +  + metrics . coding   bases ;  overlaps exon = true ;  break ;  case ribosomal:  +  + metrics . ribosomal   bases ;  break ;   }   }   }  if  (  ! rec . get supplementary alignment flag (  )  && overlaps exon && overlapping genes . size (  )   =  =  1 )   {  final  gene gene = overlapping genes . iterator (  )  . next (  )  ;  final boolean negative transcription strand = gene . is negative strand (  )  ;  final boolean read one or unpaired =  ! rec . get read paired flag (  )  || rec . get first of pair flag (  )  ;  final boolean negative read strand = rec . get read negative strand flag (  )  ;  if  ( strand specificity  !  =   strand specificity . none )   {  final boolean read and transcript strands agree = negative read strand  =  =  negative transcription strand ;  final boolean first read expected to agree = strand specificity  =  =   strand specificity . first   read   transcription   strand ;  final boolean this read expected to agree = read one or unpaired  =  =  first read expected to agree ;  if  ( read and transcript strands agree  =  =  this read expected to agree )   {   +  + metrics . correct   strand   reads ;   }  else  {   +  + metrics . incorrect   strand   reads ;   }   }  if  ( read one or unpaired )   {  final boolean proper orientation ;  final int left most aligned base  right most aligned base ;  if  ( rec . get read paired flag (  )  )   {  if  ( rec . get mate unmapped flag (  )  )   {  proper orientation = false ;  left most aligned base = right most aligned base = 0 ;   }  else  {  final  cigar mate cigar = sam utils . get mate cigar ( rec )  ;  final int mate reference length =  ( mate cigar  =  =  null )   ?  rec . get read length (  )  : mate cigar . get reference length (  )  ;  final int mate alignment end =  coord math . get end ( rec . get mate alignment start (  )  mate reference length )  ;  proper orientation =  sam pair util . get pair orientation ( rec )   =  =   sam pair util .  pair orientation . fr ;  left most aligned base =  math . min ( rec . get alignment start (  )  rec . get mate alignment start (  )  )  ;  right most aligned base =  math . max ( rec . get alignment end (  )  mate alignment end )  ;   }   }  else  {  proper orientation = true ;  left most aligned base = rec . get alignment start (  )  ;  right most aligned base = rec . get alignment end (  )  ;   }  if  ( proper orientation &&  coord math . encloses ( gene . get start (  )  gene . get end (  )  left most aligned base right most aligned base )  )   {  if  ( negative read strand  =  =  negative transcription strand )   {   +  + metrics . num   r1   transcript   strand   reads ;   }  else  {   +  + metrics . num   r2   transcript   strand   reads ;   }   }  else  {   +  + metrics . num   unexplained   reads ;   }   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\RnaSeqMetricsCollector.java,add metrics to file,@ override public void   ( final  metrics file <  rna seq metrics  integer >  file )  {  final  histogram <  integer >  normalized cov by pos = compute coverage metrics (  )  ;  file . add metric ( metrics )  ;  file . add histogram ( normalized cov by po
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\RnaSeqMetricsCollector.java,compute coverage metrics,"private  histogram <  integer >    (  )  {  final  histogram <  double >  cvs = new  histogram <  double >  (  )  ;  final  histogram <  double >  five prime skews = new  histogram <  double >  (  )  ;  final  histogram <  double >  three prime skews = new  histogram <  double >  (  )  ;  final  histogram <  double >  gap bases per kb = new  histogram <  double >  (  )  ;  final  histogram <  double >  five to three skews = new  histogram <  double >  (  )  ;   string prefix = null ;  if  ( this . metrics . read   group  !  =  null )   {  prefix = this . metrics . read   group  +  "" . "" ;   }  else if  ( this . metrics . library  !  =  null )   {  prefix = this . metrics . library  +  "" . "" ;   }  else if  ( this . metrics . sample  !  =  null )   {  prefix = this . metrics . sample  +  "" . "" ;   }  else  {  prefix = "" all    reads . "" ;   }  final  histogram <  integer >  normalized coverage by normalized position = new  histogram <  integer >  ( ""normalized   position"" prefix  +  ""normalized   coverage"" )  ;  final  map <  gene .  transcript int[] >  transcripts = pick transcripts ( coverage by transcript )  ;  final double transcript count = transcripts . size (  )  ;  for  (  final  map .  entry <  gene .  transcript int[] >  entry : transcripts . entry set (  )  )   {  final  gene .  transcript tx = entry . get key (  )  ;  final double[] coverage ;   {  final double[] tmp =  math util . promote ( entry . get value (  )  )  ;  if  ( tx . get gene (  )  . is positive strand (  )  )  coverage = tmp ;  else coverage = copy and reverse ( tmp )  ;   }  final double mean =  math util . mean ( coverage 0 coverage . length )  ;  final double stdev =  math util . stddev ( coverage 0 coverage . length mean )  ;  final double cv = stdev  /  mean ;  cvs . increment ( cv )  ;   {  final int prime   bases = 100 ;  final double five prime coverage =  math util . mean ( coverage 0 prime   bases )  ;  final double three prime coverage =  math util . mean ( coverage coverage . length  -  prime   bases coverage . length )  ;  five prime skews . increment ( five prime coverage  /  mean )  ;  three prime skews . increment ( three prime coverage  /  mean )  ;  five to three skews . increment (  math util . divide ( five prime coverage three prime coverage )  )  ;   }   {  final int last index = coverage . length  -  1 ;  for  ( int percent = 0 ;  percent  <  =  100 ;   +  + percent )   {  final double p = percent  /  100d ;  final int start =  ( int )  math . max ( 0 last index *  ( p  -  0 . 005 )  )  ;  final int end =  ( int )  math . min ( last index last index *  ( p  +  0 . 005 )  )  ;  final int length = end  -  start  +  1 ;  double sum = 0 ;  for  ( int i = start ;  i  <  =  end ;   +  + i )  sum +  = coverage[i] ;  final double normalized =  ( sum  /  length )   /  mean ;  normalized coverage by normalized position . increment ( percent normalized  /  transcript count )  ;   }   }   }  this . metrics . median   cv   coverage = cvs . get median (  )  ;  this . metrics . median   5prime   bias = five prime skews . get median (  )  ;  this . metrics . median   3prime   bias = three prime skews . get median (  )  ;  this . metrics . median   5prime   to   3prime   bias = five to three skews . get median (  )  ;  return normalized coverage by normalized position ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\RnaSeqMetricsCollector.java,copy and reverse,private double[]   ( final double[] in )  {  final double[] out = new double[in . length] ;  for  ( int i = 0  j = in . length  -  1 ;  i  <  in . length ;   +  + i   -  - j )  out[j] = in[i] ;  return out ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\RnaSeqMetricsCollector.java,finish,public void   (  )  {  if  ( metrics . pf   aligned   bases  >  0 )   {  if  ( metrics . ribosomal   bases  !  =  null )   {  metrics . pct   ribosomal   bases = metrics . ribosomal   bases  /   ( double ) metrics . pf   aligned   bases ;   }  metrics . pct   coding   bases = metrics . coding   bases  /   ( double ) metrics . pf   aligned   bases ;  metrics . pct   utr   bases = metrics . utr   bases  /   ( double ) metrics . pf   aligned   bases ;  metrics . pct   intronic   bases = metrics . intronic   bases  /   ( double ) metrics . pf   aligned   bases ;  metrics . pct   intergenic   bases = metrics . intergenic   bases  /   ( double ) metrics . pf   aligned   bases ;  metrics . pct   mrna   bases = metrics . pct   coding   bases  +  metrics . pct   utr   bases ;  metrics . pct   usable   bases =  ( metrics . coding   bases  +  metrics . utr   bases )   /   ( double ) metrics . pf   bases ;   }  if  ( metrics . correct   strand   reads  >  0 || metrics . incorrect   strand   reads  >  0 )   {  metrics . pct   correct   strand   reads = metrics . correct   strand   reads  /   ( double )  ( metrics . correct   strand   reads  +  metrics . incorrect   strand   reads )  ;   }  final long reads examined = metrics . num   r1   transcript   strand   reads  +  metrics . num   r2   transcript   strand   reads ;  if  ( 0  <  reads examined )   {  metrics . pct   r1   transcript   strand   reads = metrics . num   r1   transcript   strand   reads  /   ( double ) reads examined ;  metrics . pct   r2   transcript   strand   reads = metrics . num   r2   transcript   strand   reads  /   ( double ) reads examined ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\RnaSeqMetricsCollector.java,get genes for pick transcripts,protected  set <  gene >    (  )  {  return gene overlap detector . get all (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\RnaSeqMetricsCollector.java,get genes with transcripts,private  set <  gene >    (  collection <  gene .  transcript >  transcripts )  {  final  set <  gene >  genes with transcripts = new  hash set <  >  (  )  ;  final  set <  gene >  genes for pick transcripts = get genes for pick transcripts (  )  ;  for  (  final  gene .  transcript transcript : transcripts )   {  if  ( genes for pick transcripts . contains ( transcript . get gene (  )  )  )   {  genes with transcripts . add ( transcript . get gene (  )  )  ;   }   }  return genes with transcripts ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\RnaSeqMetricsCollector.java,get num aligned bases,protected int   ( sam record rec )  {  int num aligned bases = 0 ;  for  (  final  alignment block alignment block : rec . get alignment blocks (  )  )   {  num aligned bases +  = alignment block . get length (  )  ;   }  return num aligned bases ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\RnaSeqMetricsCollector.java,make child collector,@ override protected  per unit metric collector <  rna seq metrics  integer sam record >    ( final  string sample final  string library final  string read group )  {  return new  per unit rna seq metrics collector ( sample library read group ribosomal in
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\RnaSeqMetricsCollector.java,make ignored sequence indices set,"public static  hash set <  integer >    ( final sam file header header final  set <  string >  ignored sequence )  {  final  hash set <  integer >  ignored sequence indices = new  hash set <  integer >  (  )  ;  for  (  final  string sequence name : ignored sequence )   {  final sam sequence record sequence record = header . get sequence ( sequence name )  ;  if  ( sequence record  =  =  null )   {  throw new  picard exception ( "" unrecognized sequence ""  +  sequence name  +  "" passed as argument to ignore   sequence"" )  ;   }  ignored sequence indices . add ( sequence record . get sequence index (  )  )  ;   }  return ignored sequence indices ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\RnaSeqMetricsCollector.java,make overlap detector,"public static  overlap detector <  interval >    ( final  file sam file final sam file header header final  file ribosomal intervals file final  log log )  {  final  overlap detector <  interval >  ribosomal sequence overlap detector = new  overlap detector <  interval >  ( 0 0 )  ;  if  ( ribosomal intervals file  !  =  null )   {  final  interval list ribosomal intervals =  interval list . from file ( ribosomal intervals file )  ;  if  ( ribosomal intervals . size (  )   =  =  0 )   {  log . warn ( "" the ribosomal   intervals file  ""  +  ribosomal intervals file . get absolute path (  )   +  "" does not contain intervals"" )  ;   }  try  {   sequence util . assert sequence dictionaries equal ( header . get sequence dictionary (  )  ribosomal intervals . get header (  )  . get sequence dictionary (  )  )  ;   }  catch  (   sequence util .  sequence lists differ exception e )   {  throw new  picard exception ( "" sequence dictionaries differ in ""  +  sam file . get absolute path (  )   +  "" and "" +  ribosomal intervals file . get absolute path (  )  e )  ;   }  final  interval list uniqued ribosomal intervals = ribosomal intervals . uniqued (  )  ;  final  list <  interval >  intervals = uniqued ribosomal intervals . get intervals (  )  ;  ribosomal sequence overlap detector . add all ( intervals intervals )  ;   }  return ribosomal sequence overlap detector ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\directed\RnaSeqMetricsCollector.java,pick transcripts,public  map <  gene .  transcript int[] >    ( final  map <  gene .  transcript int[] >  transcript coverage )  {  final  set <  gene >  genes with transcripts = get genes with transcripts ( transcript coverage . key set (  )  )  ;  final  map <  gene .  transcript  double >  best per gene = new  hash map <  gene .  transcript  double >  (  )  ;  for  (  final  gene gene : genes with transcripts )   {   gene .  transcript best = null ;  double best mean = 0 ;  for  (  final  gene .  transcript tx : gene )   {  final int[] cov = transcript coverage . get ( tx )  ;  if  ( tx . length (  )   <   math . max ( minimum length 100 )  )  continue ;  final double mean =  math util . mean (  math util . promote ( cov )  0 cov . length )  ;  if  ( mean  <  1d )  continue ;  if  ( best  =  =  null || mean  >  best mean )   {  best = tx ;  best mean = mean ;   }   }  if  ( best  !  =  null )  best per gene . put ( best best mean )  ;   }  final double[] coverages = new double[best per gene . size (  ) ] ;  int i = 0 ;  for  (  final double d : best per gene . values (  )  )  coverages[i +  + ] = d ;   arrays . sort ( coverages )  ;  final double min = coverages . length  =  =  0  ?  0 : coverages[ math . max ( 0 coverages . length  -  1001 ) ] ;  final  map <  gene .  transcript int[] >  retval = new  hash map <  gene .  transcript int[] >  (  )  ;  for  (  final  map .  entry <  gene .  transcript  double >  entry : best per gene . entry set (  )  )   {  final  gene .  transcript tx = entry . get key (  )  ;  final double coverage = entry . get value (  )  ;  if  ( coverage  >  =  min )   {  retval . put ( tx transcript coverage . get ( tx )  )  ;   }   }  return retval ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasMetricsCollector.java, gc bias collector args,public   ( final sam record rec final  reference sequence ref )  {  this . rec = rec ;  this . ref = ref ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasMetricsCollector.java, gc bias metrics collector,public   ( final  set <  metric accumulation level >  accumulation levels final int[] windows by gc final  list < sam read group record >  sam rg records final int scan window size final boolean bisulfite final boolean ignore duplicates )  {  this . scan window size = scan window size ;  this . bisulfite = bisulfite ;  this . windows by gc = windows by gc ;  this . ignore duplicates = ignore duplicates ;  setup ( accumulation levels sam rg records )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasMetricsCollector.java, per unit gc bias metrics collector,public   ( final  string sample final  string library final  string read group )  {  this . sample = sample ;  this . library = library ;  this . read group = read group ;  this . gc data = prepare gc data (  )  ;  if  ( ignore duplicates )   {  this . gc data non dups = prepare gc data (  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasMetricsCollector.java,accept record,"@ override public void   ( final  gc bias collector args args )  {  final sam record rec = args . get rec (  )  ;  if  ( log counter  <  100 && rec . get read bases (  )  . length  =  =  0 )   {  log . warn ( "" omitting read ""  +  rec . get read name (  )"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasMetricsCollector.java,add gc data to file,private void   ( final  metrics file <  gc bias metrics  integer >  file final  map <  string  gc object >  gc data final boolean include duplicates )  {  for  (  final  map .  entry <  string  gc object >  entry : gc data . entry set (  )  )   {  final  gc object gc cur = entry . get value (  )  ;  final  string gc type = entry . get key (  )  ;  final int[] reads by gc = gc cur . reads by gc ;  final long[] errors by gc = gc cur . errors by gc ;  final long[] bases by gc = gc cur . bases by gc ;  final long total clusters = gc cur . total clusters ;  final long total aligned reads = gc cur . total aligned reads ;  final  string group = gc cur . group ;  final  gc bias metrics metrics = new  gc bias metrics (  )  ;  final double total windows = sum ( windows by gc )  ;  final double total reads = sum ( reads by gc )  ;  final double mean reads per window = total reads  /  total windows ;  if  ( total aligned reads  >  0 )   {  for  ( int i = 0 ;  i  <  windows by gc . length ;   +  + i )   {  final  gc bias detail metrics detail = new  gc bias detail metrics (  )  ;  detail . gc = i ;  detail . windows = windows by gc[i] ;  detail . read   starts = reads by gc[i] ;  if  ( errors by gc[i]  >  0 )   {  detail . mean   base   quality =  quality util . get phred score from obs and errors ( bases by gc[i] errors by gc[i] )  ;   }  if  ( windows by gc[i]  !  =  0 )   {  detail . normalized   coverage =  ( detail . read   starts  /   ( double ) detail . windows )   /  mean reads per window ;  detail . error   bar   width =  (  math . sqrt ( detail . read   starts )   /   ( double ) detail . windows )   /  mean reads per window ;   }  else  {  detail . normalized   coverage = 0 ;  detail . error   bar   width = 0 ;   }  detail . accumulation   level = group ;  if  ( group . equals ( accumulation   level   read   group )  )   {  detail . read   group = gc type ;   }  else if  ( group . equals ( accumulation   level   sample )  )   {  detail . sample = gc type ;   }  else if  ( group . equals ( accumulation   level   library )  )   {  detail . library = gc type ;   }  detail . reads   used = include duplicates  ?  reads   used   all : reads   used   unique ;  metrics . details . add metric ( detail )  ;   }  final  gc bias summary metrics summary = new  gc bias summary metrics (  )  ;  if  ( group . equals ( accumulation   level   read   group )  )   {  summary . read   group = gc type ;   }  else if  ( group . equals ( accumulation   level   sample )  )   {  summary . sample = gc type ;   }  else if  ( group . equals ( accumulation   level   library )  )   {  summary . library = gc type ;   }  summary . reads   used = include duplicates  ?  reads   used   all : reads   used   unique ;  summary . accumulation   level = group ;  summary . window   size = scan window size ;  summary . total   clusters = total clusters ;  summary . aligned   reads = total aligned reads ;  summary . gc   nc   0   19 = calculate gc norm coverage ( mean reads per window reads by gc 0 19 )  ;  summary . gc   nc   20   39 = calculate gc norm coverage ( mean reads per window reads by gc 20 39 )  ;  summary . gc   nc   40   59 = calculate gc norm coverage ( mean reads per window reads by gc 40 59 )  ;  summary . gc   nc   60   79 = calculate gc norm coverage ( mean reads per window reads by gc 60 79 )  ;  summary . gc   nc   80   100 = calculate gc norm coverage ( mean reads per window reads by gc 80 100 )  ;  calculate dropout metrics ( metrics . details . get metrics (  )  summary )  ;  metrics . summary = summary ;  file . add metric ( metrics )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasMetricsCollector.java,add metrics to file,@ override public void   ( final  metrics file <  gc bias metrics  integer >  file )  {  add gc data to file ( file this . gc data true )  ;  if  ( ignore duplicates )   {  add gc data to file ( file this . gc data non dups false )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasMetricsCollector.java,add read,private void   ( final  gc object gc obj final sam record rec final  string group final byte[] gc final byte[] ref bases )  {  if  (  ! rec . get read paired flag (  )  || rec . get first of pair flag (  )  )   +  + gc obj . total clusters ;  final int pos = rec . get read negative strand flag (  )   ?  rec . get alignment end (  )   -  scan window size : rec . get alignment start (  )  ;   +  + gc obj . total aligned reads ;  if  ( pos  >  0 )   {  final int window gc = gc[pos] ;  if  ( window gc  >  =  0 )   {   +  + gc obj . reads by gc[window gc] ;  gc obj . bases by gc[window gc] +  = rec . get read length (  )  ;  gc obj . errors by gc[window gc] +  =  sequence util . count mismatches ( rec ref bases bisulfite )   +   sequence util . count inserted bases ( rec )   +   sequence util . count deleted bases ( rec )  ;   }   }  if  ( gc obj . group  =  =  null )   {  gc obj . group = group ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasMetricsCollector.java,add read to gc data,private void   ( final sam record rec final  map <  string  gc object >  gc data )  {  final  string type ;   string group ;  if  ( this . read group  !  =  null )   {  type = this . read group ;  group = accumulation   level   read   group ;   }  else if  ( this . library  !  =  null )   {  type = this . library ;  group = accumulation   level   library ;   }  else if  ( this . sample  !  =  null )   {  type = this . sample ;  group = accumulation   level   sample ;   }  else  {  type = all reads ;  group = accumulation   level   all   reads ;   }  add read ( gc data . get ( type )  rec group gc ref bases )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasMetricsCollector.java,calculate dropout metrics,private void   ( final  collection <  gc bias detail metrics >  details final  gc bias summary metrics summary )  {  double total reads = 0 ;  double total windows = 0 ;  for  (  final  gc bias detail metrics detail : details )   {  total reads +  = detail . read   starts ;  total windows +  = detail . windows ;   }  double at dropout = 0 ;  double gc dropout = 0 ;  for  (  final  gc bias detail metrics detail : details )   {  final double relative reads = detail . read   starts  /  total reads ;  final double relative windows = detail . windows  /  total windows ;  final double dropout =  ( relative windows  -  relative reads )  * 100 ;  if  ( dropout  >  0 )   {  if  ( detail . gc  <  =  50 )  at dropout +  = dropout ;  else  {  gc dropout +  = dropout ;   }   }   }  summary . at   dropout = at dropout ;  summary . gc   dropout = gc dropout ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasMetricsCollector.java,calculate gc norm coverage,private double   ( final double mean reads per window final int[] reads by gc final int start final int end )  {  int windows total = 0 ;  double sum = 0 . 0 ;  for  ( int i = start ;  i  <  =  end ;  i +  +  )   {  if  ( windows by gc[i]  !  =  0 )   {  sum +  =  ( double ) reads by gc[i] ;  windows total +  = windows by gc[i] ;   }   }  if  ( windows total  =  =  0 )   {  return 0 . 0 ;   }  else  {  return  ( sum  /   ( windows total * mean reads per window )  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasMetricsCollector.java,get rec,public sam record   (  )  {  return rec ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasMetricsCollector.java,get ref,public  reference sequence   (  )  {  return ref ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasMetricsCollector.java,make arg,@ override protected  gc bias collector args   ( final sam record rec final  reference sequence ref )  {  return new  gc bias collector args ( rec ref )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasMetricsCollector.java,make child collector,@ override protected  per unit metric collector <  gc bias metrics  integer  gc bias collector args >    ( final  string sample final  string library final  string read group )  {  return new  per unit gc bias metrics collector ( sample library read group
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasMetricsCollector.java,prepare gc data,private  map <  string  gc object >    (  )  {  final  string prefix ;  final  map <  string  gc object >  gc data = new  hash map <  >  (  )  ;  if  ( this . read group  !  =  null )   {  prefix = this . read group ;   }  else if  ( this . library  !  =  null )   {  prefix = this . library ;   }  else if  ( this . sample  !  =  null )   {  prefix = this . sample ;   }  else  {  prefix = all reads ;   }  gc data . put ( prefix new  gc object (  )  )  ;  return gc data ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasMetricsCollector.java,sum,private double   ( final int[] values )  {  final int length = values . length ;  double total = 0 ;  for  ( int i = 0 ;  i  <  length ;  i +  +  )   {  total +  = values[i] ;   }  return total ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\GcBiasMetricsCollector.java,update total clusters,private void   ( final sam record rec final  map <  string  gc object >  gc data )  {  for  (  final  map .  entry <  string  gc object >  entry : gc data . entry set (  )  )   {  final  gc object gc cur = entry . get value (  )  ;  if  (  ! rec . get read paired flag (  )  || rec . get first of pair flag (  )  )   +  + gc cur . total clusters ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\MeanQualityByCycle.java, histogram generator,private   ( final boolean use original qualities )  {  this . use original qualities = use original qualities ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\MeanQualityByCycle.java,accept read,@ override protected void   ( final sam record rec final  reference sequence ref )  {  if  ( pf   reads   only && rec . get read fails vendor quality check flag (  )  )  return ;  if  ( aligned   reads   only && rec . get read unmapped flag (  )  )  retur
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\QualityScoreDistribution.java,accept read,@ override protected void   ( final sam record rec final  reference sequence ref )  {  if  ( pf   reads   only && rec . get read fails vendor quality check flag (  )  )  return ;  if  ( aligned   reads   only && rec . get read unmapped flag (  )  )  retur
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\QualityScoreDistribution.java,finish,"@ override protected void   (  )  {  final  histogram <  byte >  q histo = new  histogram <  byte >  ( ""quality"" ""count   of   q"" )  ;  final  histogram <  byte >  oq histo = new  histogram <  byte >  ( ""quality"" ""count   of   oq"" )  ;  for  ( int i = 0 ;"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\QualityScoreDistribution.java,main,public static void   ( final  string[] args )  {   system . exit ( new  quality score distribution (  )  . instance main ( args )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\QualityScoreDistribution.java,setup,@ override protected void   ( final sam file header header final  file sam file )  {  io util . assert file is writable ( output )  ;  io util . assert file is writable ( chart   output )  ;  final  list < sam read group record >  read groups = header . g
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\MeanQualityByCycle.java,add record,void   ( final sam record rec )  {  final byte[] quals =  ( use original qualities  ?  rec . get original base qualities (  )  : rec . get base qualities (  )  )  ;  if  ( quals  =  =  null )  return ;  final int length = quals . length ;  final boolean rc = rec . get read negative strand flag (  )  ;  ensure arrays big enough ( length  +  1 )  ;  for  ( int i = 0 ;  i  <  length ;   +  + i )   {  final int cycle = rc  ?  length  -  i : i  +  1 ;  if  ( rec . get read paired flag (  )  && rec . get second of pair flag (  )  )   {  second read totals by cycle[cycle] +  = quals[i] ;  second read counts by cycle[cycle] +  = 1 ;   }  else  {  first read totals by cycle[cycle] +  = quals[i] ;  first read counts by cycle[cycle] +  = 1 ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\MeanQualityByCycle.java,ensure arrays big enough,private void   ( final int length )  {  if  ( length  >  max length so far )   {  first read totals by cycle =  arrays . copy of ( first read totals by cycle length )  ;  first read counts by cycle =  arrays . copy of ( first read counts by cycle length )  ;  second read totals by cycle =  arrays . copy of ( second read totals by cycle length )  ;  second read counts by cycle =  arrays . copy of ( second read counts by cycle length )  ;  max length so far = length ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\MeanQualityByCycle.java,finish,@ override protected void   (  )  {  final  metrics file <  ?   integer >  metrics = get metrics file (  )  ;  metrics . add histogram ( q . get mean quality histogram (  )  )  ;  if  (  ! oq . is empty (  )  )  metrics . add histogram ( oq . get mean qua
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\MeanQualityByCycle.java,get mean quality histogram," histogram <  integer >    (  )  {  final  string label = use original qualities  ?  ""mean   original   quality"" : ""mean   quality"" ;  final  histogram <  integer >  mean qualities = new  histogram <  integer >  ( ""cycle"" label )  ;  int first read length = 0 ;  for  ( int cycle = 0 ;  cycle  <  first read totals by cycle . length ;   +  + cycle )   {  if  ( first read totals by cycle[cycle]  >  0 )   {  mean qualities . increment ( cycle first read totals by cycle[cycle]  /  first read counts by cycle[cycle] )  ;  first read length = cycle ;   }   }  for  ( int i = 0 ;  i  <  second read totals by cycle . length ;   +  + i )   {  if  ( second read counts by cycle[i]  >  0 )   {  final int cycle = first read length  +  i ;  mean qualities . increment ( cycle second read totals by cycle[i]  /  second read counts by cycle[i] )  ;   }   }  return mean qualities ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\MeanQualityByCycle.java,is empty,boolean   (  )  {  return max length so far  =  =  0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\MeanQualityByCycle.java,main,public static void   (  string[] args )  {   system . exit ( new  mean quality by cycle (  )  . instance main ( args )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\MeanQualityByCycle.java,setup,@ override protected void   ( final sam file header header final  file sam file )  {  io util . assert file is writable ( chart   output )  ;  final  list < sam read group record >  read groups = header . get read groups (  )  ;  if  ( read groups . size 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\MergeableMetricBase.java,can merge,public boolean   ( final  mergeable metric base other )  {  try  {  for  (  final  field field : this . get class (  )  . get declared fields (  )  )   {  if  ( field . is synthetic (  )  )  continue ;  field . get ( other )  ;  final  annotation[] equal annotations = field . get annotations by type (  merge by assert equals . class )  ;  if  ( equal annotations . length  !  =  0 )   {  if  ( field . get ( this )   =  =  null )  return true ;  if  ( field . get ( other )   =  =  null )  return true ;  if  (  ! field . get ( this )  . equals ( field . get ( other )  )  )  return false ;   }   }   }  catch  (  final  exception e )   {  return false ;   }  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\MergeableMetricBase.java,get all fields,private static  list <  field >    (  class clazz )  {  final  list <  field >  fields = new  array list <  >  (  )  ;  fields . add all (  arrays . as list ( clazz . get declared fields (  )  )  )  ;  final  class super class = clazz . get superclass (  )  ;  if  ( super class  !  =  null )  fields . add all ( get all fields ( super class )  )  ;  return fields ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\MergeableMetricBase.java,merge,"public  mergeable metric base   ( final  mergeable metric base other )  {  for  (  final  field field : get all fields ( this . get class (  )  )  )   {  if  ( field . is synthetic (  )  )  continue ;  if  ( field . get annotations by type (  merge by adding . class )  . length  +  field . get annotations by type (  merge by assert equals . class )  . length  +  field . get annotations by type (  no merging is derived . class )  . length +  field . get annotations by type (  merging is manual . class )  . length +  field . get annotations by type (  no merging keeps value . class )  . length  =  =  0 )   {  throw new  illegal state exception ( "" all fields of this class must be annotated with @ merge by adding  @ no merging is derived  or @ merge by assert equals .  ""  +  "" field ""  +  field . get name (  )   +  "" isn't annotated . "" )  ;   }  final  annotation[] summable annotations = field . get annotations by type (  merge by adding . class )  ;  field . set accessible ( true )  ;  if  ( summable annotations . length  !  =  0 )   {  try  {  if  ( field . get type (  )   =  =   integer . class )   {  field . set ( this  (  integer ) field . get ( this )   +   (  integer ) field . get ( other )  )  ;   }  else if  ( field . get type (  )   =  =  int . class )   {  field . set ( this  ( int ) field . get ( this )   +   ( int ) field . get ( other )  )  ;   }  else if  ( field . get type (  )   =  =   float . class )   {  field . set ( this  (  float ) field . get ( this )   +   (  float ) field . get ( other )  )  ;   }  else if  ( field . get type (  )   =  =  float . class )   {  field . set ( this  ( float ) field . get ( this )   +   ( float ) field . get ( other )  )  ;   }  else if  ( field . get type (  )   =  =   double . class )   {  field . set ( this  (  double ) field . get ( this )   +   (  double ) field . get ( other )  )  ;   }  else if  ( field . get type (  )   =  =  double . class )   {  field . set ( this  ( double ) field . get ( this )   +   ( double ) field . get ( other )  )  ;   }  else if  ( field . get type (  )   =  =   long . class )   {  field . set ( this  (  long ) field . get ( this )   +   (  long ) field . get ( other )  )  ;   }  else if  ( field . get type (  )   =  =  long . class )   {  field . set ( this  ( long ) field . get ( this )   +   ( long ) field . get ( other )  )  ;   }  else if  ( field . get type (  )   =  =   byte . class )   {  final  integer result =  (  byte ) field . get ( this )   +   (  byte ) field . get ( other )  ;  if  ( result  >   byte . max   value )  throw new  illegal argument exception ( "" overflow detected in adding ""  +  field . get ( this )   +  "" to "" +  field . get ( other )  )  ;  field . set ( this  ( byte )  ( int ) result )  ;   }  else if  ( field . get type (  )   =  =  byte . class )   {  final int result =  ( byte ) field . get ( this )   +   ( byte ) field . get ( other )  ;  if  ( result  >   byte . max   value )  throw new  illegal argument exception ( "" overflow detected in adding ""  +  field . get ( this )   +  "" to "" +  field . get ( other )  )  ;  field . set ( this  ( byte ) result )  ;   }  else if  ( field . get type (  )   =  =   short . class )   {  final  integer result =  (  short ) field . get ( this )   +   (  short ) field . get ( other )  ;  if  ( result  >   short . max   value )  throw new  illegal argument exception ( "" overflow detected in adding ""  +  field . get ( this )   +  "" to "" +  field . get ( other )  )  ;  field . set ( this  (  short )  ( short )  ( int ) result )  ;   }  else if  ( field . get type (  )   =  =  short . class )   {  final  integer result =  ( short ) field . get ( this )   +   ( short ) field . get ( other )  ;  if  ( result  >   short . max   value )  throw new  illegal argument exception ( "" overflow detected in adding ""  +  field . get ( this )   +  "" to "" +  field . get ( other )  )  ;  field . set ( this  ( short )  ( int ) result )  ;   }  else throw new  illegal argument exception ( ""i don't know how to  merge by adding type ""  +  field . get declaring class (  )  . get canonical name (  )   +  "" of field "" +  field . get name (  )  +  ""please teach me ! "" )  ;   }  catch  (   illegal access exception e )   {  e . print stack trace (  )  ;   }   }  final  annotation[] equal annotations = field . get annotations by type (  merge by assert equals . class )  ;  if  ( equal annotations . length  !  =  0 )   {  try  {  if  ( field . get ( this )   =  =  null )   {  field . set ( this field . get ( other )  )  ;   }  else if  ( field . get ( other )   !  =  null &&  ! field . get ( this )  . equals ( field . get ( other )  )  )   {  throw new  illegal state exception ( "" field ""  +  field . get name (  )   +  "" is annotated as @ merge by assert equals  but found two different values: "" +  field . get ( this )  +  "" & "" +  field . get ( other )  )  ;   }   }  catch  (   illegal access exception e )   {  e . print stack trace (  )  ;   }   }   }  return this ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\MergeableMetricBase.java,merge if can,public boolean   ( final  mergeable metric base other )  {  if  ( can merge ( other )  )   {  merge ( other )  ;  return true ;   }  else  {  return false ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\replicates\CollectIndependentReplicateMetrics.java,calculate edit distance,private static byte   ( final  string lhs final  string rhs )  {  assert  ( lhs . length (  )   =  =  rhs . length (  )  )  ;  byte tmp = 0 ;  for  ( int i = 0 ;  i  <  rhs . length (  )  ;   +  + i )   {  if  ( rhs . char at ( i )   !  =  lhs . char at ( i )  )   +  + tmp ;   }  return tmp ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\replicates\CollectIndependentReplicateMetrics.java,classify set,"private static  set classification   ( final int n ref final int n alt final int n other )  {  if  ( n other  !  =  0 )  return  set classification . mismatching   allele ;  if  ( n alt  >  0 && n ref  >  0 )  return  set classification . different   alleles ;  if  ( n ref  =  =  0 )  return  set classification . alternate   allele ;  if  ( n alt  =  =  0 )  return  set classification . reference   allele ;  throw new  illegal access error ( ""shouldn't be here ! "" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\replicates\CollectIndependentReplicateMetrics.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( vcf )  ;  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  if  ( matrix   output  !  =  null )  io util . assert file is writable ( mat
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\replicates\CollectIndependentReplicateMetrics.java,get query intervals map,private  sorted map <  query interval  list <  allele >  >    ( final  file vcf )  {  final  map <  string  integer >  contig index map = new  hash map <  >  (  )  ;  final vcf file reader vcf reader = new vcf file reader ( vcf false )  ;  final  compound filter compound filter = new  compound filter ( true )  ;  compound filter . add ( new  snp filter (  )  )  ;  compound filter . add ( new  passing variant filter (  )  )  ;  compound filter . add ( new  genotype quality filter ( minimum   gq sample )  )  ;  compound filter . add ( new  heterozygosity filter ( true sample )  )  ;  final  iterator <  variant context >  het iterator = new  filtering variant context iterator ( vcf reader . iterator (  )  compound filter )  ;  for  (  final vcf contig header line vcf contig : vcf reader . get file header (  )  . get contig lines (  )  )   {  contig index map . put ( vcf contig . getid (  )  vcf contig . get contig index (  )  )  ;   }  final  sorted map <  query interval  list <  allele >  >  map = new  tree map <  >  (  )  ;  while  ( het iterator . has next (  )  )   {  final  variant context vc = het iterator . next (  )  ;  map . put ( new  query interval ( contig index map . get ( vc . get contig (  )  )  vc . get start (  )  vc . get end (  )  )  vc . get genotype ( sample )  . get alleles (  )  )  ;   }  vcf reader . close (  )  ;  return map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\replicates\CollectIndependentReplicateMetrics.java,is cleanly before,private static boolean   ( final  query interval lhs final  query interval rhs )  {  return  ! lhs . overlaps ( rhs )  && lhs . compare to ( rhs )   <  0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\replicates\CollectIndependentReplicateMetrics.java,query interval from sam record,private static  query interval   ( final sam record sam record )  {  return new  query interval ( sam record . get reference index (  )  sam record . get start (  )  sam record . get end (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\replicates\IndependentReplicateMetric.java,calculate derived fields,@ override public void   (  )  {  bi site heterogeneity rate = n different alleles bi dups  /   ( double )  ( n different alleles bi dups  +  n alternate alleles bi dups  +  n reference alleles bi dups )  ;  bi site homogeneity rate = 1  -  bi site hetero
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetrics.java, rrbs metrics,public   ( final  rrbs summary metrics summary metrics final  list <  rrbs cpg detail metrics >  detail metrics )  {  this . summary metrics = summary metrics ;  this . detail metrics = detail metrics ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetrics.java,get detail metrics,public  list <  rrbs cpg detail metrics >    (  )  {  return detail metrics ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetrics.java,get summary metrics,public  rrbs summary metrics   (  )  {  return summary metrics ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java, cpg location,public   ( final  string sequence final int position )  {  this . sequence = sequence ;  this . position = position ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java, per unit rrbs metrics collector,public   ( final  string sample final  string library final  string read group )  {  this . sample = sample ;  this . library = library ;  this . read group = read group ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java, rrbs metrics collector,public   ( final  set <  metric accumulation level >  accumulation levels final  list < sam read group record >  sam rg records final int c quality threshold final int next base quality threshold final int min read length final double max mismatch rate )  {  this . c quality threshold = c quality threshold ;  this . next base quality threshold = next base quality threshold ;  this . min read length = min read length ;  this . max mismatch rate = max mismatch rate ;  setup ( accumulation levels sam rg records )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java,accept record,public void   ( final sam record and reference args )  {  mapped record count +  +  ;  final sam record sam record = args . get sam record (  )  ;  final  reference sequence reference sequence = args . get reference sequence (  )  ;  final byte[] read bases = sam record . get read bases (  )  ;  final byte[] read qualities = sam record . get base qualities (  )  ;  final byte[] ref bases = reference sequence . get bases (  )  ;  if  ( sam record . get read length (  )   <  min read length )   {  small read count +  +  ;  return ;   }  else if  (  sequence util . count mismatches ( sam record ref bases true )   >   math . round ( sam record . get read length (  )  * max mismatch rate )  )   {  mismatch count +  +  ;  return ;   }  int record cpgs = 0 ;  for  (  final  alignment block alignment block : sam record . get alignment blocks (  )  )   {  final int block length = alignment block . get length (  )  ;  final int ref fragment start = alignment block . get reference start (  )   -  1 ;  final int read fragment start = alignment block . get read start (  )   -  1 ;  final byte[] ref fragment = get fragment ( ref bases ref fragment start block length )  ;  final byte[] read fragment = get fragment ( read bases read fragment start block length )  ;  final byte[] read quality fragment = get fragment ( read qualities read fragment start block length )  ;  if  ( sam record . get read negative strand flag (  )  )   {   sequence util . reverse complement ( ref fragment )  ;   sequence util . reverse complement ( read fragment )  ;   sequence util . reverse qualities ( read quality fragment )  ;   }  for  ( int i = 0 ;  i  <  block length  -  1 ;  i +  +  )   {  final int cur ref index = get cur ref index ( ref fragment start block length i sam record . get read negative strand flag (  )  )  ;  if  (  (  sequence util . bases equal ( ref fragment[i]  sequence util . c )  )  &&  (  sequence util . bases equal ( ref fragment[i  +  1]  sequence util . g )  )  )   {  if  ( is valid cpg ( ref fragment read fragment read quality fragment i )  )   {  record cpgs +  +  ;  final  cpg location cur location = new  cpg location ( sam record . get reference name (  )  cur ref index )  ;  cpg total . increment ( cur location )  ;  if  (  sequence util . is bisulfite converted ( read fragment[i] ref fragment[i] )  )   {  cpg converted . increment ( cur location )  ;   }   }  i +  +  ;   }  else if  ( isc ( ref fragment[i] read fragment[i] )  && is above cyto qc threshold ( read qualities i )  &&  sequence util . bisulfite bases equal ( false read fragment[i  +  1] ref fragment[i  +  1] )  )   {  n cyto total +  +  ;  if  (  sequence util . is bisulfite converted ( read fragment[i] ref fragment[i] )  )   {  n cyto converted +  +  ;   }   }   }   }  if  ( record cpgs  =  =  0 )   {  no cpg count +  +  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java,add metrics to file,@ override public void   ( final  metrics file <  rrbs metrics  comparable <  ?  >  >  metrics file )  {  final  rrbs summary metrics summary metrics = build summary metrics (  )  ;  final  list <  rrbs cpg detail metrics >  detail metrics = build detail 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java,build detail metrics,private  list <  rrbs cpg detail metrics >    (  )  {  final  list <  rrbs cpg detail metrics >  detail metrics = new  array list <  rrbs cpg detail metrics >  (  )  ;  for  (  final  cpg location key : cpg total . key set (  )  )   {  final  rrbs cpg detail metrics cpg metric = new  rrbs cpg detail metrics (  )  ;  cpg metric . sample = sample ;  cpg metric . read   group = read group ;  cpg metric . library = library ;  cpg metric . sequence   name = key . get sequence (  )  ;  cpg metric . position = key . get position (  )  ;  cpg metric . total   sites =  ( int ) cpg total . get ( key )  . get value (  )  ;  cpg metric . converted   sites = cpg converted . contains key ( key )   ?   ( int ) cpg converted . get ( key )  . get value (  )  : 0 ;  cpg metric . pct   converted = cpg metric . converted   sites  =  =  0  ?  0 : cpg metric . converted   sites  /   ( double ) cpg metric . total   sites ;  detail metrics . add ( cpg metric )  ;   }  return detail metrics ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java,build summary metrics,private  rrbs summary metrics   (  )  {  final  rrbs summary metrics summary metrics = new  rrbs summary metrics (  )  ;  summary metrics . sample = sample ;  summary metrics . read   group = read group ;  summary metrics . library = library ;  summary metrics . reads   aligned = mapped record count ;  summary metrics . non   cpg   bases = n cyto total ;  summary metrics . non   cpg   converted   bases = n cyto converted ;  summary metrics . pct   non   cpg   bases   converted = cyto conversion rate ;  summary metrics . cpg   bases   seen = n cpg seen ;  summary metrics . cpg   bases   converted = n cpg converted ;  summary metrics . pct   cpg   bases   converted = cpg conversion rate ;  summary metrics . mean   cpg   coverage = coverage mean ;  summary metrics . median   cpg   coverage = coverage median ;  summary metrics . reads   ignored   short = small read count ;  summary metrics . reads   with   no   cpg = no cpg count ;  summary metrics . reads   ignored   mismatches = mismatch count ;  return summary metrics ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java,compare to,@ override public int   ( final  cpg location other )  {  final int seq comp = sequence . compare to ( other . sequence )  ;  return seq comp  =  =  0  ?  position . compare to ( other . position )  : seq comp ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java,equals,@ override public boolean   ( final  object other )  {  if  ( this  =  =  other )   {  return true ;   }  if  ( other  =  =  null || get class (  )   !  =  other . get class (  )  )   {  return false ;   }  final  cpg location that =  (  cpg location ) ot
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java,finish,public void   (  )  {  cyto conversion rate = n cyto total  =  =  0  ?  0 : n cyto converted  /   ( double ) n cyto total ;  n cpg seen =  ( int ) cpg total . get sum of values (  )  ;  n cpg converted =  ( int ) cpg converted . get sum of values (  )  ;  cpg conversion rate = n cpg seen  =  =  0  ?  0 : n cpg converted  /   ( double ) n cpg seen ;  coverage mean = cpg total . get mean bin size (  )  ;  coverage median =  ( int ) cpg total . get median bin size (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java,get cur ref index,private int   ( final int ref start final int block length final int idx final boolean is negative )  {  return is negative  ?  ref start  +   ( block length  -  1 )   -  idx  -  1 : ref start  +  idx ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java,get fragment,private byte[]   ( final byte[] full array final int fragment start final int length )  {  return  arrays . copy of range ( full array fragment start fragment start  +  length )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java,get position,public  integer   (  )  {  return position ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java,get sequence,public  string   (  )  {  return sequence ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java,hash code,@ override public int   (  )  {  int result = sequence . hash code (  )  ;  result = 31 * result  +  position ;  return result ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java,is above cyto qc threshold,private boolean   ( final byte[] read qualities final int index )  {  return  (  ( index  <  read qualities . length  -  1 )  &&  ( read qualities[index]  >  =  c quality threshold )  &&  ( read qualities[index  +  1]  >  =  next base quality threshold )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java,isc,private boolean   ( final byte ref base final byte read base )  {  return  (  sequence util . bases equal ( ref base  sequence util . c )  &&  sequence util . bisulfite bases equal ( read base ref base )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java,is valid cpg,private boolean   ( final byte[] ref bases final byte[] read bases final byte[] read qualities final int index )  {  return isc ( ref bases[index] read bases[index] )  &&  sequence util . bases equal ( ref bases[index  +  1] read bases[index  +  1] )  && is above cyto qc threshold ( read qualities index )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\RrbsMetricsCollector.java,make child collector,@ override protected  per unit metric collector <  rrbs metrics  comparable <  ?  >  sam record and reference >    ( final  string sample final  string library final  string read group )  {  return new  per unit rrbs metrics collector ( sample library rea
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\AnnotationException.java, annotation exception,public   (  string message  throwable throwable )  {  super ( message throwable )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java, exon,public   ( final int start final int end )  {  this . start = start ;  this . end = end ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java, gene,public   ( final  string sequence final int start final int end final boolean negative final  string name )  {  super ( sequence start end negative name )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java, transcript,public   ( final  string name final int transcription start final int transcription end final int coding start final int coding end final int num exons )  {  this . name = name ;  this . transcription start = transcription start ;  this . transcription end = transcription end ;  this . coding start = coding start ;  this . coding end = coding end ;  this . exons = new  exon[num exons] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java,add coverage counts,public void   ( final int genome start final int genome end final int[] coverage )  {  for  ( int i = genome start ;  i  <  genome end ;   +  + i )   {  final int tx base = get transcript coordinate ( i )  ;  if  ( tx base  >  0 )  coverage[tx base  -  1] +  +  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java,add exon,"public  exon   ( final int start final int end )  {  for  ( int i = 0 ;  i  <  this . exons . length ;   +  + i )   {  if  ( exons[i]  =  =  null )   {  exons[i] = new  exon ( start end )  ;  this . length +  =  coord math . get length ( start end )  ;  return exons[i] ;   }   }  throw new  illegal state exception ( "" attempting to add more exons that exist for transcript . "" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java,add transcript,"public  transcript   ( final  string name final int transcription start final int transcription end final int coding start final int coding end final int num exons )  {  if  ( transcripts . contains key ( name )  )   {  throw new  annotation exception ( "" transcript ""  +  name  +  "" for gene "" +  this . get name (  )  +  "" appears more than once"" )  ;   }  else  {  final  transcript tx = new  transcript ( name transcription start transcription end coding start coding end num exons )  ;  transcripts . put ( name tx )  ;  return tx ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java,assign locus function for range,public void   ( final int start final  locus function[] locus functions )  {  for  ( int i =  math . max ( start transcription start )  ;  i  <  =   math . min ( transcription end  coord math . get end ( start locus functions . length )  )  ;   +  + i )   {  if  ( locus functions[i  -  start] . ordinal (  )   >   locus function . coding . ordinal (  )  )  continue ;  final  locus function locus function ;  if  ( in exon ( i )  )   {  if  ( utr ( i )  )  locus function =  locus function . utr ;  else locus function =  locus function . coding ;   }  else locus function =  locus function . intronic ;  if  ( locus function . ordinal (  )   >  locus functions[i  -  start] . ordinal (  )  )   {  locus functions[i  -  start] = locus function ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java,compare to,public int   ( final  gene that )  {  final int ret = super . compare to ( that )  ;  if  ( ret  !  =  0 )  return ret ;  return  boolean . value of ( this . is positive strand (  )  )  . compare to ( that . is positive strand (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java,end,public int   (  )  {  return exons[exons . length  -  1] . end ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java,equals,@ override public boolean   ( final  object o )  {  if  ( this  =  =  o )  return true ;  if  ( o  =  =  null || get class (  )   !  =  o . get class (  )  )  return false ;  final  transcript that =  (  transcript ) o ;  if  ( coding end  !  =  that . co
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java,get gene,public  gene   (  )  {  return  gene . this ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java,get transcript coordinate,public int   ( final int genome coordinate )  {  int exon offset = 0 ;  for  (  final  exon e : exons )   {  if  ( genome coordinate  >  =  e . start && genome coordinate  <  =  e . end )   {  return  ( genome coordinate  -  e . start  +  1 )   +  exon offset ;   }  else  {  exon offset +  =  coord math . get length ( e . start e . end )  ;   }   }  return  - 1 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java,hash code,@ override public int   (  )  {  int result = name . hash code (  )  ;  result = 31 * result  +  transcription start ;  result = 31 * result  +  transcription end ;  result = 31 * result  +  coding start ;  result = 31 * result  +  coding end ;  return re
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java,in exon,private boolean   ( final int locus )  {  for  ( int i = 0 ;  i  <  exons . length ;   +  + i )   {  final  exon exon = exons[i] ;  if  ( exon . start  >  locus )  return false ;  if  ( in range ( exon . start exon . end locus )  )  return true ;   }  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java,in range,private boolean   ( final int start final int end final int locus )  {  return  ( locus  >  =  start && locus  <  =  end )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java,is solo transcript,public boolean   (  )  {  return  gene . this . transcripts . size (  )   =  =  1 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java,iterator,public  iterator <  transcript >    (  )  {  return transcripts . values (  )  . iterator (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java,length,public int   (  )  {  return this . length ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java,start,public int   (  )  {  return exons[0] . start ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\Gene.java,utr,private boolean   ( final int locus )  {  return locus  <  coding start || locus  >  coding end ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\TheoreticalSensitivity.java, roulette wheel,"  ( final double[] weights )  {  rng = new  random ( 51 )  ;  n = weights . length ;  probabilities = new  array list <  >  (  )  ;  final double w max =  math util . max ( weights )  ;  if  ( w max  =  =  0 )   {  throw new  picard exception ( "" quality score distribution is empty . "" )  ;   }  for  (  final double w : weights )   {  probabilities . add ( w  /  w max )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\TheoreticalSensitivity.java,draw,public int   (  )  {  while  ( true )   {  final int n =  ( int )  ( n * rng . next double (  )  )  ;  count +  +  ;  if  ( rng . next double (  )   <  probabilities . get ( n )  )   {  count = 0 ;  return n ;   }  else if  ( count  >  =  sampling   max )   {  count = 0 ;  return 0 ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\TheoreticalSensitivity.java,het alt depth distribution,public static  list <  array list <  double >  >    ( final int n )  {  final  list <  array list <  double >  >  table = new  array list <  >  (  )  ;  for  ( int n = 0 ;  n  <  n ;  n +  +  )   {  final  array list <  double >  nth row = new  array list <  >  (  )  ;  nth row . add (  math . pow ( 0 . 5 n )  )  ;  for  ( int m = 1 ;  m  <  n ;  m +  +  )  nth row . add (  ( n * 0 . 5  /  m )  * table . get ( n  -  1 )  . get ( m  -  1 )  )  ;  if  ( n  >  0 )  nth row . add ( nth row . get ( 0 )  )  ;  table . add ( nth row )  ;   }  return table ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\TheoreticalSensitivity.java,hetsnp sensitivity,"public static double   ( final double[] depth distribution final double[] quality distribution final int sample size final double log odds threshold final boolean with logging )  {  final int n =  math . min ( depth distribution . length max   considered   depth  +  1 )  ;  if  ( with logging )  log . info ( "" creating  roulette  wheel"" )  ;  final  roulette wheel quality sampler = new  roulette wheel ( quality distribution )  ;  if  ( with logging )  log . info ( "" calculating quality sums from quality sampler"" )  ;  final  list <  array list <  integer >  >  quality sums = quality sampler . sample cumulative sums ( n sample size with logging )  ;  final  array list <  double >  quality sum thresholds = new  array list <  >  ( n )  ;  final double log   10 =  math . log10 ( 2 )  ;  for  ( int n = 0 ;  n  <  n ;  n +  +  )  quality sum thresholds . add ( 10 *  ( n * log   10  +  log odds threshold )  )  ;  if  ( with logging )  log . info ( "" calculating theoretical het sensitivity"" )  ;  final  list <  array list <  double >  >  probability to exceed threshold = proportions above thresholds ( quality sums quality sum thresholds )  ;  final  list <  array list <  double >  >  alt depth distribution = het alt depth distribution ( n )  ;  double result = 0 . 0 ;  for  ( int n = 0 ;  n  <  n ;  n +  +  )   {  for  ( int m = 0 ;  m  <  =  n ;  m +  +  )   {  result +  = depth distribution[n] * alt depth distribution . get ( n )  . get ( m )  * probability to exceed threshold . get ( m )  . get ( n )  ;   }   }  return result ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\TheoreticalSensitivity.java,normalize histogram,"public static double[]   ( final  histogram <  integer >  histogram )  {  if  ( histogram  =  =  null )  throw new  picard exception ( "" histogram is null and cannot be normalized"" )  ;  final double histogram sum of values = histogram . get sum of values (  )  ;  final double[] normalized histogram = new double[histogram . size (  ) ] ;  for  ( int i = 0 ;  i  <  histogram . size (  )  ;  i +  +  )   {  if  ( histogram . get ( i )   !  =  null )   {  normalized histogram[i] = histogram . get ( i )  . get value (  )   /  histogram sum of values ;   }   }  return normalized histogram ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\TheoreticalSensitivity.java,proportions above thresholds,public static  list <  array list <  double >  >    ( final  list <  array list <  integer >  >  lists final  list <  double >  thresholds )  {  final  array list <  array list <  double >  >  result = new  array list <  >  (  )  ;  for  (  final  array list <  integer >  list : lists )   {  final  array list <  double >  new row = new  array list <  >  (  collections . n copies ( thresholds . size (  )  0 . 0 )  )  ;   collections . sort ( list )  ;  int n = 0 ;  int j = 0 ;  while  ( n  <  thresholds . size (  )  && j  <  list . size (  )  )   {  if  ( thresholds . get ( n )   >  list . get ( j )  )  j +  +  ;  else new row . set ( n +  +   ( double )  ( list . size (  )   -  j )   /  list . size (  )  )  ;   }  result . add ( new row )  ;   }  return result ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\TheoreticalSensitivity.java,sample cumulative sums,"public  list <  array list <  integer >  >    ( final int max number of summands final int sample size final boolean with logging )  {  final  list <  array list <  integer >  >  result = new  array list <  >  (  )  ;  for  ( int m = 0 ;  m  <  max number of summands ;  m +  +  )  result . add ( new  array list <  >  (  )  )  ;  for  ( int iteration = 0 ;  iteration  <  sample size ;  iteration +  +  )   {  int cumulative sum = 0 ;  for  ( int m = 0 ;  m  <  max number of summands ;  m +  +  )   {  result . get ( m )  . add ( cumulative sum )  ;  cumulative sum +  = draw (  )  ;   }  if  ( with logging && iteration % 1000  =  =  0 )   {  log . info ( iteration  +  "" sampling iterations completed"" )  ;   }   }  return result ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\GeneAnnotationReader.java,load ref flat,public static  overlap detector <  gene >    (  file ref flat file sam sequence dictionary sequence dictionary )  {  return  ref flat reader . load ( ref flat file sequence dictionary )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\WgsMetricsProcessorImpl.java, wgs metrics processor impl,public   (  abstract locus iterator < t  abstract locus info < t >  >  iterator  reference sequence file walker ref walker  abstract wgs metrics collector < t >  collector  progress logger progress )  {  this . iterator = iterator ;  this . collector = collector ;  this . ref walker = ref walker ;  this . progress = progress ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\WgsMetricsProcessorImpl.java,add to metrics file,@ override public void   (  metrics file <  collect wgs metrics .  wgs metrics  integer >  file boolean includebq histogram  counting filter dupe filter  counting filter mapq filter  counting paired filter pair filter )  {  collector . add to metrics file
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\analysis\WgsMetricsProcessorImpl.java,process file,@ override public void   (  )  {  long counter = 0 ;  while  ( iterator . has next (  )  )   {  final  abstract locus info < t >  info = iterator . next (  )  ;  final  reference sequence ref = ref walker . get ( info . get sequence index (  )  )  ;  bool
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\argumentcollections\RequiredReferenceArgumentCollection.java,get reference file,public  file   (  )  {  return reference   sequence ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\argumentcollections\OptionalReferenceArgumentCollection.java,get reference file,@ override public  file   (  )  {  return reference   sequence ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\RefFlatReader.java, ref flat reader,  ( final  file ref flat file final sam sequence dictionary sequence dictionary )  {  this . ref flat file = ref flat file ;  this . sequence dictionary = sequence dictionary ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\RefFlatReader.java,is sequence recognized,private boolean   ( final  string sequence )  {  return  ( sequence dictionary . get sequence ( sequence )   !  =  null )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\RefFlatReader.java,load," overlap detector <  gene >    (  )  {  final  overlap detector <  gene >  overlap detector = new  overlap detector <  gene >  ( 0 0 )  ;  final int expected columns =  ref flat columns . values (  )  . length ;  final  tabbed text file with header parser parser = new  tabbed text file with header parser ( ref flat file  ref flat column labels )  ;  final  map <  string  list <  tabbed text file with header parser .  row >  >  ref flat lines by gene = new  hash map <  string  list <  tabbed text file with header parser .  row >  >  (  )  ;  for  (  final  tabbed text file with header parser .  row row : parser )   {  final int line number = parser . get current line number (  )  ;  if  ( row . get fields (  )  . length  !  =  expected columns )   {  throw new  annotation exception ( "" wrong number of fields in ref flat file ""  +  ref flat file  +  "" at line "" +  line number )  ;   }  final  string gene name = row . get field (  ref flat columns . gene   name . name (  )  )  ;  final  string transcript name = row . get field (  ref flat columns . transcript   name . name (  )  )  ;  final  string transcript description = gene name  +  "":""  +  transcript name ;  final  string chromosome = row . get field (  ref flat columns . chromosome . name (  )  )  ;  if  (  ! is sequence recognized ( chromosome )  )   {  log . debug ( "" skipping ""  +  transcript description  +  "" due to unrecognized sequence "" +  chromosome )  ;   }  else  {   list <  tabbed text file with header parser .  row >  transcript lines = ref flat lines by gene . get ( gene name )  ;  if  ( transcript lines  =  =  null )   {  transcript lines = new  array list <  tabbed text file with header parser .  row >  (  )  ;  ref flat lines by gene . put ( gene name transcript lines )  ;   }  transcript lines . add ( row )  ;   }   }  int longest interval = 0 ;  int num intervals over1mb = 0 ;  for  (  final  list <  tabbed text file with header parser .  row >  transcript lines : ref flat lines by gene . values (  )  )   {  try  {  final  gene gene = make gene from ref flat lines ( transcript lines )  ;  overlap detector . add lhs ( gene gene )  ;  if  ( gene . length (  )   >  longest interval )  longest interval = gene . length (  )  ;  if  ( gene . length (  )   >  1000000 )   +  + num intervals over1mb ;   }  catch  (   annotation exception e )   {  log . debug ( e . get message (  )   +  ""  -  -  skipping"" )  ;   }   }  log . debug ( "" longest gene: ""  +  longest interval  +  "" ;  number of genes  >  1mb: "" +  num intervals over1mb )  ;  return overlap detector ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\RefFlatReader.java,make gene from ref flat lines,"private  gene   ( final  list <  tabbed text file with header parser .  row >  transcript lines )  {  final  string gene name = transcript lines . get ( 0 )  . get field (  ref flat columns . gene   name . name (  )  )  ;  final  string strand str = transcript lines . get ( 0 )  . get field (  ref flat columns . strand . name (  )  )  ;  final boolean negative = strand str . equals ( "" - "" )  ;  final  string chromosome = transcript lines . get ( 0 )  . get field (  ref flat columns . chromosome . name (  )  )  ;  int start =  integer . max   value ;  int end =  integer . min   value ;  for  (  final  tabbed text file with header parser .  row row : transcript lines )   {  start =  math . min ( start row . get integer field (  ref flat columns . tx   start . name (  )  )   +  1 )  ;  end =  math . max ( end row . get integer field (  ref flat columns . tx   end . name (  )  )  )  ;   }  final  gene gene = new  gene ( chromosome start end negative gene name )  ;  for  (  final  tabbed text file with header parser .  row row : transcript lines )   {  if  (  ! strand str . equals ( row . get field (  ref flat columns . strand . name (  )  )  )  )   {  throw new  annotation exception ( "" strand disagreement in ref flat file for gene ""  +  gene name )  ;   }  if  (  ! chromosome . equals ( row . get field (  ref flat columns . chromosome . name (  )  )  )  )   {  throw new  annotation exception ( "" chromosome disagreement ( ""  +  chromosome  +  ""  !  =  "" +  row . get field (  ref flat columns . chromosome . name (  )  )  +  "" )  in ref flat file for gene "" +  gene name )  ;   }  final  transcript tx = make transcript from ref flat line ( gene row )  ;   }  return gene ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\annotation\RefFlatReader.java,make transcript from ref flat line,"private  gene .  transcript   ( final  gene gene final  tabbed text file with header parser .  row row )  {  final  string gene name = row . get field (  ref flat columns . gene   name . name (  )  )  ;  final  string transcript name = row . get field (  ref flat columns . transcript   name . name (  )  )  ;  final  string transcript description = gene name  +  "":""  +  transcript name ;  final int exon count =  integer . parse int ( row . get field (  ref flat columns . exon   count . name (  )  )  )  ;  final  string[] exon starts = row . get field (  ref flat columns . exon   starts . name (  )  )  . split ( "" "" )  ;  final  string[] exon ends = row . get field (  ref flat columns . exon   ends . name (  )  )  . split ( "" "" )  ;  if  ( exon count  !  =  exon starts . length )   {  throw new  annotation exception ( "" number of exon starts does not agree with number of exons for ""  +  transcript description )  ;   }  if  ( exon count  !  =  exon ends . length )   {  throw new  annotation exception ( "" number of exon ends does not agree with number of exons for ""  +  transcript description )  ;   }  final int transcription start = row . get integer field (  ref flat columns . tx   start . name (  )  )   +  1 ;  final int transcription end = row . get integer field (  ref flat columns . tx   end . name (  )  )  ;  final int coding start = row . get integer field (  ref flat columns . cds   start . name (  )  )   +  1 ;  final int coding end = row . get integer field (  ref flat columns . cds   end . name (  )  )  ;  final  transcript tx = gene . add transcript ( transcript name transcription start transcription end coding start coding end exon count )  ;  for  ( int i = 0 ;  i  <  exon count ;   +  + i )   {  final  exon e = tx . add exon (  integer . parse int ( exon starts[i] )   +  1  integer . parse int ( exon ends[i] )  )  ;  if  ( e . start  >  e . end )   {  throw new  annotation exception ( "" exon has 0 or negative extent for ""  +  transcript description )  ;   }  if  ( i  >  0 && tx . exons[i  -  1] . end  >  =  tx . exons[i] . start )   {  throw new  annotation exception ( "" exons overlap for ""  +  transcript description )  ;   }   }  return tx ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\CommandLineDefaults.java,get boolean property,private static boolean   ( final  string name final boolean def )  {  final  string value = get string property ( name  string . value of ( def )  )  ;  return  boolean . parse boolean ( value )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\CommandLineDefaults.java,get file property,private static  file   ( final  string name final  string def )  {  final  string value = get string property ( name def )  ;  return  ( null  =  =  value )   ?  null : new  file ( value )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\CommandLineDefaults.java,get int property,private static int   ( final  string name final int def )  {  final  string value = get string property ( name  string . value of ( def )  )  ;  return  integer . parse int ( value )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\CommandLineDefaults.java,get string property,"private static  string   ( final  string name final  string def )  {  return  system . get property ( ""picard . cmdline . ""  +  name def )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\ClassFinder.java, class finder,public   ( final  file jar file )  throws io exception  {  jar path = jar file . get canonical path (  )  ;  final url[] urls =  { new  file ( jar path )  . touri (  )  . tourl (  )  }  ;  loader = new url class loader ( urls  thread . current thread (  )  . get context class loader (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\ClassFinder.java,find,"public void   (  string package name final  class <  ?  >  parent type )  {  this . parent type = parent type ;  package name = package name . replace ( ' . ' ' / ' )  ;  final  enumeration < url >  urls ;  try  {  urls = loader . get resources ( package name )  ;   }  catch  (  io exception ioe )   {  log . warn ( "" could not read package: ""  +  package name ioe )  ;  return ;   }  while  ( urls . has more elements (  )  )   {  try  {   string url path = urls . next element (  )  . get file (  )  ;  try  {  uri uri = new uri ( url path )  ;  url path = uri . get path (  )  ;   }  catch  (  uri syntax exception e )   {  log . warn ( "" cannot convert to uri the ""  +  url path  +  "" url"" )  ;   }  if  ( url path . index of ( ' ! ' )   >  0 )   {  url path = url path . substring ( 0 url path . index of ( ' ! ' )  )  ;   }  if  ( jar path  !  =  null &&  ! jar path . equals ( url path )  )   {  continue ;   }  final  file file = new  file ( url path )  ;  if  ( file . is directory (  )  )   {  scan dir ( file package name )  ;   }  else  {  scan jar ( file package name )  ;   }   }  catch  (  io exception ioe )   {  log . warn ( ""could not read entries"" ioe )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\ClassFinder.java,get classes,public  set <  class <  ?  >  >    (  )  {  return this . classes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\ClassFinder.java,handle item,"protected void   ( final  string name )  {  if  ( name . ends with ( "" . class"" )  )   {  final  string classname = to class name ( name )  ;  try  {  final  class <  ?  >  type = loader . load class ( classname )  ;  if  ( parent type . is assignable from ( type )  )   {  this . classes . add ( type )  ;   }   }  catch  (   throwable t )   {  log . debug ( ""could not load class: ""  +  classname t )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\ClassFinder.java,scan dir,protected void   ( final  file file final  string path )  {  for  (  final  file child : file . list files (  )  )   {  final  string new path =  ( path  =  =  null  ?  child . get name (  )  : path  +  ' / '  +  child . get name (  )  )  ;  if  ( child . is directory (  )  )   {  scan dir ( child new path )  ;   }  else  {  handle item ( new path )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\ClassFinder.java,scan jar,protected void   ( final  file file final  string package path )  throws io exception  {  final  zip file zip = new  zip file ( file )  ;  final  enumeration <  ?  extends  zip entry >  entries = zip . entries (  )  ;  while  ( entries . has more elements (  )  )   {  final  zip entry entry = entries . next element (  )  ;  final  string name = entry . get name (  )  ;  if  ( name . starts with ( package path )  )   {  handle item ( name )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\ClassFinder.java,to class name,"public  string   ( final  string filename )  {  return filename . substring ( 0 filename . last index of ( "" . class"" )  )  . replace ( ' / ' ' . ' )  . replace ( '\\' ' . ' )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\CommandLineSyntaxTranslater.java,translate picard style to posix style,"public static  string[]   ( final  string argv[] )  {  final  list <  string >  converted args =  arrays . stream ( argv )  . flat map ( original arg pair  -  >   {  final  string[] split arg pair = original arg pair . split ( "" = ""  - 1 )  ;  if  ( split arg pair . length  =  =  1 )   {  return  arrays . stream ( new  string[] { original arg pair }  )  ;   }  else if  ( split arg pair . length  =  =  2 )   {  return  arrays . stream ( new  string[] { "" - ""  +  split arg pair[0] split arg pair[1] }  )  ;   }  else  {  throw new  runtime exception ( "" argument syntax conversion failed .   too many \"" = \"" separated tokens to translate: ""  +  original arg pair )  ;   }   }   )  . collect (  collectors . to list (  )  )  ;  return converted args . to array ( new  string[converted args . size (  ) ] )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\CommandLineProgram.java,custom command line validation,protected  string[]   (  )  {  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\DiagnosticsAndQCProgramGroup.java,get description,@ override public  string   (  )  {  return  help constants . doc   cat   diagnostics   and   qc   summary ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\DiagnosticsAndQCProgramGroup.java,get name,@ override public  string   (  )  {  return  help constants . doc   cat   diagnostics   and   qc ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\PicardCommandLine.java,compare,@ override public int   ( final  class a class final  class b class )  {  return a class . get simple name (  )  . compare to ( b class . get simple name (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\PicardCommandLine.java,extract command line program,"private static  command line program   ( final  string[] args final  list <  string >  package list final  string command line name )  {  final  map <  string  class <  ?  >  >  simple name to class = new  hash map <  >  (  )  ;  final  list <  string >  missing annotation classes = new  array list <  >  (  )  ;  process all command line programs ( package list  (   class <  command line program >  clazz   command line program properties cl properties )   -  >   {  if  ( null  =  =  cl properties )   {  missing annotation classes . add ( clazz . get simple name (  )  )  ;   }  else if  (  ! cl properties . omit from command line (  )  )   {  if  ( simple name to class . contains key ( clazz . get simple name (  )  )  )   {  throw new  runtime exception ( "" simple class name collision: ""  +  clazz . get simple name (  )  )  ;   }  simple name to class . put ( clazz . get simple name (  )  clazz )  ;   }   }   )  ;  if  (  ! missing annotation classes . is empty (  )  )   {  throw new  runtime exception ( "" the following classes are missing the required  command line program properties annotation: ""  +  missing annotation classes . stream (  )  . collect (  collectors . joining (  ( ""  "" )  )  )  )  ;   }  final  set <  class <  ?  >  >  classes = new  hash set <  >  (  )  ;  classes . add all ( simple name to class . values (  )  )  ;  if  ( args . length  <  1 )   {  print usage ( classes command line name )  ;   }  else  {  if  ( args[0] . equals ( "" - h"" )  )   {  print usage ( classes command line name )  ;   }  else if  ( args[0] . equals ( "" -  - list - commands"" )  )   {  print command list ( classes )  ;   }  else  {  if  ( simple name to class . contains key ( args[0] )  )   {  final  class clazz = simple name to class . get ( args[0] )  ;  try  {  return  (  command line program ) clazz . new instance (  )  ;   }  catch  (  final  instantiation exception e )   {  throw new  runtime exception ( e )  ;   }  catch  (  final  illegal access exception e )   {  throw new  runtime exception ( e )  ;   }   }  print usage ( classes command line name )  ;  print unknown ( classes args[0] )  ;   }   }  return null ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\PicardCommandLine.java,get package list,"protected static  list <  string >    (  )  {  final  list <  string >  package list = new  array list <  string >  (  )  ;  package list . add ( ""picard"" )  ;  return package list ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\PicardCommandLine.java,get program property,public static  command line program properties   (  class clazz )  {  return  (  command line program properties ) clazz . get annotation (  command line program properties . class )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\PicardCommandLine.java,get tool summary prefix,"private static  string   (  class <  ?  >  clazz )  {  if  ( clazz . get annotation (  experimental feature . class )   !  =  null )   {  return experimental   prefix ;   }  if  ( clazz . get annotation (  beta feature . class )   !  =  null )   {  return beta   prefix ;   }  return """" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\PicardCommandLine.java,initialize color,"private static  string   ( final  string color )  {  if  (  command line defaults . color   status )  return color ;  else return """" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\PicardCommandLine.java,instance main,protected int   ( final  string[] args )  {  return instance main ( args get package list (  )  command   line   name )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\PicardCommandLine.java,main,public static void   ( final  string[] args )  {   system . exit ( new  picard command line (  )  . instance main ( args get package list (  )  command   line   name )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\PicardCommandLine.java,print command list,private static void   ( final  set <  class <  ?  >  >  classes )  {  print usage ( classes null true true )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\PicardCommandLine.java,print unknown,"public static void   ( final  set <  class <  ?  >  >  classes final  string command )  {  final  map <  class  integer >  distances = new  hash map <  class  integer >  (  )  ;  int best distance =  integer . max   value ;  int bestn = 0 ;  for  (  final  class clazz : classes )   {  final  string name = clazz . get simple name (  )  ;  final int distance ;  if  ( name . equals ( command )  )   {  throw new  runtime exception ( "" command matches: ""  +  command )  ;   }  if  ( name . starts with ( command )  ||  ( minimum   substring   length  <  =  command . length (  )  && name . contains ( command )  )  )   {  distance = 0 ;   }  else  {  distance =  string util . levenshtein distance ( command name 0 2 1 4 )  ;   }  distances . put ( clazz distance )  ;  if  ( distance  <  best distance )   {  best distance = distance ;  bestn = 1 ;   }  else if  ( distance  =  =  best distance )   {  bestn +  +  ;   }   }  if  ( 0  =  =  best distance && bestn  =  =  classes . size (  )  )   {  best distance = help   similarity   floor  +  1 ;   }   system . err . println (  string . format ( ""'%s' is not a valid command .   see  picard command line  - h for more information . "" command )  )  ;  if  ( best distance  <  help   similarity   floor )   {   system . err . println (  string . format ( "" did you mean %s ? ""  ( bestn  <  2 )   ?  ""this"" : ""one of these"" )  )  ;  for  (  final  class clazz : classes )   {  if  ( best distance  =  =  distances . get ( clazz )  )   {   system . err . println (  string . format ( "" %s"" clazz . get simple name (  )  )  )  ;   }   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\PicardCommandLine.java,print usage,"private static void   ( final  set <  class <  ?  >  >  classes final  string command line name boolean command list only boolean to stdout )  {  final  string builder builder = new  string builder (  )  ;  if  (  ! command list only )   {  builder . append ( kbldred  +  ""usage: ""  +  command line name +  "" "" +  kgrn +  "" < program name > "" +  kbldred +  "" [ - h]\n\n"" +  knrm )  ;  builder . append ( kbldred  +  "" available  programs:\n""  +  knrm )  ;   }  final  map <  class <  ?  extends  command line program group >   command line program group >  program group class to program group instance = new  hash map <  class <  ?  extends  command line program group >   command line program group >  (  )  ;  final  map <  command line program group  list <  class >  >  programs by group = new  tree map <  command line program group  list <  class >  >  (  command line program group . comparator )  ;  final  map <  class  command line program properties >  programs to property = new  hash map <  class  command line program properties >  (  )  ;  for  (  final  class clazz : classes )   {  final  command line program properties property = get program property ( clazz )  ;  if  ( null  =  =  property )   {  throw new  runtime exception (  string . format ( "" the class '%s' is missing the required  command line program properties annotation . "" clazz . get simple name (  )  )  )  ;   }  programs to property . put ( clazz property )  ;   command line program group program group = program group class to program group instance . get ( property . program group (  )  )  ;  if  ( null  =  =  program group )   {  try  {  program group = property . program group (  )  . new instance (  )  ;   }  catch  (  final  instantiation exception e )   {  throw new  runtime exception ( e )  ;   }  catch  (  final  illegal access exception e )   {  throw new  runtime exception ( e )  ;   }  program group class to program group instance . put ( property . program group (  )  program group )  ;   }   list <  class >  programs = programs by group . get ( program group )  ;  if  ( null  =  =  programs )   {  programs by group . put ( program group programs = new  array list <  class >  (  )  )  ;   }  programs . add ( clazz )  ;   }  for  (   map .  entry <  command line program group  list <  class >  >  entry : programs by group . entry set (  )  )   {  final  command line program group program group = entry . get key (  )  ;  if  (  ! command list only )   {  builder . append ( kwht  +  "" -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - \n""  +  knrm )  ;  builder . append (  string . format ( ""%s% - 48s % - 45s%s\n"" kred program group . get name (  )   +  "":"" program group . get description (  )  knrm )  )  ;   }  final  list <  class >  sorted classes = new  array list <  class >  (  )  ;  sorted classes . add all ( entry . get value (  )  )  ;   collections . sort ( sorted classes new  simple name comparator (  )  )  ;  for  (  final  class clazz : sorted classes )   {  final  command line program properties property = programs to property . get ( clazz )  ;  if  ( null  =  =  property )   {  throw new  runtime exception (  string . format ( "" unexpected error: did not find the  command line program properties annotation for '%s'"" clazz . get simple name (  )  )  )  ;   }  if  (  ! command list only )   {  builder . append (  string . format ( clazz . get simple name (  )  . length (  )   >  =  45  ?  ""%s %s %s%s%s%s%s\n"" : ""%s % - 45s%s%s%s%s%s\n"" kgrn clazz . get simple name (  )  kred get tool summary prefix ( clazz )  kcyn property . one line summary (  )  knrm )  )  ;   }  else  {  builder . append ( clazz . get simple name (  )   +  ""\n"" )  ;   }   }  if  (  ! command list only )  builder . append (  string . format ( ""\n"" )  )  ;   }  if  (  ! command list only )  builder . append ( kwht  +  "" -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - \n\n""  +  knrm )  ;  if  ( to stdout )   {   system . out . print ( builder . to string (  )  )  ;   }  else  {   system . err . print ( builder . to string (  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\PicardCommandLine.java,process all command line programs,public static void   ( final  list <  string >  package list final  bi consumer <  class <  command line program >   command line program properties >  clp class processor )  {  final  class finder class finder = new  class finder (  )  ;  package list . for each ( pkg  -  >  class finder . find ( pkg  command line program . class )  )  ;  for  (  final  class clazz : class finder . get classes (  )  )   {  if  (  ! clazz . is interface (  )  &&  ! clazz . is synthetic (  )  &&  ! clazz . is primitive (  ) &&  ! clazz . is local class (  ) &&  !  modifier . is abstract ( clazz . get modifiers (  )  )  )   {  clp class processor . accept ( clazz  picard command line . get program property ( clazz )  )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\BaseCallingProgramGroup.java,get description,@ override public  string   (  )  {  return  help constants . doc   cat   base   calling   summary ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\BaseCallingProgramGroup.java,get name,@ override public  string   (  )  {  return  help constants . doc   cat   base   calling ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\OtherProgramGroup.java,get description,@ override public  string   (  )  {  return  help constants . doc   cat   other   summary ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\OtherProgramGroup.java,get name,@ override public  string   (  )  {  return  help constants . doc   cat   other ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\ReadDataManipulationProgramGroup.java,get description,@ override public  string   (  )  {  return  help constants . doc   cat   read   data   manipulation   summary ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\ReadDataManipulationProgramGroup.java,get name,@ override public  string   (  )  {  return  help constants . doc   cat   read   data   manipulation ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\IntervalsManipulationProgramGroup.java,get description,@ override public  string   (  )  {  return  help constants . doc   cat   intervals   manipulation   summary ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\IntervalsManipulationProgramGroup.java,get name,@ override public  string   (  )  {  return  help constants . doc   cat   intervals   manipulation ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\VariantFilteringProgramGroup.java,get description,@ override public  string   (  )  {  return  help constants . doc   cat   variant   filtering   summary ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\VariantFilteringProgramGroup.java,get name,@ override public  string   (  )  {  return  help constants . doc   cat   variant   filtering ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\ReferenceProgramGroup.java,get description,@ override public  string   (  )  {  return  help constants . doc   cat   reference   summary ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\ReferenceProgramGroup.java,get name,@ override public  string   (  )  {  return  help constants . doc   cat   reference ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\Testing.java,get description,@ override public  string   (  )  {  return  help constants . doc   cat   test   summary ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\Testing.java,get name,@ override public  string   (  )  {  return  help constants . doc   cat   test ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\VariantManipulationProgramGroup.java,get description,@ override public  string   (  )  {  return  help constants . doc   cat   variant   manipulation   summary ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\VariantManipulationProgramGroup.java,get name,@ override public  string   (  )  {  return  help constants . doc   cat   variant   manipulation ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\VariantEvaluationProgramGroup.java,get description,@ override public  string   (  )  {  return  help constants . doc   cat   variant   evaluation   summary ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\cmdline\programgroups\VariantEvaluationProgramGroup.java,get name,@ override public  string   (  )  {  return  help constants . doc   cat   variant   evaluation ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\BamToBfqWriter.java, bam to bfq writer,public   ( final  file bam file final  string output prefix final boolean paired reads  string name prefix boolean include non pf reads )  {  this ( bam file output prefix null null paired reads name prefix include non pf reads true null )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\BamToBfqWriter.java,count writable records,"private int   (  )  {  int count = 0 ;  final  sam reader reader =  sam reader factory . make default (  )  . open ( this . bam file )  ;  if  (  ! reader . get file header (  )  . get sort order (  )  . equals ( sam file header .  sort order . queryname )  )   {  throw new  picard exception ( "" input file  ( ""  +  this . bam file . get absolute path (  )   +  "" )  needs to be sorted by queryname . "" )  ;   }  final  peekable iterator < sam record >  it = new  peekable iterator < sam record >  ( reader . iterator (  )  )  ;  if  (  ! this . paired reads )   {  final  list <  sam record filter >  filters = new  array list <  sam record filter >  (  )  ;  filters . add ( new  tag filter (  reserved tag constants . xn 1 )  )  ;  if  (  ! this . include non pf reads )   {  filters . add ( new  fails vendor read quality filter (  )  )  ;   }  final  filtering sam iterator itr = new  filtering sam iterator ( it new  aggregate filter ( filters )  )  ;  while  ( itr . has next (  )  )   {  itr . next (  )  ;  count +  +  ;   }   }  else  {  while  ( it . has next (  )  )   {  final sam record first = it . next (  )  ;  final sam record second = it . next (  )  ;  if  ( first . get attribute (  reserved tag constants . xn )   !  =  null && second . get attribute (  reserved tag constants . xn )   !  =  null )   {   }  else if  (  ! this . include non pf reads &&  ( first . get read fails vendor quality check flag (  )  || second . get read fails vendor quality check flag (  )  )  )   {   }  else  {  count +  +  ;   }   }   }  it . close (  )  ;   closer util . close ( reader )  ;  return count ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\BamToBfqWriter.java,encode base and quality,private byte   ( int base int quality )  {  return  ( byte )  (  ( base  <  <  6 )  | quality )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\BamToBfqWriter.java,encode seqs and quals,"private byte[]   ( char[] seqs char[] quals int retained length )  {  final byte[] seqs and quals = new byte[bases to write  =  =  null  ?  seqs . length : bases to write] ;  int seed region no call fixes = 0 ;  for  ( int i = 0 ;  i  <  retained length && i  <  seqs and quals . length ;  i +  +  )   {  int quality =  math . min ( quals[i]  -  33 63 )  ;  final int base ;  switch  ( seqs[i] )   {  case 'a': case 'a': base = 0 ;  break ;  case 'c': case 'c': base = 1 ;  break ;  case 'g': case 'g': base = 2 ;  break ;  case 't': case 't': base = 3 ;  break ;  case 'n': case 'n': case ' . ': base = 0 ;  if  ( i  <  seed   region   length )   {  if  ( seed region no call fixes  <  max   seed   region   nocall   fixes )   {  quality = 1 ;  seed region no call fixes +  +  ;   }  else  {  quality = 0 ;   }   }  else  {  quality = 1 ;   }  break ;  default : throw new  picard exception ( "" unknown base when writing bfq file: ""  +  seqs[i] )  ;   }  seqs and quals[i] = encode base and quality ( base quality )  ;   }  for  ( int i = retained length ;  i  <  seqs and quals . length ;  i +  +  )   {  seqs and quals[i] = encode base and quality ( 0 1 )  ;   }  return seqs and quals ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\BamToBfqWriter.java,get output file,"private  file   ( final  string output prefix final int read final int index )  {  final  file result = new  file ( output prefix  +  index  +  "" . "" +  read +  "" . bfq"" )  ;  io util . assert file is writable ( result )  ;  return result ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\BamToBfqWriter.java,initialize next bfq files,"private void   ( final int file index )  {  if  ( codec1  !  =  null )   {  codec1 . close (  )  ;  if  ( paired reads )   {  codec2 . close (  )  ;   }   }  final  file bfq1 = get output file ( this . output prefix 1 file index )  ;  codec1 = new  binary codec ( io util . open file for writing ( bfq1 )  )  ;  log . info ( "" now writing to file ""  +  bfq1 . get absolute path (  )  )  ;  if  ( paired reads )   {  final  file bfq2 = get output file ( this . output prefix 2 file index )  ;  codec2 = new  binary codec ( io util . open file for writing ( bfq2 )  )  ;  log . info ( "" now writing to file ""  +  bfq2 . get absolute path (  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\BamToBfqWriter.java,write bfq files,"public void   (  )  {  final  sam reader reader =  sam reader factory . make default (  )  . open ( bam file )  ;  final  iterator < sam record >  iterator = reader . iterator (  )  ;  final  tag filter tag filter = new  tag filter (  reserved tag constants . xn 1 )  ;  final  fails vendor read quality filter quality filter = new  fails vendor read quality filter (  )  ;  final  whole read clipped filter clipped filter = new  whole read clipped filter (  )  ;  if  (  ! paired reads )   {   list <  sam record filter >  filters = new  array list <  sam record filter >  (  )  ;  filters . add ( tag filter )  ;  filters . add ( clipped filter )  ;  if  (  ! this . include non pf reads )   {  filters . add ( quality filter )  ;   }  write single end bfqs ( iterator filters )  ;  codec1 . close (  )  ;   }  else  {  write paired end bfqs ( iterator tag filter quality filter clipped filter )  ;  codec1 . close (  )  ;  codec2 . close (  )  ;   }  log . info ( "" wrote ""  +  wrote  +  "" bfq records . "" )  ;   closer util . close ( reader )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\BamToBfqWriter.java,write fastq record,private void   ( final  binary codec codec final sam record rec )  {   string read name = rec . get read name (  )  ;  if  ( name prefix  !  =  null && read name . starts with ( name prefix )  )   {  read name = read name . substring ( name trim )  ;   }  codec . write string ( read name true true )  ;  final char[] seqs = rec . get read string (  )  . to char array (  )  ;  final char[] quals = rec . get base quality string (  )  . to char array (  )  ;  int retained length = seqs . length ;  if  ( clip adapters )   {   integer trim point = rec . get integer attribute (  reserved tag constants . xt )  ;  if  ( trim point  !  =  null )   {  assert  ( rec . get read length (  )   =  =  seqs . length )  ;  retained length =  math . min ( seqs . length  math . max ( seed   region   length trim point  -  1 )  )  ;   }   }  codec . write int ( bases to write  !  =  null  ?  bases to write : seqs . length )  ;  final byte[] seqs and quals = encode seqs and quals ( seqs quals retained length )  ;  codec . write bytes ( seqs and quals )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\BamToBfqWriter.java,write paired end bfqs,"private void   ( final  iterator < sam record >  iterator final  tag filter tag filter final  fails vendor read quality filter quality filter  sam record filter .  .  .  other filters )  {  int file index = 0 ;  initialize next bfq files ( file index +  +  )  ;  int records = 0 ;  record   loop: while  ( iterator . has next (  )  )   {  final sam record first = iterator . next (  )  ;  if  (  ! iterator . has next (  )  )   {  throw new  picard exception ( "" mismatched number of records in ""  +  this . bam file . get absolute path (  )  )  ;   }  final sam record second = iterator . next (  )  ;  if  (  ! second . get read name (  )  . equals ( first . get read name (  )  )  || first . get first of pair flag (  )   =  =  second . get first of pair flag (  )  )   {  throw new  picard exception ( "" unmatched read pairs in ""  +  this . bam file . get absolute path (  )   +  "": "" +  first . get read name (  )  +  ""  "" +  second . get read name (  )  +  "" . "" )  ;   }  if  ( tag filter . filter out ( first )  && tag filter . filter out ( second )  )   {  continue ;   }  if  (  ! include non pf reads &&  ( quality filter . filter out ( first )  || quality filter . filter out ( second )  )  )   {  continue ;   }  for  (   sam record filter filter : other filters )   {  if  ( filter . filter out ( first )  || filter . filter out ( second )  )   {  continue record   loop ;   }   }  records +  +  ;  if  ( records % increment  =  =  0 )   {  first . set read name ( first . get read name (  )   +  "" / 1"" )  ;  write fastq record ( first . get first of pair flag (  )   ?  codec1 : codec2 first )  ;  second . set read name ( second . get read name (  )   +  "" / 2"" )  ;  write fastq record ( second . get first of pair flag (  )   ?  codec1 : codec2 second )  ;  wrote +  +  ;  if  ( wrote % 1000000  =  =  0 )   {  log . info ( wrote  +  "" records written . "" )  ;   }  if  ( chunk  >  0 && wrote % chunk  =  =  0 )   {  initialize next bfq files ( file index +  +  )  ;   }   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\BamToBfqWriter.java,write single end bfqs,"private void   ( final  iterator < sam record >  iterator final  list <  sam record filter >  filters )  {  int file index = 0 ;  initialize next bfq files ( file index +  +  )  ;  int records = 0 ;  final  filtering sam iterator it = new  filtering sam iterator ( iterator new  aggregate filter ( filters )  )  ;  while  ( it . has next (  )  )   {  final sam record record = it . next (  )  ;  records +  +  ;  if  ( records % increment  =  =  0 )   {  record . set read name ( record . get read name (  )   +  "" / 1"" )  ;  write fastq record ( codec1 record )  ;  wrote +  +  ;  if  ( wrote % 1000000  =  =  0 )   {  log . info ( wrote  +  "" records processed . "" )  ;   }  if  ( chunk  >  0 && wrote % chunk  =  =  0 )   {  initialize next bfq files ( file index +  +  )  ;   }   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\BamToBfq.java,custom command line validation,"protected  string[]   (  )  {  if  ( output   file   prefix  =  =  null )   {  output   file   prefix = flowcell   barcode  +  "" . ""  +  lane ;   }  if  ( read   name   prefix  =  =  null )   {  read   name   prefix = run   barcode  +  "":"" ;   }  return null ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\BamToBfq.java,do work,"protected int   (  )  {   string output prefix = analysis   dir . get absolute path (  )  ;  if  (  ! output prefix . ends with ( "" / "" )  )   {  output prefix +  = "" / "" ;   }  output prefix +  = output   file   prefix  +  "" . "" ;   bam to bfq writer writer = new  bam to bfq writer ( input output prefix reads   to   align read   chunk   size paired   run read   name   prefix include   non   pf   reads clip   adapters bases   to   write )  ;  writer . write bfq files (  )  ;  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\BamToBfq.java,main,public static void   (  string[] argv )  {   system . exit ( new  bam to bfq (  )  . instance main ( argv )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\Casava18ReadNameEncoder.java, casava read name encoder,public   ( final  string instrument name final  string run id final  string flowcell id )  {  this . run id = run id ;  this . instrument name = instrument name ;  this . flowcell id = flowcell id ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\Casava18ReadNameEncoder.java,generate read name,"@ override public  string   ( final  cluster data cluster final  integer pair number )  {  return new  string builder (  )  . append ( instrument name )  . append ( "":"" )  . append ( run id )  . append ( "":"" )  . append ( flowcell id )  . append ( "":"" )  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\Casava18ReadNameEncoder.java,get,static  is filtered label   ( final boolean passes filter )  {  return passes filter  ?  n : y ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\filter\CountingDuplicateFilter.java,really filter out,@ override public boolean   ( final sam record record )  {  return record . get duplicate read flag (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\IlluminaReadNameEncoder.java, illumina read name encoder,public   ( final  string run barcode )  {  this . run barcode = run barcode ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\IlluminaReadNameEncoder.java,generate pair number suffix,"private static  string   ( final  integer pair number )  {  if  ( pair number  =  =  null )  return """" ;  else return "" / ""  +  pair number ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fastq\IlluminaReadNameEncoder.java,generate read name,"@ override public  string   ( final  cluster data cluster final  integer pair number )  {  return run barcode  +  "":""  +  cluster . get lane (  )  +  "":"" +  cluster . get tile (  )  +  "":"" +  cluster . getx (  )  +  "":"" +  cluster . gety (  )  +  generate"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\filter\CountingFilter.java,filter out,@ override public boolean   ( final sam record first final sam record second )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\filter\CountingFilter.java,get filtered bases,public long   (  )  {  return this . filtered bases ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\filter\CountingFilter.java,get filtered records,public long   (  )  {  return this . filtered records ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\filter\CountingMapQFilter.java, counting mapq filter,public   ( final int min mapq )  {  this . min mapq = min mapq ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\filter\CountingMapQFilter.java,really filter out,@ override public boolean   ( final sam record record )  {  return record . get mapping quality (  )   <  min mapq ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CheckFingerprint.java,custom command line validation,"protected  string[]   (  )  {  try  {  final boolean is bam or sam file = is bam or sam ( io util . get path ( input )  )  ;  if  (  ! is bam or sam file && ignore   read   groups )   {  return new  string[] { "" the parameter ignore   read   groups can only be used with bam / sam inputs . "" }  ;   }  if  ( is bam or sam file && observed   sample   alias  !  =  null )   {  return new  string[] { "" the parameter observed   sample   alias can only be used with a vcf input . "" }  ;   }   }  catch  (  io exception e )   {  e . print stack trace (  )  ;   }  return super . custom command line validation (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CheckFingerprint.java,do work,@ override protected int   (  )  {  final  file output detail metrics file  output summary metrics file ;  if  ( output  =  =  null )   {  output detail metrics file = detail   output ;  output summary metrics file = summary   output ;   }  else  {  if  (
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CheckFingerprint.java,is bam or sam,static boolean   ( final  path p )  {  return  ( p . to uri (  )  . get raw path (  )  . ends with (  bam file io utils . bam   file   extension )  || p . to uri (  )  . get raw path (  )  . ends with ( io util . sam   file   extension )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\filter\CountingPairedFilter.java,really filter out,@ override public boolean   ( final sam record record )  {  return  ! record . get read paired flag (  )  || record . get mate unmapped flag (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\ClusteredCrosscheckMetric.java, clustered crosscheck metric,public   (  crosscheck metric metric )  {  super (  )  ;   reflection util . copy from base class ( metric this )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\ClusterCrosscheckMetrics.java,cluster metrics,private  metrics file <  clustered crosscheck metric  ?  >    ( final  list <  crosscheck metric >  metrics )  {  final  graph utils .  graph <  string >  graph = new  graph utils .  graph <  >  (  )  ;  metrics . stream (  )  . filter ( metric  -  >  metric . lod   score  >  lod   threshold )  . for each ( metric  -  >   {  final  string lhs by = metric . left   group   value ;  final  string rhs by = metric . right   group   value ;  graph . add edge ( lhs by rhs by )  ;   }   )  ;  final  map <  string  integer >  clusters = graph . cluster (  )  ;  final  map <  integer  set <  string >  >  collection = clusters . entry set (  )  . stream (  )  . collect (  collectors . grouping by (  map .  entry::get value )  )  . entry set (  )  . stream (  )  . collect (  collectors . to map (  map .  entry::get key entry  -  >  entry . get value (  )  . stream (  )  . map (  map .  entry::get key )  . collect (  collectors . to set (  )  )  )  )  ;  final  metrics file <  clustered crosscheck metric  ?  >  clustered metrics = get metrics file (  )  ;  for  (  final  map .  entry <  integer  set <  string >  >  cluster : collection . entry set (  )  )   {  clustered metrics . add all metrics ( metrics . stream (  )  . filter ( metric  -  >  cluster . get value (  )  . contains ( metric . left   group   value )  && cluster . get value (  )  . contains ( metric . right   group   value )  )  . map ( metric  -  >   {  final  clustered crosscheck metric clustered crosscheck metric = new  clustered crosscheck metric ( metric )  ;  clustered crosscheck metric . cluster = cluster . get key (  )  ;  clustered crosscheck metric . cluster   size = cluster . get value (  )  . size (  )  ;  return clustered crosscheck metric ;   }   )  . collect (  collectors . to set (  )  )  )  ;   }  return clustered metrics ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\ClusterCrosscheckMetrics.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  if  ( output  !  =  null )  io util . assert file is writable ( output )  ;  final  metrics file <  crosscheck metric  ?  >  metrics file = get metrics file (  )  ;  try  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CrosscheckMetric.java, fingerprint result,  (  boolean is expected  boolean is match )  {  this . is expected = is expected ;  this . is match = is match ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CrosscheckMetric.java,is expected,public  boolean   (  )  {  return is expected ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CrosscheckMetric.java,is match,public  boolean   (  )  {  return is match ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\DiploidGenotype.java, diploid genotype,private   ( final char allele1 final char allele2 )  {  this . allele1 =  ( byte )  ( allele1 & 0xff )  ;  this . allele2 =  ( byte )  ( allele2 & 0xff )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\DiploidGenotype.java,from bases,"public static  diploid genotype   ( final byte base1 final byte base2 )  {  final byte first =  string util . to upper case ( base1 )  ;  final byte second =  string util . to upper case ( base2 )  ;  final  diploid genotype genotype = genotypes . get ( first  +  second )  ;  if  ( genotype  =  =  null )   {  throw new  illegal argument exception ( "" unknown genotype string [""  +   string util . bytes to string ( new byte[] { base1 base2 }  )   +  ""]  any pair of actg case insensitive is acceptable"" )  ;   }  return genotype ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\DiploidGenotype.java,get allele,public byte   (  )  {  return allele1 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\DiploidGenotype.java,get allele,public byte   (  )  {  return allele2 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\DiploidGenotype.java,is heterozygous,public boolean   (  )  {  return this . allele1  !  =  this . allele2 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\DiploidGenotype.java,is homomozygous,public boolean   (  )  {  return this . allele1  =  =  this . allele2 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\DiploidGenotype.java,is valid base,public static boolean   ( final byte base )  {  switch  (  string util . to upper case ( base )  )   {  case 'a': case 'c': case 'g': case 't': return true ;  default : return false ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CrosscheckReadGroupFingerprints.java,custom command line validation,"@ override protected  string[]   (  )  {  final  list <  string >  errors = new  array list <  >  (  )  ;  if  ( crosscheck   by  !  =   crosscheck metric .  data type . readgroup )   {  errors . add ( "" when calling  crosscheck read group fingerprints  p"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CrosscheckReadGroupFingerprints.java,do work,@ override protected int   (  )  {  if  ( expect   all   read   groups   to   match )   {  expect   all   groups   to   match = expect   all   read   groups   to   match ;   }  if  ( crosscheck   libraries )   {  crosscheck   by =  crosscheck metric .  da
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Fingerprint.java, fingerprint,public   ( final  string sample final  path source final  string info )  {  this . sample = sample ;  this . source = source ;  this . info = info ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Fingerprint.java,add,public void   ( final  haplotype probabilities h )  {  put ( h . get haplotype (  )  h )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Fingerprint.java,filter suspect sites,public void   (  )  {  final  iterator <  map .  entry <  haplotype block  haplotype probabilities >  >  iterator = entry set (  )  . iterator (  )  ;  while  ( iterator . has next (  )  )   {  final  map .  entry <  haplotype block  haplotype probabilities >  entry = iterator . next (  )  ;  final  haplotype probabilities p = entry . get value (  )  ;  if  ( p instanceof  haplotype probabilities from sequence )   {  final  haplotype probabilities from sequence probs =  (  haplotype probabilities from sequence ) p ;  if  ( probs . get lod most probable genotype (  )   >  =  3 && probs . get fraction unexpected allele obs (  )   >  0 . 1 )   {  iterator . remove (  )  ;   }   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Fingerprint.java,get info,public  string   (  )  {  return info ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Fingerprint.java,get printable id,"public  string   (  )  {  return get sample (  )   +  ""@""  +   ( source  =  =  null  ?  """" : source . to uri (  )  . to string (  )  )  +   ( info  =  =  null  ?  """" :  ( "":""  +  info )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Fingerprint.java,get sample,public  string   (  )  {  return sample ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Fingerprint.java,get source,public  path   (  )  {  return source ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Fingerprint.java,merge,public void   ( final  fingerprint other )  {  final  set <  haplotype block >  haps = new  hash set <  >  (  )  ;  haps . add all ( key set (  )  )  ;  haps . add all ( other . key set (  )  )  ;  for  (  final  haplotype block haplotype : haps )   {   haplotype probabilities probabilities = get ( haplotype )  ;  final  haplotype probabilities other probabilities = other . get ( haplotype )  ;  if  ( probabilities  =  =  null )   {  probabilities = other probabilities ;  put ( haplotype probabilities )  ;   }  else if  ( other probabilities  !  =  null )   {  probabilities . merge ( other probabilities )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintResults.java, fingerprint results,public   ( final  path input file final  string read group final  string sample alias )  {  this . input file = input file ;  this . read group = read group ;  this . sample alias = sample alias ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintResults.java,add results,public void   ( final  match results match results )  {  this . match results . add ( match results )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintResults.java,get input file,public  path   (  )  {  return input file ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintResults.java,get match results,public  sorted set <  match results >    (  )  {  return match results ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintResults.java,get read group,public  string   (  )  {  return read group ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintResults.java,get sample alias,public  string   (  )  {  return sample alias ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintIdDetails.java, fingerprint id details,public   ( final sam read group record rg final  string file )  {  this ( rg . get platform unit (  )  file )  ;  this . sample = rg . get sample (  )  ;  this . library = rg . get library (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintIdDetails.java,equal value or else,static private  < t > t   ( final t lhs final t rhs final t or else )  {  if  ( rhs  =  =  null )  return lhs ;  if  ( lhs  =  =  null )  return rhs ;  return lhs . equals ( rhs )   ?  lhs : or else ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintIdDetails.java,equals,@ override public boolean   ( final  object o )  {  if  ( this  =  =  o )  return true ;  if  ( o  =  =  null || get class (  )   !  =  o . get class (  )  )  return false ;  final  fingerprint id details that =  (  fingerprint id details ) o ;  if  ( pla
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintIdDetails.java,get platform unit,public  string   (  )  {  return platform unit ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintIdDetails.java,get platform unit details,"private void   ( final  string pu string )  {  this . run barcode = "" ? "" ;  this . run lane =  - 1 ;  this . molecular barcode = "" ? "" ;  if  ( pu string  =  =  null )  return ;  final  string[] tmp = pu string . split ( ""\\ . "" )  ;  if  (  ( tmp . length  =  =  3 )  ||  ( tmp . length  =  =  2 )  )   {  this . run barcode = tmp[0] ;  this . molecular barcode =  ( tmp . length  =  =  3 )   ?  tmp[2] : """" ;  try  {  this . run lane =  integer . parse int ( tmp[1] )  ;   }  catch  (  final  number format exception e )   {   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintIdDetails.java,get sample,public  string   (  )  {  return sample ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintIdDetails.java,hash code,@ override public int   (  )  {  int result = platform unit  !  =  null  ?  platform unit . hash code (  )  : 0 ;  result = 31 * result  +   ( run barcode  !  =  null  ?  run barcode . hash code (  )  : 0 )  ;  result = 31 * result  +   ( run lane  !  =  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintIdDetails.java,merge,public  fingerprint id details   ( final  fingerprint id details other )  {  platform unit = equal value or else ( platform unit other . platform unit multiple values string )  ;  run barcode = equal value or else ( run barcode other . run barcode multiple values string )  ;  run lane = equal value or else ( run lane other . run lane  integer . min   value )  ;  library = equal value or else ( library other . library multiple values string )  ;  file = equal value or else ( file other . file multiple values string )  ;  sample = equal value or else ( sample other . sample multiple values string )  ;  molecular barcode = equal value or else ( molecular barcode other . molecular barcode multiple values string )  ;  return this ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeBlock.java, haplotype block,public   ( final double maf )  {  this . maf = maf ;  final double major af =  ( 1  -  maf )  ;  this . haplotype frequencies[0] = major af * major af ;  this . haplotype frequencies[1] = major af * maf * 2 ;  this . haplotype frequencies[2] = maf * maf ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeBlock.java,add snp,"public void   ( final  snp snp )  {  if  ( this . snps by name . is empty (  )  )   {  this . chrom = snp . get chrom (  )  ;  this . start = snp . get pos (  )  ;  this . end = snp . get pos (  )  ;  this . first snp = snp ;   }  else if  (  ! this . chrom . equals ( snp . get chrom (  )  )  )   {  throw new  picard exception ( "" snp chromosome ""  +  snp . get chrom (  )   +  "" does not agree with chromosome of existing snp ( s ) : "" +  this . chrom )  ;   }  else  {  if  ( snp . get pos (  )   <  this . start )   {  this . start = snp . get pos (  )  ;  this . first snp = snp ;   }  if  ( snp . get pos (  )   >  this . end )   {  this . end = snp . get pos (  )  ;   }   }  this . snps by name . put ( snp . get name (  )  snp )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeBlock.java,compare to,@ override public int   ( final  haplotype block that )  {  int retval = this . chrom . compare to ( that . chrom )  ;  if  ( retval  =  =  0 )  retval = this . start  -  that . start ;  if  ( retval  =  =  0 )  retval = this . end  -  that . end ;  retur
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeBlock.java,contains,public boolean   ( final  snp snp )  {  final  snp contained = this . snps by name . get ( snp . get name (  )  )  ;  return contained  !  =  null && contained . get chrom (  )  . equals ( snp . get chrom (  )  )  && contained . get pos (  )   =  =  snp . get pos (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeBlock.java,equals,@ override public boolean   ( final  object o )  {  if  ( this  =  =  o )  return true ;  if  ( o  =  =  null || get class (  )   !  =  o . get class (  )  )  return false ;  else return this . compare to (  (  haplotype block ) o )   =  =  0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeBlock.java,get diploid haplotype,"public  diploid haplotype   ( final  snp snp final  diploid genotype gt )  {  if  (  ! contains ( snp )  )  throw new  illegal argument exception ( "" snp is not part of haplotype ""  +  snp )  ;  return  diploid haplotype . values (  ) [snp . index of ( gt ) ] ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeBlock.java,get first snp,public  snp   (  )  {  return this . first snp ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeBlock.java,get haplotype frequencies,public double[]   (  )  {  return this . haplotype frequencies ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeBlock.java,get haplotype frequency,"public double   ( final int i )  {  if  ( i  <  0 || i  >  2 )  throw new  illegal argument exception ( "" illegal haplotype index ""  +  i )  ;  else return this . haplotype frequencies[i] ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeBlock.java,get maf,public double   (  )  {  return this . maf ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeBlock.java,get snp,public  snp   ( final  string name )  {  return this . snps by name . get ( name )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeBlock.java,get snp genotype,"public  diploid genotype   ( final  snp snp final  diploid haplotype haplotype )  {  if  (  ! contains ( snp )  )  throw new  illegal argument exception ( "" snp is not part of haplotype ""  +  snp )  ;  return snp . get genotype ( haplotype )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeBlock.java,get snps,public  collection <  snp >    (  )  {  return  collections . unmodifiable collection ( this . snps by name . values (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeBlock.java,hash code,@ override public int   (  )  {  return this . start ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeBlock.java,size,public int   (  )  {  return snps by name . size (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeBlock.java,to string,"@ override public  string   (  )  {  return this . chrom  +  ""[""  +  this . start +  "" - "" +  this . end +  ""]"" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java, fingerprint checker,public   ( final  haplotype map haplotypes )  {  this . haplotypes = haplotypes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,calculate match results,public static  match results   ( final  fingerprint observed fp final  fingerprint expected fp )  {  return calculate match results ( observed fp expected fp 0 0 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,check fingerprints,"public  list <  fingerprint results >    ( final  list <  path >  sam files final  list <  path >  genotype files final  string specific sample final boolean ignore read groups )  {  final  list <  fingerprint >  expected fingerprints = new  linked list <  >  (  )  ;  for  (  final  path p : genotype files )   {  expected fingerprints . add all ( load fingerprints ( p specific sample )  . values (  )  )  ;   }  if  ( expected fingerprints . is empty (  )  )   {  throw new  illegal state exception ( "" could not find any fingerprints in: ""  +  genotype files )  ;   }  final  list <  fingerprint results >  results list = new  array list <  >  (  )  ;  final  interval list intervals = get loci to genotype ( expected fingerprints )  ;  for  (  final  path p : sam files )   {  final  map <  fingerprint id details  fingerprint >  fingerprints by read group = fingerprint sam file ( p intervals )  ;  if  ( ignore read groups )   {  final  fingerprint combined fp = new  fingerprint ( specific sample p null )  ;  fingerprints by read group . values (  )  . for each ( combined fp::merge )  ;  final  fingerprint results results = new  fingerprint results ( p null specific sample )  ;  for  (  final  fingerprint expected fp : expected fingerprints )   {  final  match results result = calculate match results ( combined fp expected fp 0 p lossof het )  ;  results . add results ( result )  ;   }  results list . add ( results )  ;   }  else  {  for  (  final  fingerprint id details rg : fingerprints by read group . key set (  )  )   {  final  fingerprint results results = new  fingerprint results ( p rg . platform unit rg . sample )  ;  for  (  final  fingerprint expected fp : expected fingerprints )   {  final  match results result = calculate match results ( fingerprints by read group . get ( rg )  expected fp 0 p lossof het )  ;  results . add results ( result )  ;   }  results list . add ( results )  ;   }   }   }  return results list ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,check fingerprints from paths,"public  list <  fingerprint results >    ( final  list <  path >  observed genotype files final  list <  path >  expected genotype files final  string observed sample final  string expected sample )  {  final  list <  fingerprint >  expected fingerprints = new  array list <  >  (  )  ;  for  (  final  path p : expected genotype files )   {  expected fingerprints . add all ( load fingerprints ( p expected sample )  . values (  )  )  ;   }  if  ( expected fingerprints . is empty (  )  )   {  throw new  illegal state exception ( "" could not find any fingerprints in: ""  +  expected genotype files )  ;   }  final  list <  fingerprint results >  results list = new  array list <  >  (  )  ;  for  (  final  path p : observed genotype files )   {  final  map <  string  fingerprint >  observed fingerprints by sample = load fingerprints ( p observed sample )  ;  if  ( observed fingerprints by sample . is empty (  )  )   {  throw new  illegal state exception ( "" found no fingerprints in observed genotypes file: ""  +  observed genotype files )  ;   }  for  (  final  string sample : observed fingerprints by sample . key set (  )  )   {  final  fingerprint results results = new  fingerprint results ( p null sample )  ;  for  (  final  fingerprint expected fp : expected fingerprints )   {  final  match results result = calculate match results ( observed fingerprints by sample . get ( sample )  expected fp 0 p lossof het )  ;  results . add results ( result )  ;   }  results list . add ( results )  ;   }   }  return results list ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,create unknownfp,"private  fingerprint id details   ( final  path sam file final sam record rec )  {  final  picard exception e = new  picard exception ( "" found read with no readgroup: ""  +  rec . get read name (  )   +  "" in file: "" +  sam file )  ;  if  ( validation stringency  !  =   validation stringency . strict )   {  final sam read group record read group record = new sam read group record ( "" < unknown > :::""  +  sam file . to uri (  )  . to string (  )  )  ;  read group record . set library ( "" < unknown > "" )  ;  read group record . set sample ( "" < unknown > "" )  ;  read group record . set platform unit ( "" < unknown >  . 0 . zzz"" )  ;  if  ( validation stringency  =  =   validation stringency . lenient )   {  log . warn ( e )  ;  log . warn ( ""further messages from this file will be suppressed"" )  ;   }  return new  fingerprint id details ( read group record sam file . to uri (  )  . to string (  )  )  ;   }  else  {  log . error ( e )  ;  throw e ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,fingerprint files,"public  map <  fingerprint id details  fingerprint >    ( final  collection <  path >  files final int threads final int wait time final  time unit wait time unit )  {  final  atomic integer files read = new  atomic integer ( 0 )  ;  final  executor service executor = new  thread pool executor with exceptions ( threads )  ;  final  executor completion service <  path >  executor completion service = new  executor completion service <  >  ( executor )  ;  final  interval list intervals = this . haplotypes . get interval list (  )  ;  final  map <  fingerprint id details  fingerprint >  retval = new  concurrent hash map <  >  (  )  ;  for  (  final  path p : files )   {  executor completion service . submit (  (  )   -  >   {  if  (  check fingerprint . is bam or sam ( p )  )   {  retval . put all ( fingerprint sam file ( p intervals )  )  ;   }  else  {  retval . put all ( fingerprint vcf ( p )  )  ;   }  log . debug ( "" processed file: ""  +  p . to uri (  )  . to string (  )   +  ""  ( "" +  files read . get (  )  +  "" ) "" )  ;  if  ( files read . increment and get (  )  % 100  =  =  0 )   {  log . info ( "" processed ""  +  files read . get (  )   +  "" out of "" +  files . size (  )  )  ;   }   }   p )  ;   }  executor . shutdown (  )  ;  try  {  executor . await termination ( wait time wait time unit )  ;   }  catch  (  final  interrupted exception ie )   {  throw new  picard exception ( "" interrupted while waiting for executor to terminate . "" ie )  ;   }  for  ( int i = 0 ;  i  <  files . size (  )  ;  i +  +  )   {  try  {  executor completion service . take (  )  . get (  )  ;   }  catch  (   interrupted exception| execution exception e )   {  throw new  picard exception ( "" failed to fingerprint"" e )  ;   }   }  return retval ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,fingerprint sam file,"public  map <  fingerprint id details  fingerprint >    ( final  path sam file final  interval list loci )  {  final  sam reader in =  sam reader factory . make default (  )  . enable (  sam reader factory .  option . cache   file   based   indexes )  . open ( sam file )  ;   sequence util . assert sequence dictionaries equal ( this . haplotypes . get header (  )  . get sequence dictionary (  )  in . get file header (  )  . get sequence dictionary (  )  )  ;  final  sam locus iterator iterator = new  sam locus iterator ( in loci in . has index (  )  )  ;  iterator . set emit uncovered loci ( true )  ;  iterator . set mapping quality score cutoff ( this . minimum mapping quality )  ;  iterator . set quality score cutoff ( this . minimum base quality )  ;  if  ( this . allow duplicate reads )   {  final  list <  sam record filter >  filters = new  array list <  >  ( 1 )  ;  filters . add ( new  secondary alignment filter (  )  )  ;  iterator . set sam filters ( filters )  ;   }  final  map < sam read group record  fingerprint id details >  fingerprint id details map = new  hash map <  >  (  )  ;  final  map <  fingerprint id details  fingerprint >  fingerprints by read group = new  hash map <  >  (  )  ;  for  (  final sam read group record rg : in . get file header (  )  . get read groups (  )  )   {  final  fingerprint id details id = new  fingerprint id details ( rg . get platform unit (  )  sam file . to uri (  )  . to string (  )  )  ;  id . library = rg . get library (  )  ;  id . sample = rg . get sample (  )  ;  fingerprint id details map . put ( rg id )  ;  final  fingerprint fingerprint = new  fingerprint ( id . sample sam file id . platform unit )  ;  fingerprints by read group . put ( id fingerprint )  ;  for  (  final  haplotype block h : this . haplotypes . get haplotypes (  )  )   {  fingerprint . add ( new  haplotype probabilities from sequence ( h )  )  ;   }   }  final  set <  string >  used read names = new  hash set <  >  ( 10000 )  ;  for  (  final  sam locus iterator .  locus info info : iterator )   {  final  haplotype block haplotype block = this . haplotypes . get haplotype ( info . get sequence name (  )  info . get position (  )  )  ;  final  snp snp = this . haplotypes . get snp ( info . get sequence name (  )  info . get position (  )  )  ;  for  (  final  sam locus iterator .  record and offset rec : info . get record and offsets (  )  )   {  final sam read group record rg = rec . get record (  )  . get read group (  )  ;  final  fingerprint id details details ;  if  ( rg  =  =  null ||  ! fingerprint id details map . contains key ( rg )  )   {  final  fingerprint id details unknownfp details = create unknownfp ( sam file rec . get record (  )  )  ;  fingerprint id details map . put ( null unknownfp details )  ;  final  fingerprint fp = new  fingerprint ( unknownfp details . sample sam file unknownfp details . platform unit )  ;  fingerprints by read group . put ( unknownfp details fp )  ;  for  (  final  haplotype block h : this . haplotypes . get haplotypes (  )  )   {  fp . add ( new  haplotype probabilities from sequence ( h )  )  ;   }   }  if  ( fingerprint id details map . contains key ( rg )  )   {  details = fingerprint id details map . get ( rg )  ;  final  string read name = rec . get record (  )  . get read name (  )  ;  if  (  ! used read names . contains ( read name )  )   {  final  haplotype probabilities from sequence probs =  (  haplotype probabilities from sequence ) fingerprints by read group . get ( details )  . get ( haplotype block )  ;  final byte base =  string util . to upper case ( rec . get read base (  )  )  ;  final byte qual = rec . get base quality (  )  ;  probs . add to probs ( snp base qual )  ;  used read names . add ( read name )  ;   }   }  else  {  final  picard exception e = new  picard exception ( "" unknown read group: ""  +  rg  +  "" in file: "" +  sam file )  ;  log . error ( e )  ;  throw e ;   }   }   }  return fingerprints by read group ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,fingerprint vcf,public  map <  fingerprint id details  fingerprint >    ( final  path vcf file )  {  final  map <  fingerprint id details  fingerprint >  fp id map = new  hash map <  >  (  )  ;  final  map <  string  fingerprint >  sample fp map = load fingerprints ( vcf file null )  ;  sample fp map . for each (  ( key value )   -  >   {  final  fingerprint id details fp id = new  fingerprint id details (  )  ;  fp id . sample = key ;  fp id . file = vcf file . to uri (  )  . to string (  )  ;  fp id map . put ( fp id value )  ;   }   )  ;  return fp id map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,get fingerprint from vc,"private void   ( final  map <  string  fingerprint >  fingerprints final  variant context ctx )  throws  illegal argument exception  {  final  haplotype block h = this . haplotypes . get haplotype ( ctx . get contig (  )  ctx . get start (  )  )  ;  if  ( h  =  =  null )  return ;  final  snp snp = this . haplotypes . get snp ( ctx . get contig (  )  ctx . get start (  )  )  ;  final  variant context usable snp =  allele subsetting utils . subsetvc to match snp ( ctx snp )  ;  if  ( usable snp  =  =  null )   {  return ;   }   {  boolean alleles ok = true ;  for  (  final  allele allele : usable snp . get alleles (  )  )   {  final byte[] bases = allele . get bases (  )  ;  if  ( bases . length  >  1 ||  ( bases[0]  !  =  snp . get allele1 (  )  && bases[0]  !  =  snp . get allele2 (  )  )  )   {  alleles ok = false ;   }   }  if  (  ! alleles ok )   {  log . warn ( "" problem with genotype file:  alleles ""  +  usable snp . get alleles (  )   +  "" do not match to alleles for snp "" +  snp +  "" with alleles "" +  snp . get allele string (  )  )  ;  throw new  illegal argument exception ( "" alleles do not match between database and file"" )  ;   }   }  for  (  final  string sample : fingerprints . key set (  )  )   {  final  fingerprint fp = fingerprints . get ( sample )  ;  final  genotype genotype = usable snp . get genotype ( sample )  ;  if  ( genotype  =  =  null )   {  throw new  illegal argument exception ( "" cannot find sample ""  +  sample  +  "" in provided file .  "" )  ;   }  if  ( genotype . haspl (  )  )   {  final  haplotype probabilities from genotype likelihoods h fp = new  haplotype probabilities from genotype likelihoods ( h )  ;  final int[] pls = genotype . getpl (  )  ;  final int[] newp ls = new int[pls . length] ;  for  ( int i = 0 ;  i  <  pls . length ;  i +  +  )   {  newp ls[i] =  math . min ( maximalpl difference pls[i] )  ;   }  h fp . add to log likelihoods ( snp usable snp . get alleles (  )   genotype likelihoods . fromp ls ( newp ls )  . get as vector (  )  )  ;  fp . add ( h fp )  ;   }  else  {  if  ( genotype . is no call (  )  )  continue ;  if  ( fp . contains key ( h )  )  continue ;  final boolean hom = genotype . is hom (  )  ;  final byte allele =  string util . to upper case ( genotype . get allele ( 0 )  . get bases (  ) [0] )  ;  final double half error = this . genotyping error rate  /  2 ;  final double accuracy = 1  -  this . genotyping error rate ;  final double[] probs = new double[] {  ( hom && allele  =  =  snp . get allele1 (  )  )   ?  accuracy : half error  (  ! hom )   ?  accuracy : half error  ( hom && allele  =  =  snp . get allele2 (  )  )   ?  accuracy : half error }  ;  fp . add ( new  haplotype probabilities from genotype ( snp h probs[0] probs[1] probs[2] )  )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,get header,public sam file header   (  )  {  return haplotypes . get header (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,get loci to genotype,public  interval list   ( final  collection <  fingerprint >  fingerprints )  {  final  interval list intervals = new  interval list ( this . haplotypes . get header (  )  )  ;  for  (  final  fingerprint fp : fingerprints )   {  for  (  final  haplotype probabilities genotype : fp . values (  )  )   {  final  haplotype block h = genotype . get haplotype (  )  ;  for  (  final  snp snp : h . get snps (  )  )   {  intervals . add ( new  interval ( snp . get chrom (  )  snp . get pos (  )  snp . get pos (  )  false snp . get name (  )  )  )  ;   }   }   }  return intervals . uniqued (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,get validation stringency,public  validation stringency   (  )  {  return validation stringency ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,identify contaminant,"public  map <  string  fingerprint >    ( final  path sam file final double contamination final int locus max reads )  {  final  map <  string  fingerprint >  fingerprints by sample = new  hash map <  >  (  )  ;  try  ( final  sam reader in =  sam reader factory . make default (  )  . enable ( cache   file   based   indexes )  . open ( sam file )  )  {   sequence util . assert sequence dictionaries equal ( this . haplotypes . get header (  )  . get sequence dictionary (  )  in . get file header (  )  . get sequence dictionary (  )  )  ;  final  sam locus iterator iterator = new  sam locus iterator ( in haplotypes . get interval list (  )  in . has index (  )  )  ;  iterator . set emit uncovered loci ( true )  ;  iterator . set mapping quality score cutoff ( this . minimum mapping quality )  ;  iterator . set quality score cutoff ( this . minimum base quality )  ;  if  ( this . allow duplicate reads )   {  final  list <  sam record filter >  filters = new  array list <  >  ( 1 )  ;  filters . add ( new  secondary alignment filter (  )  )  ;  iterator . set sam filters ( filters )  ;   }  for  (  final sam read group record rg : in . get file header (  )  . get read groups (  )  )   {  if  (  ! fingerprints by sample . contains key ( rg . get sample (  )  )  )   {  final  fingerprint fingerprint = new  fingerprint ( rg . get sample (  )  sam file rg . get sample (  )  )  ;  for  (  final  haplotype block h : this . haplotypes . get haplotypes (  )  )   {  fingerprint . add ( new  haplotype probabilities from contaminator sequence ( h contamination )  )  ;   }  fingerprints by sample . put ( rg . get sample (  )  fingerprint )  ;   }   }  final  set <  string >  used read names = new  hash set <  >  ( 10000 )  ;  for  (  final  sam locus iterator .  locus info info : iterator )   {  final  haplotype block haplotype block = this . haplotypes . get haplotype ( info . get sequence name (  )  info . get position (  )  )  ;  final  snp snp = this . haplotypes . get snp ( info . get sequence name (  )  info . get position (  )  )  ;  final  list <  sam locus iterator .  record and offset >  record and offset list = random sublist ( info . get record and positions (  )  locus max reads )  ;  for  (  final  sam locus iterator .  record and offset rec : record and offset list )   {  final sam read group record rg = rec . get record (  )  . get read group (  )  ;  if  ( rg  =  =  null ||  ! fingerprints by sample . contains key ( rg . get sample (  )  )  )   {  final  picard exception e = new  picard exception ( "" unknown sample: ""  +   ( rg  !  =  null  ?  rg . get sample (  )  : "" ( null readgroup ) "" )  )  ;  log . error ( e )  ;  throw e ;   }  else  {  final  string read name = rec . get record (  )  . get read name (  )  ;  if  (  ! used read names . contains ( read name )  )   {  final  haplotype probabilities from contaminator sequence probs =  (  haplotype probabilities from contaminator sequence ) fingerprints by sample . get ( rg . get sample (  )  )  . get ( haplotype block )  ;  final byte base =  string util . to upper case ( rec . get read base (  )  )  ;  final byte qual = rec . get base quality (  )  ;  probs . add to probs ( snp base qual )  ;  used read names . add ( read name )  ;   }   }   }   }   }  catch  (  io exception e )   {  log . error ( "" unexpected  error while reading from ""  +  sam file  +  "" .   trying to continue . "" e . get message (  )  e . get stack trace (  )  )  ;   }  return fingerprints by sample ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,load fingerprints,"public  map <  string  fingerprint >    ( final  path fingerprint file final  string specific sample )  {   sequence util . assert sequence dictionaries equal ( this . haplotypes . get header (  )  . get sequence dictionary (  )  vcf file reader . get sequence dictionary ( fingerprint file )  )  ;  final vcf file reader reader = new vcf file reader ( fingerprint file false )  ;  if  ( reader . is queryable (  )  )   {  return load fingerprints from queriable reader ( reader specific sample fingerprint file )  ;   }  else  {  log . warn ( "" couldn't find index for file ""  +  fingerprint file  +  "" going to read through it all . "" )  ;  return load fingerprints from variant contexts ( reader specific sample fingerprint file )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,load fingerprints from indexed vcf,public  map <  string  fingerprint >    ( final  path fingerprint file final  string specific sample )  {  final vcf file reader reader = new vcf file reader ( fingerprint file true )  ;  return load fingerprints from queriable reader ( reader specific sample fingerprint file )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,load fingerprints from non indexed vcf,public  map <  string  fingerprint >    ( final  path fingerprint file final  string specific sample )  {  final vcf file reader reader = new vcf file reader ( fingerprint file false )  ;   sequence util . assert sequence dictionaries equal ( this . haplotypes . get header (  )  . get sequence dictionary (  )  sam sequence dictionary extractor . extract dictionary ( fingerprint file )  )  ;  return load fingerprints from variant contexts ( reader specific sample fingerprint file )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,load fingerprints from queriable reader,public  map <  string  fingerprint >    ( final vcf file reader reader final  string specific sample final  path source )  {   sequence util . assert sequence dictionaries equal ( this . haplotypes . get header (  )  . get sequence dictionary (  )  reader . get file header (  )  . get sequence dictionary (  )  )  ;  final  sorted set <  snp >  snps = new  tree set <  >  ( haplotypes . get all snps (  )  )  ;  return load fingerprints from variant contexts (  (  )   -  >  snps . stream (  )  . map ( snp  -  >   {  try  {  return reader . query ( snp . get chrom (  )  snp . get pos (  )  snp . get pos (  )  )  . next (  )  ;   }  catch  (   no such element exception e )   {  return null ;   }   }   )  . iterator (  )  specific sample source )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,load fingerprints from variant contexts,"public  map <  string  fingerprint >    ( final  iterable <  variant context >  iterable final  string specific sample final  path source )  {  final  map <  string  fingerprint >  fingerprints = new  hash map <  >  (  )  ;   set <  string >  samples = null ;  for  (  final  variant context ctx : iterable )   {  if  ( ctx  =  =  null )  continue ;  if  ( samples  =  =  null )   {  if  ( specific sample  !  =  null )   {  samples = new  hash set <  >  (  )  ;  samples . add ( specific sample )  ;   }  else  {  samples = ctx . get sample names (  )  ;  if  ( samples  =  =  null )   {  log . warn ( "" no samples found in file: ""  +  source . to uri (  )  . to string (  )   +  "" .   skipping . "" )  ;  return  collections . empty map (  )  ;   }   }  samples . for each ( s  -  >  fingerprints . put ( s new  fingerprint ( s source null )  )  )  ;   }  try  {  get fingerprint from vc ( fingerprints ctx )  ;   }  catch  (  final  illegal argument exception e )   {  log . warn ( e "" there was a genotyping error in  file: ""  +  source . to uri (  )  . to string (  )   +  ""\n"" +  e . get message (  )  )  ;   }   }  return fingerprints ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,random sublist,protected static  < t >  list < t >    ( final  list < t >  list final int n )  {  int available elements = list . size (  )  ;  if  ( available elements  <  =  n )  return list ;  int still needed = n ;  final  random rg = new  random (  )  ;  final  list < t >  short list = new  array list <  >  ( n )  ;  for  (  final t a list : list )   {  if  ( rg . next double (  )   <  still needed  /   ( double ) available elements )   {  short list . add ( a list )  ;  still needed -  -  ;   }  if  ( still needed  =  =  0 )  break ;  available elements -  -  ;   }  return short list ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,set allow duplicate reads,public void   ( final boolean allow duplicate reads )  {  this . allow duplicate reads = allow duplicate reads ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,set genotyping error rate,public void   ( final double genotyping error rate )  {  this . genotyping error rate = genotyping error rate ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,set minimum base quality,public void   ( final int minimum base quality )  {  this . minimum base quality = minimum base quality ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,set minimum mapping quality,public void   ( final int minimum mapping quality )  {  this . minimum mapping quality = minimum mapping quality ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,set validation stringency,public void   ( final  validation stringency validation stringency )  {  this . validation stringency = validation stringency ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,setmaximalpl difference,public void   ( final int maximalpl difference )  {  this . maximalpl difference = maximalpl difference ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintChecker.java,setp lossof het,public void   ( final double p lossof het )  {  this . p lossof het = p lossof het ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintUtils.java, variant context set,  ( final sam sequence dictionary dict )  {  super (  ( lhs rhs )   -  >   {  final int lhs contig = dict . get sequence index ( lhs . get contig (  )  )  ;  final int rhs contig = dict . get sequence index ( rhs . get contig (  )  )  ;  final int retval = lhs contig  -  rhs contig ;  if  ( retval  !  =  0 )  return retval ;  return lhs . get start (  )   -  rhs . get start (  )  ;   }   )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintUtils.java,createvc set from fingerprint,"public static  variant context set   ( final  fingerprint finger print final  reference sequence file reference final  string sample )  {  final  variant context set variant contexts = new  variant context set ( reference . get sequence dictionary (  )  )  ;  finger print . values (  )  . stream (  )  . map ( hp  -  >  hp . get representative snp (  )  . get name (  )  )  . filter (  objects::non null )  . filter ( n  -  >   ! n . equals ( """" )  )  . collect (  collectors . grouping by (  function . identity (  )   collectors . counting (  )  )  )  . entry set (  )  . stream (  )  . filter ( e  -  >  e . get value (  )   >  1 )  . find first (  )  . if present ( e  -  >   {  throw new  illegal argument exception ( "" found same snp name twice  ( ""  +  e . get key (  )   +  "" )  in fingerprint .   cannot create a vcf . "" )  ;   }   )  ;  finger print . values (  )  . stream (  )  . map ( hp  -  >  get variant context ( reference sample hp )  )  . for each ( variant contexts::add )  ;  return variant contexts ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintUtils.java,get variant context,"private static  variant context   ( final  reference sequence file reference final  string sample final  haplotype probabilities haplotype probabilities )  {  final  snp snp = haplotype probabilities . get representative snp (  )  ;  final byte ref allele =  string util . to upper case ( reference . get subsequence at ( snp . get chrom (  )  snp . get pos (  )  snp . get pos (  )  )  . get bases (  ) [0] )  ;  final  allele allele1 =  allele . create ( snp . get allele1 (  )  snp . get allele1 (  )   =  =  ref allele )  ;  final  allele allele2 =  allele . create ( snp . get allele2 (  )  snp . get allele2 (  )   =  =  ref allele )  ;  final  list <  allele >  alleles =  arrays . as list ( allele1 allele2 )  ;  final  genotype gt = new  genotype builder (  )  . dp ( haplotype probabilities . get total obs (  )  )  . no attributes (  )  . pl ( haplotype probabilities . get log likelihoods (  )  )  . ad ( new int[] { haplotype probabilities . get obs allele1 (  )  haplotype probabilities . get obs allele2 (  )  }  )  . name ( sample )  . make (  )  ;  try  {  return new  variant context builder ( snp . get name (  )  snp . get chrom (  )  snp . get pos (  )  snp . get pos (  )  alleles )  . log10p error (  variant context . no   log10   perror )  . genotypes ( gt )  . unfiltered (  )  . make (  )  ;   }  catch  (   illegal argument exception e )   {  throw new  illegal argument exception (  string . format ( "" trouble creating variant at %s - %d"" snp . get chrom (  )  snp . get pos (  )  )  e )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintUtils.java,get variant context writer,"private static  variant context writer   ( final  file output file final  file reference sequence file name final  string sample final  string source final  reference sequence file ref )  {  final  variant context writer variant context writer = new  variant context writer builder (  )  . set reference dictionary ( ref . get sequence dictionary (  )  )  . set output file ( output file )  . build (  )  ;  final  set < vcf header line >  lines = new  linked hash set <  >  (  )  ;  lines . add ( new vcf header line ( ""reference"" reference sequence file name . get absolute path (  )  )  )  ;  lines . add ( new vcf header line ( ""source"" source )  )  ;  lines . add ( new vcf header line ( ""file date"" new  date (  )  . to string (  )  )  )  ;  lines . add ( vcf standard header lines . get format line ( vcf constants . genotype   pl   key )  )  ;  lines . add ( vcf standard header lines . get format line ( vcf constants . genotype   allele   depths )  )  ;  lines . add ( vcf standard header lines . get format line ( vcf constants . depth   key )  )  ;  final vcf header header = new vcf header ( lines  collections . singleton list ( sample )  )  ;  header . set sequence dictionary ( ref . get sequence dictionary (  )  )  ;  variant context writer . write header ( header )  ;  return variant context writer ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\FingerprintUtils.java,write finger print,public static void   ( final  fingerprint fingerprint final  file output file final  file reference sequence file name final  string sample final  string source )  throws io exception  {  try  ( final  reference sequence file ref =  reference sequence file factory . get reference sequence file ( reference sequence file name )  ; final  variant context writer variant context writer = get variant context writer ( output file reference sequence file name sample source ref )  )  {  createvc set from fingerprint ( fingerprint ref sample )  . for each ( variant context writer::add )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CrosscheckFingerprints.java,check fingerprints by sample,"private int   ( final  map <  fingerprint id details  fingerprint >  fingerprints1 final  map <  fingerprint id details  fingerprint >  fingerprints2 final  list <  crosscheck metric >  metrics )  {  int unexpected results = 0 ;  final  map <  fingerprint id details  fingerprint >  fingerprints1 by sample = merge fingerprints by ( fingerprints1 get fingerprint id details string function (  crosscheck metric .  data type . sample )  )  ;  final  map <  fingerprint id details  fingerprint >  fingerprints2 by sample = merge fingerprints by ( fingerprints2 get fingerprint id details string function (  crosscheck metric .  data type . sample )  )  ;  final  map <  string  fingerprint id details >  sample to detail1 = fingerprints1 by sample . key set (  )  . stream (  )  . collect (  collectors . to map ( id  -  >  id . group id  -  >  id )  )  ;  final  map <  string  fingerprint id details >  sample to detail2 = fingerprints2 by sample . key set (  )  . stream (  )  . collect (  collectors . to map ( id  -  >  id . group id  -  >  id )  )  ;   set <  string >  samples = new  hash set <  >  (  )  ;  samples . add all ( sample to detail1 . key set (  )  )  ;  samples . add all ( sample to detail2 . key set (  )  )  ;  for  (  final  string sample : samples )   {  final  fingerprint id details lhsid = sample to detail1 . get ( sample )  ;  final  fingerprint id details rhsid = sample to detail2 . get ( sample )  ;  if  ( lhsid  =  =  null || rhsid  =  =  null )   {  log . error (  string . format ( ""sample %s is missing from %s group"" sample lhsid  =  =  null  ?  ""left"" : ""right"" )  )  ;  unexpected results +  +  ;  continue ;   }  final  match results results =  fingerprint checker . calculate match results ( fingerprints1 by sample . get ( lhsid )  fingerprints2 by sample . get ( rhsid )  genotyping   error   rate loss   of   het   rate false calculate   tumor   aware   results )  ;  final  crosscheck metric .  fingerprint result result = get match results ( true results )  ;  if  (  ! output   errors   only ||  ! result . is expected (  )  )   {  metrics . add ( get match details ( result results lhsid rhsid  crosscheck metric .  data type . sample )  )  ;   }  if  ( result  !  =   fingerprint result . inconclusive &&  ! result . is expected (  )  )  unexpected results +  +  ;   }  return unexpected results ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CrosscheckFingerprints.java,cross check fingerprints,"private int   ( final  map <  fingerprint id details  fingerprint >  lhs fingerprints final  map <  fingerprint id details  fingerprint >  rhs fingerprints final  crosscheck metric .  data type type final  list <  crosscheck metric >  metrics )  {  int unexpected results = 0 ;  long checks made = 0 ;  final int log every = 100   000 ;  final  list <  fingerprint id details >  lhs fingerprint id details = new  array list <  >  ( lhs fingerprints . key set (  )  )  ;  final  list <  fingerprint id details >  rhs fingerprint id details = new  array list <  >  ( rhs fingerprints . key set (  )  )  ;  final long total checks = lhs fingerprint id details . size (  )  *  (  ( long ) rhs fingerprint id details . size (  )  )  ;  for  ( int row = 0 ;  row  <  lhs fingerprint id details . size (  )  ;  row +  +  )   {  final  fingerprint id details lhs id = lhs fingerprint id details . get ( row )  ;  for  ( int col = 0 ;  col  <  rhs fingerprint id details . size (  )  ;  col +  +  )   {  final  fingerprint id details rhs id = rhs fingerprint id details . get ( col )  ;  final boolean expected to match = expect   all   groups   to   match || lhs id . sample . equals ( rhs id . sample )  ;  final  match results results =  fingerprint checker . calculate match results ( lhs fingerprints . get ( lhs id )  rhs fingerprints . get ( rhs id )  genotyping   error   rate loss   of   het   rate false calculate   tumor   aware   results )  ;  final  fingerprint result result = get match results ( expected to match results )  ;  if  (  ! output   errors   only || result  =  =   fingerprint result . inconclusive ||  ! result . is expected (  )  )   {  metrics . add ( get match details ( result results lhs id rhs id type )  )  ;   }  if  ( result  !  =   fingerprint result . inconclusive &&  ! result . is expected (  )  )  unexpected results +  +  ;  if  ( crosscheck matrix  !  =  null )   {  crosscheck matrix[row][col] = results . getlod (  )  ;   }  if  (  +  + checks made % log every  =  =  0 )   {  log . info ( "" compared ""  +  checks made  +  "" of "" +  total checks )  ;   }   }   }  return unexpected results ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CrosscheckFingerprints.java,cross check grouped,private int   ( final  map <  fingerprint id details  fingerprint >  lhs fingerprints final  map <  fingerprint id details  fingerprint >  rhs fingerprints final  list <  crosscheck metric >  metrics final  function <  fingerprint id details  string >  by final  crosscheck metric .  data type type )  {  final  map <  fingerprint id details  fingerprint >  lhs fingerprints by group = merge fingerprints by ( lhs fingerprints by )  ;  final  map <  fingerprint id details  fingerprint >  rhs fingerprints by group = merge fingerprints by ( rhs fingerprints by )  ;  if  ( matrix   output  !  =  null )   {  crosscheck matrix = new double[lhs fingerprints by group . size (  ) ][] ;  for  ( int row = 0 ;  row  <  lhs fingerprints by group . size (  )  ;  row +  +  )   {  crosscheck matrix[row] = new double[rhs fingerprints by group . size (  ) ] ;   }  lhs fingerprints by group . key set (  )  . for each ( k  -  >  lhs matrix keys . add ( k . group )  )  ;  rhs fingerprints by group . key set (  )  . for each ( k  -  >  rhs matrix keys . add ( k . group )  )  ;   }  return cross check fingerprints ( lhs fingerprints by group rhs fingerprints by group type metrics )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CrosscheckFingerprints.java,custom command line validation,"@ override protected  string[]   (  )  {  if  ( genotyping   error   rate  <  =  0 || genotyping   error   rate  >  =  1 )   {  return new  string[] { "" genotyping error must be strictly greater than 0 and less than 1  found ""  +  genotyping   error   rat"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CrosscheckFingerprints.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( haplotype   map )  ;  if  ( output  !  =  null )  io util . assert file is writable ( output )  ;  if  (  ! second   input . is empty (  )  && crosscheck   mode  =  =  check   same   
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CrosscheckFingerprints.java,get fingerprint id details string function,"public static  function <  fingerprint id details  string >    (  crosscheck metric .  data type crosscheck   by )  {  final  function <  fingerprint id details  string >  group by temp ;  switch  ( crosscheck   by )   {  case readgroup: group by temp = details  -  >  details . platform unit ;  break ;  case library: group by temp = details  -  >  details . sample  +  ""::""  +  details . library ;  break ;  case file: group by temp = details  -  >  details . file  +  ""::""  +  details . sample ;  break ;  case sample: group by temp = details  -  >  details . sample ;  break ;  default : throw new  picard exception ( ""unpossible"" )  ;   }  return key  -  >   {  final  string temp = group by temp . apply ( key )  ;  return temp  =  =  null  ?   integer . to string ( key . hash code (  )  )  : temp ;   }   ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CrosscheckFingerprints.java,get help doc,"@ override public  string   (  )  {  return "" in this mode  each sample in input will be checked against all the samples in second   input . "" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CrosscheckFingerprints.java,get match details,private  crosscheck metric   ( final  fingerprint result match result final  match results results final  fingerprint id details left pu details final  fingerprint id details right pu details final  crosscheck metric .  data type type )  {  final  crosscheck metric metric = new  crosscheck metric (  )  ;  metric . left   group   value = left pu details . group ;  metric . right   group   value = right pu details . group ;  metric . result = match result ;  metric . lod   score = results . getlod (  )  ;  metric . lod   score   tumor   normal = results . get lodtn (  )  ;  metric . lod   score   normal   tumor = results . get lodnt (  )  ;  metric . data   type = type ;  metric . left   run   barcode = left pu details . run barcode ;  metric . left   lane = left pu details . run lane ;  metric . left   molecular   barcode   sequence = left pu details . molecular barcode ;  metric . left   library = left pu details . library ;  metric . left   sample = left pu details . sample ;  metric . left   file = left pu details . file ;  metric . right   run   barcode = right pu details . run barcode ;  metric . right   lane = right pu details . run lane ;  metric . right   molecular   barcode   sequence = right pu details . molecular barcode ;  metric . right   library = right pu details . library ;  metric . right   sample = right pu details . sample ;  metric . right   file = right pu details . file ;  return metric ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CrosscheckFingerprints.java,get match results,private  fingerprint result   ( final boolean expected to match final  match results results )  {  if  ( expected to match )   {  if  ( results . getlod (  )   <  lod   threshold )   {  return  fingerprint result . unexpected   mismatch ;   }  else if  ( results . getlod (  )   >   - lod   threshold )   {  return  fingerprint result . expected   match ;   }  else  {  return  fingerprint result . inconclusive ;   }   }  else  {  if  ( results . getlod (  )   >   - lod   threshold )   {  return  fingerprint result . unexpected   match ;   }  else if  ( results . getlod (  )   <  lod   threshold )   {  return  fingerprint result . expected   mismatch ;   }  else  {  return  fingerprint result . inconclusive ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CrosscheckFingerprints.java,merge fingerprints by,public static  map <  fingerprint id details  fingerprint >    ( final  map <  fingerprint id details  fingerprint >  fingerprints final  function <  fingerprint id details  string >  by )  {  final  map <  string  list <  map .  entry <  fingerprint id details  fingerprint >  >  >  collection = fingerprints . entry set (  )  . stream (  )  . collect (  collectors . grouping by ( entry  -  >  by . apply ( entry . get key (  )  )  )  )  ;  return collection . entry set (  )  . stream (  )  . collect (  collectors . to map ( entry  -  >   {  final  fingerprint id details final id = new  fingerprint id details (  )  ;  entry . get value (  )  . for each ( id  -  >  final id . merge ( id . get key (  )  )  )  ;  final id . group = entry . get key (  )  ;  return final id ;   }   entry  -  >   {  final  fingerprint id details first detail = entry . get value (  )  . get ( 0 )  . get key (  )  ;  final  fingerprint sample fp = new  fingerprint ( first detail . sample null by . apply ( first detail )  )  ;  entry . get value (  )  . stream (  )  . map (  map .  entry::get value )  . collect (  collectors . to set (  )  )  . for each ( sample fp::merge )  ;  return sample fp ;   }   )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CrosscheckFingerprints.java,remap fingerprints,"private void   ( final  map <  fingerprint id details  fingerprint >  fp map final  file sample map file final  string input field name )  {  final  map <  string  string >  sample map = new  hash map <  >  (  )  ;  final  tabbed input parser parser = new  tabbed input parser ( false sample map file )  ;  for  (  final  string[] strings : parser )   {  if  ( strings . length  !  =  2 )   {  throw new  illegal argument exception ( "" each line of the ""  +  input field name  +  "" must have exactly two strings separated by a tab .  "" +  "" found: ["" +   string . join ( "" ""  arrays . as list ( strings )  )  +  ""] right before ["" +  parser . get current line (  )  +  ""]  in "" +  sample map file . get absolute path (  )  )  ;   }  if  ( sample map . contains key ( strings[0] )  )   {  throw new  illegal argument exception ( "" strings in first column of the ""  +  input field name  +  "" must be unique .  found ["" +  strings[0] +  ""] twice .   right before ["" +  parser . get current line (  )  +  ""] in "" +  sample map file . get absolute path (  )  )  ;   }  sample map . put ( strings[0] strings[1] )  ;   }  final  set <  string >  samples in fp map = fp map . key set (  )  . stream (  )  . map ( id  -  >  id . sample )  . collect (  collectors . to set (  )  )  ;  final  set <  string >  samples not in sample map = sample map . key set (  )  . stream (  )  . filter (  (  (  predicate <  string >  ) samples in fp map::contains )  . negate (  )  )  . collect (  collectors . to set (  )  )  ;  if  (  ! samples not in sample map . is empty (  )  )   {  log . warn ( "" some samples in first column in the ""  +  input field name  +  "" were not present as samples in fingerprinted file: ["" +   string . join ( ""  "" samples not in sample map )  +  ""] . "" )  ;   }  final  list <  string >  resulting samples = new  array list <  >  ( samples in fp map )  ;  sample map . key set (  )  . for each ( s  -  >   {  if  ( resulting samples . remove ( s )  )   {  resulting samples . add ( sample map . get ( s )  )  ;   }   }   )  ;  if  (  collection util . make set ( resulting samples . to array ( new  string[0] )  )  . size (  )   !  =  resulting samples . size (  )  )   {  final  set <  string >  duplicates = new  hash set <  >  (  )  ;  final  set <  string >  unique = new  hash set <  >  (  )  ;  resulting samples . for each ( s  -  >   {  if  ( unique . add ( s )  )  duplicates . add ( s )  ;   }   )  ;  throw new  illegal argument exception ( "" after applying the mapping found in the ""  +  input field name  +  "" the resulting "" +  ""sample names must be unique when taken together with the remaining unmapped samples .  "" +  "" duplicates are: ["" +   string . join ( "" "" duplicates )  +  ""]  "" +  input field name )  ;   }  final  set <  fingerprint id details >  ids = fp map . key set (  )  ;  ids . for each ( id  -  >   {  if  (  ! sample map . contains key ( id . sample )  )  return ;  final  fingerprint fingerprint = fp map . remove ( id )  ;  id . sample = sample map . get ( id . sample )  ;  fp map . put ( id fingerprint )  ;   }   )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\CrosscheckFingerprints.java,write matrix,private void   (  )  {  final  number format format =  number format . get instance (  )  ;  format . set maximum fraction digits ( 4 )  ;  try  ( final  output stream stream = new  file output stream ( matrix   output )  ; final  buffered writer writer = new  buffered writer ( new  output stream writer ( stream )  )  )  {  writer . write ( crosscheck   by . name (  )  )  ;  for  ( int col = 0 ;  col  <  rhs matrix keys . size (  )  ;  col +  +  )   {  writer . write ( '\t'  +  rhs matrix keys . get ( col )  )  ;   }  writer . new line (  )  ;  for  ( int row = 0 ;  row  <  lhs matrix keys . size (  )  ;  row +  +  )   {  writer . write ( lhs matrix keys . get ( row )  )  ;  for  ( int col = 0 ;  col  <  rhs matrix keys . size (  )  ;  col +  +  )   {  writer . write ( '\t'  +  format . format ( crosscheck matrix[col][row] )  )  ;   }  writer . new line (  )  ;   }   }  catch  (  io exception e )   {  throw new  runtime exception ( e )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java, haplotype map,public   ( final  file file )  {  if  (  vcf utils . is variant file ( file )  )   {  from vcf ( file )  ;   }  else  {  from haplotype database ( file )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java, haplotype map file entry,public   ( final  string chrom final int pos final  string name final byte major final byte minor final double maf final  string anchor snp final  list <  string >  fingerprint panels )  {  this . chromosome = chrom ;  this . position = pos ;  this . snp name = name ;  this . major allele = major ;  this . minor allele = minor ;  this . minor allele frequency = maf ;  this . anchor snp = anchor snp ;  this . panels = new  array list <  >  (  )  ;  if  ( fingerprint panels  !  =  null )   {  this . panels . add all ( fingerprint panels )  ;   collections . sort ( this . panels )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,add haplotype,"public void   ( final  haplotype block haplotype block )  {  this . haplotype blocks . add ( haplotype block )  ;  for  (  final  snp snp : haplotype block . get snps (  )  )   {  if  ( haplotypes by snp . contains key ( snp )  )   {  throw new  illegal state exception ( "" same snp name cannot be used twice""  +  snp . to string (  )  )  ;   }  this . haplotypes by snp . put ( snp haplotype block )  ;  this . haplotypes by snp name . put ( snp . get name (  )  haplotype block )  ;  this . haplotypes by snp locus . put ( to key ( snp . get chrom (  )  snp . get pos (  )  )  haplotype block )  ;  this . snps by position . put ( to key ( snp . get chrom (  )  snp . get pos (  )  )  snp )  ;  this . intervals . add ( new  interval ( snp . get chrom (  )  snp . get pos (  )  snp . get pos (  )  false snp . get name (  )  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,anchor from vc,"static private  string   ( final  variant context vc )  {  final  genotype genotype = vc . get genotype ( 0 )  ;  if  ( genotype  =  =  null ||  ! genotype . has extended attribute ( vcf constants . phase   set   key )  )   {  return synthetic   phaseset   prefix  +  ""   ""  +  vc . get contig (  )  +  ""   "" +  vc . get start (  )  ;   }  else  {  return phaseset   prefix  +  ""   ""  +  vc . get contig (  )  +  ""   "" +  genotype . get extended attribute ( vcf constants . phase   set   key )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,as vcf,"public  collection <  variant context >    ( final  reference sequence file ref )  {  final  list <  variant context >  entries = new  array list <  >  (  )  ;  final  sorted set <  snp >  snps = new  tree set <  >  ( get all snps (  )  )  ;  final  map <  snp  boolean >  allele1 matches reference = new  hash map <  >  ( snps . size (  )  )  ;  for  (  final  snp snp : snps )   {  final  reference sequence seq = ref . get subsequence at ( snp . get chrom (  )  snp . get pos (  )  snp . get pos (  )  )  ;  if  ( seq . get bases (  ) [0]  =  =  snp . get allele1 (  )  )   {  allele1 matches reference . put ( snp true )  ;   }  else if  ( seq . get bases (  ) [0]  =  =  snp . get allele2 (  )  )   {  allele1 matches reference . put ( snp false )  ;   }  else  {  throw new  runtime exception ( "" one of the two alleles should agree with the reference: ""  +  snp . to string (  )  )  ;   }   }  for  (  final  haplotype block block : this . get haplotypes (  )  )   {   snp anchor snp = null ;  final  sorted set <  snp >  blocks snps = new  tree set <  >  ( block . get snps (  )  )  ;  for  (  final  snp snp : blocks snps )   {  if  ( anchor snp  =  =  null )   {  anchor snp = snp ;   }  final  string allele string = snp . get allele string (  )  ;  final boolean swap = allele1 matches reference . get ( snp )  ;  final  string reference =  ! swap  ?  allele string . substring ( 0 1 )  : allele string . substring ( 1 2 )  ;  final  string alternate = swap  ?  allele string . substring ( 0 1 )  : allele string . substring ( 1 2 )  ;  final double maf =  ! swap  ?  snp . get maf (  )  : 1  -  snp . get maf (  )  ;   variant context builder builder = new  variant context builder (  )  . chr ( snp . get chrom (  )  )  . start ( snp . get pos (  )  )  . stop ( snp . get pos (  )  )  . alleles ( reference alternate )  . attribute ( vcf constants . allele   frequency   key maf )  . id ( snp . get name (  )  )  ;   genotype builder genotype builder = new  genotype builder ( het   genotype   for   phasing )  ;  if  ( blocks snps . size (  )   >  1 && swap )   {  genotype builder . alleles (  arrays . as list ( builder . get alleles (  )  . get ( 1 )  builder . get alleles (  )  . get ( 0 )  )  )  ;   }  else  {  genotype builder . alleles ( builder . get alleles (  )  )  ;   }  if  ( blocks snps . size (  )   >  1 )   {  genotype builder . phased ( true )  ;  genotype builder . attribute ( vcf constants . phase   set   key anchor snp . get pos (  )  )  ;   }  builder . genotypes ( genotype builder . make (  )  )  ;  entries . add ( builder . make (  )  )  ;   }   }  return entries ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,compare to,public int   ( final  object o )  {  final  haplotype map file entry that =  (  haplotype map file entry ) o ;  int diff = header . get sequence index ( this . chromosome )   -  header . get sequence index ( that . chromosome )  ;  if  ( diff  !  =  0 )  return diff ;  diff = this . position  -  that . position ;  if  ( diff  !  =  0 )  return diff ;  diff = this . snp name . compare to ( that . snp name )  ;  if  ( diff  !  =  0 )  return diff ;  diff = this . major allele  -  that . major allele ;  if  ( diff  !  =  0 )  return diff ;  diff = this . minor allele  -  that . minor allele ;  if  ( diff  !  =  0 )  return diff ;  diff =  double . compare ( this . minor allele frequency that . minor allele frequency )  ;  if  ( diff  !  =  0 )  return diff ;  if  ( this . anchor snp  !  =  null )   {  if  ( that . anchor snp  !  =  null )   {  diff = this . anchor snp . compare to ( that . anchor snp )  ;   }  else  {  diff = 1 ;   }   }  else  {  if  ( that . anchor snp  !  =  null )   {  diff =  - 1 ;   }  else  {  diff = 0 ;   }   }  if  ( diff  !  =  0 )  return diff ;  final  string p1 = this . get panels (  )  ;  final  string p2 = that . get panels (  )  ;  if  ( p1  !  =  null )   {  if  ( p2  !  =  null )   {  return p1 . compare to ( p2 )  ;   }  return 1 ;   }  else if  ( p2  !  =  null )   {  return  - 1 ;   }  else  {  return 0 ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,from haplotype database,"private void   ( final  file file )  {   buffered reader in = null ;  try  {  in = new  buffered reader ( new  input stream reader ( io util . open file for reading ( file )  )  )  ;  final  string builder builder = new  string builder ( 4096 )  ;   string line = null ;  while  (  ( line = in . read line (  )  )   !  =  null )   {  if  ( line . starts with ( ""@"" )  )   {  builder . append ( line )  . append ( '\n' )  ;   }  else  {  break ;   }   }  if  ( builder . length (  )   =  =  0 )   {  throw new  illegal state exception ( "" haplotype map file must contain header: ""  +  file . get absolute path (  )  )  ;   }  final sam file header header = new sam text header codec (  )  . decode ( new  string line reader ( builder . to string (  )  )  "" buffered reader"" )  ;  initialize ( header )  ;  final  format util format = new  format util (  )  ;  final  list <  haplotype map file entry >  entries = new  array list <  >  (  )  ;  final  map <  string  haplotype block >  anchor to haplotype = new  hash map <  >  (  )  ;  do  {  if  ( line . trim (  )  . is empty (  )  )  continue ;  if  ( line . starts with ( ""#"" )  )  continue ;  final  string[] fields = line . split ( ""\\t"" )  ;  if  ( fields . length  <  6 || fields . length  >  8 )   {  throw new  picard exception ( "" invalid haplotype map record contains ""  +  fields . length  +  "" fields: "" +  line )  ;   }  final  string chrom = fields[0] ;  final int pos = format . parse int ( fields[1] )  ;  final  string name = fields[2] ;  final byte major =  ( byte ) fields[3] . char at ( 0 )  ;  final byte minor =  ( byte ) fields[4] . char at ( 0 )  ;  final double maf = format . parse double ( fields[5] )  ;  final  string anchor = fields . length  >  6  ?  fields[6] : null ;  final  string fp panels = fields . length  >  7  ?  fields[7] : null ;   list <  string >  panels = null ;  if  ( fp panels  !  =  null )   {  panels = new  array list <  >  (  )  ;  for  (  final  string panel : fp panels . split ( "" "" )  )   {  panels . add ( panel )  ;   }   }  if  ( anchor  =  =  null || anchor . trim (  )  . equals ( """" )  || name . equals ( anchor )  )   {  final  haplotype block type = new  haplotype block ( maf )  ;  type . add snp ( new  snp ( name chrom pos major minor maf panels )  )  ;  anchor to haplotype . put ( name type )  ;   }  else  {  final  haplotype map file entry entry = make haplotype map file entry ( chrom pos name major minor maf anchor panels )  ;  entries . add ( entry )  ;   }   }  while  (  ( line = in . read line (  )  )   !  =  null )  ;  for  (  final  haplotype map file entry entry : entries )   {  final  haplotype block block = anchor to haplotype . get ( entry . anchor snp )  ;  if  ( block  =  =  null )   {  throw new  picard exception ( "" no haplotype found for anchor snp ""  +  entry . anchor snp )  ;   }  block . add snp ( new  snp ( entry . snp name entry . chromosome entry . position entry . major allele entry . minor allele entry . minor allele frequency entry . panels )  )  ;   }  anchor to haplotype . values (  )  . for each ( this::add haplotype )  ;   }  catch  (  io exception ioe )   {  throw new  picard exception ( "" error parsing haplotype map . "" ioe )  ;   }  finally  {  if  ( in  !  =  null )   {  try  {  in . close (  )  ;   }  catch  (   exception e )   {   }   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,from vcf,"private void   ( final  file file )  {  try  ( final vcf file reader reader = new vcf file reader ( file false )  )  {  final sam sequence dictionary dict = reader . get file header (  )  . get sequence dictionary (  )  ;  if  ( dict  =  =  null || dict . get sequences (  )  . is empty (  )  )   {  throw new  illegal state exception ( "" haplotype map vcf file must contain header: ""  +  file . get absolute path (  )  )  ;   }  initialize ( new sam file header ( dict )  )  ;  final  map <  string  haplotype block >  anchor to haplotype = new  hash map <  >  (  )  ;  for  (  final  variant context vc : reader )   {  if  ( vc . getn samples (  )   >  1 )   {  throw new  illegal state exception ( "" haplotype map vcf file must contain at most one sample: ""  +  file . get absolute path (  )  )  ;   }  final  genotype gc = vc . get genotype ( 0 )  ;  final boolean has gc = gc  !  =  null ;  if  ( vc . get alternate alleles (  )  . size (  )   !  =  1 )   {  throw new  illegal state exception ( "" haplotype map vcf file must contain exactly one alternate allele per site: ""  +  vc . to string (  )  )  ;   }  if  (  ! vc . issnp (  )  )   {  throw new  illegal state exception ( "" haplotype map vcf file must contain only sn ps: ""  +  vc . to string (  )  )  ;   }  if  (  ! vc . has attribute ( vcf constants . allele   frequency   key )  )   {  throw new  illegal state exception ( "" haplotype map vcf  variants must have an '""  +  vcf constants . allele   frequency   key  +  ""' info field: "" +  vc . to string (  )  )  ;   }  if  ( has gc && gc . is phased (  )  &&  ! gc . has extended attribute ( vcf constants . phase   set   key )  )   {  throw new  illegal state exception ( "" haplotype map vcf  variants' genotypes that are phased must have a  phase set  ( ""  +  vcf constants . phase   set   key  +  "" ) "" +  vc . to string (  )  )  ;   }  if  ( has gc && gc . is phased (  )  &&  ! gc . is het (  )  )   {  throw new  illegal state exception ( "" haplotype map vcf  variants' genotypes that are phased must be het""  +  vc . to string (  )  )  ;   }  final  string chrom = vc . get contig (  )  ;  final int pos = vc . get start (  )  ;  final  string name = vc . getid (  )  ;  final byte ref = vc . get reference (  )  . get bases (  ) [0] ;  final byte var = vc . get alternate allele ( 0 )  . get bases (  ) [0] ;  final double temp   maf = vc . get attribute as double ( vcf constants . allele   frequency   key 0d )  ;  final boolean swapped = has gc &&  ! gc . get allele ( 0 )  . equals ( vc . get reference (  )  )  ;  final byte major  minor ;  final double maf ;  if  ( swapped )   {  major = var ;  minor = ref ;  maf = 1  -  temp   maf ;   }  else  {  major = ref ;  minor = var ;  maf = temp   maf ;   }  final  string anchor = anchor from vc ( vc )  ;  if  (  ! anchor to haplotype . contains key ( anchor )  )   {  final  haplotype block new block = new  haplotype block ( maf )  ;  anchor to haplotype . put ( anchor new block )  ;   }  final  haplotype block block = anchor to haplotype . get ( anchor )  ;  block . add snp ( new  snp ( name chrom pos major minor maf null )  )  ;   }  anchor to haplotype . values (  )  . for each ( this::add haplotype )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,get all snps,public  set <  snp >    (  )  {  return  collections . unmodifiable set ( haplotypes by snp . key set (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,get haplotype,public  haplotype block   ( final  string chrom final int pos )  {  return this . haplotypes by snp locus . get ( to key ( chrom pos )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,get haplotypes,public  list <  haplotype block >    (  )  {  return  collections . unmodifiable list ( this . haplotype blocks )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,get header,public sam file header   (  )  {  return header ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,get interval list,public  interval list   (  )  {  this . intervals = this . intervals . sorted (  )  ;  return this . intervals ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,get panels,"public  string   (  )  {  if  ( panels  =  =  null )  return """" ;  final  string builder sb = new  string builder (  )  ;  for  (  final  string panel : panels )   {  if  ( sb . length (  )   >  0 )  sb . append ( ' ' )  ;  sb . append ( panel )  ;   }  return sb . to string (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,get snp,public  snp   ( final  string chrom final int pos )  {  return this . snps by position . get ( to key ( chrom pos )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,initialize,private void   ( final sam file header header )  {  this . header = header ;  this . intervals = new  interval list ( header )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,make haplotype map file entry,private  haplotype map file entry   ( final  string chrom final int pos final  string name final byte major final byte minor final double maf final  string anchor snp final  list <  string >  fingerprint panels )  {  return new  haplotype map file entry ( chrom pos name major minor maf anchor snp fingerprint panels )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,to key,"private  string   ( final  string chrom final int pos )  {  return chrom  +  "":""  +  pos ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,without chromosomes,public  haplotype map   ( final  set <  string >  chroms )  {  final  haplotype map out = new  haplotype map ( get header (  )  )  ;  for  (  final  haplotype block block : this . haplotype blocks )   {  if  (  ! chroms . contains ( block . get first snp (  )  . get chrom (  )  )  )   {  out . add haplotype ( block )  ;   }   }  return out ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,write as vcf,"public void   ( final  file output final  file ref file )  throws  file not found exception  {   reference sequence file ref = new  indexed fasta sequence file ( ref file )  ;  try  (  variant context writer writer = new  variant context writer builder (  )  . set output file ( output )  . set reference dictionary ( ref . get sequence dictionary (  )  )  . build (  )  )  {  final vcf header vcf header = new vcf header ( vcf utils . with updated contigs as lines (  collections . empty set (  )  ref file header . get sequence dictionary (  )  false )   collections . singleton ( het   genotype   for   phasing )  )  ;  vcf utils . with updated contigs as lines (  collections . empty set (  )  ref file header . get sequence dictionary (  )  false )  ;  vcf header . add meta data line ( new vcf header line ( vcf header version . vcf4   2 . get format string (  )  vcf header version . vcf4   2 . get version string (  )  )  )  ;  vcf header . add meta data line ( new vcf info header line ( vcf constants . allele   frequency   key vcf header line count . a vcf header line type .  float "" allele  frequency  for each alt allele  in the same order as listed"" )  )  ;  vcf header . add meta data line ( new vcf format header line ( vcf constants . genotype   key 1 vcf header line type .  string "" genotype"" )  )  ;  vcf header . add meta data line ( new vcf format header line ( vcf constants . phase   set   key 1 vcf header line type .  string "" phase - set identifier for phased genotypes . "" )  )  ;  vcf header . add meta data line ( new vcf header line ( vcf header . source   key "" haplotype map::write as vcf"" )  )  ;  vcf header . add meta data line ( new vcf header line ( ""reference"" "" haplotype map::write as vcf"" )  )  ;  writer . write header ( vcf header )  ;  final  linked list <  variant context >  variants = new  linked list <  >  ( this . as vcf ( ref )  )  ;  variants . sort ( vcf header . getvcf record comparator (  )  )  ;  variants . for each ( writer::add )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeMap.java,write to file,"public void   ( final  file file )  {  try  {  final  buffered writer out = new  buffered writer ( new  output stream writer ( io util . open file for writing ( file )  )  )  ;  final  format util format = new  format util (  )  ;  if  ( this . header  !  =  null )   {  final sam text header codec codec = new sam text header codec (  )  ;  codec . encode ( out this . header )  ;   }  out . write ( ""#chromosome\tposition\tname\tmajor   allele\tminor   allele\tmaf\tanchor   snp\tpanels"" )  ;  out . new line (  )  ;  final  list <  haplotype map file entry >  entries = new  array list <  >  (  )  ;  for  (  final  haplotype block block : this . get haplotypes (  )  )   {   string anchor = null ;  final  sorted set <  snp >  snps = new  tree set <  >  ( block . get snps (  )  )  ;  for  (  final  snp snp : snps )   {  entries . add ( new  haplotype map file entry ( snp . get chrom (  )  snp . get pos (  )  snp . get name (  )  snp . get allele1 (  )  snp . get allele2 (  )  snp . get maf (  )  anchor snp . get fingerprint panels (  )  )  )  ;  if  ( anchor  =  =  null )   {  anchor = snp . get name (  )  ;   }   }   }   collections . sort ( entries )  ;  for  (  final  haplotype map file entry entry : entries )   {  out . write ( entry . chromosome  +  ""\t"" )  ;  out . write ( format . format ( entry . position )   +  ""\t"" )  ;  out . write ( entry . snp name  +  ""\t"" )  ;  out . write (  ( char ) entry . major allele  +  ""\t"" )  ;  out . write (  ( char ) entry . minor allele  +  ""\t"" )  ;  out . write ( format . format ( entry . minor allele frequency )   +  ""\t"" )  ;  if  ( entry . anchor snp  !  =  null )   {  out . write ( entry . anchor snp )  ;   }  out . write ( ""\t"" )  ;  if  ( entry . get panels (  )   !  =  null )   {  out . write ( entry . get panels (  )  )  ;   }  out . new line (  )  ;   }  out . flush (  )  ;  out . close (  )  ;   }  catch  (  io exception ioe )   {  throw new  picard exception ( "" error writing out haplotype map to file: ""  +  file . get absolute path (  )  ioe )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromContaminatorSequence.java, haplotype probabilities from contaminator sequence,public   ( final  haplotype block haplotype block final double contamination )  {  super ( haplotype block )  ;  assert  ( contamination  <  =  1 . 0 )  ;  assert  ( contamination  >  =  0 . 0 )  ;  this . contamination = contamination ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromContaminatorSequence.java,add to probs,public void   ( final  snp snp final byte base final byte qual )  {  assert snp part of haplotype ( snp )  ;  final boolean alt allele ;  if  ( base  =  =  snp . get allele1 (  )  )   {  this . obs allele1 +  +  ;  alt allele = false ;   }  else if  ( base  =  =  snp . get allele2 (  )  )   {  this . obs allele2 +  +  ;  alt allele = true ;   }  else  {  this . obs allele other +  +  ;  return ;   }  final double p err =  quality util . get error probability from phred score ( qual )  ;  for  (  final  genotype cont geno :  genotype . values (  )  )   {  for  (  final  genotype main geno :  genotype . values (  )  )   {  final double theta = 0 . 5 *  (  ( 1  -  contamination )  * main geno . v  +  contamination * cont geno . v )  ;  likelihood map[cont geno . v][main geno . v]* =  (  ( alt allele  ?  theta :  ( 1  -  theta )  )  *  ( 1  -  p err )   +   (  ! alt allele  ?  theta :  ( 1  -  theta )  )  * p err )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromContaminatorSequence.java,get log likelihoods,@ override public double[]   (  )  {  update likelihoods (  )  ;  return super . get log likelihoods (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromContaminatorSequence.java,merge,"@ override public void   ( final  haplotype probabilities other )  {  super . merge ( other )  ;  if  (  ! this . get haplotype (  )  . equals ( other . get haplotype (  )  )  )   {  throw new  illegal argument exception ( "" mismatched haplotypes in call "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromContaminatorSequence.java,update likelihoods,private void   (  )  {  final double[] ll = new double[ genotype . values (  )  . length] ;  for  (  final  genotype cont geno :  genotype . values (  )  )   {  ll[cont geno . v] = log10 (  math util . sum (  math util . multiply ( this . get prior probablities (  )  likelihood map[cont geno . v] )  )  )  ;   }  set log likelihoods ( ll )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilities.java, genotype,  ( final int v )  {  this . v = v ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilities.java, haplotype probabilities,protected   ( final  haplotype block haplotype block )  {  this . haplotype block = haplotype block ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilities.java,assert snp part of haplotype,"void   ( final  snp snp )  {  if  (  ! this . haplotype block . contains ( snp )  )   {  throw new  illegal argument exception ( "" snp ""  +  snp  +  "" does not belong to haplotype "" +  this . haplotype block )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilities.java,get haplotype,public  haplotype block   (  )  {  return this . haplotype block ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromGenotype.java, haplotype probabilities from genotype,public   ( final  snp snp final  haplotype block haplotype block final double aa final double  aa final double aa )  {  super ( haplotype block )  ;  this . snp = snp ;  this . likelihoods = new double[] { aa  aa aa }  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromGenotype.java,get likelihoods,public double[]   (  )  {  return likelihoods ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromGenotype.java,get representative snp,@ override public  snp   (  )  {  return snp ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromGenotype.java,merge,"@ override public void   ( final  haplotype probabilities other )  {  if  (  ! this . get haplotype (  )  . equals ( other . get haplotype (  )  )  )   {  throw new  illegal argument exception ( "" mismatched haplotypes in call to  haplotype probabilities "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromGenotypeLikelihoods.java, haplotype probabilities from genotype likelihoods,public   ( final  haplotype block haplotype block )  {  super ( haplotype block )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromGenotypeLikelihoods.java,add to log likelihoods,public void   ( final  snp snp final  list <  allele >  alleles final double[] log genotype likelihoods )  {  assert snp part of haplotype ( snp )  ;  assert  ( log genotype likelihoods . length  =  =   genotype . values (  )  . length )  ;  assert  ( alleles . size (  )   =  =  2 )  ;  for  ( int i = 0 ;  i  <  2 ;  i +  +  )   {  assert  ( alleles . get ( i )  . get bases (  )  . length  =  =  1 )  ;   }  final byte allele1 = alleles . get ( 0 )  . get bases (  ) [0] ;  final byte allele2 = alleles . get ( 1 )  . get bases (  ) [0] ;  if  ( snp . get allele1 (  )   =  =  allele1 && snp . get allele2 (  )   =  =  allele2 )   {  set log likelihoods (  math util . sum ( get log likelihoods (  )  log genotype likelihoods )  )  ;  return ;   }  if  ( snp . get allele2 (  )   =  =  allele1 && snp . get allele1 (  )   =  =  allele2 )   {  final double[] ll = get log likelihoods (  )  ;  ll[ genotype . hom   allele1 . v] +  = log genotype likelihoods[ genotype . hom   allele2 . v] ;  ll[ genotype . het   allele12 . v] +  = log genotype likelihoods[ genotype . het   allele12 . v] ;  ll[ genotype . hom   allele2 . v] +  = log genotype likelihoods[ genotype . hom   allele1 . v] ;  set log likelihoods ( ll )  ;  return ;   }  assert true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesUsingLogLikelihoods.java, haplotype probabilities using log likelihoods,public   ( final  haplotype block haplotype block )  {  super ( haplotype block )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesUsingLogLikelihoods.java,get likelihoods,@ override public double[]   (  )  {  update dependent values (  )  ;  return likelihoods ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesUsingLogLikelihoods.java,get likelihoods,private double[]   (  )  {  return  math util . p normalize log probability ( get log likelihoods (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesUsingLogLikelihoods.java,get lod most probable genotype,@ override public double   (  )  {  final double[] logs = get shifted log posterior (  )  ;  double biggest =  -  double . max   value ;  double second biggest = biggest ;  for  (  double prob : logs )   {  if  ( prob  >  biggest )   {  second biggest = b
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesUsingLogLikelihoods.java,get log likelihoods,@ override public double[]   (  )  {  return this . loglikelihoods ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesUsingLogLikelihoods.java,get posterior probabilities,public double[]   (  )  {  update dependent values (  )  ;  return posterior probabilities ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesUsingLogLikelihoods.java,get posterior probabilities,private double[]   (  )  {  return  math util . p normalize log probability ( get shifted log posterior0 (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesUsingLogLikelihoods.java,get representative snp,@ override public  snp   (  )  {  return get haplotype (  )  . get first snp (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesUsingLogLikelihoods.java,get shifted log posterior,private double[]   (  )  {  update dependent values (  )  ;  return shifted log posteriors ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesUsingLogLikelihoods.java,get shifted log posterior,private double[]   (  )  {  final double[] ll = this . get log likelihoods (  )  ;  final double[] shifted log posterior = new double[ genotype . values (  )  . length] ;  final double[] haplotype frequencies = get prior probablities (  )  ;  for  (  final  genotype g :  genotype . values (  )  )   {  shifted log posterior[g . v] = ll[g . v]  +  log10 ( haplotype frequencies[g . v] )  ;   }  return shifted log posterior ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesUsingLogLikelihoods.java,has evidence,@ override public boolean   (  )  {  final double[] ll = this . get log likelihoods (  )  ;  return ll[ genotype . hom   allele1 . v]  !  =  0 || ll[ genotype . het   allele12 . v]  !  =  0 || ll[ genotype . hom   allele2 . v]  !  =  0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesUsingLogLikelihoods.java,merge,"@ override public void   ( final  haplotype probabilities other )  {  if  (  ! this . get haplotype (  )  . equals ( other . get haplotype (  )  )  )   {  throw new  illegal argument exception ( "" mismatched haplotypes in call to  haplotype probabilities "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesUsingLogLikelihoods.java,set log likelihoods,public void   ( final double[] ll )  {  assert  ( ll . length  =  =   genotype . values (  )  . length )  ;   system . arraycopy ( ll 0 loglikelihoods 0 ll . length )  ;  likelihoods need updating = true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesUsingLogLikelihoods.java,update dependent values,private void   (  )  {  if  ( likelihoods need updating )   {  likelihoods = get likelihoods0 (  )  ;  posterior probabilities = get posterior probabilities0 (  )  ;  shifted log posteriors = get shifted log posterior0 (  )  ;  likelihoods need updating = false ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilityOfNormalGivenTumor.java, haplotype probability of normal given tumor,public   ( final  haplotype probabilities hp of tumor final double p loh )  {  super ( hp of tumor . get haplotype (  )  )  ;  transition matrix = transition matrix map . get ( p loh )  . get transition matrix (  )  ;  this . hp of tumor = hp of tumor ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilityOfNormalGivenTumor.java, transition matrix,public   ( double p loh )  {  transition matrix = new double[][] {  { 1 0 0 }   { p loh  /  2 1  -  p loh p loh  /  2 }   { 0 0 1 }  }  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilityOfNormalGivenTumor.java,get likelihoods,@ override public double[]   (  )  {  final double[] normal haplotype likelihoods = new double[3] ;  final double[] tumor haplotype likelihoods = hp of tumor . get likelihoods (  )  ;  for  (  final  genotype g   n :  genotype . values (  )  )   {  normal
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilityOfNormalGivenTumor.java,get obs allele,@ override public int   (  )  {  return hp of tumor . get obs allele1 (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilityOfNormalGivenTumor.java,get obs allele,@ override public int   (  )  {  return hp of tumor . get obs allele2 (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilityOfNormalGivenTumor.java,get representative snp,@ override public  snp   (  )  {  return hp of tumor . get representative snp (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilityOfNormalGivenTumor.java,get total obs,@ override public int   (  )  {  return hp of tumor . get total obs (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilityOfNormalGivenTumor.java,get transition matrix,public double[][]   (  )  {  return transition matrix ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilityOfNormalGivenTumor.java,has evidence,@ override public boolean   (  )  {  return hp of tumor . has evidence (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilityOfNormalGivenTumor.java,merge,"@ override public void   ( final  haplotype probabilities ignored )  {  throw new  illegal argument exception ( "" cannot merge  haplotype probability of normal given tumor .   merge the underlying object and create a new wrapper . "" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\IdentifyContaminant.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is readable ( haplotype   map )  ;  io util . assert file is writable ( output )  ;  io util . assert file is readable ( reference   sequence )  ;  f
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\IdentifyContaminant.java,get sample to use,"private  string   ( final  string fp sample )  {  if  ( sample   alias  =  =  null )   {  return  string . format ( ""%s - %s"" fp sample extract   contaminated  ?  ""contaminated"" : ""contamination"" )  ;   }  else  {  return sample   alias ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\IdentifyContaminant.java,requires reference,@ override protected boolean   (  )  {  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromSequence.java, haplotype probabilities from sequence,public   ( final  haplotype block haplotype block )  {  super ( haplotype block )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromSequence.java,add to probs,public void   ( final  snp snp final byte base final byte qual )  {  assert snp part of haplotype ( snp )  ;  final double[] ll = get log likelihoods (  )  ;  final double p error =  quality util . get error probability from phred score ( qual )  ;  if  ( base  =  =  snp . get allele1 (  )  )   {  obs allele1 +  +  ;  for  (  final  genotype g :  genotype . values (  )  )   {  final double p alt = g . v  /  2d ;  ll[g . v] +  = log10 (  ( 1d  -  p alt )  *  ( 1d  -  p error )   +  p alt * p error )  ;   }   }  else if  ( base  =  =  snp . get allele2 (  )  )   {  obs allele2 +  +  ;  for  (  final  genotype g :  genotype . values (  )  )   {  final double p alt = 1  -  g . v  /  2d ;  ll[g . v] +  = log10 (  ( 1d  -  p alt )  *  ( 1d  -  p error )   +  p alt * p error )  ;   }   }  else  {  obs allele other +  +  ;   }  set log likelihoods ( ll )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromSequence.java,get fraction unexpected allele obs,public double   (  )  {  return obs allele other  /   ( double )  ( get total obs (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromSequence.java,get obs allele,@ override public int   (  )  {  return obs allele1 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromSequence.java,get obs allele,@ override public int   (  )  {  return obs allele2 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromSequence.java,get total obs,@ override public int   (  )  {  return obs allele1  +  obs allele2  +  obs allele other ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromSequence.java,has evidence,@ override public boolean   (  )  {  return super . has evidence (  )  || obs allele1  >  0 || obs allele2  >  0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\HaplotypeProbabilitiesFromSequence.java,merge,"@ override public void   ( final  haplotype probabilities other )  {  super . merge ( other )  ;  if  (  ! this . get haplotype (  )  . equals ( other . get haplotype (  )  )  )   {  throw new  illegal argument exception ( "" mismatched haplotypes in call "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java, snp,public   ( final  string name final  string chrom final int pos final byte allele1 final byte allele2 final double maf final  list <  string >  fingerprint panels )  {  this . name = name ;  this . chrom = chrom ;  this . pos = pos ;  this . allele1 =  string util . to upper case ( allele1 )  ;  this . allele2 =  string util . to upper case ( allele2 )  ;  this . maf = maf ;  this . fingerprint panels = fingerprint panels  =  =  null  ?  new  array list <  string >  (  )  : fingerprint panels ;  this . genotypes[0] =  diploid genotype . from bases ( allele1 allele1 )  ;  this . genotypes[1] =  diploid genotype . from bases ( allele1 allele2 )  ;  this . genotypes[2] =  diploid genotype . from bases ( allele2 allele2 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,compare to,@ override public int   ( final  snp that )  {  int retval = this . chrom . compare to ( that . chrom )  ;  if  ( retval  =  =  0 )  retval = this . pos  -  that . pos ;  return retval ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,equals,@ override public boolean   ( final  object o )  {  return  ( this  =  =  o )  ||  (  ( o instanceof  snp )  && compare to (  (  snp ) o )   =  =  0 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,flip,public  snp   (  )  {  return new  snp ( name chrom pos allele2 allele1 1  -  maf fingerprint panels )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,get allele,public byte   (  )  {  return allele1 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,get allele,public byte   (  )  {  return allele2 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,get allele string,public  string   (  )  {  return  string util . bytes to string ( new byte[] { allele1  string util . to lower case ( allele2 )  }  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,get chrom,public  string   (  )  {  return chrom ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,get fingerprint panels,public  list <  string >    (  )  {  return this . fingerprint panels ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,get genotype, diploid genotype   ( final  diploid haplotype haplotype )  {  return this . genotypes[haplotype . ordinal (  ) ] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,get heterogyzous genotype,public  diploid genotype   (  )  {  return this . genotypes[1] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,get homozygous allele genotype,public  diploid genotype   (  )  {  return this . genotypes[0] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,get homozygous allele genotype,public  diploid genotype   (  )  {  return this . genotypes[2] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,get maf,public double   (  )  {  return maf ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,get name,public  string   (  )  {  return name ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,get pos,public int   (  )  {  return pos ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,hash code,@ override public int   (  )  {  int result = chrom . hash code (  )  ;  result = 31 * result  +  pos ;  return result ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,index of,"int   ( final  diploid genotype gt )  {  for  ( int i = 0 ;  i  <  this . genotypes . length ;   +  + i )   {  if  ( gt  =  =  this . genotypes[i] )  return i ;   }  throw new  illegal argument exception ( "" genotype ""  +  gt  +  "" is not valid for this snp . "" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\Snp.java,to string,"@ override public  string   (  )  {  return this . chrom  +  "":""  +  this . pos ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\BasecallsConverter.java, basecalls converter,  ( final  map <  string  ?  extends  converted cluster data writer < cluster   output   record >  >  barcode record writer map final int max reads in ram per tile final  list <  file >  tmp dirs final  sorting collection .  codec < cluster   output   record >  codec prototype final boolean ignore unexpected barcodes final boolean demultiplex final  comparator < cluster   output   record >  output record comparator final  bcl quality evaluation strategy bcl quality evaluation strategy final  class < cluster   output   record >  output record class final int num processors final  illumina data provider factory factory )  {  this . barcode record writer map = barcode record writer map ;  this . max reads in ram per tile = max reads in ram per tile ;  this . tmp dirs = tmp dirs ;  this . codec prototype = codec prototype ;  this . ignore unexpected barcodes = ignore unexpected barcodes ;  this . demultiplex = demultiplex ;  this . output record comparator = output record comparator ;  this . bcl quality evaluation strategy = bcl quality evaluation strategy ;  this . output record class = output record class ;  this . factory = factory ;  if  ( num processors  =  =  0 )   {  this . num threads =  runtime . get runtime (  )  . available processors (  )  ;   }  else if  ( num processors  <  0 )   {  this . num threads =  runtime . get runtime (  )  . available processors (  )   +  num processors ;   }  else  {  this . num threads = num processors ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\MatchResults.java, match results,  ( final  path fingerprint file final  string sample final double sample likelihood final double population likelihood final double lodtn final double lodnt final  collection <  locus result >  locus results )  {  this . fingerprint file = fingerprint file ;  this . sample = sample ;  this . sample likelihood = sample likelihood ;  this . population likelihood = population likelihood ;  this . lod = sample likelihood  -  population likelihood ;  this . lodtn = lodtn ;  this . lodnt = lodnt ;  if  ( locus results  !  =  null )   {  this . locus results = new  tree set <  >  ( locus results )  ;   }  else  {  this . locus results = null ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\MatchResults.java,compare to,@ override public int   (  match results that )  {  if  ( this . lod  !  =  that . lod )   {  return this . lod  >  that . lod  ?   - 1 : 1 ;   }  else  {  return this . sample . compare to ( that . sample )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\MatchResults.java,get fingerprint file,public  path   (  )  {  return this . fingerprint file ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\MatchResults.java,getlod,public double   (  )  {  return lod ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\MatchResults.java,get locus results,public  sorted set <  locus result >    (  )  {  return locus results ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\MatchResults.java,get lodnt,public double   (  )  {  return lodnt ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\MatchResults.java,get lodtn,public double   (  )  {  return lodtn ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\MatchResults.java,get population likelihood,public double   (  )  {  return population likelihood ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\MatchResults.java,get sample,public  string   (  )  {  return sample ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\MatchResults.java,get sample likelihood,public double   (  )  {  return sample likelihood ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\LocusResult.java, locus result,  ( final  snp snp final  diploid genotype expected genotype final  diploid genotype most likely genotype final int allele1 count final int allele2 count final double lod genotype final double l expected sample final double l random sample final double lod genotype tumor normal final double lod genotype normal tumor )  {  this . snp = snp ;  this . expected genotype = expected genotype ;  this . most likely genotype = most likely genotype ;  this . allele1 count = allele1 count ;  this . allele2 count = allele2 count ;  this . lod genotype = lod genotype ;  this . l expected sample = l expected sample ;  this . l random sample = l random sample ;  this . lod expected sample tumor normal = lod genotype tumor normal ;  this . lod expected sample normal tumor = lod genotype normal tumor ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\LocusResult.java,compare to,@ override public int   ( final  locus result that )  {  return this . snp . compare to ( that . snp )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\LocusResult.java,get allele count,public int   (  )  {  return allele1 count ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\LocusResult.java,get allele count,public int   (  )  {  return allele2 count ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\LocusResult.java,get expected genotype,public  diploid genotype   (  )  {  return expected genotype ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\LocusResult.java,get lod expected sample normal tumor,public double   (  )  {  return lod expected sample normal tumor ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\LocusResult.java,get lod expected sample tumor normal,public double   (  )  {  return lod expected sample tumor normal ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\LocusResult.java,get lod genotype,public double   (  )  {  return lod genotype ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\LocusResult.java,get most likely genotype,public  diploid genotype   (  )  {  return most likely genotype ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\LocusResult.java,get snp,public  snp   (  )  {  return snp ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\LocusResult.java,l expected sample,public double   (  )  {  return l expected sample ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\fingerprint\LocusResult.java,l random sample,public double   (  )  {  return l random sample ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CheckIlluminaDirectory.java,create loc file symlinks,"private void   ( final  illumina file util file util final int lane )  {  final  file base file = new  file ( basecalls   dir . get parent file (  )  . get absolute path (  )   +   file . separator  +   abstract illumina position file reader . s   locs   file )  ;  final  file new file base = new  file ( base file . get parent (  )   +   file . separator  +   illumina file util . long lane str ( lane )  +   file . separator )  ;  if  ( base file . exists (  )  )   {  boolean success = true ;  if  (  ! new file base . exists (  )  )   {  success = new file base . mkdirs (  )  ;   }  if  ( success )   {  for  (  final  integer tile : file util . get expected tiles (  )  )   {  final  string new name = new file base  +   file . separator  +   string . format ( ""s   %d   %d . locs"" lane tile )  ;  final  process executor .  exit status and output output =  process executor . execute and return interleaved output ( new  string[] { ""ln"" "" - fs"" base file . get absolute path (  )  new name }  )  ;  if  ( output . exit status  !  =  0 )   {  throw new  picard exception ( "" could not create symlink: ""  +  output . stdout )  ;   }   }   }  else  {  throw new  picard exception (  string . format ( "" could not create lane directory: %s . "" new file base . get absolute path (  )  )  )  ;   }   }  else  {  throw new  picard exception (  string . format ( "" locations file %s does not exist . "" base file . get absolute path (  )  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CheckIlluminaDirectory.java,custom command line validation,"@ override protected  string[]   (  )  {  io util . assert directory is readable ( basecalls   dir )  ;  final  list <  string >  errors = new  array list <  >  (  )  ;  for  (  final  integer lane : lanes )   {  if  ( lane  <  1 )   {  errors . add ( ""la"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CheckIlluminaDirectory.java,do work,@ override protected int   (  )  {  final  read structure read structure = new  read structure ( read   structure )  ;  if  ( data   types . is empty (  )  )   {  data   types . add all (  arrays . as list (  illumina basecalls converter . data   types   
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CheckIlluminaDirectory.java,main,public static void   ( final  string[] argv )  {  new  check illumina directory (  )  . instance main with exit ( argv )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CheckIlluminaDirectory.java,verify lane,"private static int   ( final  illumina file util file util final  list <  integer >  expected tiles final int[] cycles final  set <  illumina data type >  data types final boolean fake files )  {  if  ( expected tiles . is empty (  )  )   {  throw new  picard exception ( ""0 input tiles were specified !   check to make sure this lane is in the  inter op file ! "" )  ;   }  if  ( cycles . length  =  =  0 )   {  throw new  picard exception ( ""0 output cycles were specified ! "" )  ;   }  int num failures = 0 ;  final  map <  illumina file util .  supported illumina format  set <  illumina data type >  >  format to data types =  illumina data provider factory . determine formats ( data types file util )  ;  final  set <  illumina data type >  unmatched data types =  illumina data provider factory . find unmatched types ( data types format to data types )  ;  if  (  ! unmatched data types . is empty (  )  )   {  if  ( fake files )   {  for  (  final  illumina data type data type : unmatched data types )   {  final  illumina file util .  supported illumina format format =  illumina data provider factory . find preferred format ( data type file util )  ;  file util . get util ( format )  . fake files ( expected tiles cycles format )  ;   }   }  log . info ( "" could not find a format with available files for the following data types: ""  +   string util . join ( ""  "" new  array list <  >  ( unmatched data types )  )  )  ;  num failures +  = unmatched data types . size (  )  ;   }  for  (  final  illumina file util .  supported illumina format format : format to data types . key set (  )  )   {  final  parameterized file util util = file util . get util ( format )  ;  util . set tiles for per run file ( expected tiles )  ;  final  list <  string >  failures = util . verify ( expected tiles cycles )  ;  if  (  ! failures . is empty (  )  && fake files )   {  util . fake files ( expected tiles cycles format )  ;   }  num failures +  = failures . size (  )  ;  for  (  final  string failure : failures )   {  log . info ( failure )  ;   }   }  return num failures ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaLaneMetrics.java,calculate lane density from tiles,private static double   ( final  collection <  tile >  tiles )  {  double area = 0 ;  double clusters = 0 ;  for  (  final  tile tile : tiles )   {  if  ( tile . get cluster density (  )   >  0 )  area +  =  ( tile . get cluster count (  )   /  tile . get cluster density (  )  )  ;  clusters +  = tile . get cluster count (  )  ;   }  return  ( area  >  0 )   ?  clusters  /  area : 0 . 0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaLaneMetrics.java,collect lane metrics,public static void   ( final  file run directory final  file output directory final  string output prefix final  metrics file <  metric base  comparable <  ?  >  >  lane metrics file final  metrics file <  metric base  comparable <  ?  >  >  phasing metrics file final  read structure read structure final  string file extension final  validation stringency validation stringency final boolean is nova seq )  {  final  map <  integer  ?  extends  collection <  tile >  >  lane tiles = read lane tiles ( run directory read structure validation stringency is nova seq )  ;  write lane metrics ( lane tiles output directory output prefix lane metrics file file extension )  ;  write phasing metrics ( lane tiles output directory output prefix phasing metrics file file extension is nova seq )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaLaneMetrics.java,do work,@ override protected int   (  )  {  final  metrics file <  metric base  comparable <  ?  >  >  lane metrics file = this . get metrics file (  )  ;  final  metrics file <  metric base  comparable <  ?  >  >  phasing metrics file = this . get metrics file (
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaLaneMetrics.java,main,public static void   ( final  string[] args )  {  new  collect illumina lane metrics (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaLaneMetrics.java,read lane tiles,"public static  map <  integer  ?  extends  collection <  tile >  >    ( final  file illumina run directory final  read structure read structure final  validation stringency validation stringency final boolean is nova seq )  {  final  collection <  tile >  tiles ;  try  {   file tile metrics out file =  tile metrics util . render tile metrics file from basecalling directory ( illumina run directory read structure . total cycles is nova seq )  ;  if  ( is nova seq )   {  tiles =  tile metrics util . parse tile metrics ( tile metrics out file  tile metrics util . render phasing metrics files from basecalling directory ( illumina run directory )  read structure validation stringency )  ;   }  else  {  tiles =  tile metrics util . parse tile metrics ( tile metrics out file read structure validation stringency )  ;   }   }  catch  (  final  file not found exception e )   {  throw new  picard exception ( "" unable to open lane metrics file . "" e )  ;   }  return tiles . stream (  )  . filter ( tile  -  >  tile . get lane number (  )   >  0 )  . collect (  collectors . grouping by (  tile::get lane number )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaLaneMetrics.java,write lane metrics,public static  file   ( final  map <  integer  ?  extends  collection <  tile >  >  lane tiles final  file output directory final  string output prefix final  metrics file <  metric base  comparable <  ?  >  >  lane metrics file final  string file extension )  {  lane tiles . entry set (  )  . for each ( entry  -  >   {  final  illumina lane metrics lane metric = new  illumina lane metrics (  )  ;  lane metric . lane = entry . get key (  )  . long value (  )  ;  lane metric . cluster   density = calculate lane density from tiles ( entry . get value (  )  )  ;  lane metrics file . add metric ( lane metric )  ;   }   )  ;  return write metrics ( lane metrics file output directory output prefix  illumina lane metrics . get extension (  )   +  file extension )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaLaneMetrics.java,write metrics,"private static  file   ( final  metrics file <  metric base  comparable <  ?  >  >  metrics file final  file output directory final  string output prefix final  string output extension )  {  final  file output file = new  file ( output directory  string . format ( ""%s . %s"" output prefix output extension )  )  ;  log . info (  string . format ( "" writing %s lane metrics to %s  .  .  . "" metrics file . get metrics (  )  . size (  )  output file )  )  ;  metrics file . write ( output file )  ;  return output file ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaLaneMetrics.java,write phasing metrics,public static  file   ( final  map <  integer  ?  extends  collection <  tile >  >  lane tiles final  file output directory final  string output prefix final  metrics file <  metric base  comparable <  ?  >  >  phasing metrics file final  string file extension final boolean is nova seq )  {  lane tiles . for each (  ( key value )   -  >   illumina phasing metrics . get phasing metrics for tiles ( key . long value (  )  value  ! is nova seq )  . for each ( phasing metrics file::add metric )  )  ;  return write metrics ( phasing metrics file output directory output prefix  illumina phasing metrics . get extension (  )   +  file extension )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CustomAdapterPair.java, custom adapter pair,  ( final  string five prime final  string three prime )  {  this . three prime = three prime ;  this . three prime bytes =  string util . string to bytes ( three prime )  ;  this . five prime = five prime ;  this . five prime read order =  sequence util . reverse complement ( five prime )  ;  this . five prime bytes =  string util . string to bytes ( five prime )  ;  this . five prime read order bytes =  string util . string to bytes ( five prime read order )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CustomAdapterPair.java,get prime adapter,public  string   (  )  {  return three prime ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CustomAdapterPair.java,get prime adapter bytes,public byte[]   (  )  {  return three prime bytes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CustomAdapterPair.java,get prime adapter bytes in read order,public byte[]   (  )  {  return three prime bytes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CustomAdapterPair.java,get prime adapter in read order,public  string   (  )  {  return three prime ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CustomAdapterPair.java,get prime adapter,public  string   (  )  {  return five prime ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CustomAdapterPair.java,get prime adapter bytes,public byte[]   (  )  {  return five prime bytes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CustomAdapterPair.java,get prime adapter bytes in read order,public byte[]   (  )  {  return five prime read order bytes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CustomAdapterPair.java,get prime adapter in read order,public  string   (  )  {  return five prime read order ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CustomAdapterPair.java,get name,"public  string   (  )  {  return "" custom adapter pair"" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ClusterDataToSamConverter.java, cluster data to sam converter,public   ( final  string run barcode final  string read group id final  read structure read structure final  list <  adapter pair >  adapters )  {  this . read group id = read group id ;  this . read name encoder = new  illumina read name encoder ( run barcode )  ;  this . is paired end = read structure . templates . length (  )   =  =  2 ;  this . has sample barcode =  ! read structure . sample barcodes . is empty (  )  ;  this . has molecular barcode =  ! read structure . molecular barcode . is empty (  )  ;  if  ( adapters . is empty (  )  )   {  this . adapter marker = null ;   }  else  {  this . adapter marker = new  adapter marker ( adapters . to array ( new  adapter pair[adapters . size (  ) ] )  )  ;   }  this . template indices = read structure . templates . get indices (  )  ;  this . sample barcode indices = read structure . sample barcodes . get indices (  )  ;  this . molecular barcode indices = read structure . molecular barcode . get indices (  )  ;  this . output records per cluster = read structure . templates . length (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ClusterDataToSamConverter.java,convert cluster to output record,public  illumina basecalls to sam . sam records for cluster   ( final  cluster data cluster )  {  final  illumina basecalls to sam . sam records for cluster ret = new  illumina basecalls to sam . sam records for cluster ( output records per cluster )  ;  final  string read name = read name encoder . generate read name ( cluster null )  ;   string unmatched barcode = null ;  if  ( has sample barcode && cluster . get matched barcode (  )   =  =  null )   {  final byte[][] barcode = new byte[sample barcode indices . length][] ;  for  ( int i = 0 ;  i  <  sample barcode indices . length ;  i +  +  )   {  barcode[i] = cluster . get read ( sample barcode indices[i] )  . get bases (  )  ;   }  unmatched barcode =  illumina util . barcode seqs to string ( barcode )  . replace ( ' . ' 'n' )  ;   }  final  list <  string >  molecular indexes ;  final  list <  string >  molecular index qualities ;  if  ( has molecular barcode )   {  molecular indexes = new  array list <  >  (  )  ;  molecular index qualities = new  array list <  >  (  )  ;  for  ( int i = 0 ;  i  <  molecular barcode indices . length ;  i +  +  )   {  molecular indexes . add ( new  string ( cluster . get read ( molecular barcode indices[i] )  . get bases (  )  )  . replace ( ' . ' 'n' )  )  ;  molecular index qualities . add ( sam utils . phred to fastq ( cluster . get read ( molecular barcode indices[i] )  . get qualities (  )  )  )  ;   }   }  else  {  molecular indexes =  collections . empty list (  )  ;  molecular index qualities =  collections . empty list (  )  ;   }  final sam record first of pair = create sam record ( cluster . get read ( template indices[0] )  read name cluster . is pf (  )  true unmatched barcode molecular indexes molecular index qualities )  ;  ret . records[0] = first of pair ;  sam record second of pair = null ;  if  ( is paired end )   {  second of pair = create sam record ( cluster . get read ( template indices[1] )  read name cluster . is pf (  )  false unmatched barcode molecular indexes molecular index qualities )  ;  ret . records[1] = second of pair ;   }  if  ( adapter marker  !  =  null )   {  if  ( is paired end )   {  adapter marker . adapter trim illumina paired reads ( first of pair second of pair )  ;   }  else  {  adapter marker . adapter trim illumina single read ( first of pair )  ;   }   }  return ret ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ClusterDataToSamConverter.java,create sam record,"private sam record   ( final  read data read data final  string read name final boolean is pf final boolean first of pair final  string unmatched barcode final  list <  string >  molecular indexes final  list <  string >  molecular index qualities )  {  final sam record sam = new sam record ( null )  ;  sam . set read name ( read name )  ;  sam . set read bases ( read data . get bases (  )  )  ;  sam . set base qualities ( read data . get qualities (  )  )  ;  sam . set read paired flag ( is paired end )  ;  sam . set read unmapped flag ( true )  ;  sam . set read fails vendor quality check flag (  ! is pf )  ;  if  ( is paired end )   {  sam . set mate unmapped flag ( true )  ;  sam . set first of pair flag ( first of pair )  ;  sam . set second of pair flag (  ! first of pair )  ;   }  if  ( filters . filter out ( sam )  )   {  sam . set attribute (  reserved tag constants . xn 1 )  ;   }  if  ( this . read group id  !  =  null )   {  sam . set attribute ( sam tag . rg . name (  )  read group id )  ;   }  if  ( unmatched barcode  !  =  null )   {  sam . set attribute ( sam tag . bc . name (  )  unmatched barcode )  ;   }  if  (  ! molecular indexes . is empty (  )  )   {  if  (  ! this . molecular index tag . is empty (  )  )   {  sam . set attribute ( this . molecular index tag  string . join ( molecular index delimiter molecular indexes )  )  ;   }  if  (  ! this . molecular index quality tag . is empty (  )  )   {  sam . set attribute ( this . molecular index quality tag  string . join ( molecular index delimiter molecular index qualities )  )  ;   }  if  (  ! this . tag per molecular index . is empty (  )  )   {  if  ( tag per molecular index . size (  )   !  =  molecular indexes . size (  )  )   {  throw new  picard exception ( "" found ""  +  molecular indexes . size (  )   +  "" molecular indexes but only "" +  tag per molecular index . size (  )  +  "" sam tags given . "" )  ;   }  for  ( int i = 0 ;  i  <  this . tag per molecular index . size (  )  ;  i +  +  )   {  sam . set attribute ( this . tag per molecular index . get ( i )  molecular indexes . get ( i )  )  ;   }   }   }  return sam ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ClusterDataToSamConverter.java,with molecular index quality tag,"public  cluster data to sam converter   ( final  string molecular index quality tag )  {  if  ( molecular index quality tag  =  =  null )  throw new  illegal argument exception ( "" molecular index quality tag was null"" )  ;  this . molecular index quality tag = molecular index quality tag ;  return this ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ClusterDataToSamConverter.java,with molecular index tag,"public  cluster data to sam converter   ( final  string molecular index tag )  {  if  ( molecular index tag  =  =  null )  throw new  illegal argument exception ( "" molecular index tag was null"" )  ;  this . molecular index tag = molecular index tag ;  return this ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ClusterDataToSamConverter.java,with tag per molecular index,"public  cluster data to sam converter   ( final  list <  string >  tag per molecular index )  {  if  ( tag per molecular index  =  =  null )  throw new  illegal argument exception ( "" null given for tag per molecular index"" )  ;  this . tag per molecular index = tag per molecular index ;  return this ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallingMetrics.java,to string,"@ override public  string   (  )  {  return  string . format ( "" illumina basecalling metric (  lane:%s  barcode:%s  name:%s mean   clusters   per   tile:%s sd   clusters   per   tile:%s ""  +  ""mean   pct   pf   clusters   per   tile:%s sd   pct   pf   cl"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaBasecallingMetrics.java, collect illumina basecalling metrics,public   (  )  {  this . barcode to metric counts = new  tree map <  >  (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaBasecallingMetrics.java, illumina metric counts,public   ( final  string barcode final  string barcode name final  integer lane number )  {  this . tile to cluster histogram = new  histogram <  >  (  )  ;  this . tile to pf cluster histogram = new  histogram <  >  (  )  ;  this . metrics = new  illumina basecalling metrics (  )  ;  this . metrics . molecular   barcode   sequence   1 = barcode ;  this . metrics . molecular   barcode   name = barcode name ;  this . metrics . lane =  integer . to string ( lane number )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaBasecallingMetrics.java,add cluster,private void   ( final  cluster data cluster )  {   string barcode = cluster . get matched barcode (  )  ;  if  ( barcode  =  =  null )  barcode = unmatched barcode ;   illumina metric counts counters = barcode to metric counts . get ( barcode )  ;  if  ( counters  =  =  null )   {  counters = new  illumina metric counts ( barcode null lane )  ;  barcode to metric counts . put ( barcode counters )  ;   }  final int tile number = cluster . get tile (  )  ;  counters . increment cluster count ( tile number cluster . is pf (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaBasecallingMetrics.java,add illumina metric counts,public void   ( final  illumina metric counts counts )  {  this . tile to cluster histogram . add histogram ( counts . tile to cluster histogram )  ;  this . tile to pf cluster histogram . add histogram ( counts . tile to pf cluster histogram )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaBasecallingMetrics.java,add metrics to file,public void   ( final  metrics file <  illumina basecalling metrics  comparable <  ?  >  >  file )  {  on complete (  )  ;  file . add metric ( metrics )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaBasecallingMetrics.java,do work,"@ override protected int   (  )  {  io util . assert directory is readable ( basecalls   dir )  ;  if  ( output  =  =  null )  output = new  file ( basecalls   dir  string . format ( ""lane%s   basecalling   metrics"" lane )  )  ;  io util . assert file is "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaBasecallingMetrics.java,increment cluster count,public void   ( final  integer tile number final double increment amount final double pf increment amount )  {  tile to cluster histogram . increment ( tile number increment amount )  ;  tile to pf cluster histogram . increment ( tile number pf increment amount )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaBasecallingMetrics.java,main,public static void   ( final  string[] argv )  {  new  collect illumina basecalling metrics (  )  . instance main with exit ( argv )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaBasecallingMetrics.java,on complete,"private void   (  )  {  final double mean clusters per tile = tile to cluster histogram . get mean bin size (  )  ;  metrics . mean   clusters   per   tile =  math . round ( mean clusters per tile )  ;  metrics . sd   clusters   per   tile =  math . round ( tile to cluster histogram . get standard deviation bin size ( mean clusters per tile )  )  ;  final double mean pf clusters per tile = tile to pf cluster histogram . get mean bin size (  )  ;  metrics . mean   pf   clusters   per   tile =  math . round ( mean pf clusters per tile )  ;  metrics . sd   pf   clusters   per   tile =  math . round ( tile to pf cluster histogram . get standard deviation bin size ( mean pf clusters per tile )  )  ;  final  decimal format dec format = new  decimal format ( ""# . ##"" )  ;  final  histogram <  integer >  lane to pct pf cluster histogram = tile to pf cluster histogram . divide by histogram ( tile to cluster histogram )  ;  final double mean pct pf clusters per tile = lane to pct pf cluster histogram . get mean bin size (  )  ;  metrics . mean   pct   pf   clusters   per   tile =  (  double . is nan ( mean pct pf clusters per tile )   ?  0 :  double . value of ( dec format . format ( mean pct pf clusters per tile * 100 )  )  )  ;  metrics . sd   pct   pf   clusters   per   tile =  double . value of ( dec format . format ( lane to pct pf cluster histogram . get standard deviation bin size ( mean pct pf clusters per tile )  * 100 )  )  ;  metrics . total   clusters =  ( long ) this . tile to cluster histogram . get sum of values (  )  ;  metrics . pf   clusters =  ( long ) this . tile to pf cluster histogram . get sum of values (  )  ;  final  read structure read structure = new  read structure ( read   structure )  ;  int template base count per cluster = 0 ;  for  ( int i = 0 ;  i  <  read structure . templates . length (  )  ;  i +  +  )   {  template base count per cluster +  = read structure . templates . get ( i )  . length ;   }  metrics . total   reads = metrics . total   clusters * read structure . templates . length (  )  ;  metrics . pf   reads = metrics . pf   clusters * read structure . templates . length (  )  ;  metrics . total   bases = metrics . total   clusters * template base count per cluster ;  metrics . pf   bases = metrics . pf   clusters * template base count per cluster ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\CollectIlluminaBasecallingMetrics.java,setup new data provider,"private void   ( final  illumina data provider factory factory )  {  if  ( barcodes   dir  =  =  null )  barcodes   dir = basecalls   dir ;  final  file lane dir = new  file ( basecalls   dir  illumina file util . long lane str ( lane )  )  ;  final  file[] cycle dirs = io util . get files matching regexp ( lane dir  illumina file util . cycle   subdirectory   pattern )  ;  final  list <  file >  cbcls =  arrays . stream ( cycle dirs )  . flat map ( cycle dir  -  >   arrays . stream ( io util . get files matching regexp ( cycle dir ""^""  +   illumina file util . long lane str ( lane )   +  ""    ( \\d { 1 5 }  )  . cbcl$"" )  )  )  . collect (  collectors . to list (  )  )  ;  if  ( cbcls . size (  )   =  =  0 )   {  throw new  picard exception ( "" no cbcl files found . "" )  ;   }  io util . assert files are readable ( cbcls )  ;  final  list <  abstract illumina position file reader .  position info >  locs = new  array list <  >  (  )  ;  final  file locs file = new  file ( basecalls   dir . get parent file (  )   abstract illumina position file reader . s   locs   file )  ;  io util . assert file is readable ( locs file )  ;  try  (  locs file reader locs file reader = new  locs file reader ( locs file )  )  {  while  ( locs file reader . has next (  )  )   {  locs . add ( locs file reader . next (  )  )  ;   }   }  final  pattern lane tile regex =  pattern . compile (  parameterized file util . escape periods (  parameterized file util . make lane tile regex ( "" . filter"" lane )  )  )  ;  final  file[] filter files =  new illumina basecalls converter . get tiled files ( lane dir lane tile regex )  ;  io util . assert files are readable (  arrays . as list ( filter files )  )  ;  final  pattern barcode regex =  pattern . compile (  parameterized file util . escape periods (  parameterized file util . make barcode regex ( lane )  )  )  ;  final  map <  integer  file >  barcodes files = new  hash map <  >  (  )  ;  for  (  final  file barcode file :  new illumina basecalls converter . get tiled files ( barcodes   dir barcode regex )  )   {  final  matcher tile matcher = barcode regex . matcher ( barcode file . get name (  )  )  ;  if  ( tile matcher . matches (  )  )   {  io util . assert file is readable ( barcode file )  ;  barcodes files . put (  integer . value of ( tile matcher . group ( 1 )  )  barcode file )  ;   }   }  factory . get available tiles (  )  . for each ( tile  -  >   {  final  file barcode file = barcodes files . get ( tile )  ;  final  base illumina data provider provider = factory . make data provider ( cbcls locs filter files tile barcode file )  ;  while  ( provider . has next (  )  )   {  add cluster ( provider . next (  )  )  ;   }   }   )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java, illumina basecalls converter,"public   ( final  file basecalls dir final  file barcodes dir final int lane final  read structure read structure final  map <  string  ?  extends  converted cluster data writer < cluster   output   record >  >  barcode record writer map final boolean demultiplex final int max reads in ram per tile final  list <  file >  tmp dirs final int num processors final boolean force gc final  integer first tile final  integer tile limit final  comparator < cluster   output   record >  output record comparator final  sorting collection .  codec < cluster   output   record >  codec prototype final  class < cluster   output   record >  output record class final  bcl quality evaluation strategy bcl quality evaluation strategy final boolean apply eamss filtering final boolean include non pf reads final boolean ignore unexpected barcodes )  {  super ( barcode record writer map max reads in ram per tile tmp dirs codec prototype ignore unexpected barcodes demultiplex output record comparator bcl quality evaluation strategy output record class num processors new  illumina data provider factory ( basecalls dir barcodes dir lane read structure bcl quality evaluation strategy get data types from read structure ( read structure demultiplex )  )  )  ;  this . include non pf reads = include non pf reads ;  this . tiles = factory . get available tiles (  )  ;  tiles . sort ( tile   number   comparator )  ;  set tile limits ( first tile tile limit )  ;  this . num threads =  math . max ( 1  math . min ( this . num threads tiles . size (  )  )  )  ;  if  ( force gc )   {  final  timer gc timer = new  timer ( true )  ;  final long delay = 5 * 1000 * 60 ;  gc timer task = new  timer task (  )  {  @ override public void run (  )  {  log . info ( "" before explicit gc   runtime . total memory (  )  = ""  +   runtime . get runtime (  )  . total memory (  )  )  ;   system . gc (  )  ;   system . run finalization (  )  ;  log . info ( "" after explicit gc   runtime . total memory (  )  = ""  +   runtime . get runtime (  )  . total memory (  )  )  ;   }   }   ;  gc timer . schedule at fixed rate ( gc timer task delay delay )  ;   }  else  {  gc timer task = null ;   }  this . factory . set apply eamss filtering ( apply eamss filtering )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java, priority runnable,public   ( final int priority )  {  this . priority = priority ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java, tile,public   ( final int i )  {  tile number = i ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java, tile read aggregator,public   ( final  collection <  tile >  tiles )  {  for  (  final  tile t : tiles )   {  tile records . put ( t new  tile processing record (  )  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java, tile reader,public   ( final  tile tile final  tile read aggregator handler final  tile processing record processing record )  {  this . tile = tile ;  this . handler = handler ;  this . processing record = processing record ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,add record,"public synchronized void   ( final  string barcode final cluster   output   record record )  {  this . record count +  = 1 ;   sorting collection < cluster   output   record >  record collection = this . barcode to record collection . get ( barcode )  ;  if  ( record collection  =  =  null )   {  if  (  ! barcode record writer map . contains key ( barcode )  )   {  if  ( ignore unexpected barcodes )   {  return ;   }  throw new  picard exception (  string . format ( "" read records with barcode %s  but this barcode was not expected .   (  is it referenced in the parameters file ?  ) "" barcode )  )  ;   }  record collection = this . new sorting collection (  )  ;  this . barcode to record collection . put ( barcode record collection )  ;  this . barcode to processing state . put ( barcode null )  ;   }  record collection . add ( record )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java, barcode metric,public   (  )  {  barcode bytes = null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java, extract illumina barcodes,public   (  )  {  tile number formatter . set minimum integer digits ( 4 )  ;  tile number formatter . set grouping used ( false )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,await work complete,public void   (  )  throws  interrupted exception  {  synchronized  ( this . completion latch )   {  this . completion latch . wait (  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,compare to,@ override public int   ( final  tile o )  {  return tile   number   comparator . compare ( this . get number (  )  o . get number (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java, per tile barcode extractor,public   ( final int tile final  file barcode file final  map <  string  barcode metric >  barcode to metrics final  barcode metric no match metric final  illumina data provider factory factory final int minimum base quality final int max no calls final int max mismatches final int min mismatch delta )  {  this . tile = tile ;  this . barcode file = barcode file ;  this . using quality scores = minimum base quality  >  0 ;  this . max no calls = max no calls ;  this . max mismatches = max mismatches ;  this . min mismatch delta = min mismatch delta ;  this . minimum base quality = minimum base quality ;  this . metrics = new  linked hash map <  >  ( barcode to metrics . size (  )  )  ;  for  (  final  string key : barcode to metrics . key set (  )  )   {  this . metrics . put ( key  barcode metric . copy ( barcode to metrics . get ( key )  )  )  ;   }  this . no match =  barcode metric . copy ( no match metric )  ;  this . provider = factory . make data provider (  arrays . as list ( tile )  )  ;  this . output read structure = factory . get output read structure (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,complete tile,"private void   ( final  tile tile )  {  final  tile processing record tile record = this . tile records . get ( tile )  ;  if  ( tile record . get state (  )   =  =   tile processing state . done   reading )   {  throw new  illegal state exception ( "" this tile is already in the completed state . "" )  ;   }  for  (  final  string barcode : tile record . get barcodes (  )  )   {  tile record . set barcode state ( barcode  tile barcode processing state . read )  ;  tile record . barcode to record collection . get ( barcode )  . done adding (  )  ;   }  tile record . set state (  tile processing state . done   reading )  ;  log . debug (  string . format ( "" completed reading tile %s ;  collected %s reads spanning %s barcodes . "" tile . get number (  )  tile record . get record count (  )  tile record . get barcode count (  )  )  )  ;  this . find and enqueue work or signal completion (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java,copy,public static  barcode metric   ( final  barcode metric metric )  {  final  barcode metric result = new  barcode metric (  )  ;  result . barcode = metric . barcode ;  result . barcode   without   delimiter = metric . barcode   without   delimiter ;  result . barcode   name = metric . barcode   name ;  result . library   name = metric . library   name ;  result . barcode bytes = metric . barcode bytes ;  return result ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java,count mismatches,private static int   ( final byte[][] barcode bytes final byte[][] read subsequence final byte[][] qualities final int minimum base quality )  {  int num mismatches = 0 ;  for  ( int j = 0 ;  j  <  barcode bytes . length ;  j +  +  )   {  for  ( int i = 0 ;   ( i  <  barcode bytes[j] . length && read subsequence[j] . length  >  i )  ;   +  + i )   {  if  (  sequence util . is no call ( read subsequence[j][i] )  )   {  continue ;   }  if  (  !  sequence util . bases equal ( barcode bytes[j][i] read subsequence[j][i] )  )   {   +  + num mismatches ;  continue ;   }  if  ( qualities  !  =  null && qualities[j][i]  <  minimum base quality )   {   +  + num mismatches ;   }   }   }  return num mismatches ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,do tile processing,@ override public void   (  )  {  try  {  final  list <  tile >  tiles = new  array list <  >  (  )  ;  for  (  final  integer tile number : this . tiles )   {  tiles . add ( new  tile ( tile number )  )  ;   }  final  tile read aggregator tile read aggre
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,equals,@ override public boolean   ( final  object o )  {  return o instanceof  tile && this . get number (  )   =  =   (  (  tile ) o )  . get number (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,find and enqueue work or signal completion,"private void   (  )  {  synchronized  ( this . work enqueue monitor )   {  if  ( this . is work completed (  )  )   {  this . signal work complete (  )  ;   }  else  {  final  queue <  runnable >  tasks = new  linked list <  >  (  )  ;  for  (  final  string barcode : barcode record writer map . key set (  )  )   {  next   barcode: for  (  final  map .  entry <  tile  tile processing record >  entry : this . tile records . entry set (  )  )   {  final  tile tile = entry . get key (  )  ;  final  tile processing record tile record = entry . get value (  )  ;  if  ( tile record . get state (  )   !  =   tile processing state . done   reading )   {  break ;   }  switch  ( tile record . get barcode state ( barcode )  )   {  case na: case written: continue ;  case queued   for   write: break next   barcode ;  case read: tile record . set barcode state ( barcode  tile barcode processing state . queued   for   write )  ;  log . debug (  string . format ( "" enqueuing work for tile %s and barcode %s . "" tile . get number (  )  barcode )  )  ;  tasks . add ( this . new barcode work instance ( tile tile record barcode )  )  ;  break next   barcode ;   }   }   }  for  ( final  runnable task : tasks )   {  this . prioritizing thread pool . execute ( task )  ;   }   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,get barcode count,public synchronized long   (  )  {  return this . barcode to record collection . size (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java,custom command line validation,@ override protected  string[]   (  )  {  final  array list <  string >  messages = new  array list <  >  (  )  ;  this . bcl quality evaluation strategy = new  bcl quality evaluation strategy ( minimum   quality )  ;  read structure = new  read structure
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,get barcode processing states,public synchronized  map <  string  tile barcode processing state >    (  )  {  return this . barcode to processing state ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,get barcode records,public synchronized  map <  string  sorting collection < cluster   output   record >  >    (  )  {  return barcode to record collection ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,get barcode state,"public synchronized  tile barcode processing state   ( final  string barcode )  {  if  ( this . get state (  )   =  =   tile processing state . not   done   reading )   {  throw new  illegal state exception ( ""a tile's barcode data's state cannot be queried until the tile has been completely read . "" )  ;   }  return this . barcode to processing state . get or default ( barcode  tile barcode processing state . na )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,get barcodes,public synchronized  set <  string >    (  )  {  return this . get barcode records (  )  . key set (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,get data types from read structure,private static  illumina data type[]   ( final  read structure read structure final boolean demultiplex )  {  if  ( read structure . sample barcodes . is empty (  )  ||  ! demultiplex )   {  return data   types   no   barcode ;   }  else  {  return data   types   with   barcode ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,get number,public int   (  )  {  return tile number ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,get priority,int   (  )  {  return this . priority ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,get record count,public synchronized long   (  )  {  return record count ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,get state,public synchronized  tile processing state   (  )  {  return this . state ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,is work completed,"public boolean   (  )  {  for  (  final  map .  entry <  tile  tile processing record >  entry : this . tile records . entry set (  )  )   {  final  tile processing record tile processing record = entry . get value (  )  ;  if  ( tile processing record . get state (  )   !  =   tile processing state . done   reading )   {  log . debug (  string . format ( "" work is not completed because a tile isn't done being read: %s . "" entry . get key (  )  . get number (  )  )  )  ;  return false ;   }  else  {  for  (  final  map .  entry <  string  tile barcode processing state >  barcode state entry : tile processing record . get barcode processing states (  )  . entry set (  )  )   {  final  tile barcode processing state barcode processing state = barcode state entry . get value (  )  ;  if  ( barcode processing state  !  =   tile barcode processing state . written )   {  log . debug (  string . format ( "" work is not completed because a tile isn't done being read:  tile %s   barcode %s   processing  state %s . "" entry . get key (  )  . get number (  )  barcode state entry . get key (  )  barcode processing state )  )  ;  return false ;   }   }   }   }  log . info ( "" all work is complete . "" )  ;  return true ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java,do work,@ override protected int   (  )  {  io util . assert file is writable ( metrics   file )  ;  if  ( output   dir  =  =  null )   {  output   dir = basecalls   dir ;   }  io util . assert directory is writable ( output   dir )  ;  final  string[] no match b
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,new barcode work instance,"private  priority runnable   ( final  tile tile final  tile processing record tile record final  string barcode )  {  return new  priority runnable (  )  {  @ override public void run (  )  {  try  {  final  sorting collection < cluster   output   record >  records = tile record . get barcode records (  )  . get ( barcode )  ;  final  converted cluster data writer < cluster   output   record >  writer = barcode record writer map . get ( barcode )  ;  log . debug (  string . format ( "" writing records from tile %s with barcode %s  .  .  . "" tile . get number (  )  barcode )  )  ;  final  peek iterator < cluster   output   record >  it = new  peek iterator <  >  ( records . iterator (  )  )  ;  while  ( it . has next (  )  )   {  final cluster   output   record rec = it . next (  )  ;  if  ( it . has next (  )  )   {  final cluster   output   record look ahead = it . peek (  )  ;  if  ( output record comparator . compare ( rec look ahead )   =  =  0 )   {  it . next (  )  ;  log . info ( "" skipping reads with identical read names: ""  +  rec . to string (  )  )  ;  continue ;   }   }  writer . write ( rec )  ;  write progress logger . record ( null 0 )  ;   }  tile record . set barcode state ( barcode  tile barcode processing state . written )  ;  find and enqueue work or signal completion (  )  ;   }  catch  (  final  runtime exception| error e )   {  parent thread . interrupt (  )  ;  throw e ;   }   }   }   ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,new sorting collection,private synchronized  sorting collection < cluster   output   record >    (  )  {  final int max records in ram =  math . max ( 1 max reads in ram per tile  /  barcode record writer map . size (  )  )  ;  return  sorting collection . new instance ( output record class codec prototype . clone (  )  output record comparator max records in ram tmp dirs )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,process,"public void   (  )  {  final  base illumina data provider data provider = factory . make data provider (  collections . singleton list ( this . tile . get number (  )  )  )  ;  log . debug (  string . format ( "" reading data from tile %s  .  .  . "" tile . get number (  )  )  )  ;  while  ( data provider . has next (  )  )   {  final  cluster data cluster = data provider . next (  )  ;  read progress logger . record ( null 0 )  ;  if  ( cluster . is pf (  )  || include non pf reads )   {  final  string barcode =  ( demultiplex  ?  cluster . get matched barcode (  )  : null )  ;  this . processing record . add record ( barcode converter . convert cluster to output record ( cluster )  )  ;   }   }  this . handler . complete tile ( this . tile )  ;  data provider . close (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java,finalize metrics,public static void   ( final  map <  string  barcode metric >  barcode to metrics final  barcode metric no match metric )  {  int total reads = no match metric . reads ;  int total pf reads = no match metric . pf   reads ;  int total pf reads assigned = 0 ;  for  (  final  barcode metric barcode metric : barcode to metrics . values (  )  )   {  total reads +  = barcode metric . reads ;  total pf reads +  = barcode metric . pf   reads ;  total pf reads assigned +  = barcode metric . pf   reads ;   }  if  ( total reads  >  0 )   {  no match metric . pct   matches = no match metric . reads  /   ( double ) total reads ;  double best pct of all barcode matches = 0 ;  for  (  final  barcode metric barcode metric : barcode to metrics . values (  )  )   {  barcode metric . pct   matches = barcode metric . reads  /   ( double ) total reads ;  if  ( barcode metric . pct   matches  >  best pct of all barcode matches )   {  best pct of all barcode matches = barcode metric . pct   matches ;   }   }  if  ( best pct of all barcode matches  >  0 )   {  no match metric . ratio   this   barcode   to   best   barcode   pct = no match metric . pct   matches  /  best pct of all barcode matches ;  for  (  final  barcode metric barcode metric : barcode to metrics . values (  )  )   {  barcode metric . ratio   this   barcode   to   best   barcode   pct = barcode metric . pct   matches  /  best pct of all barcode matches ;   }   }   }  if  ( total pf reads  >  0 )   {  no match metric . pf   pct   matches = no match metric . pf   reads  /   ( double ) total pf reads ;  double best pct of all barcode matches = 0 ;  for  (  final  barcode metric barcode metric : barcode to metrics . values (  )  )   {  barcode metric . pf   pct   matches = barcode metric . pf   reads  /   ( double ) total pf reads ;  if  ( barcode metric . pf   pct   matches  >  best pct of all barcode matches )   {  best pct of all barcode matches = barcode metric . pf   pct   matches ;   }   }  if  ( best pct of all barcode matches  >  0 )   {  no match metric . pf   ratio   this   barcode   to   best   barcode   pct = no match metric . pf   pct   matches  /  best pct of all barcode matches ;  for  (  final  barcode metric barcode metric : barcode to metrics . values (  )  )   {  barcode metric . pf   ratio   this   barcode   to   best   barcode   pct = barcode metric . pf   pct   matches  /  best pct of all barcode matches ;   }   }   }  if  ( total pf reads assigned  >  0 )   {  final double mean =  ( double ) total pf reads assigned  /   ( double ) barcode to metrics . values (  )  . size (  )  ;  for  (  final  barcode metric m : barcode to metrics . values (  )  )   {  m . pf   normalized   matches = m . pf   reads  /  mean ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,run,@ override public void   (  )  {  try  {  final  sorting collection < cluster   output   record >  records = tile record . get barcode records (  )  . get ( barcode )  ;  final  converted cluster data writer < cluster   output   record >  writer = barcode
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,set barcode state,"public synchronized void   ( final  string barcode final  tile barcode processing state state )  {  if  ( this . barcode to processing state . contains key ( barcode )  )   {  this . barcode to processing state . put ( barcode state )  ;   }  else  {  throw new  no such element exception (  string . format ( "" no record of the provided barcode  %s . "" barcode )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,set state,public synchronized void   ( final  tile processing state state )  {  this . state = state ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,shutdown,public void   (  )  {  this . prioritizing thread pool . shutdown now (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,signal work complete,private void   (  )  {  synchronized  ( this . completion latch )   {  this . completion latch . notify all (  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsConverter.java,submit,"public void   (  )  {  if  (  ! this . submitted . compare and set ( false true )  )   {  throw new  illegal state exception ( "" the submit (  )  method may not be called more than once . "" )  ;   }  this . parent thread =  thread . current thread (  )  ;  int priority = 0 ;  for  (  final  tile tile : this . tile records . key set (  )  )   {  final  tile reader reader = new  tile reader ( tile this this . tile records . get ( tile )  )  ;  this . prioritizing thread pool . execute ( new  priority runnable (  -  - priority )  {  @ override public void run (  )  {  try  {  reader . process (  )  ;   }  catch  (  final  runtime exception| error e )   {  parent thread . interrupt (  )  ;  throw e ;   }   }   }   )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java,find best barcode and update metrics,"public static  barcode match   ( final byte[][] read subsequences final byte[][] quality scores final boolean passing filter final  map <  string  barcode metric >  metrics final  barcode metric no match barcode metric final int max no calls final int max mismatches final int min mismatch delta final int minimum base quality )  {   barcode metric best barcode metric = null ;  int total barcode read bases = 0 ;  int num no calls = 0 ;  for  (  final byte[] bc : read subsequences )   {  total barcode read bases +  = bc . length ;  for  (  final byte b : bc )  if  (  sequence util . is no call ( b )  )   +  + num no calls ;   }  int num mismatches in best barcode = total barcode read bases  +  1 ;  int num mismatches in second best barcode = total barcode read bases  +  1 ;  for  (  final  barcode metric barcode metric : metrics . values (  )  )   {  final int num mismatches = count mismatches ( barcode metric . barcode bytes read subsequences quality scores minimum base quality )  ;  if  ( num mismatches  <  num mismatches in best barcode )   {  if  ( best barcode metric  !  =  null )   {  num mismatches in second best barcode = num mismatches in best barcode ;   }  num mismatches in best barcode = num mismatches ;  best barcode metric = barcode metric ;   }  else if  ( num mismatches  <  num mismatches in second best barcode )   {  num mismatches in second best barcode = num mismatches ;   }   }  final boolean matched = best barcode metric  !  =  null && num no calls  <  =  max no calls && num mismatches in best barcode  <  =  max mismatches && num mismatches in second best barcode  -  num mismatches in best barcode  >  =  min mismatch delta ;  final  barcode match match = new  barcode match (  )  ;  if  ( num no calls  +  num mismatches in best barcode  <  total barcode read bases && best barcode metric  !  =  null )   {  match . mismatches = num mismatches in best barcode ;  match . mismatches to second best = num mismatches in second best barcode ;  match . barcode = best barcode metric . barcode   without   delimiter . to lower case (  )  ;   }  else  {  match . mismatches = total barcode read bases ;  match . barcode = """" ;   }  if  ( matched )   {   +  + best barcode metric . reads ;  if  ( passing filter )   {   +  + best barcode metric . pf   reads ;   }  if  ( num mismatches in best barcode  =  =  0 )   {   +  + best barcode metric . perfect   matches ;  if  ( passing filter )   {   +  + best barcode metric . pf   perfect   matches ;   }   }  else if  ( num mismatches in best barcode  =  =  1 )   {   +  + best barcode metric . one   mismatch   matches ;  if  ( passing filter )   {   +  + best barcode metric . pf   one   mismatch   matches ;   }   }  match . matched = true ;  match . barcode = best barcode metric . barcode   without   delimiter ;   }  else  {   +  + no match barcode metric . reads ;  if  ( passing filter )   {   +  + no match barcode metric . pf   reads ;   }   }  return match ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java,get barcode,public  string   (  )  {  return barcode ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java,get barcode file,"private  file   ( final int tile )  {  return new  file ( output   dir ""s   ""  +  lane  +  ""   "" +  tile number formatter . format ( tile )  +  ""   barcode . txt"" +   ( compress   outputs  ?  "" . gz"" : """" )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java,get exception,public synchronized  exception   (  )  {  return this . exception ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java,get metrics,public synchronized  map <  string  barcode metric >    (  )  {  return this . metrics ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java,get no match metric,public synchronized  barcode metric   (  )  {  return this . no match ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java,is matched,public boolean   (  )  {  return matched ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java,main,public static void   ( final  string[] argv )  {  new  extract illumina barcodes (  )  . instance main with exit ( argv )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java,merge,public void   ( final  barcode metric metric )  {  this . reads +  = metric . reads ;  this . pf   reads +  = metric . pf   reads ;  this . perfect   matches +  = metric . perfect   matches ;  this . pf   perfect   matches +  = metric . pf   perfect   matches ;  this . one   mismatch   matches +  = metric . one   mismatch   matches ;  this . pf   one   mismatch   matches +  = metric . pf   one   mismatch   matches ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java,parse barcode file,"private void   ( final  array list <  string >  messages )  {  final  tabbed text file with header parser barcodes parser = new  tabbed text file with header parser ( barcode   file )  ;  final  string sequence column = barcodes parser . has column ( barcode   sequence   column )   ?  barcode   sequence   column : barcodes parser . has column ( barcode   sequence   1   column )   ?  barcode   sequence   1   column : null ;  if  ( sequence column  =  =  null )   {  messages . add ( barcode   file  +  "" does not have ""  +  barcode   sequence   column +  "" or "" +  barcode   sequence   1   column +  "" column header"" )  ;  return ;   }  final boolean has barcode name = barcodes parser . has column ( barcode   name   column )  ;  final boolean has library name = barcodes parser . has column ( library   name   column )  ;  final int num barcodes = read structure . sample barcodes . length (  )  ;  final  set <  string >  barcodes = new  hash set <  >  (  )  ;  for  (  final  tabbed text file with header parser .  row row : barcodes parser )   {  final  string[] bc strings = new  string[num barcodes] ;  int barcode num = 1 ;  for  (  final  read descriptor rd : read structure . descriptors )   {  if  ( rd . type  !  =   read type .  barcode )  continue ;  final  string header = barcode num  =  =  1  ?  sequence column : ""barcode   sequence   ""  +   string . value of ( barcode num )  ;  bc strings[barcode num  -  1] = row . get field ( header )  ;  barcode num +  +  ;   }  final  string bc str =  illumina util . barcode seqs to string ( bc strings )  ;  if  ( barcodes . contains ( bc str )  )   {  messages . add ( "" barcode ""  +  bc str  +  "" specified more than once in "" +  barcode   file )  ;   }  barcodes . add ( bc str )  ;  final  string barcode name =  ( has barcode name  ?  row . get field ( barcode   name   column )  : """" )  ;  final  string library name =  ( has library name  ?  row . get field ( library   name   column )  : """" )  ;  final  barcode metric metric = new  barcode metric ( barcode name library name bc str bc strings )  ;  barcode to metrics . put (  string util . join ( """" bc strings )  metric )  ;   }  barcodes parser . close (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\ExtractIlluminaBarcodes.java,run,"synchronized public void   (  )  {  try  {  if  ( this . provider  =  =  null )   {  this . provider = factory . make data provider ( cbcls locs filter files tile null )  ;   }  log . info ( "" extracting barcodes for tile ""  +  tile )  ;  final int[] barcode indices = output read structure . sample barcodes . get indices (  )  ;  final  buffered writer writer = io util . open file for buffered writing ( barcode file )  ;  final byte[][] barcode subsequences = new byte[barcode indices . length][] ;  final byte[][] quality scores = using quality scores  ?  new byte[barcode indices . length][] : null ;  while  ( provider . has next (  )  )   {  final  cluster data cluster = provider . next (  )  ;  for  ( int i = 0 ;  i  <  barcode indices . length ;  i +  +  )   {  barcode subsequences[i] = cluster . get read ( barcode indices[i] )  . get bases (  )  ;  if  ( using quality scores )  quality scores[i] = cluster . get read ( barcode indices[i] )  . get qualities (  )  ;   }  final boolean passing filter = cluster . is pf (  )  ;  final  barcode match match = find best barcode and update metrics ( barcode subsequences quality scores passing filter metrics no match max no calls max mismatches min mismatch delta minimum base quality )  ;  final  string y orn =  ( match . matched  ?  ""y"" : ""n"" )  ;  for  (  final byte[] bc : barcode subsequences )   {  writer . write (  string util . bytes to string ( bc )  )  ;   }  writer . write ( ""\t""  +  y orn  +  ""\t"" +  match . barcode +  ""\t"" +   string . value of ( match . mismatches )  +  ""\t"" +   string . value of ( match . mismatches to second best )  )  ;  writer . new line (  )  ;   }  writer . close (  )  ;   }  catch  (  final  exception e )   {  log . error ( e "" error processing tile "" this . tile )  ;  this . exception = e ;   }  finally  {   closer util . close ( provider )  ;  provider = null ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java, codec,  ( final int num records )  {  this ( num records new bam record codec ( null )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,sam file writer wrapper,private   ( final sam file writer writer )  {  this . writer = writer ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,sam records for cluster,  ( final int num records )  {  records = new sam record[num records] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,build sam file writer,private sam file writer wrapper   ( final  file output final  string sample alias final  string library name final  map <  string  string >  header parameters final boolean presorted )  {  io util . assert file is writable ( output )  ;  final sam read group record rg = new sam read group record ( read   group   id )  ;  rg . set sample ( sample alias )  ;  if  ( library name  !  =  null )  rg . set library ( library name )  ;  for  (  final  map .  entry <  string  string >  tag name to value : header parameters . entry set (  )  )   {  if  ( tag name to value . get value (  )   !  =  null )   {  rg . set attribute ( tag name to value . get key (  )  tag name to value . get value (  )  )  ;   }   }  final sam file header header = new sam file header (  )  ;  header . set sort order ( sam file header .  sort order . queryname )  ;  header . add read group ( rg )  ;  return new sam file writer wrapper ( new sam file writer factory (  )  . makesam orbam writer ( header presorted output )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,build sam header parameters,"private  map <  string  string >    ( final  list <  string >  barcodes )  {  final  map <  string  string >  params = new  linked hash map <  >  (  )  ;   string platform unit = run   barcode  +  "" . ""  +  lane ;  if  ( barcodes  !  =  null )  platform unit +  =  ( "" . ""  +   illumina util . barcode seqs to string ( barcodes )  )  ;  params . put ( ""pl"" platform )  ;  params . put ( ""pu"" platform unit )  ;  params . put ( ""cn"" sequencing   center )  ;  params . put ( ""dt"" run   start   date  =  =  null  ?  null : new  iso8601 date ( run   start   date )  . to string (  )  )  ;  return params ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,check rg tag columns,"private void   ( final  set <  string >  rg tag columns )  {  final  set <  string >  forbidden headers = build sam header parameters ( null )  . key set (  )  ;  forbidden headers . retain all ( rg tag columns )  ;  if  (  ! forbidden headers . is empty (  )  )   {  throw new  picard exception ( "" illegal  read group tags in library params ( barcode params )  file ( ""  +  library   params . get absolute path (  )   +  "" )   offending headers  =  "" +   string util . join ( ""  "" forbidden headers )  )  ;   }  for  (  final  string column : rg tag columns )   {  if  ( column . length (  )   >  2 )   {  throw new  picard exception ( "" column label  ( ""  +  column  +  "" )  unrecognized .   library params ( barcode params )  can only contain the columns "" +  "" ( output  library   name  sample   alias  barcode  barcode    < x >  where x is a positive integer )  or two letter rg tags ! "" )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,clone,@ override public  sorting collection .  codec < sam records for cluster >    (  )  {  return new  codec ( num records bam codec . clone (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,close,@ override public void   (  )  {  writer . close (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,compare,@ override public int   ( final sam records for cluster s1 final sam records for cluster s2 )  {  return comparator . compare ( s1 . records[0] s2 . records[0] )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,custom command line validation,@ override protected  string[]   (  )  {  if  ( barcode   params  !  =  null )   {  library   params = barcode   params ;   }  final  array list <  string >  messages = new  array list <  >  (  )  ;  read structure = new  read structure ( read   structure
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,decode,@ override public sam records for cluster   (  )  {  final sam record zeroth record = bam codec . decode (  )  ;  if  ( zeroth record  =  =  null )  return null ;  final sam records for cluster ret = new sam records for cluster ( num records )  ;  ret . r
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,do work,@ override protected int   (  )  {  initialize (  )  ;  basecalls converter . do tile processing (  )  ;  return 0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,encode,"@ override public void   ( final sam records for cluster val )  {  if  ( val . records . length  !  =  num records )   {  throw new  illegal state exception (  string . format ( "" expected number of clusters %d  !  =  actual %d"" num records val . records "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,find and filter expected columns,"private  set <  string >    ( final  set <  string >  actual cols final  set <  string >  expected cols )  {  final  set <  string >  missing columns = new  hash set <  >  ( expected cols )  ;  missing columns . remove all ( actual cols )  ;  if  (  ! missing columns . is empty (  )  )   {  throw new  picard exception (  string . format ( ""library   params file %s is missing the following columns: %s . "" library   params . get absolute path (  )   string util . join ( ""  "" missing columns )  )  )  ;   }  final  set <  string >  remaining columns = new  hash set <  >  ( actual cols )  ;  remaining columns . remove all ( expected cols )  ;  return remaining columns ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,initialize,"private void   (  )  {  final  bcl quality evaluation strategy bcl quality evaluation strategy = new  bcl quality evaluation strategy ( minimum   quality )  ;  if  ( output  !  =  null )   {  io util . assert file is writable ( output )  ;   }  if  ( library   params  !  =  null )   {  io util . assert file is readable ( library   params )  ;   }  if  ( output  !  =  null )   {  barcode sam writer map . put ( null build sam file writer ( output sample   alias library   name build sam header parameters ( null )  true )  )  ;   }  else  {  populate writers from library params (  )  ;   }  final int num output records = read structure . templates . length (  )  ;  final  list <  adapter pair >  adapters = new  array list <  >  ( adapters   to   check )  ;  if  ( five   prime   adapter  !  =  null && three   prime   adapter  !  =  null )   {  adapters . add ( new  custom adapter pair ( five   prime   adapter three   prime   adapter )  )  ;   }  if  (  illumina file util . has cbcls ( basecalls   dir lane )  )   {  if  ( barcodes   dir  =  =  null )  barcodes   dir = basecalls   dir ;  basecalls converter = new  new illumina basecalls converter <  >  ( basecalls   dir barcodes   dir lane read structure barcode sam writer map true  math . max ( 1 max   reads   in   ram   per   tile  /  num output records )  tmp   dir num   processors first   tile tile   limit new  query name comparator (  )  new  codec ( num output records )  sam records for cluster . class bcl quality evaluation strategy ignore   unexpected   barcodes )  ;   }  else  {  basecalls converter = new  illumina basecalls converter <  >  ( basecalls   dir barcodes   dir lane read structure barcode sam writer map true max   reads   in   ram   per   tile  /  num output records tmp   dir num   processors force   gc first   tile tile   limit new  query name comparator (  )  new  codec ( num output records )  sam records for cluster . class bcl quality evaluation strategy apply   eamss   filter include   non   pf   reads ignore   unexpected   barcodes )  ;   }  final  cluster data to sam converter converter = new  cluster data to sam converter ( run   barcode read   group   id basecalls converter . get factory (  )  . get output read structure (  )  adapters )  . with molecular index tag ( molecular   index   tag )  . with molecular index quality tag ( molecular   index   base   quality   tag )  . with tag per molecular index ( tag   per   molecular   index )  ;  basecalls converter . set converter ( converter )  ;  log . info ( ""done   reading structure is ""  +  read structure . to string (  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,main,public static void   ( final  string[] args )  {   system . exit ( new  illumina basecalls to sam (  )  . instance main ( args )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,populate writers from library params,"private void   (  )  {  final  tabbed text file with header parser library params parser = new  tabbed text file with header parser ( library   params )  ;  final  set <  string >  expected column labels =  collection util . make set ( ""output"" ""sample   alias"" ""library   name"" )  ;  final  list <  string >  barcode column labels = new  array list <  >  (  )  ;  if  ( read structure . sample barcodes . length (  )   =  =  1 )   {  if  ( library params parser . has column ( ""barcode"" )  )   {  barcode column labels . add ( ""barcode"" )  ;   }  else if  ( library params parser . has column ( ""barcode   1"" )  )   {  barcode column labels . add ( ""barcode   1"" )  ;   }  else  {  throw new  picard exception ( ""library   params ( barcode   params )  file ""  +  library   params  +  "" does not have column barcode or barcode   1 . "" )  ;   }   }  else  {  for  ( int i = 1 ;  i  <  =  read structure . sample barcodes . length (  )  ;  i +  +  )   {  barcode column labels . add ( ""barcode   ""  +  i )  ;   }   }  expected column labels . add all ( barcode column labels )  ;  final  set <  string >  rg tag columns = find and filter expected columns ( library params parser . column labels (  )  expected column labels )  ;  check rg tag columns ( rg tag columns )  ;  for  (  final  tabbed text file with header parser .  row row : library params parser )   {   list <  string >  barcode values = null ;  if  (  ! barcode column labels . is empty (  )  )   {  barcode values = new  array list <  >  (  )  ;  for  (  final  string barcode label : barcode column labels )   {  barcode values . add ( row . get field ( barcode label )  )  ;   }   }  final  string key =  ( barcode values  =  =  null || barcode values . contains ( ""n"" )  )   ?  null :  string util . join ( """" barcode values )  ;  if  ( barcode sam writer map . contains key ( key )  )   {  throw new  picard exception ( "" row for barcode ""  +  key  +  "" appears more than once in library   params or barcode   params file "" +  library   params )  ;   }  final  map <  string  string >  sam header params = build sam header parameters ( barcode values )  ;  for  (  final  string tag name : rg tag columns )   {  sam header params . put ( tag name row . get field ( tag name )  )  ;   }   file output file = new  file ( row . get field ( ""output"" )  )  ;  if  ( process   single   tile  !  =  null )   {  output file = new  file ( output file . get parent file (  )  process   single   tile  +  "" . ""  +  output file . get name (  )  )  ;   }  final sam file writer wrapper writer = build sam file writer ( output file row . get field ( ""sample   alias"" )  row . get field ( ""library   name"" )  sam header params true )  ;  barcode sam writer map . put ( key writer )  ;   }  if  ( barcode sam writer map . is empty (  )  )   {  throw new  picard exception ( ""library   params ( barcode   params )  file ""  +  library   params  +  "" does have any data rows . "" )  ;   }  library params parser . close (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,set input stream,@ override public void   ( final  input stream is )  {  bam codec . set input stream ( is )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,set output stream,@ override public void   ( final  output stream os )  {  bam codec . set output stream ( os )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToSam.java,write,@ override public void   ( final sam records for cluster records )  {  for  (  final sam record rec : records . records )   {  writer . add alignment ( rec )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java, cluster to fastq records for cluster converter,  ( final  read structure output read structure )  {  this . template indices = output read structure . templates . get indices (  )  ;  this . sample barcode indicies = output read structure . sample barcodes . get indices (  )  ;  this . molecular barcode indicies = output read structure . molecular barcode . get indices (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java, fastq records for cluster,  ( final int num templates final int num sample barcodes final int num molecular barcodes )  {  template records = new  fastq record[num templates] ;  sample barcode records = new  fastq record[num sample barcodes] ;  molecular barcode records = new  fastq record[num molecular barcodes] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java, fastq records for cluster codec,  ( final int num templates final int num sample barcodes final int num molecular barcodes )  {  this . num templates = num templates ;  this . num sample barcodes = num sample barcodes ;  this . num molecular barcodes = num molecular barcodes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java, fastq records writer,private   ( final  fastq writer[] template writers final  fastq writer[] sample barcode writers final  fastq writer[] molecular barcode writers )  {  this . template writers = template writers ;  this . sample barcode writers = sample barcode writers ;  this . molecular barcode writers = molecular barcode writers ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,assert expected columns,"private void   ( final  set <  string >  actual cols final  set <  string >  expected cols )  {  final  set <  string >  missing columns = new  hash set <  >  ( expected cols )  ;  missing columns . remove all ( actual cols )  ;  if  (  ! missing columns . is empty (  )  )   {  throw new  picard exception (  string . format ( ""multiplex   params file %s is missing the following columns: %s . "" multiplex   params . get absolute path (  )   string util . join ( ""  "" missing columns )  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,build writer,"private  fastq records writer   ( final  file output prefix )  {  final  file output dir = output prefix . get absolute file (  )  . get parent file (  )  ;  io util . assert directory is writable ( output dir )  ;  final  string prefix string = output prefix . get name (  )  ;  final  string suffix string = compress   outputs  ?  ""fastq . gz"" : ""fastq"" ;  final  fastq writer[] template writers = new  fastq writer[read structure . templates . length (  ) ] ;  final  fastq writer[] sample barcode writers = new  fastq writer[read structure . sample barcodes . length (  ) ] ;  final  fastq writer[] molecular barcode writers = new  fastq writer[read structure . molecular barcode . length (  ) ] ;  for  ( int i = 0 ;  i  <  template writers . length ;   +  + i )   {  final  string filename =  string . format ( ""%s . %d . %s"" prefix string i  +  1 suffix string )  ;  template writers[i] = fastq writer factory . new writer ( new  file ( output dir filename )  )  ;   }  for  ( int i = 0 ;  i  <  sample barcode writers . length ;   +  + i )   {  final  string filename =  string . format ( ""%s . barcode   %d . %s"" prefix string i  +  1 suffix string )  ;  sample barcode writers[i] = fastq writer factory . new writer ( new  file ( output dir filename )  )  ;   }  for  ( int i = 0 ;  i  <  molecular barcode writers . length ;   +  + i )   {  final  string filename =  string . format ( ""%s . index   %d . %s"" prefix string i  +  1 suffix string )  ;  molecular barcode writers[i] = fastq writer factory . new writer ( new  file ( output dir filename )  )  ;   }  return new  fastq records writer ( template writers sample barcode writers molecular barcode writers )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,clone,@ override public  sorting collection .  codec <  fastq records for cluster >    (  )  {  return new  fastq records for cluster codec ( num templates num sample barcodes num molecular barcodes )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,close,@ override public void   (  )  {  for  (  final  fastq writer writer : template writers )   {  writer . close (  )  ;   }  for  (  final  fastq writer writer : sample barcode writers )   {  writer . close (  )  ;   }  for  (  final  fastq writer writer : 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,convert cluster to output record,@ override public  fastq records for cluster   ( final  cluster data cluster )  {  final  fastq records for cluster ret = new  fastq records for cluster ( read structure . templates . length (  )  read structure . sample barcodes . length (  )  read struc
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,custom command line validation,"@ override protected  string[]   (  )  {  final  linked list <  string >  errors = new  linked list <  >  (  )  ;  if  ( read   name   format  =  =   read name format . casava   1   8 && machine   name  =  =  null )   {  errors . add ( ""machine   name is "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,decode,@ override public  fastq records for cluster   (  )  {  if  (  ! reader . has next (  )  )  return null ;  final  fastq records for cluster ret = new  fastq records for cluster ( num templates num sample barcodes num molecular barcodes )  ;  decode array 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,decode array,private void   ( final  fastq record[] recs )  {  for  ( int i = 0 ;  i  <  recs . length ;   +  + i )   {  recs[i] = reader . next (  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,do work,@ override protected int   (  )  {  initialize (  )  ;  basecalls converter . do tile processing (  )  ;  return 0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,encode,@ override public void   ( final  fastq records for cluster val )  {  if  ( num templates  !  =  val . template records . length )  throw new  illegal state exception (  )  ;  if  ( num sample barcodes  !  =  val . sample barcode records . length )  throw
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,encode array,private void   ( final  fastq record[] recs )  {  for  (  final  fastq record rec : recs )   {  writer . write ( rec )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,initialize,"private void   (  )  {  fastq writer factory . set create md5 ( create   md5   file )  ;  switch  ( read   name   format )   {  case casava   1   8: read name encoder = new  casava18 read name encoder ( machine   name run   barcode flowcell   barcode )  ;  break ;  case illumina: read name encoder = new  illumina read name encoder ( run   barcode )  ;  break ;   }  final  bcl quality evaluation strategy bcl quality evaluation strategy = new  bcl quality evaluation strategy ( minimum   quality )  ;  read structure = new  read structure ( read   structure )  ;  if  ( multiplex   params  !  =  null )   {  io util . assert file is readable ( multiplex   params )  ;   }  final boolean demultiplex ;  if  ( output   prefix  !  =  null )   {  sample barcode fastq writer map . put ( null build writer ( output   prefix )  )  ;  demultiplex = false ;   }  else  {  populate writers from multiplex params (  )  ;  demultiplex = true ;   }  final int reads per cluster = read structure . templates . length (  )   +  read structure . sample barcodes . length (  )  ;  if  (  illumina file util . has cbcls ( basecalls   dir lane )  )   {  if  ( barcodes   dir  =  =  null )  barcodes   dir = basecalls   dir ;  basecalls converter = new  new illumina basecalls converter <  >  ( basecalls   dir barcodes   dir lane read structure sample barcode fastq writer map demultiplex  math . max ( 1 max   reads   in   ram   per   tile  /  reads per cluster )  tmp   dir num   processors first   tile tile   limit query name comparator new  fastq records for cluster codec ( read structure . templates . length (  )  read structure . sample barcodes . length (  )  read structure . molecular barcode . length (  )  )   fastq records for cluster . class bcl quality evaluation strategy ignore   unexpected   barcodes )  ;   }  else  {  basecalls converter = new  illumina basecalls converter <  >  ( basecalls   dir barcodes   dir lane read structure sample barcode fastq writer map demultiplex  math . max ( 1 max   reads   in   ram   per   tile  /  reads per cluster )  tmp   dir num   processors force   gc first   tile tile   limit query name comparator new  fastq records for cluster codec ( read structure . templates . length (  )  read structure . sample barcodes . length (  )  read structure . molecular barcode . length (  )  )   fastq records for cluster . class bcl quality evaluation strategy this . apply   eamss   filter include   non   pf   reads ignore   unexpected   barcodes )  ;   }  basecalls converter . set converter ( new  cluster to fastq records for cluster converter ( basecalls converter . get factory (  )  . get output read structure (  )  )  )  ;  log . info ( ""read structure is ""  +  read structure . to string (  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,main,public static void   ( final  string[] args )  {  new  illumina basecalls to fastq (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,make fastq records,private void   ( final  fastq record[] recs final int[] indices final  cluster data cluster final boolean append read number suffix )  {  for  ( short i = 0 ;  i  <  indices . length ;   +  + i )   {  final  read data read data = cluster . get read ( indices[i] )  ;  final  string read bases =  string util . bytes to string ( read data . get bases (  )  )  . replace ( ' . ' 'n' )  ;  final  string read name = read name encoder . generate read name ( cluster append read number suffix  ?  i  +  1 : null )  ;  recs[i] = new  fastq record ( read name read bases null sam utils . phred to fastq ( read data . get qualities (  )  )  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,populate writers from multiplex params,"private void   (  )  {  final  tabbed text file with header parser library params parser = new  tabbed text file with header parser ( multiplex   params )  ;  final  set <  string >  expected column labels =  collection util . make set ( ""output   prefix"" )  ;  final  list <  string >  sample barcode column labels = new  array list <  >  (  )  ;  for  ( int i = 1 ;  i  <  =  read structure . sample barcodes . length (  )  ;  i +  +  )   {  sample barcode column labels . add ( ""barcode   ""  +  i )  ;   }  expected column labels . add all ( sample barcode column labels )  ;  assert expected columns ( library params parser . column labels (  )  expected column labels )  ;  for  (  final  tabbed text file with header parser .  row row : library params parser )   {   list <  string >  sample barcode values = null ;  if  (  ! sample barcode column labels . is empty (  )  )   {  sample barcode values = new  array list <  >  (  )  ;  for  (  final  string sample barcode label : sample barcode column labels )   {  sample barcode values . add ( row . get field ( sample barcode label )  )  ;   }   }  final  string key =  ( sample barcode values  =  =  null || sample barcode values . contains ( ""n"" )  )   ?  null :  string util . join ( """" sample barcode values )  ;  if  ( sample barcode fastq writer map . contains key ( key )  )   {  throw new  picard exception ( "" row for barcode ""  +  key  +  "" appears more than once in multiplex   params file "" +  multiplex   params )  ;   }  final  fastq records writer writer = build writer ( new  file ( row . get field ( ""output   prefix"" )  )  )  ;  sample barcode fastq writer map . put ( key writer )  ;   }  if  ( sample barcode fastq writer map . is empty (  )  )   {  throw new  picard exception ( ""multiplex   params file ""  +  multiplex   params  +  "" does have any data rows . "" )  ;   }  library params parser . close (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,set input stream,@ override public void   ( final  input stream is )  {  reader = new  fastq reader ( new  buffered reader ( new  input stream reader ( is )  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,set output stream,@ override public void   ( final  output stream os )  {  writer = new  basic fastq writer ( new  print stream ( os )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaBasecallsToFastq.java,write,private void   ( final  fastq writer[] writers final  fastq record[] records )  {  for  ( int i = 0 ;  i  <  writers . length ;   +  + i )   {  writers[i] . write ( records[i] )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaPhasingMetrics.java,get extension,"public static  string   (  )  {  return ""illumina   phasing   metrics"" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaPhasingMetrics.java,get phasing metrics for tiles,public static  collection <  illumina phasing metrics >    ( final long lane final  collection <  tile >  tiles for lane final boolean use percentage )  {  final  lane phasing metrics collector lane phasing metrics collector = new  lane phasing metrics collector ( tiles for lane use percentage )  ;  final  collection <  illumina phasing metrics >  phasing metrics = new  array list <  illumina phasing metrics >  (  )  ;  for  (  final  tile template read tile template read : lane phasing metrics collector . get median phasing map (  )  . key set (  )  )   {  final  illumina phasing metrics phasing metric = new  illumina phasing metrics (  )  ;  phasing metric . lane = lane ;  phasing metric . type   name = tile template read . to string (  )  ;  phasing metric . phasing   applied = lane phasing metrics collector . get median phasing map (  )  . get ( tile template read )  ;  phasing metric . prephasing   applied = lane phasing metrics collector . get median pre phasing map (  )  . get ( tile template read )  ;  phasing metrics . add ( phasing metric )  ;   }  return phasing metrics ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\LanePhasingMetricsCollector.java, lane phasing metrics collector,public   ( final  collection <  tile >  lane tiles final boolean use percentage )  {  final  map <  tile template read  float >  median phasing map = new  tree map <  tile template read  float >  (  )  ;  final  map <  tile template read  float >  median pre phasing map = new  tree map <  tile template read  float >  (  )  ;  final  collection util .  multi map <  tile template read  float >  phasing values = new  collection util .  multi map <  tile template read  float >  (  )  ;  final  collection util .  multi map <  tile template read  float >  pre phasing values = new  collection util .  multi map <  tile template read  float >  (  )  ;  for  (  final  tile tile : lane tiles )   {  for  (  final  tile template read tile template read : tile . get phasing map (  )  . key set (  )  )   {  phasing values . append ( tile template read tile . get phasing map (  )  . get ( tile template read )  )  ;  pre phasing values . append ( tile template read tile . get pre phasing map (  )  . get ( tile template read )  )  ;   }   }  for  (  final  tile template read tile template read : phasing values . key set (  )  )   {  median phasing map . put ( tile template read median ( phasing values . get ( tile template read )  use percentage )  )  ;  median pre phasing map . put ( tile template read median ( pre phasing values . get ( tile template read )  use percentage )  )  ;   }  this . median phasing map =  collections . unmodifiable map ( median phasing map )  ;  this . median pre phasing map =  collections . unmodifiable map ( median pre phasing map )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\LanePhasingMetricsCollector.java,get median phasing map,public  map <  tile template read  float >    (  )  {  return median phasing map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\LanePhasingMetricsCollector.java,get median pre phasing map,public  map <  tile template read  float >    (  )  {  return median pre phasing map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\LanePhasingMetricsCollector.java,median,private static float   ( final  collection <  float >  phase values boolean use percentage )  {  final double[] values = new double[phase values . size (  ) ] ;  int i = 0 ;  for  (   float phase value : phase values )   {  values[i] =  ( double ) phase value ;  i +  +  ;   }  float median =  ( float )  math util . median ( values )  ;  return use percentage  ?  median * 100 : median ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\NewIlluminaBasecallsConverter.java, closer,private   ( final  converted cluster data writer < cluster   output   record >  writer final  string barcode )  {  this . writer = writer ;  this . barcode = barcode ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\NewIlluminaBasecallsConverter.java, new illumina basecalls converter,"public   ( final  file basecalls dir final  file barcodes dir final int lane final  read structure read structure final  map <  string  ?  extends  converted cluster data writer < cluster   output   record >  >  barcode record writer map final boolean demultiplex final int max reads in ram per tile final  list <  file >  tmp dirs final int num processors final  integer first tile final  integer tile limit final  comparator < cluster   output   record >  output record comparator final  sorting collection .  codec < cluster   output   record >  codec prototype final  class < cluster   output   record >  output record class final  bcl quality evaluation strategy bcl quality evaluation strategy final boolean ignore unexpected barcodes )  {  super ( barcode record writer map max reads in ram per tile tmp dirs codec prototype ignore unexpected barcodes demultiplex output record comparator bcl quality evaluation strategy output record class num processors new  illumina data provider factory ( basecalls dir barcodes dir lane read structure bcl quality evaluation strategy )  )  ;  this . tiles = new  array list <  >  (  )  ;  barcode record writer map . key set (  )  . for each ( barcode  -  >  barcode writer threads . put ( barcode new  thread pool executor with exceptions ( 1 )  )  )  ;  final  file lane dir = new  file ( basecalls dir  illumina file util . long lane str ( lane )  )  ;  final  file[] cycle dirs = io util . get files matching regexp ( lane dir  illumina file util . cycle   subdirectory   pattern )  ;  cbcls = new  array list <  >  (  )  ;   arrays . as list ( cycle dirs )  . for each ( cycle dir  -  >  cbcls . add all (  arrays . as list ( io util . get files matching regexp ( cycle dir ""^""  +   illumina file util . long lane str ( lane )   +  ""    ( \\d { 1 5 }  )  . cbcl$"" )  )  )  )  ;  if  ( cbcls . size (  )   =  =  0 )   {  throw new  picard exception ( "" no cbcl files found . "" )  ;   }  io util . assert files are readable ( cbcls )  ;  final  file locs file = new  file ( basecalls dir . get parent file (  )   abstract illumina position file reader . s   locs   file )  ;  try  (  locs file reader locs file reader = new  locs file reader ( locs file )  )  {  while  ( locs file reader . has next (  )  )   {  locs . add ( locs file reader . next (  )  )  ;   }   }  io util . assert file is readable ( locs file )  ;  final  pattern filter regex =  pattern . compile (  parameterized file util . escape periods (  parameterized file util . make lane tile regex ( "" . filter"" lane )  )  )  ;  filter files = get tiled files ( lane dir filter regex )  ;  for  (  final  file filter file : filter files )   {  final  matcher tile matcher = filter regex . matcher ( filter file . get name (  )  )  ;  if  ( tile matcher . matches (  )  )   {  tiles . add (  integer . value of ( tile matcher . group ( 1 )  )  )  ;   }   }  io util . assert files are readable (  arrays . as list ( filter files )  )  ;  tiles . sort ( tile   number   comparator )  ;  if  ( demultiplex )   {  final  pattern barcode regex =  pattern . compile (  parameterized file util . escape periods (  parameterized file util . make barcode regex ( lane )  )  )  ;  final  file[] barcode tile files = get tiled files ( barcodes dir barcode regex )  ;  if  ( barcode tile files . length  !  =  tiles . size (  )  )   {  throw new  picard exception (  string . format ( "" barcode files are required for each tile .   found %d expected %d . "" barcode tile files . length tiles . size (  )  )  )  ;   }  for  (  final  file barcode file : barcode tile files )   {  final  matcher tile matcher = barcode regex . matcher ( barcode file . get name (  )  )  ;  if  ( tile matcher . matches (  )  )   {  barcodes files . put (  integer . value of ( tile matcher . group ( 1 )  )  barcode file )  ;   }   }   }  set tile limits ( first tile tile limit )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\NewIlluminaBasecallsConverter.java, record writer,  ( final  converted cluster data writer < cluster   output   record >  writer final  sorting collection < cluster   output   record >  record collection final  string barcode )  {  this . writer = writer ;  this . record collection = record collection ;  this . barcode = barcode ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\NewIlluminaBasecallsConverter.java, tile processor,  ( final int tile num final  file barcode file )  {  this . tile num = tile num ;  this . barcode file = barcode file ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\NewIlluminaBasecallsConverter.java,add record,"private synchronized void   ( final  string barcode final cluster   output   record record )  {   sorting collection < cluster   output   record >  record collection = this . barcode to record collection . get ( barcode )  ;  if  ( record collection  =  =  null )   {  if  (  ! barcode record writer map . contains key ( barcode )  )   {  if  ( ignore unexpected barcodes )   {  return ;   }  throw new  picard exception (  string . format ( "" read records with barcode %s  but this barcode was not expected .   (  is it referenced in the parameters file ?  ) "" barcode )  )  ;   }  record collection = new sorting collection (  )  ;  this . barcode to record collection . put ( barcode record collection )  ;   }  record collection . add ( record )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\NewIlluminaBasecallsConverter.java,await thread pool termination,"private void   ( final  string executor name final  thread pool executor executor service )  {  try  {  while  (  ! executor service . await termination ( 300  time unit . seconds )  )   {  log . info (  string . format ( ""%s waiting for job completion .   finished jobs  -  %d :  running jobs  -  %d :  queued jobs  -  %d"" executor name executor service . get completed task count (  )  executor service . get active count (  )  executor service . get queue (  )  . size (  )  )  )  ;   }   }  catch  (  final  interrupted exception e )   {  e . print stack trace (  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\NewIlluminaBasecallsConverter.java,do tile processing,@ override public void   (  )  {  final  thread pool executor completed work executor = new  thread pool executor with exceptions ( 1 )  ;  final  completed work checker work checker = new  completed work checker (  )  ;  completed work executor . submit 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\NewIlluminaBasecallsConverter.java,get barcode,public  string   (  )  {  return barcode ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\NewIlluminaBasecallsConverter.java,get tiled files,public static  file[]   ( final  file base directory final  pattern pattern )  {  return io util . get files matching regexp ( base directory pattern )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\NewIlluminaBasecallsConverter.java,new sorting collection,private synchronized  sorting collection < cluster   output   record >    (  )  {  final int max records in ram =  math . max ( 1 max reads in ram per tile  /  barcode record writer map . size (  )  )  ;  return  sorting collection . new instance ( output record class codec prototype . clone (  )  output record comparator max records in ram tmp dirs )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\NewIlluminaBasecallsConverter.java,run,"@ override public void   (  )  {  while  ( current tile index  <  tiles . size (  )  )   {  final  integer current tile = tiles . get ( current tile index )  ;  if  ( completed work . contains key ( current tile )  )   {  log . info ( "" writing out tile """
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\MarkIlluminaAdapters.java,custom command line validation,"@ override protected  string[]   (  )  {  if  (  ( five   prime   adapter  !  =  null && three   prime   adapter  =  =  null )  ||  ( three   prime   adapter  !  =  null && five   prime   adapter  =  =  null )  )   {  return new  string[] { ""three   prime"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\MarkIlluminaAdapters.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( metrics )  ;  final  sam reader in =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . open ( i
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\MarkIlluminaAdapters.java,main,public static void   ( final  string[] args )  {   system . exit ( new  mark illumina adapters (  )  . instance main ( args )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BarcodeParser.java, barcode data iterator,public   ( final  file file )  {  bfr = new  barcode file reader ( file )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BarcodeParser.java, barcode parser,public   ( final  illumina file map tiles to files final int next tile )  {  super ( tiles to files next tile )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BarcodeParser.java,close,public void   (  )  {  bfr . close (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BarcodeParser.java,get barcode,public  string   (  )  {  return bfr . next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BarcodeParser.java,has next,public boolean   (  )  {  return bfr . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BarcodeParser.java,make tile iterator,@ override protected  closeable iterator <  barcode data >    (  file next tile file )  {  return new  barcode data iterator ( next tile file )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BarcodeParser.java,next,public  barcode data   (  )  {  return new  barcode data (  )  {  public  string get barcode (  )  {  return bfr . next (  )  ;   }   }   ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BarcodeParser.java,remove,public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BarcodeParser.java,supported types,public  set <  illumina data type >    (  )  {  return supported   types ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BaseIlluminaDataProvider.java, base illumina data provider,public   ( final int lane final  output mapping output mapping )  {  num reads = output mapping . num output reads (  )  ;  this . lane = lane ;  this . output read types =  stream support . stream ( output mapping . get output descriptors (  )  . spliterator (  )  false )  . map ( rd  -  >  rd . type )  . to array (  read type[]::new )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BaseIlluminaDataProvider.java,add data,protected void   ( final  cluster data cluster data final  barcode data barcode data )  {  cluster data . set matched barcode ( barcode data . get barcode (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BaseIlluminaDataProvider.java,add read data,protected void   ( final  cluster data cluster data final int num reads final  cbcl data cbcl data )  {  final byte[][] bases = cbcl data . get bases (  )  ;  for  ( int i = 0 ;  i  <  num reads ;  i +  +  )   {  cluster data . get read ( i )  . set bases ( bases[i] )  ;   }  final byte[][] qualities = cbcl data . get qualities (  )  ;  for  ( int i = 0 ;  i  <  num reads ;  i +  +  )   {  cluster data . get read ( i )  . set qualities ( qualities[i] )  ;   }  cluster data . set pf ( cbcl data . is pf (  )  )  ;  cluster data . setx ( cbcl data . get position info (  )  . x qseq coord )  ;  cluster data . sety ( cbcl data . get position info (  )  . y qseq coord )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BclData.java, bcl data,public   ( final int[] output lengths )  {  bases = new byte[output lengths . length][] ;  qualities = new byte[output lengths . length][] ;  for  ( int i = 0 ;  i  <  output lengths . length ;  i +  +  )   {  bases[i] = new byte[output lengths[i]] ;  qualities[i] = new byte[output lengths[i]] ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BclData.java,get bases,@ override public byte[][]   (  )  {  return bases ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BclData.java,get qualities,@ override public byte[][]   (  )  {  return qualities ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BclParser.java, bcl data cycle file parser,public   ( final  list <  file >  files )  {  reader = new  bcl reader ( files output mapping . get output read lengths (  )  bcl quality evaluation strategy false )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BclParser.java, bcl parser,public   ( final  file directory final int lane final  cycle illumina file map tiles to cycle files final  output mapping output mapping final boolean apply eamss filter final  bcl quality evaluation strategy bcl quality evaluation strategy )  {  super ( directory lane tiles to cycle files output mapping )  ;  this . bcl quality evaluation strategy = bcl quality evaluation strategy ;  this . apply eamss filter = apply eamss filter ;  this . initialize (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BclParser.java,close,@ override public void   (  )  {  reader . close (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BclParser.java,has next,@ override public boolean   (  )  {  try  {  return reader . has next (  )  ;   }  catch  (  final  null pointer exception npe )   {  return false ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BclParser.java,initialize,@ override public void   (  )  {  seek to tile ( current tile )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BclParser.java,make cycle file parser,@ override protected  cycle files parser <  bcl data >    ( final  list <  file >  files )  {  return new  bcl data cycle file parser ( files )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BclParser.java,next,@ override public  bcl data   (  )  {  if  (  ! has next (  )  )   {  throw new  no such element exception (  )  ;   }  return reader . next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BclParser.java,run eamss for read in place,protected static void   ( final byte[] bases final byte[] qualities )  {  int eamss tally = 0 ;  int max tally =  integer . min   value ;  int index of max =  - 1 ;  for  ( int i = bases . length  -  1 ;  i  >  =  0 ;  i -  -  )   {  final int quality =  ( 0xff & qualities[i] )  ;  if  ( quality  >  =  eamss   m2   ge   threshold )   {  eamss tally -  = 2 ;   }  else if  ( quality  <  eamss   s1   lt   threshold )   {  eamss tally +  = 1 ;   }  if  ( eamss tally  >  =  max tally )   {  index of max = i ;  max tally = eamss tally ;   }   }  if  ( max tally  >  =  1 )   {  int num gs = 0 ;  int exceptions = 0 ;  for  ( int i = index of max ;  i  >  =  0 ;  i -  -  )   {  if  ( bases[i]  =  =  'g' )   {   +  + num gs ;   }  else  {  final  integer skip = skip by ( i num gs exceptions bases )  ;  if  ( skip  !  =  null )   {  exceptions +  = skip ;  num gs +  = skip ;  i -  =  ( skip  -  1 )  ;   }  else  {  break ;   }   }   }  if  ( num gs  >  =  10 )   {  index of max =  ( index of max  +  1 )   -  num gs ;   }  for  ( int i = index of max ;  i  <  qualities . length ;  i +  +  )   {  qualities[i] = masking   quality ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BclParser.java,skip by,private static  integer   ( final int index final int num gs final int prev exceptions final byte[] bases )  {   integer skip = null ;  for  ( int backup = 1 ;  backup  <  =  index ;  backup +  +  )   {  final int exception limit =  math . max (  ( num gs  +  backup )   /  10 1 )  ;  if  ( prev exceptions  +  backup  >  exception limit )   {  break ;   }  if  ( bases[index  -  backup]  =  =  'g' )   {  skip = backup ;  break ;   }   }  return skip ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\BclParser.java,supported types,@ override public  set <  illumina data type >    (  )  {  return supported   types ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java, cluster data,public   ( final  read type[] read types )  {  reads = new  read data[read types . length] ;  for  ( int i = 0 ;  i  <  read types . length ;  i +  +  )   {  reads[i] = new  read data ( read types[i] )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,get lane,public int   (  )  {  return lane ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,get matched barcode,public  string   (  )  {  return matched barcode ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,get num reads,public int   (  )  {  return reads . length ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,get read,public  read data   ( final int index )  {  return reads[index] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,get tile,public int   (  )  {  return tile ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,getx,public int   (  )  {  return x ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,gety,public int   (  )  {  return y ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,is pf,public  boolean   (  )  {  return pf ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,lane is set,public boolean   (  )  {  return lane  !  =   - 1 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,set lane,public void   ( final int lane )  {  this . lane = lane ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,set matched barcode,public void   ( final  string matched barcode )  {  this . matched barcode = matched barcode ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,set or check lane,"public void   ( final int lane )  {  if  ( lane is set (  )  )   {  if  ( this . lane  !  =  lane )   {  throw new  picard exception ( "" lane number mismatch for ""  +  this  +  "" : "" +  this . lane +  ""  !  =  "" +  lane )  ;   }   }  else  {  this . lane = lane ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,set or check pf,"public void   ( final boolean pf )  {  if  ( this . pf  =  =  null )   {  this . pf = pf ;   }  else if  ( this . pf  !  =  pf )   {  throw new  picard exception ( ""pf value mismatch for ""  +  this  +  "" : "" )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,set or check tile,"public void   ( final int tile )  {  if  ( tile is set (  )  )   {  if  ( this . tile  !  =  tile )   {  throw new  picard exception ( "" tile number mismatch for ""  +  this  +  "" : "" +  this . tile +  ""  !  =  "" +  tile )  ;   }   }  else  {  this . tile = tile ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,set or checkx,"public void   ( final int x )  {  if  ( x is set (  )  )   {  if  ( this . x  !  =  x )   {  throw new  picard exception ( ""x value mismatch for ""  +  this  +  "" : "" +  this . x +  ""  !  =  "" +  x )  ;   }   }  else  {  this . x = x ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,set or checky,"public void   ( final int y )  {  if  ( y is set (  )  )   {  if  ( this . y  !  =  y )   {  throw new  picard exception ( ""y value mismatch for ""  +  this  +  "" : "" +  this . y +  ""  !  =  "" +  y )  ;   }   }  else  {  this . y = y ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,set pf,public void   ( final boolean pf )  {  this . pf = pf ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,set tile,public void   ( final int tile )  {  this . tile = tile ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,setx,public void   ( final int x )  {  this . x = x ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,sety,public void   ( final int y )  {  this . y = y ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,tile is set,public boolean   (  )  {  return tile  !  =   - 1 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,to string,"public  string   (  )  {  return "" cluster data ( lane: ""  +  lane  +  "" ;  tile: "" +  tile +  "" ;  x: "" +  x +  "" ;  y: "" +  y +  "" ;  pf: "" +  pf +  "" ;  matched barcode: "" +  matched barcode +  "" ) "" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,x is set,public boolean   (  )  {  return x  !  =   - 1 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterData.java,y is set,public boolean   (  )  {  return y  !  =   - 1 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\CbclData.java, cbcl data,public   ( int[] output lengths int tile )  {  super ( output lengths )  ;  this . tile = tile ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\CbclData.java,get position info,public  abstract illumina position file reader .  position info   (  )  {  return position info ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\CbclData.java,get tile,public int   (  )  {  return tile ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\CbclData.java,getx coordinate,@ override public int   (  )  {  return this . position info . x qseq coord ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\CbclData.java,gety coordinate,@ override public int   (  )  {  return this . position info . y qseq coord ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\CbclData.java,is pf,@ override public boolean   (  )  {  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\CbclData.java,set position info,public void   (  abstract illumina position file reader .  position info position info )  {  this . position info = position info ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\BarcodeFileFaker.java,add leading zeros,@ override protected boolean   (  )  {  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\BarcodeFileFaker.java,buffer size,@ override protected int   (  )  {  return barcode   string . get bytes (  )  . length ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\BarcodeFileFaker.java,fake file,@ override protected void   ( final  byte buffer buffer )  {  buffer . put ( barcode   string . get bytes (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterIntensityFileReader.java, cluster intensity file header,"public   ( final byte[] header bytes final  file file )  {  if  ( header bytes . length  <  header   size )   {  throw new  picard exception ( "" bytes past to header constructor are too short excpected ( ""  +  header   size  +  "" )  received  ( "" +  header bytes . length )  ;   }   byte buffer buf =  byte buffer . allocate ( header bytes . length )  ;  buf . order (  byte order . little   endian )  ;  buf . put ( header bytes )  ;  buf . position ( 0 )  ;  final byte[] identifier buf = new byte[identifier . length] ;  buf . get ( identifier buf )  ;  if  (  !  arrays . equals ( identifier buf identifier )  )   {  throw new  picard exception ( "" cluster intensity file ""  +  file  +  "" contains unexpected header: "" +   string util . bytes to string ( identifier buf )  )  ;   }  final byte file version = buf . get (  )  ;  if  ( file version  !  =  file   version )   {  throw new  picard exception ( "" cluster intensity file ""  +  file  +  "" contains unexpected version: "" +  file version )  ;   }  element size = buf . get (  )  ;  if  ( element size  <  1 || element size  >  2 )   {  throw new  picard exception ( "" cluster intensity file ""  +  file  +  "" contains unexpected element size: "" +  element size )  ;   }  first cycle =  unsigned type util . u short to int ( buf . get short (  )  )  ;  num cycles =  unsigned type util . u short to int ( buf . get short (  )  )  ;  if  ( num cycles  =  =  0 )   {  throw new  picard exception ( "" cluster intensity file ""  +  file  +  "" has zero cycles . "" )  ;   }  num clusters = buf . get int (  )  ;  if  ( num clusters  <  0 )   {  throw new  picard exception ( "" cluster intensity file ""  +  file  +  "" has negative number of clusters: "" +  num clusters )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterIntensityFileReader.java, cluster intensity file reader,"public   ( final  file file )  {  try  {  this . file = file ;  final  file input stream is = new  file input stream ( this . file )  ;  final  file channel channel = is . get channel (  )  ;  final long file size = channel . size (  )  ;  buf = channel . map (  file channel .  map mode . read   only 0 file size )  ;  buf . order (  byte order . little   endian )  ;   closer util . close ( channel )  ;   closer util . close ( is )  ;  final byte[] header bytes = new byte[header   size] ;  buf . get ( header bytes )  ;  this . header = new  cluster intensity file header ( header bytes this . file )  ;   }  catch  (  io exception e )   {  throw new  picard exception ( ""io exception opening cluster intensity file ""  +  file e )  ;   }  cycle size = num   channels * header . num clusters * header . element size ;  channel size = header . num clusters * header . element size ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterIntensityFileReader.java,get element size,public int   (  )  {  return header . element size ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterIntensityFileReader.java,get file,public  file   (  )  {  return file ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterIntensityFileReader.java,get first cycle,public int   (  )  {  return header . first cycle ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterIntensityFileReader.java,get num clusters,public int   (  )  {  return header . num clusters ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterIntensityFileReader.java,get num cycles,public int   (  )  {  return header . num cycles ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterIntensityFileReader.java,get value,"public short   ( final int cluster final  intensity channel channel final int cycle )  {  if  ( cycle  <  header . first cycle || cycle  >  =  header . first cycle  +  header . num cycles )   {  throw new  illegal argument exception ( "" requested cycle  ( ""  +  cycle  +  "" )  number out of range .   first cycle = "" +  header . first cycle +  "" ;  num cycles = "" +  header . num cycles )  ;   }  if  ( cluster  <  0 || cluster  >  =  header . num clusters )   {  throw new  illegal argument exception ( "" requested cluster  ( ""  +  cluster  +  "" )  number out of range .  num clusters in tile = "" +  header . num clusters )  ;   }  final int relative cycle = cycle  -  header . first cycle ;  final int position = header   size  +  relative cycle * cycle size  +  channel . ordinal (  )  * channel size  +  cluster * header . element size ;  buf . position ( position )  ;  if  ( header . element size  =  =  1 )   {  return buf . get (  )  ;   }  else  {  return buf . get short (  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ClusterIntensityFileReader.java,read headers,"public static  cluster intensity file header   ( final  file intensity file )  {   file input stream reader = null ;  byte[] header bytes = new byte[header   size] ;  int bytes read = 0 ;  try  {  reader = new  file input stream ( intensity file )  ;  bytes read = reader . read ( header bytes )  ;   }  catch  (   file not found exception fnf exc )   {  throw new  picard exception ( "" error opening intensity file  ( ""  +  intensity file . get absolute path (  )   +  "" ) "" fnf exc )  ;   }  catch  (  io exception io exc )   {  throw new  picard exception ( "" error reading values from header for intensity file  ( ""  +  intensity file . get absolute path (  )   +  "" ) "" io exc )  ;   }  finally  {   closer util . close ( reader )  ;   }  if  ( bytes read  !  =  header   size )  throw new  picard exception ( "" error reading intensity file header  too few bytes read  expected (  ""  +  header   size  +  "" )  read ( "" +  bytes read +  "" ) "" )  ;  return new  cluster intensity file header ( header bytes intensity file )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\CycleIlluminaFileMap.java,assert valid,"public void   ( final  list <  integer >  expected tiles final int[] expected cycles )  {  if  ( size (  )   !  =  expected cycles . length )   {  throw new  picard exception ( "" expected  cycled illumina file map to contain ""  +  expected cycles . length  +  "" cycles but only "" +  size (  )  +  "" were found ! "" )  ;   }  if  ( this . first entry (  )  . get value (  )  . size (  )   !  =  expected tiles . size (  )  )   {  throw new  picard exception ( "" expected  cycled illumina file map to contain ""  +  expected tiles . size (  )   +  "" tiles but only "" +  this . first entry (  )  . get value (  )  . size (  )  +  "" were found ! "" )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\CycleIlluminaFileMap.java,keep,public  cycle illumina file map   ( final  list <  integer >  tiles to keep final  set <  integer >  cycles )  {  final  cycle illumina file map ci map = new  cycle illumina file map (  )  ;  if  ( cycles  !  =  null )   {  for  (  final int cycle : cycles )   {  final  illumina file map template = this . get ( cycle )  ;  if  ( template  !  =  null )   {  ci map . put ( cycle template . keep ( tiles to keep )  )  ;   }   }   }  return ci map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\BclFileFaker.java,add leading zeros,@ override protected boolean   (  )  {  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\BclFileFaker.java,buffer size,protected int   (  )  {  return size  +  4 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\BclFileFaker.java,fake file,@ override public void   ( final  byte buffer buffer )  {  buffer . put int ( size )  ;  while  ( size  >  0 )   {  buffer . put (  ( byte ) 0 )  ;  size -  -  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\IlluminaLaneMetrics.java,get extension,"public static  string   (  )  {  return ""illumina   lane   metrics"" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\BciFileFaker.java,add leading zeros,@ override protected boolean   (  )  {  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\BciFileFaker.java,buffer size,@ override protected int   (  )  {  return 8 * tiles . size (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\BciFileFaker.java,fake bci file,public void   ( final  file bci final  list <  integer >  expected tiles )  throws io exception  {  tiles = expected tiles ;  final  file output stream file output stream = new  file output stream ( bci )  ;  final  file channel channel = file output stream . get channel (  )  ;  final  byte buffer buffer =  byte buffer . allocate ( 8 * expected tiles . size (  )  )  ;  buffer . order (  byte order . little   endian )  ;  fake file ( buffer )  ;  buffer . flip (  )  ;  channel . write ( buffer )  ;  channel . force ( true )  ;   closer util . close ( channel )  ;   closer util . close ( file output stream )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\BciFileFaker.java,fake file,@ override protected void   ( final  byte buffer buffer )  {  for  (  final  integer tile : tiles )   {  buffer . put int ( tile )  ;  buffer . put int ( 1 )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\LocsFileFaker.java,add leading zeros,@ override protected boolean   (  )  {  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\LocsFileFaker.java,buffer size,@ override protected int   (  )  {  return  (  integer . size * 2 )   +   (  float . size * 3 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\LocsFileFaker.java,fake file,@ override protected void   ( final  byte buffer buffer )  {  buffer . put int ( 1 )  ;  buffer . put float ( 1 . 0f )  ;  buffer . put int ( 1 )  ;  buffer . put float ( 5 . 0f )  ;  buffer . put float ( 5 . 0f )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\FilterFileFaker.java,add leading zeros,@ override protected boolean   (  )  {  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\FilterFileFaker.java,buffer size,@ override protected int   (  )  {  return  integer . size * 3 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\FilterFileFaker.java,fake file,@ override protected void   ( final  byte buffer buffer )  {  buffer . put int ( 0 )  ;  buffer . put int ( 3 )  ;  buffer . put int ( 1 )  ;  buffer . put (  ( byte ) 0 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\MultiTileLocsFileFaker.java,add leading zeros,@ override protected boolean   (  )  {  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\MultiTileLocsFileFaker.java,buffer size,@ override protected int   (  )  {  return  (  integer . size * 2 )   +   (  float . size * tiles . size (  )  )   +   float . size ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\MultiTileLocsFileFaker.java,fake file,@ override protected void   ( final  byte buffer buffer )  {  buffer . put int ( 1 )  ;  buffer . put float ( 1 . 0f )  ;  buffer . put int ( 1 )  ;  for  ( int count = 0 ;  count  <  tiles . size (  )  ;  count +  +  )   {  buffer . put float ( 5 . 0f  +
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\MultiTileBclFileFaker.java,add leading zeros,@ override protected boolean   (  )  {  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\MultiTileBclFileFaker.java,buffer size,@ override protected int   (  )  {  return  (  ( size  -   integer . size )  * tiles . size (  )  )   +   integer . size ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\MultiTileBclFileFaker.java,fake file,@ override protected void   ( final  byte buffer buffer )  {  buffer . put int ( 1 )  ;  for  (  final  integer tile : tiles )   {  long per tile size = size ;  while  ( per tile size  >  0 )   {  buffer . put (  ( byte ) 0 )  ;  per tile size -  -  ;   }
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\ClocsFileFaker.java,add leading zeros,@ override protected boolean   (  )  {  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\ClocsFileFaker.java,buffer size,@ override protected int   (  )  {  return  integer . size  +   (  byte . size * 4 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\ClocsFileFaker.java,fake file,@ override protected void   ( final  byte buffer buffer )  {  buffer . put (  ( byte ) 1 )  ;  buffer . put int ( 1 )  ;  buffer . put (  ( byte )  ( 0xff & 1 )  )  ;  buffer . put (  ( byte )  ( 0xff & 5 )  )  ;  buffer . put (  ( byte )  ( 0xff & 5 )  )
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\PosFileFaker.java,add leading zeros,@ override protected boolean   (  )  {  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\PosFileFaker.java,buffer size,@ override protected int   (  )  {  return pos   file   string . get bytes (  )  . length ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\fakers\PosFileFaker.java,fake file,@ override protected void   ( final  byte buffer buffer )  {  buffer . put ( pos   file   string . get bytes (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\FilterParser.java, filter parser,public   ( final  illumina file map tiles to files final int starting tile )  {  super ( tiles to files starting tile )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\FilterParser.java,close,public void   (  )  {  reader = null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\FilterParser.java,has next,public boolean   (  )  {  return reader . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\FilterParser.java,is pf,public boolean   (  )  {  return next value ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\FilterParser.java,make tile iterator,@ override protected  closeable iterator <  pf data >    ( final  file iterator )  {  return new  closeable iterator <  pf data >  (  )  {  private  filter file reader reader = new  filter file reader ( iterator )  ;  public void close (  )  {  reader = n
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\FilterParser.java,next,public  pf data   (  )  {  final boolean next value = reader . next (  )  ;  return new  pf data (  )  {  public boolean is pf (  )  {  return next value ;   }   }   ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\FilterParser.java,remove,public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\FilterParser.java,supported types,public  set <  illumina data type >    (  )  {  return supported types ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\FourChannelIntensityData.java, four channel intensity data,public   ( final int number of cycles )  {  a = new short[number of cycles] ;  c = new short[number of cycles] ;  g = new short[number of cycles] ;  t = new short[number of cycles] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\FourChannelIntensityData.java,equals,@ override public boolean   ( final  object o )  {  if  ( this  =  =  o )  return true ;  if  ( o  =  =  null || get class (  )   !  =  o . get class (  )  )  return false ;  final  four channel intensity data that =  (  four channel intensity data ) o ; 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\FourChannelIntensityData.java,geta,public short[]   (  )  {  return a ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\FourChannelIntensityData.java,getc,public short[]   (  )  {  return c ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\FourChannelIntensityData.java,get channel,"public short[]   ( final  intensity channel channel )  {  switch  ( channel )   {  case a: return a ;  case c: return c ;  case g: return g ;  case t: return t ;   }  throw new  picard exception ( "" unexpected intensity channel ""  +  channel )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\FourChannelIntensityData.java,getg,public short[]   (  )  {  return g ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\FourChannelIntensityData.java,gett,public short[]   (  )  {  return t ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\FourChannelIntensityData.java,hash code,@ override public int   (  )  {  int ret = 0 ;  ret = ret * 31  +   arrays . hash code ( a )  ;  ret +  = ret * 31  +   arrays . hash code ( c )  ;  ret +  = ret * 31  +   arrays . hash code ( g )  ;  ret +  = ret * 31  +   arrays . hash code ( t )  ;  re
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaDataProvider.java, illumina data provider,"  ( final  output mapping output mapping final  map <  illumina parser  set <  illumina data type >  >  parsers to data types final  file basecall directory final int lane )  {  super ( lane output mapping )  ;  this . basecall directory = basecall directory ;  final int num parsers = parsers to data types . size (  )  ;  if  ( num parsers  =  =  0 )   {  throw new  picard exception ( "" there were 0 parsers passed to  illumina data provider ! "" )  ;   }  int i = 0 ;  parsers = new  illumina parser[num parsers] ;  data types = new  illumina data type[num parsers][] ;  for  (  final  map .  entry <  illumina parser  set <  illumina data type >  >  p tod : parsers to data types . entry set (  )  )   {  parsers[i] = p tod . get key (  )  ;  final  set <  illumina data type >  dts = p tod . get value (  )  ;  data types[i] = new  illumina data type[dts . size (  ) ] ;  dts . to array ( data types[i +  + ] )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaDataProvider.java,close,@ override public void   (  )  {  for  (  final  illumina parser parser : parsers )   {  parser . close (  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaDataProvider.java,has next,"public boolean   (  )  {  final boolean more = parsers[0] . has next (  )  ;  if  (  ! more )   {  for  ( int i = 1 ;  i  <  parsers . length ;  i +  +  )   {  if  ( parsers[i] . has next (  )  )   {  throw new  picard exception ( "" unequal length  illumina files in ""  +  basecall directory  +  ""  lane "" +  lane +  "" .   failing parser: "" +  parsers[i] . get class (  )  . get name (  )  )  ;   }   }   }  return more ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaDataProvider.java,next,"public  cluster data   (  )  {  if  (  ! has next (  )  )   {  throw new  no such element exception (  )  ;   }  final  cluster data cluster = new  cluster data ( output read types )  ;  cluster . set lane ( lane )  ;  cluster . set tile ( parsers[0] . get tile of next cluster (  )  )  ;  for  ( int i = 0 ;  i  <  parsers . length ;  i +  +  )   {  final  illumina data il data = parsers[i] . next (  )  ;  for  (  final  illumina data type il data type : data types[i] )   {  switch  ( il data type )   {  case  position: add data ( cluster  (  positional data ) il data )  ;  break ;  case pf: add data ( cluster  (  pf data ) il data )  ;  break ;  case  barcodes: add data ( cluster  (  barcode data ) il data )  ;  break ;  case  base calls: add read data ( cluster num reads  (  base data ) il data )  ;  break ;  case  quality scores: add read data ( cluster num reads  (  quality data ) il data )  ;  break ;  default : throw new  picard exception ( "" unknown data type ""  +  il data type  +  "" requested by  illumina data provider factory"" )  ;   }   }   }  return cluster ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaDataProvider.java,remove,public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaDataProvider.java,seek to tile,@ override public void   ( final int one based tile number )  {  for  (  final  illumina parser parser : parsers )   {  parser . seek to tile ( one based tile number )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaFileMap.java,get files starting at,public  list <  file >    ( final int starting tile )  {  return new  array list <  file >  ( this . tail map ( starting tile )  . values (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaFileMap.java,keep,public  illumina file map   ( final  list <  integer >  tiles to keep )  {  final  illumina file map file map = new  illumina file map (  )  ;  for  (  final  integer tile : tiles to keep )   {  final  file file = this . get ( tile )  ;  if  ( file  !  =  null )   {  file map . put ( tile file )  ;   }   }  return file map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaFileNotFoundException.java, illumina file not found exception,public   ( final  file file final  string message final  throwable throwable )  {  super ( message throwable )  ;  this . file = file ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaFileUtil.java, illumina file util,"public   ( final  file basecall dir final  file barcode dir final int lane )  {  this . lane = lane ;  this . basecall dir = basecall dir ;  this . barcode dir = barcode dir ;  this . intensity dir = basecall dir . get parent file (  )  ;  final  file data dir = intensity dir . get parent file (  )  ;  this . basecall lane dir = new  file ( basecall dir long lane str ( lane )  )  ;  this . intensity lane dir = new  file ( intensity dir long lane str ( lane )  )  ;  final  file interop dir = new  file ( data dir . get parent file (  )  "" inter op"" )  ;  tile metrics out = new  file ( interop dir "" tile metrics out . bin"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaFileUtil.java,get actual tiles,"public  list <  integer >    ( final  list <  supported illumina format >  formats )  {  if  ( formats  =  =  null )   {  throw new  picard exception ( "" format list provided to get tiles was null ! "" )  ;   }  if  ( formats . is empty (  )  )   {  throw new  picard exception ( ""0  formats were specified .   you need to specify at least  supported illumina format to use get tiles"" )  ;   }  final  list <  parameterized file util >  tile based formats = formats . stream (  )  . map ( this::get util )  . filter (  parameterized file util::check tile count )  . collect (  collectors . to list (  )  )  ;  if  ( tile based formats . size (  )   >  0 )   {  final  list <  integer >  expected tiles = tile based formats . get ( 0 )  . get tiles (  )  ;  tile based formats . for each ( util  -  >   {  if  ( expected tiles . size (  )   !  =  util . get tiles (  )  . size (  )  ||  ! expected tiles . contains all ( util . get tiles (  )  )  )   {  throw new  picard exception ( "" formats do not have the same number of tiles !  ""  +  summarize tile counts ( formats )  )  ;   }   }   )  ;  return expected tiles ;   }  else  {  return new  array list <  >  (  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaFileUtil.java,get expected tiles,public  list <  integer >    (  )  {  io util . assert file is readable ( tile metrics out )  ;  final  tree set <  integer >  expected tiles = new  tree set <  >  (  )  ;  final  iterator <  tile metrics out reader .  illumina tile metrics >  tile metrics = new  tile metrics out reader ( tile metrics out  tile metrics out reader .  tile metrics version . two )  ;  while  ( tile metrics . has next (  )  )   {  final  tile metrics out reader .  illumina tile metrics tile metric = tile metrics . next (  )  ;  if  ( tile metric . get lane number (  )   =  =  lane &&  ! expected tiles . contains ( tile metric . get tile number (  )  )  )   {  expected tiles . add ( tile metric . get tile number (  )  )  ;   }   }   closer util . close ( tile metrics )  ;  return new  array list <  >  ( expected tiles )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaFileUtil.java,get lane,public int   (  )  {  return lane ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaFileUtil.java,get util,"public  parameterized file util   ( final  supported illumina format format )  {   parameterized file util parameterized file util = utils . get ( format )  ;  if  ( parameterized file util  =  =  null )   {  switch  ( format )   {  case  bcl: final  parameterized file util bcl file util = new  per tile per cycle file util ( "" . bcl"" basecall lane dir new  bcl file faker (  )  lane )  ;  final  parameterized file util gz bcl file util = new  per tile per cycle file util ( "" . bcl . gz"" basecall lane dir new  bcl file faker (  )  lane )  ;  if  ( bcl file util . files available (  )  &&  ! gz bcl file util . files available (  )  )   {  parameterized file util = bcl file util ;   }  else if  (  ! bcl file util . files available (  )  && gz bcl file util . files available (  )  )   {  parameterized file util = gz bcl file util ;   }  else if  (  ! bcl file util . files available (  )  &&  ! gz bcl file util . files available (  )  )   {  parameterized file util = bcl file util ;   }  else  {  throw new  picard exception ( "" not all bcl files in ""  +  basecall lane dir . get absolute path (  )   +  "" have the same extension ! "" )  ;   }  utils . put (  supported illumina format .  bcl parameterized file util )  ;  break ;  case  locs: parameterized file util = new  per tile or per run file util ( "" . locs"" intensity lane dir new  locs file faker (  )  lane )  ;  utils . put (  supported illumina format .  locs parameterized file util )  ;  break ;  case  clocs: parameterized file util = new  per tile file util ( "" . clocs"" intensity lane dir new  clocs file faker (  )  lane )  ;  utils . put (  supported illumina format .  clocs parameterized file util )  ;  break ;  case  pos: parameterized file util = new  per tile file util ( ""   pos . txt"" intensity dir new  pos file faker (  )  lane )  ;  utils . put (  supported illumina format .  pos parameterized file util )  ;  break ;  case  filter: parameterized file util = new  per tile file util ( "" . filter"" basecall lane dir new  filter file faker (  )  lane )  ;  utils . put (  supported illumina format .  filter parameterized file util )  ;  break ;  case  barcode: parameterized file util = new  per tile file util ( ""   barcode . txt"" barcode dir  !  =  null  ?  barcode dir : basecall dir new  barcode file faker (  )  lane false )  ;  utils . put (  supported illumina format .  barcode parameterized file util )  ;  break ;  case  multi tile filter: parameterized file util = new  multi tile filter file util ( basecall lane dir lane )  ;  utils . put (  supported illumina format .  multi tile filter parameterized file util )  ;  break ;  case  multi tile locs: parameterized file util = new  multi tile locs file util ( new  file ( intensity dir basecall lane dir . get name (  )  )  basecall lane dir lane )  ;  utils . put (  supported illumina format .  multi tile locs parameterized file util )  ;  break ;  case  multi tile bcl: parameterized file util = new  multi tile bcl file util ( basecall lane dir lane )  ;  utils . put (  supported illumina format .  multi tile bcl parameterized file util )  ;  break ;   }   }  return parameterized file util ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaFileUtil.java,has cbcls,"public static boolean   ( final  file basecall dir final int lane )  {  final  file lane dir = new  file ( basecall dir  illumina file util . long lane str ( lane )  )  ;  final  file[] cycle dirs = io util . get files matching regexp ( lane dir  illumina file util . cycle   subdirectory   pattern )  ;  if  ( cycle dirs  =  =  null )   {  return false ;   }  final  list <  file >  cbcls = new  array list <  >  (  )  ;   arrays . as list ( cycle dirs )  . for each ( cycle dir  -  >  cbcls . add all (  arrays . as list ( io util . get files matching regexp ( cycle dir ""^""  +   illumina file util . long lane str ( lane )   +  ""    ( \\d { 1 5 }  )  . cbcl$"" )  )  )  )  ;  return cbcls . size (  )   >  0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaFileUtil.java,li to str,"private  string   ( final  list <  integer >  int list )  {  if  ( int list . is empty (  )  )   {  return """" ;   }  final  string builder summary = new  string builder (  string . value of ( int list . get ( 0 )  )  )  ;  for  ( int i = 1 ;  i  <  int list . size (  )  ;  i +  +  )   {  summary . append ( ""  "" )  . append (  string . value of ( int list . get ( i )  )  )  ;   }  return summary . to string (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaFileUtil.java,long lane str,"public static  string   ( final int lane )  {  final  string builder lstr = new  string builder (  string . value of ( lane )  )  ;  final int zeros to add = 3  -  lstr . length (  )  ;  for  ( int i = 0 ;  i  <  zeros to add ;  i +  +  )   {  lstr . insert ( 0 ""0"" )  ;   }  return ""l""  +  lstr ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaFileUtil.java,summarize tile counts,"private  string   ( final  list <  supported illumina format >  formats )  {  final  string builder summary ;   parameterized file util pfu = get util ( formats . get ( 0 )  )  ;   list <  integer >  tiles = pfu . get tiles (  )  ;  summary = new  string builder ( pfu . extension  +  "" ( ""  +  li to str ( tiles )  +  "" ) "" )  ;  for  (  final  supported illumina format format : formats )   {  pfu = get util ( format )  ;  tiles = pfu . get tiles (  )  ;  summary . append ( ""  "" )  . append ( pfu . extension )  . append ( "" ( "" )  . append ( li to str ( tiles )  )  . append ( "" ) "" )  ;   }  return summary . to string (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaFileUtil.java,tile metrics out,public  file   (  )  {  return tile metrics out ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaMetricsCode.java, illumina metrics code,  ( final int metrics code )  {  this . metrics code = metrics code ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaMetricsCode.java,get metrics code,public int   (  )  {  return metrics code ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaMetricsCode.java,get phasing code,"public static int   ( final int read descriptor index final  illumina metrics code phasing type )  {  if  (  ! is phasing ( phasing type )  )   {  throw new  illegal argument exception ( ""phasing type must be phasing   base or prephasing   base"" )  ;   }  return  ( phasing type . get metrics code (  )   +   ( read descriptor index * 2 )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaMetricsCode.java,is phasing,public static boolean   ( final  illumina metrics code metrics code )  {  return  ( metrics code . equals ( phasing   base )  || metrics code . equals ( prephasing   base )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaDataProviderFactory.java, illumina data provider factory,"public   (  file basecall directory  file barcodes directory int lane  read structure read structure  bcl quality evaluation strategy bcl quality evaluation strategy )  {  this . basecall directory = basecall directory ;  this . barcodes directory = barcodes directory ;  this . bcl quality evaluation strategy = bcl quality evaluation strategy ;  this . lane = lane ;  this . format to data types = null ;  this . available tiles = null ;  this . file util = null ;  output mapping = new  output mapping ( read structure )  ;   pattern lane tile regex =  pattern . compile (  parameterized file util . escape periods (  parameterized file util . make lane tile regex ( "" . filter"" lane )  )  )  ;   file lane dir = new  file ( basecall directory  illumina file util . long lane str ( lane )  )  ;   list <  integer >  tiles = new  array list <  >  (  )  ;   file[] filter files = get tiled files ( lane dir lane tile regex )  ;  for  (   file filter file : filter files )   {   matcher tile matcher = lane tile regex . matcher ( filter file . get name (  )  )  ;  if  ( tile matcher . matches (  )  )   {  tiles . add (  integer . value of ( tile matcher . group ( 1 )  )  )  ;   }   }  io util . assert files are readable (  arrays . as list ( filter files )  )  ;  tiles . sort (  new illumina basecalls converter . tile   number   comparator )  ;  available tiles = tiles ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaDataProviderFactory.java,determine formats,public static  map <  supported illumina format  set <  illumina data type >  >    ( final  set <  illumina data type >  requested data types final  illumina file util file util )  {  final  sorted set <  illumina data type >  to support = new  tree set <  >  ( requested data types )  ;  final  map <  supported illumina format  set <  illumina data type >  >  file type to data types = new  enum map <  >  (  supported illumina format . class )  ;  final  map <  illumina data type  supported illumina format >  data type to format = new  enum map <  >  (  illumina data type . class )  ;  for  (  final  illumina data type ts : to support )   {  final  supported illumina format preferred format = find preferred available format ( ts file util )  ;  if  ( preferred format  !  =  null )   {  data type to format . put ( ts preferred format )  ;   }   }  for  (  final  illumina data type dt : to support )   {  final  supported illumina format format = data type to format . get ( dt )  ;  if  ( format  !  =  null )   {  if  ( file type to data types . contains key ( format )  )   {  file type to data types . get ( format )  . add ( dt )  ;   }  else  {  file type to data types . put ( data type to format . get ( dt )  make set ( dt )  )  ;   }   }   }  return file type to data types ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaDataProviderFactory.java,find preferred available format,private static  supported illumina format   ( final  illumina data type dt final  illumina file util file util )  {  return find preferred format ( dt file util true )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaDataProviderFactory.java,find preferred format,private static  supported illumina format   ( final  illumina data type dt final  illumina file util file util final boolean check available )  {  final  list <  supported illumina format >  preferred formats = data   type   to   preferred   formats . get ( dt )  ;   supported illumina format format = null ;  for  ( int i = 0 ;  i  <  preferred formats . size (  )  && format  =  =  null ;  i +  +  )   {  if  ( check available && file util . get util ( preferred formats . get ( i )  )  . files available (  )  )   {  format = preferred formats . get ( i )  ;   }  else if  (  ! check available )   {  format = preferred formats . get ( i )  ;   }   }  return format ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaDataProviderFactory.java,find unmatched types,public static  set <  illumina data type >    ( final  set <  illumina data type >  requested data types final  map <  supported illumina format  set <  illumina data type >  >  format to matched types )  {  final  set <  illumina data type >  copied types = new  hash set <  >  ( requested data types )  ;  for  (  final  set <  illumina data type >  matched types : format to matched types . values (  )  )   {  copied types . remove all ( matched types )  ;   }  return copied types ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaDataProviderFactory.java,get available tiles,public  list <  integer >    (  )  {  return available tiles ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaDataProviderFactory.java,get output read structure,public  read structure   (  )  {  return output mapping . get output read structure (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaDataProviderFactory.java,make data provider,"public  base illumina data provider   (  list <  integer >  requested tiles )  {  if  ( requested tiles  =  =  null )   {  requested tiles = available tiles ;   }  else  {  if  ( requested tiles . is empty (  )  )   {  throw new  picard exception ( "" zero length tile list supplied to make data provider  you must specify at least 1 tile or pass null to use all available tiles"" )  ;   }   }  final  map <  illumina parser  set <  illumina data type >  >  parsers to data type = new  hash map <  >  (  )  ;  for  (  final  map .  entry <  supported illumina format  set <  illumina data type >  >  fm to dt : format to data types . entry set (  )  )   {  parsers to data type . put ( make parser ( fm to dt . get key (  )  requested tiles )  fm to dt . get value (  )  )  ;   }  log . debug ( "" the following parsers will be used by  illumina data provider: ""  +   string util . join ( "" ""  +  parsers to data type . key set (  )  )  )  ;  return new  illumina data provider ( output mapping parsers to data type basecall directory lane )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaDataProviderFactory.java,make parser,"private  illumina parser   ( final  supported illumina format format final  list <  integer >  requested tiles )  {  final  illumina parser parser ;  switch  ( format )   {  case  barcode: parser = new  barcode parser (  (  (  per tile file util ) file util . get util (  supported illumina format .  barcode )  )  . get files ( requested tiles )  )  ;  break ;  case  bcl:  {  final  cycle illumina file map bcl file map =  (  (  per tile per cycle file util ) file util . get util (  supported illumina format .  bcl )  )  . get files ( requested tiles output mapping . get output cycles (  )  )  ;  bcl file map . assert valid ( requested tiles output mapping . get output cycles (  )  )  ;  parser = new  bcl parser ( basecall directory lane bcl file map output mapping this . apply eamss filtering bcl quality evaluation strategy )  ;  break ;   }  case  filter: final  illumina file map filter file map =  (  (  per tile file util ) file util . get util (  supported illumina format .  filter )  )  . get files ( requested tiles )  ;  parser = new  filter parser ( filter file map )  ;  break ;  case  locs: case  clocs: case  pos: final  per tile file util fu =  (  per tile file util ) file util . get util ( format )  ;  parser = new  pos parser ( fu . get files ( requested tiles )  format )  ;  break ;  case  multi tile filter: parser =  (  (  multi tile filter file util ) file util . get util (  supported illumina format .  multi tile filter )  )  . make parser ( requested tiles )  ;  break ;  case  multi tile locs: parser =  (  (  multi tile locs file util ) file util . get util (  supported illumina format .  multi tile locs )  )  . make parser ( requested tiles )  ;  break ;  case  multi tile bcl:  {  final  multi tile bcl file util util =  (  multi tile bcl file util ) file util . get util (  supported illumina format .  multi tile bcl )  ;  final  cycle illumina file map bcl file map = util . get files ( requested tiles output mapping . get output cycles (  )  )  ;  bcl file map . assert valid ( requested tiles output mapping . get output cycles (  )  )  ;  parser = new  multi tile bcl parser ( basecall directory lane bcl file map output mapping this . apply eamss filtering bcl quality evaluation strategy util . tile index )  ;  break ;   }  default : throw new  picard exception ( "" unrecognized data type ( ""  +  format  +  "" )  found by  illumina data provider factory ! "" )  ;   }  return parser ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaDataProviderFactory.java,set apply eamss filtering,public void   ( final boolean apply eamss filtering )  {  this . apply eamss filtering = apply eamss filtering ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaTextIterator.java, illumina text iterator,public   ( final int lane final  illumina file map files final boolean treat grouped delimiters as one )  {  this ( lane files )  ;  this . treat grouped delimiters as one = treat grouped delimiters as one ;  current tile = files . first key (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaTextIterator.java,get current filename,public  string   (  )  {  if  ( parser  =  =  null )  initialize parser (  )  ;  return parser . get file name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaTextIterator.java,get lane,protected int   (  )  {  return lane ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaTextIterator.java,has next,public boolean   (  )  {  if  ( parser  =  =  null )  initialize parser (  )  ;  return parser . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaTextIterator.java,initialize parser,private void   (  )  {  final  list <  file >  file subset = files . get files starting at ( current tile )  ;  parser = new  basic input parser ( treat grouped delimiters as one file subset . to array ( new  file[file subset . size (  ) ] )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaTextIterator.java,next,@ override public  string[]   (  )  {  if  (  ! has next (  )  )   {  throw new  no such element exception (  )  ;   }  return parser . next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaTextIterator.java,remove,"@ override public void   (  )  {  throw new  unsupported operation exception ( "" remove is not supported by  illumina text iterator"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaTextIterator.java,seek to tile,public void   ( final int one based tile number )  {   closer util . close ( parser )  ;  current tile = one based tile number ;  initialize parser (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\IlluminaTextIterator.java,validate lane,"protected void   ( final int lane )  {  if  ( lane  !  =  get lane (  )  )   {  throw new  picard exception ( "" lane number mismatch: ""  +  lane  +  ""  !  =  "" +  get lane (  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclFileUtil.java, multi tile bcl file util,"  ( final  file basecall lane dir final int lane )  {  super ( ""^ ( \\d { 4 }  )  . bcl . bgzf$"" "" . bcl . bgzf"" basecall lane dir new  multi tile bcl file faker (  )  lane )  ;  this . basecall lane dir = basecall lane dir ;  bci = new  file ( basecall lane dir ""s   ""  +  lane  +  "" . bci"" )  ;  final  file[] cycle files = io util . get files matching regexp ( base match pattern )  ;  if  ( bci . exists (  )  )   {  tile index = new  tile index ( bci )  ;  if  ( cycle files  !  =  null )   {  for  (  final  file file : cycle files )   {  final  string file name = file . get name (  )  ;  final  string cycle num = file name . substring ( 0 file name . index of ( ' . ' )  )  ;  final  illumina file map file map = new  illumina file map (  )  ;  for  (  final  integer tile : tile index . get tiles (  )  )   {  file map . put ( tile file )  ;   }  cycle file map . put (  integer . value of ( cycle num )  file map )  ;   }   }   }  else  {  tile index = null ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclFileUtil.java,fake files,"@ override public  list <  string >    ( final  list <  integer >  expected tiles final int[] expected cycles final  illumina file util .  supported illumina format format )  {  if  ( tile index  =  =  null )   {  return  collections . singleton list ( "" "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclFileUtil.java,files available,@ override public boolean   (  )  {  return bci . exists (  )  &&  ! cycle file map . is empty (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclFileUtil.java,get files,public  cycle illumina file map   ( final  list <  integer >  tiles final int[] cycles )  {  final  array list <  integer >  good cycle list = new  array list <  integer >  ( cycles . length )  ;  for  (  final int cycle : cycles )   {  if  ( cycle file map . contains key ( cycle )  )   {  good cycle list . add ( cycle )  ;   }   }   collections . sort ( good cycle list )  ;  final int[] good cycles = new int[good cycle list . size (  ) ] ;  for  ( int i = 0 ;  i  <  good cycles . length ;   +  + i )   {  good cycles[i] = good cycle list . get ( i )  ;   }  final  cycle illumina file map cycled map = new  cycle illumina file map (  )  ;  if  ( good cycles . length  >  0 )   {  for  (  final int cycle : good cycles )   {  final  illumina file map file map = cycle file map . get ( cycle )  . keep ( tiles )  ;  cycled map . put ( cycle file map )  ;   }   }  return cycled map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclFileUtil.java,get tiles,@ override public  list <  integer >    (  )  {  if  ( tile index  =  =  null )   {  return  collections . empty list (  )  ;   }  return tile index . get tiles (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclFileUtil.java,verify,"@ override public  list <  string >    ( final  list <  integer >  expected tiles final int[] expected cycles )  {  if  ( tile index  =  =  null )   {  return  collections . singleton list ( "" tile index ( ""  +  bci . get absolute path (  )   +  "" )  does"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileFilterParser.java, multi tile filter parser,public   ( final  tile index tile index final  list <  integer >  requested tiles final  file filter file )  {  super ( tile index requested tiles  collections . singleton (  illumina data type . pf )  )  ;  reader = new  filter file reader ( filter file )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileFilterParser.java,is pf,@ override public boolean   (  )  {  return next val ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileFilterParser.java,read next,@ override  pf data   (  )  {  final boolean next val = reader . next (  )  ;  return new  pf data (  )  {  @ override public boolean is pf (  )  {  return next val ;   }   }   ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileFilterParser.java,skip records,@ override void   ( final int num to skip )  {  reader . skip records ( num to skip )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileFileUtil.java, multi tile file util,"  ( final  string extension final  file base final  file bci dir final  file faker file faker final int lane )  {  super ( false extension base file faker lane )  ;  bci = new  file ( bci dir ""s   ""  +  lane  +  "" . bci"" )  ;  if  ( bci . exists (  )  )   {  tile index = new  tile index ( bci )  ;   }  else  {  tile index = null ;   }  final  file[] files matching regexp = io util . get files matching regexp ( base match pattern )  ;  if  ( files matching regexp  =  =  null || files matching regexp . length  =  =  0 )   {  data file = null ;   }  else if  ( files matching regexp . length  =  =  1 )   {  data file = files matching regexp[0] ;   }  else  {  throw new  picard exception ( "" more than one filter file found in ""  +  base . get absolute path (  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileFileUtil.java, multi tile filter file util,"  ( final  file basecall lane dir final int lane )  {  super ( "" . filter"" basecall lane dir basecall lane dir new  filter file faker (  )  lane )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileFileUtil.java, multi tile locs file util,"  ( final  file basecall lane dir final  file bci dir final int lane )  {  super ( "" . locs"" basecall lane dir bci dir new  multi tile locs file faker (  )  lane )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileFileUtil.java,fake files,@ override public  list <  string >    ( final  list <  integer >  expected tiles final int[] expected cycles final  illumina file util .  supported illumina format format )  {  final  bci file faker bci file faker = new  bci file faker (  )  ;  try  {  b
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileFileUtil.java,files available,@ override public boolean   (  )  {  return tile index  !  =  null && data file  !  =  null && data file . exists (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileFileUtil.java,get tiles,@ override public  list <  integer >    (  )  {  if  ( tile index  =  =  null )   {  return  collections . empty list (  )  ;   }  return tile index . get tiles (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileFileUtil.java,make parser,@ override  illumina parser <  positional data >    ( final  list <  integer >  requested tiles )  {  return new  multi tile locs parser ( tile index requested tiles data file lane )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileFileUtil.java,verify,"@ override public  list <  string >    ( final  list <  integer >  expected tiles final int[] expected cycles )  {  if  ( tile index  =  =  null )   {  return  collections . singleton list ( "" tile index ( ""  +  bci . get absolute path (  )   +  "" )  does"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileLocsParser.java, multi tile locs parser,public   ( final  tile index tile index final  list <  integer >  requested tiles final  file locs file final int lane )  {  super ( tile index requested tiles  collections . singleton (  illumina data type .  position )  )  ;  final int tile number ;  if  ( requested tiles . size (  )   =  =  1 )  tile number = requested tiles . get ( 0 )  ;  else tile number =  - 1 ;  this . reader = new  locs file reader ( locs file lane tile number )  ;  this . lane = lane ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileLocsParser.java,close,@ override public void   (  )  {  reader . close (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileLocsParser.java,get lane,public int   (  )  {  return lane ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileLocsParser.java,get tile,public int   (  )  {  return tile ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileLocsParser.java,getx coordinate,public int   (  )  {  return next val . x qseq coord ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileLocsParser.java,gety coordinate,public int   (  )  {  return next val . y qseq coord ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileLocsParser.java,read next,@ override  positional data   (  )  {  final int tile = get tile of next cluster (  )  ;  final  abstract illumina position file reader .  position info next val = reader . next (  )  ;  return new  positional data (  )  {  public int getx coordinate (  )
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileLocsParser.java,skip records,@ override void   ( final int num to skip )  {  reader . skip records ( num to skip )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclParser.java, count limited iterator,  ( final  bcl reader underlying iterator final int record limit )  {  this . underlying iterator = underlying iterator ;  this . record limit = record limit ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclParser.java, multi tile bcl data cycle file parser,public   ( final  list <  file >  files final int current tile )  {  this . current tile = current tile ;  reader = make reader ( files )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclParser.java, multi tile bcl parser,public   ( final  file directory final int lane final  cycle illumina file map tiles to cycle files final  output mapping output mapping final boolean apply eamss filter final  bcl quality evaluation strategy bcl quality evaluation strategy final  tile index tile index )  {  super ( directory lane tiles to cycle files output mapping apply eamss filter bcl quality evaluation strategy )  ;  this . tile index = tile index ;  this . initialize (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclParser.java,close,@ override public void   (  )  {  reader . close (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclParser.java,get current tile,public int   (  )  {  return current tile ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclParser.java,get reader,public  bcl reader   (  )  {  return reader . get underlying iterator (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclParser.java,get underlying iterator,public  bcl reader   (  )  {  return underlying iterator ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclParser.java,has next,@ override public boolean   (  )  {  try  {  return reader . has next (  )  ;   }  catch  (  final  null pointer exception npe )   {  return false ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclParser.java,initialize,@ override public void   (  )  {  if  ( tile index  !  =  null )   {  seek to tile ( current tile )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclParser.java,make cycle file parser,@ override protected  cycle files parser <  bcl data >    ( final  list <  file >  files )  {  if  ( cycle file parser  =  =  null )   {  cycle file parser = new  multi tile bcl data cycle file parser ( files current tile )  ;   }  else  {  final int num 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclParser.java,make reader,private  count limited iterator   ( final  list <  file >  files )  {  if  ( tile index  !  =  null )   {  final  bcl reader bcl reader =  bcl reader . make seekable ( files bcl quality evaluation strategy output mapping . get output read lengths (  )  )  ;  final int num clusters in tile = bcl reader . seek ( files tile index current tile )  ;  return new  count limited iterator ( bcl reader num clusters in tile )  ;   }  else  {  return null ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclParser.java,next,@ override public  bcl data   (  )  {  if  (  ! has next (  )  )   {  throw new  no such element exception (  )  ;   }  return reader . next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclParser.java,remove,@ override public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclParser.java,reset cluster limit,public void   ( final int num clusters in tile )  {  reader . record limit = num clusters in tile ;  reader . num records read = 0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileBclParser.java,set current tile,public void   ( final int current tile )  {  this . current tile = current tile ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileParser.java, multi tile parser,public   ( final  tile index tile index final  list <  integer >  requested tiles final  set <  illumina data type >  supported types )  {  this . tile index = tile index ;  this . tile index iterator = tile index . iterator (  )  ;  this . requested tiles iterator = new  peek iterator <  integer >  ( requested tiles . iterator (  )  )  ;  this . supported types = supported types ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileParser.java,get tile of next cluster,@ override public int   (  )  {  if  (  ! has next (  )  )   {  throw new  no such element exception (  )  ;   }  if  ( current tile  !  =  null && next cluster in tile  <  current tile . num clusters in tile )  return current tile . tile ;  else return r
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileParser.java,has next,@ override public boolean   (  )  {  while  (  ( current tile  =  =  null || next cluster in tile  >  =  current tile . num clusters in tile )  && requested tiles iterator . has next (  )  )   {  seek to tile ( requested tiles iterator . next (  )  )  ;  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\MultiTileParser.java,next,@ override public output   record   (  )  {  if  (  ! has next (  )  )  throw new  no such element exception (  )  ;  output   record ret = read next (  )  ;   +  + next cluster in tile ;   +  + next record index ;  return ret ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\OutputMapping.java, output mapping,public   ( final  read structure read structure )  {  this . output substructure = read structure . non skips ;  this . cycle to output index = make cycle to output index array ( read structure )  ;  this . output read structure = output substructure . to read structure (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\OutputMapping.java, twod index,public   ( final int major index final int minor index )  {  this . major index = major index ;  this . minor index = minor index ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\OutputMapping.java,equals,@ override public boolean   ( final  object that obj )  {  if  ( that obj  =  =  null ||  !  ( that obj instanceof  twod index )  )   {  return false ;   }  final  twod index that =  (  twod index ) that obj ;  return this . major index  =  =  that . majo
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\OutputMapping.java,get cycle index ranges,public  range[]   (  )  {  return output substructure . get cycle index ranges (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\OutputMapping.java,get output cycles,public int[]   (  )  {  return output substructure . get cycles (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\OutputMapping.java,get output descriptors,public  iterable <  read descriptor >    (  )  {  return output substructure ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\OutputMapping.java,get output index for cycle,public  twod index   ( final int cycle )  {  return cycle to output index[cycle] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\OutputMapping.java,get output read lengths,public int[]   (  )  {  return output substructure . get descriptor lengths (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\OutputMapping.java,get output read structure,public  read structure   (  )  {  return output read structure ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\OutputMapping.java,get total output cycles,public int   (  )  {  return output substructure . get total cycles (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\OutputMapping.java,make cycle to output index array,"private  twod index[]   ( final  read structure read structure )  {  int total cycles = read structure . total cycles ;  final  twod index[] cycle to output index = new  twod index[total cycles  +  1] ;  final int[] output cycles = get output cycles (  )  ;  final int[] output lengths = get output read lengths (  )  ;  int output cycle index = 0 ;  int arr index = 0 ;  int element index = 0 ;  for  ( int i = 1 ;  i  <  =  total cycles && output cycle index  <  output cycles . length ;  i +  +  )   {  if  ( output cycles[output cycle index]  =  =  i )   {  if  ( element index  >  =  output lengths[arr index] )   {  element index = 0 ;   +  + arr index ;   }  cycle to output index[i] = new  twod index ( arr index element index )  ;   +  + element index ;   +  + output cycle index ;   }   }  if  ( output cycle index  !  =  output cycles . length )   {  throw new  picard exception ( "" error in read structure output cycles  ( ""  +   string util . int values to string ( output cycles )   +  "" )  and total cycles  ( "" +  total cycles +  "" )   output cycle index ( "" +  output cycle index +  "" ) "" )  ;   }  return cycle to output index ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\OutputMapping.java,num output reads,public int   (  )  {  return output substructure . length (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\OutputMapping.java,to string,"@ override public  string   (  )  {  return "" twod index ( major index  =  =  ""  +  major index  +  ""  minor index  =  =  "" +  minor index +  "" ) "" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ParameterizedFileUtil.java, parameterized file util,private   ( final  string extension final  file base final  file faker faker final int lane final boolean skip empty files )  {  this . faker = faker ;  this . extension = extension ;  this . base = base ;  this . lane = lane ;  this . skip empty files = skip empty files ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ParameterizedFileUtil.java,check tile count,public boolean   (  )  {  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ParameterizedFileUtil.java,escape periods,"public static  string   ( final  string pre escaped )  {  return pre escaped . replace all ( ""\\ . "" ""\\ . "" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileCycleParser.java, per tile cycle parser,  ( final  file directory final int lane final  cycle illumina file map cycles to tile files final  output mapping output mapping )  {  this . tile order = get tile order ( cycles to tile files )  ;  this . lane = lane ;  this . lane directory = new  file ( directory  illumina file util . long lane str ( this . lane )  )  ;  this . cycles to tile files = cycles to tile files ;  this . current tile = tile order . first (  )  ;  this . output mapping = output mapping ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileCycleParser.java,close,@ override public void   (  )  {  cycle files parser . close (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileCycleParser.java,get tile of next cluster,public int   (  )  {  if  ( cycle files parser . has next (  )  )   {  return current tile ;   }  if  ( current tile  <  tile order . last (  )  )   {  return tile order . higher ( current tile )  ;   }  throw new  no such element exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileCycleParser.java,get tile order,private  tree set <  integer >    ( final  cycle illumina file map cycles to tile files )  {  final  tree set <  integer >  unique tiles = new  tree set <  integer >  (  )  ;  for  (  final  illumina file map file map : cycles to tile files . values (  )  )   {  unique tiles . add all ( file map . key set (  )  )  ;   }  return unique tiles ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileCycleParser.java,has next,@ override public boolean   (  )  {  return cycle files parser . has next (  )  || current tile  <  tile order . last (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\NewIlluminaDataProvider.java, new illumina data provider,  ( final  list <  file >  cbcls final  list <  abstract illumina position file reader .  position info >  locs final  file[] filter files final int lane final int tile num final  output mapping output mapping final  file barcode file )  {  super ( lane output mapping )  ;   map <  integer  file >  filter file map = new  hash map <  >  (  )  ;  for  (   file filter file : filter files )   {  filter file map . put ( file to tile ( filter file . get name (  )  )  filter file )  ;   }  this . reader = new  cbcl reader ( cbcls filter file map output mapping . get output read lengths (  )  tile num locs output mapping . get output cycles (  )  false )  ;  if  ( barcode file  !  =  null )   {  this . barcode reader = new  barcode file reader ( barcode file )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\NewIlluminaDataProvider.java,close,@ override public void   (  )  {  reader . clear (  )  ;  reader . close (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\NewIlluminaDataProvider.java,file to tile,"public static  integer   ( final  string file name )  {  final  matcher matcher =  pattern . compile ( ""^s   \\d +     ( \\d { 1 5 }  )  .  + "" )  . matcher ( file name )  ;  if  (  ! matcher . matches (  )  )   {  return null ;   }  return  integer . parse int ( matcher . group ( 1 )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\NewIlluminaDataProvider.java,has next,@ override public boolean   (  )  {  return reader . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\NewIlluminaDataProvider.java,next,@ override public  cluster data   (  )  {   cbcl data cbcl data = reader . next (  )  ;  if  ( cbcl data  =  =  null )  return null ;  final  cluster data cluster = new  cluster data ( output read types )  ;  cluster . set lane ( lane )  ;  cluster . set 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileFileUtil.java, per tile file util,public   ( final  string extension final  file base final  file faker faker final int lane final boolean skip empty files )  {  super ( true extension base faker lane skip empty files )  ;  this . file map = get tiled files ( base match pattern )  ;  if  (  ! file map . is empty (  )  )   {  this . tiles = new  array list <  >  ( this . file map . key set (  )  )  ;   }  else  {  this . tiles =  collections . empty list (  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileFileUtil.java,fake files,@ override public  list <  string >    ( final  list <  integer >  expected tiles final int[] cycles final  illumina file util .  supported illumina format format )  {  final  list <  string >  failures = new  linked list <  >  (  )  ;  if  (  ! base . ex
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileFileUtil.java,files available,@ override public boolean   (  )  {  return  ! file map . is empty (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileFileUtil.java,get files,public  illumina file map   ( final  list <  integer >  tiles )  {  return file map . keep ( tiles )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileFileUtil.java,verify,@ override public  list <  string >    ( final  list <  integer >  expected tiles final int[] expected cycles )  {  return verify per tile ( this . base expected tiles )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileFileUtil.java,verify per tile," list <  string >    (  file base dir  list <  integer >  expected tiles )  {  final  list <  string >  failures = new  linked list <  >  (  )  ;  if  (  ! base dir . exists (  )  )   {  failures . add ( "" base directory ( ""  +  base dir . get absolute path (  )   +  "" )  does not exist ! "" )  ;   }  else  {  if  (  ! tiles . contains all ( expected tiles )  )   {  final  list <  integer >  missing = new  array list <  >  ( expected tiles )  ;  missing . remove all ( tiles )  ;  failures . add ( "" missing tile ""  +  missing  +  "" for file type "" +  extension +  "" . "" )  ;   }   }  return failures ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileOrPerRunFileUtil.java, per tile or per run file util,"public   (  string extension  file base  file faker faker int lane )  {  super ( extension base faker lane )  ;   pattern run file match pattern =  pattern . compile ( ""^s""  +  extension  +  ""$"" )  ;  run file = get run file ( base . get parent file (  )  run file match pattern )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileOrPerRunFileUtil.java,check tile count,@ override public boolean   (  )  {  return run file  =  =  null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileOrPerRunFileUtil.java,files available,@ override public boolean   (  )  {  return super . files available (  )  || run file  !  =  null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileOrPerRunFileUtil.java,set tiles for per run file,@ override public void   (  list <  integer >  tiles )  {  if  ( run file  !  =  null )   {  tiles . for each ( i  -  >  file map . put ( i run file )  )  ;  this . tiles = tiles ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileOrPerRunFileUtil.java,verify,@ override public  list <  string >    ( final  list <  integer >  expected tiles final int[] expected cycles )  {  final  file base dir = run file  !  =  null  ?  run file . get parent file (  )  : this . base ;  return verify per tile ( base dir expecte
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\Range.java, range,"public   ( final int start final int end )  {  if  ( end  <  start )   {  throw new  picard exception ( "" nonsensical  range ( ""  +  start  +  ""  "" +  end +  "" ) "" )  ;   }  this . start = start ;  this . end = end ;  this . length = end  -  start  +  1 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\Range.java,equals,@ override public boolean   ( final  object object )  {  if  ( object  =  =  null ||  !  ( object instanceof  range )  )   {  return false ;   }  final  range that =  (  range ) object ;  return that . start  =  =  this . start && that . end  =  =  this .
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\Range.java,hash code,@ override public int   (  )  {  return  ( int )  math . pow ( start end )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\Range.java,to string,"@ override public  string   (  )  {  return "" range ( ""  +  start  +  ""  "" +  end +  ""  "" +  length +  "" ) "" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileParser.java, per tile parser,"public   ( final  illumina file map tiles to files final int next tile )  {  this . tile to files = tiles to files ;  this . current tile = null ;  this . next tile = next tile ;  if  (  ! tiles to files . contains key ( next tile )  )   {  throw new  illegal argument exception ( "" next tile  ( ""  +  next tile  +  "" )  is not contained by tiles to files  ( "" +   string util . join ( "" "" new  array list <  integer >  ( tiles to files . key set (  )  )  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileParser.java,advance tile,"private void   (  )  {  if  ( next tile  =  =  null )   {  throw new  no such element exception ( "" no more tiles to advance ! "" )  ;   }  if  ( current iterator  !  =  null )   {  current iterator . close (  )  ;   }  current iterator = make tile iterator ( tile to files . get ( next tile )  )  ;  current tile = next tile ;  next tile = tile to files . higher key ( next tile )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileParser.java,close,public void   (  )  {  if  ( current iterator  !  =  null )   {  current iterator . close (  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileParser.java,get tile of next cluster,public int   (  )  {  maybe advance (  )  ;  return current tile ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTileParser.java,has next,public boolean   (  )  {  while  (  ( current iterator  =  =  null ||  ! current iterator . has next (  )  )  && next tile  !  =  null )   {  advance tile (  )  ;   }  return current iterator  !  =  null && current iterator . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PosParser.java, pos parser,public   ( final  illumina file map tiles to files final int starting tile final  illumina file util .  supported illumina format file type )  {  super ( tiles to files starting tile )  ;  this . file type = file type ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PosParser.java,close,public void   (  )  {  reader . close (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PosParser.java,get lane,public int   (  )  {  return next value . lane ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PosParser.java,get tile,public int   (  )  {  return next value . tile ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PosParser.java,getx coordinate,public int   (  )  {  return next value . x qseq coord ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PosParser.java,gety coordinate,public int   (  )  {  return next value . y qseq coord ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PosParser.java,has next,public boolean   (  )  {  return reader . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PosParser.java,make tile iterator,@ override protected  closeable iterator <  positional data >    ( final  file file )  {  final  abstract illumina position file reader file reader ;  switch  ( file type )   {  case  pos: file reader = new  pos file reader ( file )  ;  break ;  case  loc
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PosParser.java,next,public  positional data   (  )  {  final  abstract illumina position file reader .  position info next value = reader . next (  )  ;  return new  positional data (  )  {  public int getx coordinate (  )  {  return next value . x qseq coord ;   }  public int gety coordinate (  )  {  return next value . y qseq coord ;   }  public int get lane (  )  {  return next value . lane ;   }  public int get tile (  )  {  return next value . tile ;   }   }   ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PosParser.java,remove,public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PosParser.java,supported types,@ override public  set <  illumina data type >    (  )  {  return supported types ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadData.java, read data,public   (  read type read type )  {  this . read type = read type ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadData.java,get bases,public byte[]   (  )  {  return bases ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadData.java,get noise,public  four channel intensity data   (  )  {  return noise ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadData.java,get qualities,public byte[]   (  )  {  return qualities ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadData.java,get raw intensities,public  four channel intensity data   (  )  {  return raw intensities ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadData.java,get read type,public  read type   (  )  {  return read type ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadData.java,set bases,public void   ( final byte[] bases )  {  this . bases = bases ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadData.java,set noise,public void   ( final  four channel intensity data noise )  {  this . noise = noise ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadData.java,set qualities,public void   ( final byte[] qualities )  {  this . qualities = qualities ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadData.java,set raw intensities,public void   ( final  four channel intensity data raw intensities )  {  this . raw intensities = raw intensities ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadData.java,set read type,public void   ( final  read type read type )  {  this . read type = read type ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTilePerCycleFileUtil.java, per tile per cycle file util,public   ( final  string extension final  file base final  file faker faker final int lane )  {  super ( true extension base faker lane )  ;  this . cycle file map = get per tile per cycle files (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTilePerCycleFileUtil.java,fake files,@ override public  list <  string >    ( final  list <  integer >  expected tiles final int[] expected cycles final  illumina file util .  supported illumina format format )  {  final  list <  string >  failures = new  linked list <  string >  (  )  ;  if
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTilePerCycleFileUtil.java,files available,public boolean   (  )  {  boolean files available = false ;  for  (  final  illumina file map file map : cycle file map . values (  )  )   {  if  (  ! file map . is empty (  )  )   {  files available = true ;  break ;   }   }  return files available ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTilePerCycleFileUtil.java,get cycle from dir,"public static int   ( final  file temp cycle dir )  {  final  string file name = temp cycle dir . get name (  )  ;  final  matcher matcher =  illumina file util . cycle   subdirectory   pattern . matcher ( file name )  ;  if  (  ! matcher . matches (  )  )   {  throw new  picard exception ( "" invalid cycle directory name ""  +  temp cycle dir . get name (  )  )  ;   }  return  integer . parse int ( matcher . group ( 1 )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTilePerCycleFileUtil.java,get detected cycles,public  set <  integer >    (  )  {  return detected cycles ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTilePerCycleFileUtil.java,get file for cycle,"private  string   ( final int current cycle final int tile )  {  return ""c""  +  current cycle  +  "" . 1"" +   file . separator +  ""s   "" +  lane +  ""   "" +  tile +  extension ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTilePerCycleFileUtil.java,get files,public  cycle illumina file map   ( final  list <  integer >  tiles final int[] cycles )  {  final  set <  integer >  filtered cycles = remove non existent cycles ( cycles )  ;  return cycle file map . keep ( tiles filtered cycles )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTilePerCycleFileUtil.java,get per tile per cycle files,protected  cycle illumina file map   (  )  {  final  cycle illumina file map cycled map = new  cycle illumina file map (  )  ;  final  file lane dir = base ;  final  file[] temp cycle dirs ;  temp cycle dirs = io util . get files matching regexp ( lane dir  illumina file util . cycle   subdirectory   pattern )  ;  if  ( temp cycle dirs  =  =  null || temp cycle dirs . length  =  =  0 )   {  return cycled map ;   }  for  (  final  file temp cycle dir : temp cycle dirs )   {  detected cycles . add ( get cycle from dir ( temp cycle dir )  )  ;   }  final  set <  integer >  unique tiles = new  hash set <  integer >  (  )  ;  for  (  final  file cycle dir : temp cycle dirs )   {  final  illumina file map file map = get tiled files ( cycle dir match pattern )  ;  unique tiles . add all ( file map . key set (  )  )  ;  cycled map . put ( get cycle from dir ( cycle dir )  file map )  ;   }  this . tiles = new  array list <  >  ( unique tiles )  ;  return cycled map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTilePerCycleFileUtil.java,get tiles,public  list <  integer >    (  )  {  return tiles ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTilePerCycleFileUtil.java,remove non existent cycles,private  set <  integer >    ( final int[] cycles )  {  final  tree set <  integer >  input cycles set = new  tree set <  integer >  (  )  ;  for  (  final  integer input cycle : cycles )   {  input cycles set . add ( input cycle )  ;   }  input cycles set . retain all ( detected cycles )  ;  return input cycles set ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\PerTilePerCycleFileUtil.java,verify,@ override public  list <  string >    ( final  list <  integer >  expected tiles final int[] expected cycles )  {  final  list <  string >  failures = new  linked list <  string >  (  )  ;  final  map <  integer  long >  tile to file length map = new  ha
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadDescriptor.java, read descriptor,public   ( final int length final  read type type )  {  this . length = length ;  this . type = type ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadDescriptor.java,equals,public boolean   ( final  object other )  {  if  ( this  =  =  other )  return true ;  if  ( other . get class (  )   !  =  this . get class (  )  )  return false ;  final  read descriptor that =  (  read descriptor ) other ;  return this . length  =  =  that . length && this . type  =  =  that . type ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadDescriptor.java,hash code,@ override public int   (  )  {  return 31 * this . type . ordinal (  )   +  379 * length ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadDescriptor.java,to string,@ override public  string   (  )  {  return this . length  +  this . type . name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BarcodeFileReader.java, barcode file reader,public   ( final  file barcode file )  {  this . text iterator = new  basic input parser ( false barcode file )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BarcodeFileReader.java,close,public void   (  )  {  text iterator . close (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BarcodeFileReader.java,has next,@ override public boolean   (  )  {  return text iterator . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BarcodeFileReader.java,next,"@ override public  string   (  )  {  final  string[] fields = text iterator . next (  )  ;  final  string barcode ;  if  ( fields[y   or   n   column] . equals ( ""y"" )  )   {  barcode = fields[barcode   column] ;   }  else  {  barcode = null ;   }  return"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BarcodeFileReader.java,remove,"public void   (  )  {  throw new  unsupported operation exception ( "" remove is not supported by ""  +   barcode file reader . class . get name (  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\AbstractIlluminaPositionFileReader.java, abstract illumina position file reader,public   ( final  file file final int lane final int tile )  {  this . file = file ;  this . lane = lane ;  this . tile = tile ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\AbstractIlluminaPositionFileReader.java, position info,"public   ( final float x final float y final int lane final int tile )  {  if  ( x  <  min   pos || y  <  min   pos || x  >  max   pos || y  >  max   pos )   {  throw new  illegal argument exception (  string . format ( "" cluster location not in the range %f .  . %f .  x: %f ;  y: %f ;  lane: %d ;  tile: %d"" min   pos max   pos x y lane tile )  )  ;   }  this . x pos = x ;  this . y pos = y ;  this . x qseq coord = pos toq seq coord ( x )  ;  this . y qseq coord = pos toq seq coord ( y )  ;  this . lane = lane ;  this . tile = tile ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\AbstractIlluminaPositionFileReader.java,equals,public boolean   ( final  object other )  {  if  ( other  =  =  null || other . get class (  )   !  =   abstract illumina position file reader .  position info . class )   {  return false ;   }  if  ( other  =  =  this )  return true ;  final  position info other pi =  (  position info ) other ;  return this . x pos  =  =  other pi . x pos && this . y pos  =  =  other pi . y pos && this . lane  =  =  other pi . lane && this . tile  =  =  other pi . tile && this . x qseq coord  =  =  other pi . x qseq coord && this . y qseq coord  =  =  other pi . y qseq coord ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\AbstractIlluminaPositionFileReader.java,file name to lane and tile,"private int[]   ( final  string file name )  {  final  string[] tokens = file name . split (  file . path separator )  ;  final  matcher matcher =  file name pattern . matcher ( tokens[tokens . length  -  1] )  ;  if  (  ! matcher . matches (  )  )   {  throw new  picard exception ( "" file name not of the right structure:  < file path >  / s    < lane >     < tile >  (    pos . txt|   pos . txt . gz|   pos . txt . bz2 . locs| . clocs )  .   file name  ( ""  +  file name  +  "" ) "" )  ;   }  return new int[] {  integer . parse int ( matcher . group ( 1 )  )   integer . parse int ( matcher . group ( 2 )  )  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\AbstractIlluminaPositionFileReader.java,get file,public  file   (  )  {  return file ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\AbstractIlluminaPositionFileReader.java,get lane,public int   (  )  {  return lane ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\AbstractIlluminaPositionFileReader.java,get tile,public int   (  )  {  return tile ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BaseBclReader.java, base bcl reader,  ( int[] output lengths )  {  this . output lengths = output lengths ;  int cycles = 0 ;  for  (  final int output length : output lengths )   {  cycles +  = output length ;   }  this . cycles = cycles ;  this . streams = new  input stream[cycles] ;  this . stream files = new  file[cycles] ;  this . num clusters per cycle = new int[cycles] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BaseBclReader.java, cycle data,  ( final short version final int header size final byte bits per basecall final byte bits per quality score final int number of bins final byte[] quality bins final int num tiles final  tile data tile info final boolean pf excluded )  {  this . version = version ;  this . header size = header size ;  this . bits per basecall = bits per basecall ;  this . bits per quality score = bits per quality score ;  this . number of bins = number of bins ;  this . quality bins = quality bins ;  this . num tiles = num tiles ;  this . tile info = tile info ;  this . pf excluded = pf excluded ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BaseBclReader.java, tile data,  ( final int tile num final int num clusters in tile final int uncompressed block size final int compressed block size long file position )  {  this . tile num = tile num ;  this . num clusters in tile = num clusters in tile ;  this . uncompressed block size = uncompressed block size ;  this . compressed block size = compressed block size ;  this . file position = file position ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BaseBclReader.java,decode basecall,void   ( final  bcl data bcl data final int read final int cycle final int byte to decode )  {  if  ( byte to decode  =  =  0 )   {  bcl data . bases[read][cycle] =  ( byte ) ' . ' ;  bcl data . qualities[read][cycle] =  ( byte ) 2 ;   }  else  {  bcl data . bases[read][cycle] = base   lookup[byte to decode & base   mask] ;  bcl data . qualities[read][cycle] = bcl quality evaluation strategy . revise and conditionally log quality (  ( byte )  ( byte to decode  >  >  >  2 )  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BaseBclReader.java,decode quality binned basecall,void   ( final  bcl data bcl data final int read final int cycle final int byte to decode final  cycle data cycle data )  {  if  ( byte to decode  =  =  0 )   {  bcl data . bases[read][cycle] =  ( byte ) ' . ' ;  bcl data . qualities[read][cycle] = 2 ;   }  else  {  bcl data . bases[read][cycle] = base   lookup[byte to decode & base   mask] ;  bcl data . qualities[read][cycle] = cycle data . quality bins[byte to decode  >  >  >  2] ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BaseBclReader.java,get compressed block size,public int   (  )  {  return compressed block size ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BaseBclReader.java,get num clusters,int   (  )  {  return num clusters per cycle[0] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BaseBclReader.java,get num clusters in tile,int   (  )  {  return num clusters in tile ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BaseBclReader.java,get tile info,public  tile data   (  )  {  return tile info ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BaseBclReader.java,get tile num,public int   (  )  {  return tile num ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BaseBclReader.java,open," input stream   ( final  file file final boolean seekable final boolean is gzip final boolean is bgzf )  {  final  string file path = file . get absolute path (  )  ;  try  {  if  ( is bgzf )   {  return new  block compressed input stream ( io util . maybe buffered seekable stream ( file )  )  ;   }  else if  ( is gzip )   {  if  ( seekable )   {  throw new  illegal argument exception (  string . format ( "" cannot create a seekable reader for gzip bcl: %s . "" file path )  )  ;   }  return  ( io util . maybe buffer input stream ( new gzip input stream ( new  file input stream ( file )   defaults . buffer   size  /  2 )   defaults . buffer   size  /  2 )  )  ;   }  else  {  if  ( seekable )   {  throw new  illegal argument exception (  string . format ( "" cannot create a seekable reader for provided bcl: %s . "" file path )  )  ;   }  return io util . maybe buffer input stream ( new  file input stream ( file )  )  ;   }   }  catch  (  final  file not found exception fnfe )   {  throw new  picard exception ( "" file not found:  ( ""  +  file path  +  "" ) "" fnfe )  ;   }  catch  (  final io exception ioe )   {  throw new  picard exception ( "" error reading file:  ( ""  +  file path  +  "" ) "" ioe )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclIndexReader.java, bcl index reader,"public   ( final  file bcl file )  {  bci file = new  file ( bcl file . get absolute path (  )   +  "" . bci"" )  ;  bci iterator = m map backed iterator factory . get long iterator ( bci   header   size bci file )  ;  final  byte buffer header bytes = bci iterator . get header bytes (  )  ;  final int actual version = header bytes . get int (  )  ;  if  ( actual version  !  =  bci   version )   {  throw new  picard exception (  string . format ( "" unexpected version number %d in %s"" actual version bci file . get absolute path (  )  )  )  ;   }  num tiles = header bytes . get int (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclIndexReader.java,get,"public long   ( final int record number )  {  if  ( record number  <  next record number )   {  throw new  illegal argument exception ( "" can only read forward"" )  ;   }  if  ( record number  >  next record number )   {  bci iterator . skip elements ( record number  -  next record number )  ;  next record number = record number ;   }   +  + next record number ;  return bci iterator . get element (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclIndexReader.java,get bci file,public  file   (  )  {  return bci file ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclIndexReader.java,get num tiles,public int   (  )  {  return num tiles ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclQualityEvaluationStrategy.java, bcl quality evaluation strategy,public   ( final int minimum revised quality )  {  this . minimum revised quality = minimum revised quality ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclQualityEvaluationStrategy.java,assert minimum qualities,"public void   (  )  {  final  collection <  string >  error tokens = new  linked list <  string >  (  )  ;  for  (  final  map .  entry <  byte  atomic integer >  entry : this . quality count map . entry set (  )  )   {  if  ( generate revised quality ( entry . get key (  )  )   <  minimum revised quality )   {  error tokens . add (  string . format ( ""quality %s observed %s times"" entry . get key (  )  entry . get value (  )  )  )  ;   }   }  if  (  ! error tokens . is empty (  )  )   {  throw new  picard exception (  string . format ( "" found bcl qualities that fell beneath minimum threshold of %s: %s . "" minimum revised quality  collection util . join ( error tokens "" ;  "" )  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclQualityEvaluationStrategy.java,generate revised quality,private static byte   ( final byte quality )  {  return  ( byte )  math . max ( quality 1 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclQualityEvaluationStrategy.java,get poor quality frequencies,public  map <  byte  integer >    (  )  {  final  map <  byte  integer >  quality count map copy = new  hash map <  byte  integer >  (  )  ;  for  (  final  map .  entry <  byte  atomic integer >  entry : quality count map . entry set (  )  )   {  quality count map copy . put ( entry . get key (  )  entry . get value (  )  . int value (  )  )  ;   }  return  collections . unmodifiable map ( quality count map copy )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclQualityEvaluationStrategy.java,make,@ override public  atomic integer   ( final  byte key )  {  return new  atomic integer ( 0 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclQualityEvaluationStrategy.java,revise and conditionally log quality,public byte   ( final byte quality )  {  final byte revised quality = generate revised quality ( quality )  ;  if  ( quality  <  illumina   alleged   minimum   quality )   {  quality count map . get ( quality )  . increment and get (  )  ;   }  return revised quality ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclReader.java, bcl reader,"public   ( final  file bcl file final  bcl quality evaluation strategy bcl quality evaluation strategy final boolean seekable )  {  super ( new int[] { 1 }  bcl quality evaluation strategy )  ;  try  {  final  byte buffer byte buffer =  byte buffer . allocate ( header   size )  ;  final  string file path = bcl file . get name (  )  ;  final boolean is gzip = file path . ends with ( "" . gz"" )  ;  final boolean is bgzf = file path . ends with ( "" . bgzf"" )  ;  final  input stream stream = open ( bcl file seekable is gzip is bgzf )  ;  final int read = stream . read ( byte buffer . array (  )  )  ;  if  ( read  !  =  header   size )   {  throw new  runtimeio exception (  string . format ( ""bcl %s has invalid header structure . "" bcl file . get absolute file (  )  )  )  ;   }  byte buffer . order (  byte order . little   endian )  ;  this . num clusters per cycle[0] = byte buffer . get int (  )  ;  if  (  ! is bgzf &&  ! is gzip )   {  assert proper file structure ( bcl file this . get num clusters (  )  stream )  ;   }  this . streams[0] = stream ;  this . stream files[0] = bcl file ;   }  catch  (  final io exception ioe )   {  throw new  picard exception ( ""io exception opening file ""  +  bcl file . get absolute file (  )  ioe )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclReader.java,advance,"void   (  )  {  int total cycle count = 0 ;  final  bcl data data = new  bcl data ( output lengths )  ;  for  ( int read = 0 ;  read  <  output lengths . length ;  read +  +  )   {  for  ( int cycle = 0 ;  cycle  <  output lengths[read] ;   +  + cycle )   {  try  {  final int read byte ;  try  {  read byte = this . streams[total cycle count] . read (  )  ;   }  catch  (  io exception e )   {  throw new io exception (  string . format ( "" error while reading from bcl file for cycle %d .   offending file on disk is %s""  ( total cycle count  +  1 )  this . stream files[total cycle count] . get absolute path (  )  )  e )  ;   }  if  ( read byte  =  =   - 1 )   {  queue = null ;  return ;   }  decode basecall ( data read cycle read byte )  ;  total cycle count +  +  ;   }  catch  (  final io exception ioe )   {  throw new  runtimeio exception ( ioe )  ;   }   }   }  this . queue = data ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclReader.java,assert proper file structure,"protected void   ( final  file file )  {  final long elements in file = file . length (  )   -  header   size ;  if  ( get num clusters (  )   !  =  elements in file )   {  throw new  picard exception ( "" expected ""  +  get num clusters (  )   +  "" in file "" +  file . get absolute path (  )  +  "" but found "" +  elements in file )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclReader.java,close,public void   (  )  {  for  (  final  input stream stream : this . streams )   {   closer util . close ( stream )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclReader.java,get number of clusters,"private static long   ( final  string file path final  input stream input stream )  {  final byte[] header = new byte[header   size] ;  try  {  final int header bytes read = input stream . read ( header )  ;  if  ( header bytes read  !  =  header   size )   {  throw new  picard exception ( "" malformed file  expected header of size ""  +  header   size  +  "" but received "" +  header bytes read )  ;   }   }  catch  (  final io exception ioe )   {  throw new  picard exception ( "" unable to read header for file  ( ""  +  file path  +  "" ) "" ioe )  ;   }  final  byte buffer header buf =  byte buffer . wrap ( header )  ;  header buf . order (  byte order . little   endian )  ;  return  unsigned type util . u int to long ( header buf . get int (  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclReader.java,has next,@ override public boolean   (  )  {  if  ( queue  =  =  null )   {  advance (  )  ;   }  return queue  !  =  null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclReader.java,is block gzipped,"public static boolean   ( final  file file )  {  return file . get absolute path (  )  . ends with ( "" . bgzf"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclReader.java,is gzipped,"public static boolean   ( final  file file )  {  return file . get absolute path (  )  . ends with ( "" . gz"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclReader.java,make seekable,public static  bcl reader   ( final  list <  file >  files final  bcl quality evaluation strategy bcl quality evaluation strategy final int[] output lengths )  {  return new  bcl reader ( files output lengths bcl quality evaluation strategy true )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclReader.java,next,public  bcl data   (  )  {  if  ( queue  =  =  null )   {  advance (  )  ;   }  final  bcl data data = queue ;  queue = null ;  return data ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclReader.java,remove,@ override public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\BclReader.java,seek,"public int   ( final  list <  file >  files final  tile index tile index final int current tile )  {  int count = 0 ;  int num clusters in tile = 0 ;  for  (  final  input stream input stream : streams )   {  final  tile index .  tile index record tile index record = tile index . find tile ( current tile )  ;  final  bcl index reader bcl index reader = new  bcl index reader ( files . get ( count )  )  ;  final long virtual file pointer = bcl index reader . get ( tile index record . get zero based tile number (  )  )  ;  if  (  !  ( input stream instanceof  block compressed input stream )  )   {  throw new  unsupported operation exception ( "" seeking only allowed on bzgf"" )  ;   }  else  {  try  {  if  ( tile index . get num tiles (  )   !  =  bcl index reader . get num tiles (  )  )   {  throw new  picard exception (  string . format ( ""%s . get num tiles ( %d )   !  =  %s . get num tiles ( %d ) "" tile index . get file (  )  . get absolute path (  )  tile index . get num tiles (  )  bcl index reader . get bci file (  )  . get absolute path (  )  bcl index reader . get num tiles (  )  )  )  ;   }   (  (  block compressed input stream ) input stream )  . seek ( virtual file pointer )  ;  num clusters in tile = tile index record . get num clusters in tile (  )  ;   }  catch  (  final io exception e )   {  throw new  picard exception ( "" problem seeking to ""  +  virtual file pointer e )  ;   }   }  count +  +  ;   }  return num clusters in tile ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\ClocsFileReader.java, clocs file reader,public   ( final  file clocs file )  {  super ( clocs file )  ;  byte iterator = m map backed iterator factory . get byte iterator ( header   size clocs file )  ;  final  byte buffer hbs = byte iterator . get header bytes (  )  ;  hbs . get (  )  ;  num bins =  unsigned type util . u int to long ( hbs . get int (  )  )  ;  x offset = 0 ;  y offset = 0 ;  current bin = 0 ;  start block (  )  ;  check and advance bin (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\ClocsFileReader.java,check and advance bin,private void   (  )  {  while  ( current cluster in bin  >  =  num clusters in bin && current bin  <  num bins )   {  if  (  ( current bin  +  1 )  % num   bins   in   row  =  =  0 )   {  x offset = 0 ;  y offset +  = block   size ;   }  else  {  x offset +  = block   size ;   }  current bin +  = 1 ;  if  ( current bin  <  num bins )   {  start block (  )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\ClocsFileReader.java,has next,"@ override public boolean   (  )  {  boolean values remain = current cluster in bin  <  num clusters in bin || current bin  <   ( num bins  -  1 )  ;  if  (  ! values remain && byte iterator . has next (  )  )   {  throw new  picard exception ( "" read the"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\ClocsFileReader.java,make exception msg,"@ override protected  string   (  )  {  return "" clocs file reader ( file = ""  +  get file (  )  . get name (  )   +  ""  lane = "" +  get lane (  )  +  ""  tile = "" +  get tile (  )  +  ""  current bin = "" +  current bin +  ""  num bins = "" +  num bins +  ""  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\ClocsFileReader.java,start block,private void   (  )  {  num clusters in bin =  unsigned type util . u byte to int ( byte iterator . next (  )  )  ;  current cluster in bin = 0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\ClocsFileReader.java,unsafe next info,@ override protected  position info   (  )  {  final byte x byte = byte iterator . next (  )  ;  final byte y byte = byte iterator . next (  )  ;  final float x pos =  unsigned type util . u byte to int ( x byte )   /  10f  +  x offset ;  final float y po
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\EmpiricalPhasingMetricsOutReader.java, empirical phasing metrics out reader,public   (  file phasing metrics out file )  {  bb iterator = m map backed iterator factory . get byte buffer iterator ( header   size record   size phasing metrics out file )  ;  bb iterator . get header bytes (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\EmpiricalPhasingMetricsOutReader.java, illumina phasing metrics,  ( final  byte buffer bb )  {  this . lane tile code = new  tile metrics out reader .  illumina lane tile code (  unsigned type util . u short to int ( bb . get short (  )  )  bb . get int (  )  0 )  ;  this . cycle =  unsigned type util . u short to int ( bb . get short (  )  )  ;  this . phasing weight = bb . get float (  )  ;  this . prephasing weight = bb . get float (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\EmpiricalPhasingMetricsOutReader.java,has next,@ override public boolean   (  )  {  return bb iterator . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\EmpiricalPhasingMetricsOutReader.java,next,@ override public  illumina phasing metrics   (  )  {  if  (  ! has next (  )  )   {  throw new  no such element exception (  )  ;   }  return new  illumina phasing metrics ( bb iterator . next (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\LocsFileReader.java, locs file reader,public   ( final  file file final int lane final int tile )  {  super ( file lane tile )  ;  initialize ( file )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\LocsFileReader.java,close,public void   (  )  {  bb iterator = null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\LocsFileReader.java,has next,@ override public boolean   (  )  {  return next cluster  <  num clusters ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\LocsFileReader.java,initialize,"private void   ( final  file file )  {  bb iterator = m map backed iterator factory . get float iterator ( header   size file )  ;  final  byte buffer header buf = bb iterator . get header bytes (  )  ;  final int first value = header buf . get int (  )  ;  if  ( first value  !  =  bytes   1   to   4 )   {  throw new  picard exception ( "" first header byte of locs files should be ""  +  bytes   1   to   4  +  "" value found ( "" +  first value +  "" ) "" )  ;   }  final float version number = header buf . get float (  )  ;  if  ( version number  !  =  version )   {  throw new  picard exception ( "" first header byte of locs files should be ""  +  version  +  "" value found ( "" +  first value +  "" ) "" )  ;   }  num clusters =  unsigned type util . u int to long ( header buf . get int (  )  )  ;  bb iterator . assert total elements equal ( num clusters * 2 )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\LocsFileReader.java,make exception msg,"@ override protected  string   (  )  {  return "" locs file reader ( file = ""  +  get file (  )  . get absolute path (  )   +  ""  num clusters = "" +  num clusters +  "" )  "" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\LocsFileReader.java,skip records,public void   ( final int num to skip )  {  bb iterator . skip elements ( num to skip * 2 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\LocsFileReader.java,unsafe next info,@ override protected  position info   (  )  {  final float x val = bb iterator . next (  )  ;  final float y val = bb iterator . next (  )  ;   +  + next cluster ;  return new  position info ( x val y val get lane (  )  get tile (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\FilterFileReader.java, filter file reader,"public   ( final  file file )  {  bb iterator = m map backed iterator factory . get byte iterator ( header   size file )  ;  final  byte buffer header buf = bb iterator . get header bytes (  )  ;  for  ( int i = 0 ;  i  <  4 ;  i +  +  )   {  final byte b = header buf . get (  )  ;  if  ( b  !  =  0 )   {  throw new  picard exception ( "" the first four bytes of a  filter  file should be 0 but byte ""  +  i  +  "" was "" +  b +  "" in file "" +  file . get absolute path (  )  )  ;   }   }  version = header buf . get int (  )  ;  if  ( version  !  =  expected   version )   {  throw new  picard exception ( "" expected version is ""  +  expected   version  +  "" but version found was "" +  version +  "" in file "" +  file . get absolute path (  )  )  ;   }  num clusters =  unsigned type util . u int to long ( header buf . get int (  )  )  ;  bb iterator . assert total elements equal ( num clusters )  ;  current cluster = 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\FilterFileReader.java,has next,public boolean   (  )  {  return current cluster  <  num clusters ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\FilterFileReader.java,next,"public  boolean   (  )  {  final byte value = bb iterator . next (  )  ;  current cluster +  = 1 ;  if  ( value  =  =   passed filter )   {  return true ;   }  else if  ( value  =  =   failed filter )   {  return false ;   }  else  {   string hex val =  integer . to hex string ( value )  ;  hex val =  ( hex val . length (  )   <  2  ?  ""0x0"" : ""0x"" )   +  hex val ;  throw new  picard exception ( "" didn't recognized pf  byte  ( ""  +  hex val  +  "" ) "" +  "" for element  ( "" +  current cluster +  "" )  in file ( "" +  bb iterator . get file (  )  . get absolute path (  )  +  "" ) "" )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\FilterFileReader.java,remove,public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\FilterFileReader.java,skip records,public void   ( final int num to skip )  {  bb iterator . skip elements ( num to skip )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\MMapBackedIteratorFactory.java, binary file iterator,public   ( final byte[] header final  file file final int element size )  {  this . header = header ;  this . file = file ;  this . file size = file . length (  )  ;  this . element size = element size ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\MMapBackedIteratorFactory.java, byte bufferm map iterator,public   ( final byte[] header final  file file final int element buffer size final  byte buffer buf )  {  super ( header file element buffer size buf )  ;  this . local backing = new byte[element buffer size] ;  this . local buffer =  byte buffer . wrap ( local backing )  ;  this . local buffer . order (  byte order . little   endian )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\MMapBackedIteratorFactory.java, bytem map iterator,public   ( final byte[] header final  file file final  byte buffer buf )  {  super ( header file byte   size buf )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\MMapBackedIteratorFactory.java, floatm map iterator,public   ( final byte[] header final  file file final  byte buffer buf )  {  super ( header file float   size buf )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\MMapBackedIteratorFactory.java, integerm map iterator,public   ( final byte[] header final  file file final  byte buffer buf )  {  super ( header file int   size buf )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\MMapBackedIteratorFactory.java, longm map iterator,public   ( final byte[] header final  file file final  byte buffer buf )  {  super ( header file long   size buf )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\MMapBackedIteratorFactory.java,m map backed iterator,protected   ( final byte[] header final  file file final int element size final  byte buffer buffer )  {  super ( header file element size )  ;  this . buffer = buffer ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\MMapBackedIteratorFactory.java,assert total elements equal,"public void   ( final long num elements )  {  if  ( get elements in file (  )   !  =  num elements )   {  throw new  picard exception ( "" expected ""  +  num elements  +  "" elements in file but found "" +  get elements in file (  )  +  "" elements !   file ( "" +  file . get absolute path (  )  +  "" ) "" )  ;   }  if  ( get extra bytes (  )   !  =  0 )   {  throw new  picard exception ( "" malformed file  expected ""  +   ( header . length  +  num elements * element size )   +  "" bytes in file  found "" +  file size +  "" bytes for file ( "" +  file . get absolute path (  )  +  "" ) "" )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\MMapBackedIteratorFactory.java,check factory vars,"private static void   ( final int header size final  file binary file )  {  io util . assert file is readable ( binary file )  ;  if  ( header size  <  0 )   {  throw new  picard exception ( "" header size cannot be negative .   header size ( ""  +  header size  +  "" )  for file "" +  binary file . get absolute path (  )  )  ;   }  if  ( header size  >  binary file . length (  )  )   {  throw new  picard exception ( "" header size ( ""  +  header size  +  "" )  is greater than file size ( "" +  binary file . length (  )  +  "" )  for file "" +  binary file . get absolute path (  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\MMapBackedIteratorFactory.java,get buffer,"private static  byte buffer   ( final  file binary file )  {  final  byte buffer buf ;  try  {  final  file input stream is = new  file input stream ( binary file )  ;  final  file channel channel = is . get channel (  )  ;  final long file size = channel . size (  )  ;  buf = channel . map (  file channel .  map mode . read   only 0 file size )  ;  buf . order (  byte order . little   endian )  ;   closer util . close ( channel )  ;   closer util . close ( is )  ;   }  catch  (  io exception e )   {  throw new  picard exception ( ""io exception opening cluster binary file ""  +  binary file e )  ;   }  return buf ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\MMapBackedIteratorFactory.java,get byte buffer iterator,public static  binary file iterator <  byte buffer >    ( final int header size final int element size final  file binary file )  {  check factory vars ( header size binary file )  ;  final  byte buffer buf = get buffer ( binary file )  ;  final byte[] header = get header ( buf header size )  ;  return new  byte bufferm map iterator ( header binary file element size buf )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\MMapBackedIteratorFactory.java,get byte iterator,public static  binary file iterator <  byte >    ( final int header size final  file binary file )  {  check factory vars ( header size binary file )  ;  final  byte buffer buf = get buffer ( binary file )  ;  final byte[] header = get header ( buf header size )  ;  return new  bytem map iterator ( header binary file buf )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\CbclReader.java, cbcl reader,"public   ( final  list <  file >  cbcls final  map <  integer  file >  filter file map final int[] output lengths final int tile num final  list <  abstract illumina position file reader .  position info >  locs final int[] output cycles final boolean header only )  {  super ( output lengths )  ;  if  (  ! filter file map . contains key ( tile num )  )   {  throw new  picard exception ( "" filter file for tile ""  +  tile num  +  "" does not exist . "" )  ;   }  this . output cycles = output cycles ;  surface to tile to cbcl map = sort cbcls ( cbcls )  ;  this . filter file map = filter file map ;  cycle data = new  cycle data[cycles] ;  cached tile = new byte[cycles][] ;  cached tile position = new int[cycles] ;  for  ( int i = 1 ;  i  <  =  cycles ;  i +  +  )   {  all tiles . put ( i new  array list <  >  (  )  )  ;   }  try  {  read surface tile ( tile num locs header only )  ;   }  finally  {  close (  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\CbclReader.java,advance,private void   (  )  {  int total cycle count = 0 ;  final  cbcl data data = new  cbcl data ( output lengths cycle data[total cycle count] . tile info . tile num )  ;  for  ( int read = 0 ;  read  <  output lengths . length ;  read +  +  )   {  for  ( int cycle = 0 ;  cycle  <  output lengths[read] ;  cycle +  +  )   {  final  cycle data current cycle data = cycle data[total cycle count] ;  if  ( cached tile position[total cycle count]  >  =  cached tile[total cycle count] . length || cached tile position[total cycle count]  >  =  cycle data[total cycle count] . get tile info (  )  . get num clusters in tile (  )  )   {  return ;   }  final int single byte = cached tile[total cycle count][cached tile position[total cycle count] +  + ] ;  decode quality binned basecall ( data read cycle single byte current cycle data )  ;  total cycle count +  +  ;   }   }  data . set position info ( position info iterator . next (  )  )  ;  this . queue = data ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\CbclReader.java,cache filter and locs,private void   ( final  tile data current tile data final  list <  abstract illumina position file reader .  position info >  locs )  {  final  list <  boolean >  filter values = new  array list <  >  (  )  ;  final  filter file reader reader = new  filter file reader ( filter file map . get ( current tile data . tile num )  )  ;  final  iterator <  abstract illumina position file reader .  position info >  position info iterator = locs . iterator (  )  ;  while  ( reader . has next (  )  )   {  filter values . add ( reader . next (  )  )  ;   }  final  list <  abstract illumina position file reader .  position info >  positions = new  array list <  >  (  )  ;  for  (  final boolean filter value : filter values )   {  final  abstract illumina position file reader .  position info info = position info iterator . next (  )  ;  if  ( filter value )   {  positions . add ( info )  ;   }   }  this . position info iterator = positions . iterator (  )  ;  cached filter . put ( current tile data . tile num filter values )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\CbclReader.java,cache tile,"private void   ( final int total cycle count final  tile data tile data final  cycle data current cycle data )  throws io exception  {  final byte[] tile byte array = new byte[tile data . compressed block size] ;  final  input stream stream = this . streams[total cycle count] ;  long data left = tile data . file position  -  stream . skip ( tile data . file position )  ;  while  ( data left  >  0 )   {  data left -  = stream . skip ( data left )  ;   }  final int read bytes = stream . read ( tile byte array )  ;  if  ( read bytes  !  =  tile data . compressed block size )   {  throw new  picard exception (  string . format ( "" error while reading from bcl file for cycle %d .   offending file on disk is %s""  ( total cycle count  +  1 )  this . stream files[total cycle count] . get absolute path (  )  )  )  ;   }  final  byte array input stream byte input stream = new  byte array input stream (  arrays . copy of range ( tile byte array 0 read bytes )  )  ;  byte[] decompressed byte array = decompress tile ( total cycle count tile data byte input stream )  ;  byte[] un nibbled byte array = promote nibbles to bytes ( decompressed byte array )  ;  cached tile[total cycle count] = filter non pf reads ( tile data current cycle data un nibbled byte array )  ;  cached tile position[total cycle count] = 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\CbclReader.java,clear,public void   (  )  {  cached tile = null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\CbclReader.java,close,@ override public void   (  )  {  for  (  final  input stream stream : this . streams )   {   closer util . close ( stream )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\CbclReader.java,decompress tile,"private byte[]   ( int total cycle count  tile data tile data  byte array input stream byte input stream )  throws io exception  {  final byte[] decompressed byte array = new byte[tile data . uncompressed block size] ;  if  ( decompressed byte array . length  =  =  0 )   {  log . warn ( "" ignoring tile ""  +  tile data . tile num  +  "" there are no pf reads . "" )  ;   }  else  {  int read ;  int total read = 0 ;  try  ( gzip input stream gzip input stream = new gzip input stream ( byte input stream decompressed byte array . length )  )  {  while  (  ( read = gzip input stream . read ( decompressed byte array total read decompressed byte array . length  -  total read )  )   !  =   - 1 )   {  if  ( read  =  =  0 )   {  break ;   }  total read +  = read ;   }   }  catch  (  final eof exception eof exception )   {  throw new  picard exception ( "" unexpected end of file ""  +  this . stream files[total cycle count] . get absolute path (  )   +  "" this file is likely corrupt or truncated .   we have read "" +  total read +  "" and were expecting to read "" +  decompressed byte array . length )  ;   }  if  ( total read  !  =  tile data . uncompressed block size )   {  throw new  picard exception (  string . format ( "" error while decompressing from bcl file for cycle %d .   offending file on disk is %s""  ( total cycle count  +  1 )  this . stream files[total cycle count] . get absolute path (  )  )  )  ;   }   }  return decompressed byte array ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\CbclReader.java,filter non pf reads,private byte[]   (  tile data tile data  cycle data current cycle data byte[] un nibbled byte array )  {  if  (  ! current cycle data . pf excluded )   {  final  list <  boolean >  filter datas = cached filter . get ( tile data . tile num )  ;  int sum = 0 ;  for  (  final boolean b : filter datas )   {  sum +  = b  ?  1 : 0 ;   }  final byte[] filtered byte array = new byte[sum] ;  int filter index = 0 ;  int basecall index = 0 ;  for  (  final boolean filter data : filter datas )   {  final byte read byte = un nibbled byte array[filter index] ;  if  ( filter data )   {  filtered byte array[basecall index] = read byte ;  basecall index +  +  ;   }  filter index +  +  ;   }  return filtered byte array ;   }  else  {  return un nibbled byte array ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\CbclReader.java,get all tiles,public  map <  integer  list <  tile data >  >    (  )  {  return all tiles ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\CbclReader.java,get cycle data,public  cycle data[]   (  )  {  return cycle data ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\CbclReader.java,get files for cycle,public  list <  file >    ( final int i )  {  final  list <  file >  cbcl files = new  array list <  >  (  )  ;  surface to tile to cbcl map . values (  )  . for each ( map  -  >   {  if  ( map . contains key ( i )  )   {  cbcl files . add ( map . get ( i )  )  ;   }   }   )  ;  return cbcl files ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\CbclReader.java,get header size,public int   (  )  {  return header size ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\CbclReader.java,has next,@ override public boolean   (  )  {  if  ( queue  =  =  null )   {  advance (  )  ;   }  return queue  !  =  null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\CbclReader.java,next,public  cbcl data   (  )  {  if  ( queue  =  =  null )   {  advance (  )  ;   }  final  cbcl data data = queue ;  queue = null ;  return data ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\CbclReader.java,promote nibbles to bytes,private byte[]   ( byte[] decompressed byte array )  {  final byte[] un nibbled byte array = new byte[decompressed byte array . length * 2] ;  int index = 0 ;  for  (  final byte single byte : decompressed byte array )   {  un nibbled byte array[index] =  ( byte )  ( single byte & 0x0f )  ;  index +  +  ;  un nibbled byte array[index] =  ( byte )  (  ( single byte  >  >  4 )  & 0x0f )  ;  index +  +  ;   }  return un nibbled byte array ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\CbclReader.java,read surface tile,"private void   ( final int tile num final  list <  abstract illumina position file reader .  position info >  locs final boolean header only )  {  log . info ( "" processing tile ""  +  tile num )  ;  try  {  for  (  final  map .  entry <  integer  map <  integer  file >  >  entry : surface to tile to cbcl map . entry set (  )  )   {  final  map <  integer  file >  cycle map = entry . get value (  )  ;  for  ( int i = 0 ;  i  <  cycles ;  i +  +  )   {  final  byte buffer byte buffer =  byte buffer . allocate ( initial   header   size )  ;  byte buffer . order (  byte order . little   endian )  ;  final  file bcl file = cycle map . get ( output cycles[i] )  ;  if  ( bcl file  =  =  null )   {  throw new  picard exception ( "" expected cbcl file for surface ""  +  entry . get key (  )   +  "" cycle "" +   ( i  +  1 )  +  "" but it was not found . "" )  ;   }  final  input stream stream = open ( bcl file false false false )  ;  int read = stream . read ( byte buffer . array (  )  )  ;  if  ( read  !  =  initial   header   size )   {  throw new  runtimeio exception (  string . format ( ""bcl %s has invalid header structure . "" bcl file . get absolute file (  )  )  )  ;   }  final short version = byte buffer . get short (  )  ;  header size = byte buffer . get int (  )  ;  final  byte buffer header buffer =  byte buffer . allocate ( header size  -  initial   header   size )  ;  header buffer . order (  byte order . little   endian )  ;  read = stream . read ( header buffer . array (  )  )  ;  if  ( read  !  =  header size  -  initial   header   size )   {  throw new  picard exception (  string . format ( ""bcl %s has invalid header structure . "" bcl file . get absolute file (  )  )  )  ;   }  final byte bits per basecall = header buffer . get (  )  ;  final byte bits per quality score = header buffer . get (  )  ;  if  ( bits per basecall  !  =  2 && bits per basecall  !  =  bits per quality score )   {  throw new  picard exception ( ""cbcl data not encoded in nibbles .   ( not currently supported )  bits per basecall : ""  +  bits per basecall  +  "" bits per quality score : "" +  bits per quality score )  ;   }  final int number of bins = header buffer . get int (  )  ;  final byte[] quality bins = new byte[number of bins] ;  for  ( int j = 0 ;  j  <  number of bins ;  j +  +  )   {  header buffer . get int (  )  ;  final int to = header buffer . get int (  )  ;  quality bins[j] =  ( byte ) to ;   }  long file pos = 0 ;  final int num tiles = header buffer . get int (  )  ;   tile data tile info = null ;  for  ( int j = 0 ;  j  <  num tiles ;  j +  +  )   {  final int tile = header buffer . get int (  )  ;  final int num clusters in tile = header buffer . get int (  )  ;  final int uncompressed block size = header buffer . get int (  )  ;  final int compressed block size = header buffer . get int (  )  ;  final  tile data tile data = new  tile data ( tile num clusters in tile uncompressed block size compressed block size file pos )  ;  all tiles . get ( i  +  1 )  . add ( tile data )  ;  if  ( tile  =  =  tile num )   {  tile info = tile data ;   }  file pos +  = compressed block size ;   }  final boolean pf excluded = header buffer . get (  )   =  =  1 ;  if  ( tile info  =  =  null )   {  continue ;   }  cycle data[i] = new  cycle data ( version header size bits per basecall bits per quality score number of bins quality bins num tiles tile info pf excluded )  ;  this . streams[i] = stream ;  this . stream files[i] = bcl file ;  byte buffer . clear (  )  ;  header buffer . clear (  )  ;   }   }  if  ( header only )   {  return ;   }  int total cycle count = 0 ;  if  ( cycle data[total cycle count] . tile info  =  =  null )   {  throw new  picard exception ( "" could not find tile ""  +  tile num )  ;   }  for  (  final int output length : output lengths )   {  for  ( int cycle = 0 ;  cycle  <  output length ;  cycle +  +  )   {  final  cycle data current cycle data = cycle data[total cycle count] ;  try  {  if  ( cached tile[total cycle count]  =  =  null )   {  if  (  ! cached filter . contains key ( cycle data[total cycle count] . tile info . tile num )  )   {  cache filter and locs ( cycle data[total cycle count] . tile info locs )  ;   }  cache tile ( total cycle count cycle data[total cycle count] . tile info current cycle data )  ;   }   }  catch  (  final io exception e )   {  throw new  picard exception (  string . format ( "" error while reading from bcl file for cycle %d .   offending file on disk is %s""  ( total cycle count  +  1 )  this . stream files[total cycle count] . get absolute path (  )  )  e )  ;   }  total cycle count +  +  ;   }   }   }  catch  (  final io exception ioe )   {  throw new  runtimeio exception ( ioe )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\CbclReader.java,sort cbcls,"private  map <  integer  map <  integer  file >  >    ( final  list <  file >  cbcls )  {  final  map <  integer  map <  integer  file >  >  sorted map = new  tree map <  >  (  )  ;  for  (  final  file cbcl : cbcls )   {  final  matcher matcher = pattern . matcher ( cbcl . get absolute path (  )  )  ;  if  (  ! matcher . matches (  )  )   {  throw new  picard exception ( ""cbcl  file ""  +  cbcl . get absolute path (  )   +  "" does not match expected pattern . "" )  ;   }  final  integer surface =  integer . value of ( matcher . group ( 3 )  )  ;  final  integer cycle =  integer . value of ( matcher . group ( 1 )  )  ;  if  ( sorted map . contains key ( surface )  )   {  sorted map . get ( surface )  . put ( cycle cbcl )  ;   }  else  {  final  map <  integer  file >  cycle map = new  hash map <  >  (  )  ;  cycle map . put ( cycle cbcl )  ;  sorted map . put ( surface cycle map )  ;   }   }  return sorted map ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\PosFileReader.java, pos file reader,public   ( final  file pos file )  {  super ( pos file )  ;  this . parser = new  basic input parser ( true pos file )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\PosFileReader.java,close,public void   (  )  {   closer util . close ( parser )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\PosFileReader.java,has next,public boolean   (  )  {  return parser . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\PosFileReader.java,make exception msg,"@ override protected  string   (  )  {  return ""pos file (  ""  +  parser . get file name (  )   +  ""  )  on line number (  "" +  parser . get current line number (  )  +  ""  )  with current line  =  "" +  parser . get current line (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\PosFileReader.java,unsafe next info,"@ override protected  position info   (  )  {  final  string[] str vals = this . parser . next (  )  ;  if  ( str vals . length  !  =  2 )   {  throw new  picard exception ( "" pos file number of values  !  =  2  found  ( ""  +  str vals . length  +  "" ) "" "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java, indexed iterator,public   ( final int[] indices )  {  this . indices = indices ;  this . index = 0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\TileMetricsOutReader.java, illumina lane tile code,public   ( final int lane number final int tile number final int metric code )  {  this . lane number = lane number ;  this . tile number = tile number ;  this . metric code = metric code ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java, read structure,public   ( final  string read structure string )  {  this ( read structure string to descriptors ( read structure string )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\TileMetricsOutReader.java, illumina tile metrics,public   ( final int lane number final int tile number final int metric code final float metric value )  {  this . lane tile code = new  illumina lane tile code ( lane number tile number metric code )  ;  this . metric value = metric value ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java, substructure,public   ( final  list <  integer >  descriptor indices final  list <  range >  all ranges )  {  this . num descriptors = descriptor indices . size (  )  ;  this . descriptor indices = new int[num descriptors] ;  this . descriptor lengths = new int[num descriptors] ;  for  ( int i = 0 ;  i  <  descriptor indices . size (  )  ;  i +  +  )   {  this . descriptor indices[i] = descriptor indices . get ( i )  ;  this . descriptor lengths[i] = descriptors . get ( this . descriptor indices[i] )  . length ;   }  this . cycle index ranges = new  range[num descriptors] ;  for  ( int i = 0 ;  i  <  num descriptors ;  i +  +  )   {  this . cycle index ranges[i] = all ranges . get ( this . descriptor indices[i] )  ;   }  int total length = 0 ;  for  (  final int length : descriptor lengths )   {  total length +  = length ;   }  total cycles = total length ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\TileMetricsOutReader.java, tile metrics out reader,"public   ( final  file tile metrics out file  tile metrics out reader .  tile metrics version version )  {  bb iterator = m map backed iterator factory . get byte buffer iterator ( version . header size version . record size tile metrics out file )  ;  this . version = version ;  final  byte buffer header = bb iterator . get header bytes (  )  ;  final int actual version =  unsigned type util . u byte to int ( header . get (  )  )  ;  if  ( actual version  !  =  version . version )   {  throw new  picard exception ( "" tile metrics out reader expects the version number to be ""  +  version . version  +  "" .   actual  version in  header (  "" +  actual version +  "" ) "" )  ;   }  final int actual record size =  unsigned type util . u byte to int ( header . get (  )  )  ;  if  ( version . record size  !  =  actual record size )   {  throw new  picard exception ( "" tile metrics out reader expects the record size to be ""  +  version . record size  +  "" .   actual  record  size in  header (  "" +  actual record size +  "" ) "" )  ;   }  if  ( version  =  =   tile metrics version . three )   {  this . density =  unsigned type util . u int to float ( header . get int (  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\TileMetricsOutReader.java, tile metrics version,  ( int version int header size int record size )  {  this . version = version ;  this . header size = header size ;  this . record size = record size ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,equals,@ override public boolean   ( final  object that obj )  {  if  ( this  =  =  that obj )  return true ;  if  ( this . get class (  )   !  =  that obj . get class (  )  )  return false ;  final  read structure that =  (  read structure ) that obj ;  if  ( t
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\TileMetricsOutReader.java,equals,@ override public boolean   ( final  object o )  {  if  ( o instanceof  illumina lane tile code )   {  final  illumina lane tile code that =  (  illumina lane tile code ) o ;  return lane number  =  =  that . lane number && tile number  =  =  that . tile 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,get,public  read descriptor   ( final int index )  {  return descriptors . get ( descriptor indices[index] )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\TileMetricsOutReader.java,get density,public float   (  )  {  return density ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,get cycle index ranges,public  range[]   (  )  {  return cycle index ranges ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\TileMetricsOutReader.java,get lane number,public int   (  )  {  return lane number ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\TileMetricsOutReader.java,get lane tile code,public  illumina lane tile code   (  )  {  return lane tile code ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\TileMetricsOutReader.java,get metric code,public int   (  )  {  return metric code ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,get cycles,public int[]   (  )  {  int[] cycles = new int[total cycles] ;  int cycle index = 0 ;  for  (  final  range range : cycle index ranges )   {  for  ( int i = range . start ;  i  <  =  range . end ;  i +  +  )   {  cycles[cycle index +  + ] = i  +  1 ;   }   }  return cycles ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\TileMetricsOutReader.java,get metric value,public float   (  )  {  return metric value ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,get descriptor lengths,public int[]   (  )  {  return descriptor lengths ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\TileMetricsOutReader.java,get tile number,public int   (  )  {  return tile number ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,get indices,public int[]   (  )  {  return descriptor indices ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\TileMetricsOutReader.java,has next,public boolean   (  )  {  return bb iterator . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,get num descriptors,public int   (  )  {  return descriptors . size (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,get total cycles,public int   (  )  {  return total cycles ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\TileMetricsOutReader.java,hash code,@ override public int   (  )  {  int result = lane number ;  result = 31 * result  +  tile number ;  result = 31 * result  +  metric code ;  return result ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,has next,public boolean   (  )  {  return index  <  indices . length ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\TileMetricsOutReader.java,is cluster record,public boolean   (  )  {  return type  =  =  't' ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,hash code,@ override public int   (  )  {  int res = descriptors . get ( 0 )  . hash code (  )  ;  for  ( int i = 1 ;  i  <  descriptors . size (  )  ;  i +  +  )   {  res* = descriptors . get ( i )  . hash code (  )  ;   }  return res ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\TileMetricsOutReader.java,next,public  illumina tile metrics   (  )  {  if  (  ! has next (  )  )   {  throw new  no such element exception (  )  ;   }  return new  illumina tile metrics ( bb iterator . next (  )  version )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,is empty,public boolean   (  )  {  return num descriptors  =  =  0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\readers\TileMetricsOutReader.java,remove,public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,iterator,public  iterator <  read descriptor >    (  )  {  return new  indexed iterator ( descriptor indices )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,length,public int   (  )  {  return num descriptors ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,next,public  read descriptor   (  )  {  return descriptors . get ( indices[index +  + ] )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,read structure string to descriptors,"private final static  list <  read descriptor >    ( final  string read structure )  {  final  matcher full matcher =  full pattern . matcher ( read structure )  ;  if  (  ! full matcher . matches (  )  )   {  throw new  illegal argument exception ( read structure  +  "" cannot be parsed as a  read structure !  ""  +   read structure msg )  ;   }  final  matcher sub matcher =  sub pattern . matcher ( read structure )  ;  final  list <  read descriptor >  descriptors = new  array list <  read descriptor >  (  )  ;  while  ( sub matcher . find (  )  )   {  final  read descriptor rd = new  read descriptor (  integer . parse int ( sub matcher . group ( 1 )  )   read type . value of ( sub matcher . group ( 2 )  )  )  ;  descriptors . add ( rd )  ;   }  return descriptors ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,remove,public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,to read structure,public  read structure   (  )  {  final  list <  read descriptor >  descriptors = new  array list <  read descriptor >  ( num descriptors )  ;  for  (  final  read descriptor rd : this )   {  descriptors . add ( rd )  ;   }  return new  read structure ( descriptors )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\ReadStructure.java,to string,"@ override public  string   (  )  {   string out = """" ;  for  (  final  read descriptor rd : descriptors )   {  out +  = rd . to string (  )  ;   }  return out ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\Tile.java, tile,public   ( final int lane final int tile final float density final float clusters final  tile phasing value .  .  .  tile phasing values )  {  this . lane = lane ;  this . tile = tile ;  this . density = density ;  this . clusters = clusters ;  final  collection <  tile phasing value >  phasing values = ensure sole tile phasing values per read (  arrays . as list ( tile phasing values )  )  ;  final  map <  tile template read  float >  phasing map = new  enum map <  tile template read  float >  (  tile template read . class )  ;  final  map <  tile template read  float >  pre phasing map = new  enum map <  tile template read  float >  (  tile template read . class )  ;  for  (   tile phasing value phasing value : phasing values )   {  phasing map . put ( phasing value . get tile template read (  )  phasing value . get phasing value (  )  )  ;  pre phasing map . put ( phasing value . get tile template read (  )  phasing value . get pre phasing value (  )  )  ;   }  this . phasing map =  collections . unmodifiable map ( phasing map )  ;  this . pre phasing map =  collections . unmodifiable map ( pre phasing map )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\Tile.java,ensure sole tile phasing values per read,private static  collection <  tile phasing value >    ( final  collection <  tile phasing value >  tile phasing values )  {  final  map <  tile template read  list <  tile phasing value >  >  partitioned map = tile phasing values . stream (  )  . collect (  collectors . grouping by (  tile phasing value::get tile template read )  )  ;  final  collection <  tile phasing value >  new tile phasing values = new  linked list <  >  (  )  ;  for  (  final  tile template read read : partitioned map . key set (  )  )   {  new tile phasing values . add (  collection util . get sole element ( partitioned map . get ( read )  )  )  ;   }  return new tile phasing values ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\Tile.java,get cluster count,public float   (  )  {  return clusters ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\Tile.java,get cluster density,public float   (  )  {  return density ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\Tile.java,get lane number,public int   (  )  {  return lane ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\Tile.java,get phasing map,public  map <  tile template read  float >    (  )  {  return phasing map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\Tile.java,get pre phasing map,public  map <  tile template read  float >    (  )  {  return pre phasing map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\Tile.java,get tile number,public int   (  )  {  return tile ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileMetricsUtil.java,compute linear fit,"private static float[]   (  float[] x values  float[] y values int sample count )  {  if  ( sample count  =  =  0 || sample count  >  x values . length )  sample count = x values . length ;  if  ( x values . length  <  =  1 || x values . length  !  =  y values . length )   {  throw new  picard exception ( "" can not compute linear fit . "" )  ;   }  float sumx = 0 ;  float sumy = 0 ;  float sumxx = 0 ;  float sumxy = 0 ;  float slope = 0f ;  float offset = 0f ;  for  ( int i = 0 ;  i  <  sample count ;  i +  +  )   {  sumx +  = x values[i] ;  sumy +  = y values[i] ;  sumxy +  = x values[i] * y values[i] ;  sumxx +  = x values[i] * x values[i] ;   }  float denominator = sample count * sumxx  -  sumx * sumx ;  if  ( denominator  >   math . ulp ( denominator )  )   {  slope =  ( sample count * sumxy  -  sumx * sumy )   /  denominator ;  offset =  ( sumy * sumxx  -  sumx * sumxy )   /  denominator ;   }  return new float[] { slope offset }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileMetricsUtil.java,determine last value for lane tile metrics code,private static  collection <  illumina tile metrics >    ( final  iterator <  illumina tile metrics >  tile metrics iterator )  {  final  map <  tile metrics out reader .  illumina lane tile code  illumina tile metrics >  filtered tile metrics = new  hash map <  >  (  )  ;  for  (  final  illumina tile metrics illumina tile metrics : new  iterable adapter <  >  ( tile metrics iterator )  )   {  filtered tile metrics . put ( illumina tile metrics . get lane tile code (  )  illumina tile metrics )  ;   }  return filtered tile metrics . values (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileMetricsUtil.java,file tile metrics file,"private static  file   (  file illumina run directory  integer num cycles boolean is nova seq )  {   path inter op dir = illumina run directory . to path (  )  . resolve ( interop   subdirectory   name )  ;  final  list <  path >  paths to test = new  array list <  >  (  )  ;  paths to test . add ( inter op dir . resolve ( tile   metrics   out   file   name )  )  ;  if  ( is nova seq )   {  for  ( int i = num cycles ;  i  >  0 ;  i -  -  )   {  paths to test . add ( inter op dir . resolve (  string . format ( ""c%d . 1 / %s"" i tile   metrics   out   file   name )  )  )  ;   }   }  return paths to test . stream (  )  . filter (  files::exists )  . find first (  )  . or else throw (  (  )   -  >   {   string builder message = new  string builder (  string . format ( "" no %s file found in %s"" interop   subdirectory   name inter op dir )  )  ;  if  ( is nova seq )   {  message . append ( "" or any of its cycle directories . "" )  ;   }  return new  illegal state exception ( message . to string (  )  )  ;   }   )  . to file (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileMetricsUtil.java,get tile phasing values,"private static  collection <  tile phasing value >    ( final  map <  integer  ?  extends  collection <  illumina tile metrics >  >  code metrics map final  read structure read structure final  validation stringency validation stringency )  {  boolean is first read = true ;  final  collection <  tile phasing value >  tile phasing values = new  array list <  >  (  )  ;  for  ( int descriptor index = 0 ;  descriptor index  <  read structure . descriptors . size (  )  ;  descriptor index +  +  )   {  if  ( read structure . descriptors . get ( descriptor index )  . type  =  =   read type .  template )   {  final  tile template read tile template read = is first read  ?   tile template read . first :  tile template read . second ;  final int phasing code =  illumina metrics code . get phasing code ( descriptor index  illumina metrics code . phasing   base )  ;  final int pre phasing code =  illumina metrics code . get phasing code ( descriptor index  illumina metrics code . prephasing   base )  ;  final float phasing value  pre phasing value ;  if  ( code metrics map . contains key ( phasing code )  && code metrics map . contains key ( pre phasing code )  )   {  phasing value =  collection util . get sole element ( code metrics map . get ( phasing code )  )  . get metric value (  )  ;  pre phasing value =  collection util . get sole element ( code metrics map . get ( pre phasing code )  )  . get metric value (  )  ;   }  else  {  final  string message =  string . format ( "" don't have both phasing and prephasing values for %s read cycle %s .   phasing code was %d and prephasing code was %d . "" tile template read . to string (  )  descriptor index  +  1 phasing code pre phasing code )  ;  if  (  ! code metrics map . contains key ( phasing code )  &&  ! code metrics map . contains key ( pre phasing code )  && validation stringency  !  =   validation stringency . strict )   {  if  ( validation stringency  =  =   validation stringency . lenient )   {  log . warn ( message )  ;   }   }  else  {  throw new  picard exception ( message )  ;   }  phasing value = 0 ;  pre phasing value = 0 ;   }  tile phasing values . add ( new  tile phasing value ( tile template read phasing value pre phasing value )  )  ;  is first read = false ;   }   }  return tile phasing values ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileMetricsUtil.java,parse tile metrics,"public static  collection <  tile >    ( final  file tile metrics out file final  read structure read structure final  validation stringency validation stringency )  throws  file not found exception  {  final  collection <  illumina tile metrics >  tile metrics = determine last value for lane tile metrics code ( new  tile metrics out reader ( tile metrics out file  tile metrics out reader .  tile metrics version . two )  )  ;  final  map <  string  ?  extends  collection <  illumina tile metrics >  >  location to metrics map = partition tile metrics by location ( tile metrics )  ;  final  collection <  tile >  tiles = new  linked list <  >  (  )  ;  for  (  final  map .  entry <  string  ?  extends  collection <  illumina tile metrics >  >  entry : location to metrics map . entry set (  )  )   {  final  collection <  illumina tile metrics >  tile records = entry . get value (  )  ;  final  map <  integer  ?  extends  collection <  illumina tile metrics >  >  code metrics map = partition tile metrics by code ( tile records )  ;  final  set <  integer >  observed codes = code metrics map . key set (  )  ;  if  (  !  ( observed codes . contains (  illumina metrics code . density   id . get metrics code (  )  )  && observed codes . contains (  illumina metrics code . cluster   id . get metrics code (  )  )  )  )  throw new  picard exception (  string . format ( "" expected to find cluster and density record codes  ( %s and %s )  in records read for tile location %s  ( lane:tile )   but found only %s . ""  illumina metrics code . cluster   id . get metrics code (  )   illumina metrics code . density   id . get metrics code (  )  entry . get key (  )  observed codes )  )  ;  final  illumina tile metrics density record =  collection util . get sole element ( code metrics map . get (  illumina metrics code . density   id . get metrics code (  )  )  )  ;  final  illumina tile metrics cluster record =  collection util . get sole element ( code metrics map . get (  illumina metrics code . cluster   id . get metrics code (  )  )  )  ;  final  collection <  tile phasing value >  tile phasing values = get tile phasing values ( code metrics map read structure validation stringency )  ;  tiles . add ( new  tile ( density record . get lane number (  )  density record . get tile number (  )  density record . get metric value (  )  cluster record . get metric value (  )  tile phasing values . to array ( new  tile phasing value[tile phasing values . size (  ) ] )  )  )  ;   }  return  collections . unmodifiable collection ( tiles )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileMetricsUtil.java,partition tile metrics by code,private static  map <  integer  ?  extends  collection <  illumina tile metrics >  >    ( final  collection <  illumina tile metrics >  tile metrics )  {  return tile metrics . stream (  )  . collect (  collectors . grouping by (  illumina tile metrics::get metric code )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileMetricsUtil.java,partition tile metrics by location,private static  map <  string  ?  extends  collection <  illumina tile metrics >  >    ( final  collection <  illumina tile metrics >  tile metrics )  {  return tile metrics . stream (  )  . collect (  collectors . grouping by (  tile metrics util::render metric location key )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileMetricsUtil.java,render metric location key,"private static  string   ( final  illumina tile metrics metric )  {  return  string . format ( ""%s:%s"" metric . get lane number (  )  metric . get tile number (  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileMetricsUtil.java,render phasing metrics files from basecalling directory,"public static  map <  integer  file >    (  file illumina run directory )  {   file[] cycle dirs = io util . get files matching regexp ( new  file ( illumina run directory interop   subdirectory   name )   illumina file util . cycle   subdirectory   pattern )  ;   map <  integer  file >  phasing metrics = new  hash map <  >  (  )  ;   arrays . as list ( cycle dirs )  . for each ( cycle dir  -  >   {   file[] files matching regexp = io util . get files matching regexp ( cycle dir "" empirical phasing metrics out . bin"" )  ;  if  ( files matching regexp . length  >  0 )   {  phasing metrics . put (  per tile per cycle file util . get cycle from dir ( cycle dir )  files matching regexp[0] )  ;   }   }   )  ;  return phasing metrics ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileMetricsUtil.java,render tile metrics file from basecalling directory,public static  file   ( final  file illumina run directory  integer num cycles boolean is nova seq )  {  return file tile metrics file ( illumina run directory num cycles is nova seq )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TilePhasingValue.java, tile phasing value,public   ( final  tile template read tile template read final float phasing value final float pre phasing value )  {  this . tile template read = tile template read ;  this . phasing value = phasing value ;  this . pre phasing value = pre phasing value ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TilePhasingValue.java,get phasing value,public float   (  )  {  return phasing value ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TilePhasingValue.java,get pre phasing value,public float   (  )  {  return pre phasing value ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TilePhasingValue.java,get tile template read,public  tile template read   (  )  {  return tile template read ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileIndex.java, tile index,"  ( final  file tile index file )  {  try  {  this . tile index file = tile index file ;  final  input stream is = io util . maybe buffer input stream ( new  file input stream ( tile index file )  )  ;  final  byte buffer buf =  byte buffer . allocate ( 8 )  ;  buf . order (  byte order . little   endian )  ;  int absolute record index = 0 ;  int num tiles = 0 ;  while  ( read tile index record ( buf . array (  )  buf . capacity (  )  is )  )   {  buf . rewind (  )  ;  buf . limit ( buf . capacity (  )  )  ;  final int tile = buf . get int (  )  ;  if  ( tile  <  0 )  throw new  picard exception ( "" tile number too large in ""  +  tile index file . get absolute path (  )  )  ;  final int num clusters = buf . get int (  )  ;  if  ( num clusters  <  0 )  throw new  picard exception ( "" cluster size too large in ""  +  tile index file . get absolute path (  )  )  ;  tiles . add ( new  tile index record ( tile num clusters absolute record index num tiles +  +  )  )  ;  absolute record index +  = num clusters ;   }   closer util . close ( is )  ;   }  catch  (  final io exception e )   {  throw new  picard exception ( "" problem reading ""  +  tile index file . get absolute path (  )  e )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileIndex.java, tile index record,private   ( final int tile final int num clusters in tile final int index of first cluster in tile final int zero based tile number )  {  this . tile = tile ;  this . num clusters in tile = num clusters in tile ;  this . index of first cluster in tile = index of first cluster in tile ;  this . zero based tile number = zero based tile number ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileIndex.java,find tile,"public  tile index record   ( final int tile number )  {  for  (  final  tile index record rec : this )   {  if  ( rec . tile  =  =  tile number )  return rec ;  if  ( rec . tile  >  tile number )   {  break ;   }   }  throw new  no such element exception (  string . format ( "" tile %d not found in %s"" tile number tile index file )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileIndex.java,get file,public  file   (  )  {  return tile index file ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileIndex.java,get num clusters in tile,public int   (  )  {  return num clusters in tile ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileIndex.java,get num tiles,public int   (  )  {  return tiles . size (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileIndex.java,get tiles,public  list <  integer >    (  )  {  final  list <  integer >  ret = new  array list <  integer >  ( tiles . size (  )  )  ;  for  (  final  tile index record rec : tiles )  ret . add ( rec . tile )  ;  return ret ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileIndex.java,get zero based tile number,public int   (  )  {  return zero based tile number ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileIndex.java,iterator,@ override public  iterator <  tile index record >    (  )  {  return tiles . iterator (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileIndex.java,read tile index record,"private boolean   ( final byte[] buf final int num bytes final  input stream is )  throws io exception  {  int total bytes read = 0 ;  while  ( total bytes read  <  num bytes )   {  final int bytes read = is . read ( buf total bytes read num bytes  -  total bytes read )  ;  if  ( bytes read  =  =   - 1 )   {  if  ( total bytes read  !  =  0 )   {  throw new  picard exception ( tile index file . get absolute path (  )   +  "" has incomplete last block"" )  ;   }  else return false ;   }  total bytes read +  = bytes read ;   }  return true ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\parser\TileIndex.java,verify,"public  list <  string >    ( final  list <  integer >  expected tiles )  {  final  set <  integer >  tile set = new  hash set <  integer >  ( tiles . size (  )  )  ;  for  (  final  tile index record rec : tiles )  tile set . add ( rec . tile )  ;  final  list <  string >  failures = new  linked list <  string >  (  )  ;  for  (  final int expected tile : expected tiles )   {  if  (  ! tile set . contains ( expected tile )  )   {  failures . add ( "" tile ""  +  expected tile  +  "" not found in "" +  tile index file . get absolute path (  )  )  ;   }   }  return failures ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\quality\CollectHiSeqXPfFailMetrics.java, per tilepf metrics extractor,public   ( final int tile final pf fail summary metric summary metric final  collection < pf fail detailed metric >  detailed metrics final  illumina data provider factory factory final double p write detailed )  {  this . tile = tile ;  this . summary metric = summary metric ;  this . detailed metrics = detailed metrics ;  this . p write detailed = p write detailed ;  this . provider = factory . make data provider (  arrays . as list ( tile )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\quality\CollectHiSeqXPfFailMetrics.java, read classifier,public   ( final  read data read )  {  final int length = read . get bases (  )  . length ;  num ns = count equals ( read . get bases (  )   ( byte ) ' . ' )  ;  numq gt two = count greater than ( read . get qualities (  )   ( byte ) 2 )  ;  fail class =  pf fail reason . unknown ;  if  ( num ns  >  =   ( length  -  1 )  )   {  fail class =  pf fail reason . misaligned ;   }  else if  ( num ns  <  =  1 )   {  if  ( numq gt two  <  =  length  /  3 )   {  fail class =  pf fail reason . empty ;   }  else if  ( numq gt two  >  =  length  /  2 )   {  fail class =  pf fail reason . polyclonal ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\quality\CollectHiSeqXPfFailMetrics.java,calculate derived fields,public void   (  )  {  if  ( this . reads  !  =  0 )   {  this . pct   pf   fail   reads =  ( double ) this . pf   fail   reads  /  this . reads ;  this . pct   pf   fail   empty =  ( double ) this . pf   fail   empty  /  this . reads ;  this . pct   pf   fail   misaligned =  ( double ) this . pf   fail   misaligned  /  this . reads ;  this . pct   pf   fail   polyclonal =  ( double ) this . pf   fail   polyclonal  /  this . reads ;  this . pct   pf   fail   unknown =  ( double ) this . pf   fail   unknown  /  this . reads ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\quality\CollectHiSeqXPfFailMetrics.java,count equals,static private int   ( final byte[] array final byte to count )  {  int count = 0 ;  for  (  final byte t : array )   {  if  ( t  =  =  to count )  count +  +  ;   }  return count ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\quality\CollectHiSeqXPfFailMetrics.java,count greater than,static private int   ( final byte[] array final byte value )  {  int count = 0 ;  for  (  final int t : array )   {  if  ( t  >  value )  count +  +  ;   }  return count ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\quality\CollectHiSeqXPfFailMetrics.java,custom command line validation,"@ override protected  string[]   (  )  {  final  list <  string >  errors = new  array list <  string >  (  )  ;  if  ( n   cycles  <  0 )   {  errors . add ( "" number of  cycles to look at must be greater than 0"" )  ;   }  if  ( prob   explicit   reads  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\quality\CollectHiSeqXPfFailMetrics.java,do work,@ override protected int   (  )  {  final  illumina data provider factory factory = new  illumina data provider factory ( basecalls   dir lane read   structure new  bcl quality evaluation strategy (  bcl quality evaluation strategy . illumina   alleged   
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\quality\CollectHiSeqXPfFailMetrics.java,get exception,public  exception   (  )  {  return this . exception ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\quality\CollectHiSeqXPfFailMetrics.java,main,public static void   ( final  string[] args )  {  new  collect hi seqx pf fail metrics (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\quality\CollectHiSeqXPfFailMetrics.java,merge,public void   ( final pf fail summary metric metric )  {  this . reads +  = metric . reads ;  this . pf   fail   reads +  = metric . pf   fail   reads ;  this . pf   fail   empty +  = metric . pf   fail   empty ;  this . pf   fail   misaligned +  = metric . pf   fail   misaligned ;  this . pf   fail   polyclonal +  = metric . pf   fail   polyclonal ;  this . pf   fail   unknown +  = metric . pf   fail   unknown ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\illumina\quality\CollectHiSeqXPfFailMetrics.java,run,"public void   (  )  {  try  {  log . info ( "" extracting pf metrics for tile ""  +  tile )  ;  while  ( provider . has next (  )  )   {  final  cluster data cluster = provider . next (  )  ;  this . summary metric . reads +  +  ;  if  (  ! cluster . is pf (  )  )   {  this . summary metric . pf   fail   reads +  +  ;  final  read classifier read classifier = new  read classifier ( cluster . get read ( 0 )  )  ;  if  ( random . next double (  )   <  p write detailed )   {  detailed metrics . add ( new pf fail detailed metric ( tile cluster . getx (  )  cluster . gety (  )  read classifier . num ns read classifier . numq gt two read classifier . fail class )  )  ;   }  switch  ( read classifier . fail class )   {  case empty: this . summary metric . pf   fail   empty +  +  ;  break ;  case misaligned: this . summary metric . pf   fail   misaligned +  +  ;  break ;  case polyclonal: this . summary metric . pf   fail   polyclonal +  +  ;  break ;  case unknown: this . summary metric . pf   fail   unknown +  +  ;  break ;  default : log . error ( "" got unexpected fail  reason"" )  ;   }   }   }   }  catch  ( final  exception e )   {  log . error ( e "" error processing tile "" this . tile )  ;  this . exception = e ;   }  finally  {  provider . close (  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\metrics\MultiLevelCollector.java, all reads distributor,public   ( final  list < sam read group record >  rg recs )  {  super ( new  array list < sam read group record >  (  )  )  ;  make collector ( null )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\metrics\MultiLevelCollector.java, distributor,public   ( final  list < sam read group record >  rg recs )  {  collectors = new  linked hash map <  string  per unit metric collector < metric   type  histogram   key argtype >  >  (  )  ;  for  (  final sam read group record rg : rg recs )   {  final  string key = get key ( rg )  ;  if  (  ! collectors . contains key ( key )  )   {  collectors . put ( key make collector ( rg )  )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\metrics\MultiLevelCollector.java, library distributor,public   ( final  list < sam read group record >  rg recs )  {  super ( rg recs )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\metrics\MultiLevelCollector.java, read group collector,public   ( final  list < sam read group record >  rg recs )  {  super ( rg recs )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\metrics\MultiLevelCollector.java, sample distributor,public   ( final  list < sam read group record >  rg recs )  {  super ( rg recs )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\metrics\MultiLevelCollector.java,accept record,public void   ( final sam record record final  reference sequence ref seq )  {  final argtype arg = make arg ( record ref seq )  ;  for  (  final  distributor collector : output ordered distributors )   {  collector . accept record ( arg record . get read group (  )  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\metrics\MultiLevelCollector.java,add all levels to file,public void   ( final  metrics file < metric   type  histogram   key >  file )  {  for  (  final  distributor collector : output ordered distributors )   {  collector . add to file ( file )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\metrics\MultiLevelCollector.java,add to file,@ override public void   ( final  metrics file < metric   type  histogram   key >  file )  {  all read collector . add metrics to file ( file )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\metrics\MultiLevelCollector.java,finish,public void   (  )  {  for  (  final  distributor collector : output ordered distributors )   {  collector . finish (  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\metrics\MultiLevelCollector.java,get all reads collector,public  per unit metric collector < metric   type  histogram   key argtype >    (  )  {  return all read collector ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\metrics\MultiLevelCollector.java,get key,@ override protected  string   ( sam read group record rg )  {  return rg . get platform unit (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\metrics\MultiLevelCollector.java,make all read collector,protected  per unit metric collector < metric   type  histogram   key argtype >    (  )  {  return make child collector ( null null null )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\metrics\SAMRecordAndReference.java,sam record and reference,public   ( final sam record sam rec final  reference sequence ref seq )  {  this . sam rec = sam rec ;  this . ref seq = ref seq ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\metrics\SAMRecordAndReference.java,get reference sequence,public  reference sequence   (  )  {  return ref seq ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\metrics\SAMRecordAndReference.java,get sam record,public sam record   (  )  {  return sam rec ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\nio\GoogleStorageUtils.java,get cloud storage configuration,private static  cloud storage configuration   ( int max reopens )  {  return  cloud storage configuration . builder (  )  . max channel reopens ( max reopens )  . build (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\nio\GoogleStorageUtils.java,initialize,public static void   (  )  {   cloud storage file system provider . set default cloud storage configuration (  google storage utils . get cloud storage configuration ( 20 )  )  ;   cloud storage file system provider . set storage options (  google storage utils . set generous timeouts (  storage options . new builder (  )  )  . build (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\nio\GoogleStorageUtils.java,set generous timeouts,private static  storage options .  builder   (  storage options .  builder builder )  {  return builder . set transport options (  http transport options . new builder (  )  . set connect timeout ( 120   000 )  . set read timeout ( 120   000 )  . build (  )  )  . set retry settings (  retry settings . new builder (  )  . set max attempts ( 15 )  . set max retry delay (  duration . of millis ( 256   000l )  )  . set total timeout (  duration . of millis ( 4000   000l )  )  . set initial retry delay (  duration . of millis ( 1000l )  )  . set retry delay multiplier ( 2 . 0 )  . set initial rpc timeout (  duration . of millis ( 180   000l )  )  . set rpc timeout multiplier ( 1 . 0 )  . set max rpc timeout (  duration . of millis ( 180   000l )  )  . build (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\metrics\SAMRecordMultiLevelCollector.java,make arg,@ override protected sam record   ( sam record sam rec final  reference sequence ref seq )  {  return sam rec ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\metrics\SAMRecordAndReferenceMultiLevelCollector.java,make arg,@ override protected sam record and reference   ( sam record sam rec final  reference sequence ref seq )  {  return new sam record and reference ( sam rec ref seq )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\pedigree\PedFile.java, ped file,"public   ( final boolean is tab mode )  {  delimiter pattern = is tab mode  ?  tab : whitespace ;  delimiter string = is tab mode  ?  ""tabs"" : ""whitespace"" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\pedigree\PedFile.java, ped trio,"public   ( final  string family id final  string individual id final  string paternal id final  string maternal id final  sex sex final  number phenotype )  {  if  ( delimiter pattern . split ( family id )  . length  !  =  1 )  throw new  illegal argument exception ( "" familyid cannot contain ""  +  delimiter string  +  "": ["" +  family id +  ""]"" )  ;  if  ( delimiter pattern . split ( individual id )  . length  !  =  1 )  throw new  illegal argument exception ( "" individualid cannot contain ""  +  delimiter string  +  "": ["" +  individual id +  ""]"" )  ;  if  ( delimiter pattern . split ( paternal id )  . length  !  =  1 )  throw new  illegal argument exception ( "" paternalid cannot contain ""  +  delimiter string  +  "": ["" +  paternal id +  ""]"" )  ;  if  ( delimiter pattern . split ( maternal id )  . length  !  =  1 )  throw new  illegal argument exception ( "" maternalid cannot contain ""  +  delimiter string  +  "": ["" +  maternal id +  ""]"" )  ;  this . family id = family id ;  this . individual id = individual id ;  this . paternal id = paternal id ;  this . maternal id = maternal id ;  this . sex = sex ;  this . phenotype = phenotype ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\pedigree\PedFile.java,add,public void   ( final  ped trio trio )  {  put ( trio . get individual id (  )  trio )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\pedigree\PedFile.java,from file,"public static  ped file   ( final  file file final boolean is tab mode )  {  final  ped file ped file = new  ped file ( is tab mode )  ;  io util . assert file is readable ( file )  ;  for  (  final  string line : io util . read lines ( file )  )   {  final  string[] fields = ped file . delimiter pattern . split ( line )  ;  if  ( fields . length  !  =  6 )   {  log . error ( "" ped file line contained invalid number of fields  skipping: ""  +  line )  ;  continue ;   }  final  ped trio trio = ped file . new  ped trio ( fields[0] fields[1] fields[2] fields[3]  sex . from code (  integer . parse int ( fields[4] )  )  fields[5] . contains ( "" . "" )   ?   double . parse double ( fields[5] )  :  integer . parse int ( fields[5] )  )  ;  ped file . add ( trio )  ;   }  return ped file ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\pedigree\PedFile.java,from sex map,"static public  ped file   ( final  map <  string  sex >  sample sexes )  {  final  ped file pedfile = new  ped file ( true )  ;  for  (  final  map .  entry <  string  sex >  sample sex : sample sexes . entry set (  )  )   {  final  ped file .  ped trio ped = pedfile . new  ped trio ( sample sex . get key (  )  sample sex . get key (  )  "" . "" "" . "" sample sex . get value (  )   ped file . no   pheno )  ;  pedfile . add ( ped )  ;   }  return pedfile ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\pedigree\PedFile.java,get family id,public  string   (  )  {  return family id ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\pedigree\PedFile.java,get individual id,public  string   (  )  {  return individual id ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\pedigree\PedFile.java,get maternal id,public  string   (  )  {  return maternal id ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\pedigree\PedFile.java,get paternal id,public  string   (  )  {  return paternal id ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\pedigree\PedFile.java,get phenotype,public  number   (  )  {  return phenotype ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\pedigree\PedFile.java,get sex,public  sex   (  )  {  return sex ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\pedigree\PedFile.java,has both parents,public boolean   (  )  {  return this . paternal id  !  =  null && this . maternal id  !  =  null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\pedigree\PedFile.java,remove incomplete trios,public  ped file   (  )  {  final  iterator <  map .  entry <  string  ped trio >  >  iterator = entry set (  )  . iterator (  )  ;  while  ( iterator . has next (  )  )   {  if  (  ! iterator . next (  )  . get value (  )  . has both parents (  )  )  iterator . remove (  )  ;   }  return this ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\pedigree\PedFile.java,write,"public void   ( final  file file )  {  io util . assert file is writable ( file )  ;  final  buffered writer out = io util . open file for buffered writing ( file )  ;  try  {  for  (  final  ped trio trio : values (  )  )   {  out . write ( trio . get family id (  )  )  ;  out . write ( ""\t"" )  ;  out . write ( trio . get individual id (  )  )  ;  out . write ( ""\t"" )  ;  out . write ( trio . get paternal id (  )  )  ;  out . write ( ""\t"" )  ;  out . write ( trio . get maternal id (  )  )  ;  out . write ( ""\t"" )  ;  out . write (  string . value of ( trio . get sex (  )  . to code (  )  )  )  ;  out . write ( ""\t"" )  ;  out . write ( trio . get phenotype (  )  . to string (  )  )  ;  out . new line (  )  ;   }  out . close (  )  ;   }  catch  (  final io exception ioe )   {  throw new  runtimeio exception ( ""io exception while writing to file ""  +  file . get absolute path (  )  ioe )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\pedigree\Sex.java, sex,private   ( final int code )  {  this . code = code ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\pedigree\Sex.java,from code,public static  sex   ( final int code )  {  if  ( code  =  =   male . code )  return  male ;  else if  ( code  =  =   female . code )  return  female ;  else return  unknown ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\pedigree\Sex.java,to code,public int   (  )  {  return this . code ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\PicardException.java, picard exception,public   ( final  string message final  throwable throwable )  {  super ( message throwable )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\reference\ExtractSequences.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( interval   list )  ;  io util . assert file is readable ( reference   sequence )  ;  io util . assert file is writable ( output )  ;  final  interval list intervals =  interval list .
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\reference\ExtractSequences.java,main,public static void   ( final  string[] args )  {  new  extract sequences (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\reference\ExtractSequences.java,requires reference,@ override protected boolean   (  )  {  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\reference\NormalizeFasta.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  if  ( input . get absolute file (  )  . equals ( output . get absolute file (  )  )  )   {  throw new  illegal argument ex
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\reference\NormalizeFasta.java,main,public static void   ( final  string[] args )  {  new  normalize fasta (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AbstractAlignmentMerger.java, abstract alignment merger,"public   ( final  file unmapped bam file final  file target bam file final  file reference fasta final boolean clip adapters final boolean bisulfite sequence final boolean aligned reads only final sam program record program record final  list <  string >  attributes to retain final  list <  string >  attributes to remove final  integer read1 bases trimmed final  integer read2 bases trimmed final  list <  sam pair util .  pair orientation >  expected orientations final  sort order sort order final  primary alignment selection strategy primary alignment selection strategy final boolean add mate cigar final boolean unmap contaminant reads final  unmapping read strategy unmapping reads strategy )  {  io util . assert file is readable ( unmapped bam file )  ;  io util . assert file is writable ( target bam file )  ;  io util . assert file is readable ( reference fasta )  ;  this . unmapped bam file = unmapped bam file ;  this . target bam file = target bam file ;  this . reference fasta = reference fasta ;  this . ref seq = new  reference sequence file walker ( reference fasta )  ;  this . clip adapters = clip adapters ;  this . bisulfite sequence = bisulfite sequence ;  this . aligned reads only = aligned reads only ;  this . header = new sam file header (  )  ;  this . sort order = sort order  !  =  null  ?  sort order :  sort order . coordinate ;  header . set sort order (  sort order . coordinate )  ;  if  ( program record  !  =  null )   {  set program record ( program record )  ;   }  if  ( attributes to retain  !  =  null )   {  this . attributes to retain . add all ( attributes to retain )  ;   }  if  ( attributes to remove  !  =  null )   {  this . attributes to remove . add all ( attributes to remove )  ;  if  (  ! this . attributes to retain . is empty (  )  )   {  this . attributes to remove . stream (  )  . filter ( this . attributes to retain::contains )  . peek ( a  -  >  log . info ( "" overriding retaining the ""  +  a  +  "" tag since 'remove' overrides 'retain' . "" )  )  . for each ( this . attributes to retain::remove )  ;   }   }  this . read1 bases trimmed = read1 bases trimmed ;  this . read2 bases trimmed = read2 bases trimmed ;  this . expected orientations = expected orientations ;  this . primary alignment selection strategy = primary alignment selection strategy ;  this . add mate cigar = add mate cigar ;  this . unmap contaminant reads = unmap contaminant reads ;  this . unmapping reads strategy = unmapping reads strategy ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AbstractAlignmentMerger.java, sink,public   ( final  sorting collection < sam record >  sorter )  {  this . writer = null ;  this . sorter = sorter ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AbstractAlignmentMerger.java, unmapping read strategy,  ( final boolean reset mapping information final boolean populatepa tag )  {  this . reset mapping information = reset mapping information ;  this . populatepa tag = populatepa tag ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AbstractAlignmentMerger.java,add,void   ( final sam record rec )  {  if  ( writer  !  =  null )   {  writer . add alignment ( rec )  ;   }  if  ( sorter  !  =  null )   {  sorter . add ( rec )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AbstractAlignmentMerger.java,add if not filtered,"private void   ( final  sink out final sam record rec )  {  if  ( include secondary alignments ||  ! rec . get not primary alignment flag (  )  )   {  out . add ( rec )  ;  if  ( this . progress . record ( rec )  && cross species reads  >  0 )   {  log . info (  string . format ( ""%d  reads have been unmapped due to being suspected of being  cross - species contamination . "" cross species reads )  )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AbstractAlignmentMerger.java,clip for overlapping reads,protected static void   ( final sam record read1 final sam record read2 )  {  if  (  !  ( read1 . get read unmapped flag (  )  || read2 . get read unmapped flag (  )  )  )   {  if  ( read1 . get read negative strand flag (  )   !  =  read2 . get read negative strand flag (  )  )   {  final sam record pos =  ( read1 . get read negative strand flag (  )  )   ?  read2 : read1 ;  final sam record neg =  ( read1 . get read negative strand flag (  )  )   ?  read1 : read2 ;  if  ( pos . get alignment start (  )   <  neg . get alignment end (  )  )   {  final int pos diff = pos . get alignment end (  )   -  neg . get alignment end (  )  ;  final int neg diff = pos . get alignment start (  )   -  neg . get alignment start (  )  ;  if  ( pos diff  >  0 )   {  final  list <  cigar element >  elems = new  array list <  >  ( pos . get cigar (  )  . get cigar elements (  )  )  ;   collections . reverse ( elems )  ;  final int clipped = length of soft clipping ( elems . iterator (  )  )  ;  final int clip from = pos . get read length (  )   -  pos diff  -  clipped  +  1 ;   cigar util . soft clip3 prime end of read ( pos  math . min ( pos . get read length (  )  clip from )  )  ;  remove nm md and uq tags ( pos )  ;   }  if  ( neg diff  >  0 )   {  final int clipped = length of soft clipping ( neg . get cigar (  )  . get cigar elements (  )  . iterator (  )  )  ;  final int clip from = neg . get read length (  )   -  neg diff  -  clipped  +  1 ;   cigar util . soft clip3 prime end of read ( neg  math . min ( neg . get read length (  )  clip from )  )  ;  remove nm md and uq tags ( neg )  ;   }   }   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AbstractAlignmentMerger.java,clone,"private sam record   ( final sam record rec )  {  try  {  return  ( sam record ) rec . clone (  )  ;   }  catch  (   clone not supported exception e )   {  throw new  picard exception ( "" should never happen . "" )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AbstractAlignmentMerger.java,close,public void   (  )  {   closer util . close ( this . ref seq )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AbstractAlignmentMerger.java,create new cigar if maps off end of reference,private static  cigar   ( sam file header header boolean is unmapped int reference index int alignment end int read length  cigar old cigar )  {   cigar new cigar = null ;  if  (  ! is unmapped )   {  final sam sequence record refseq = header . get sequence ( reference index )  ;  final int overhang = alignment end  -  refseq . get sequence length (  )  ;  if  ( overhang  >  0 )   {  int clip from = read length  -  overhang  +  1 ;  final  cigar element cigar element = old cigar . get cigar element ( old cigar . get cigar elements (  )  . size (  )   -  1 )  ;  if  (  cigar operator . soft   clip  =  =  cigar element . get operator (  )  )  clip from -  = cigar element . get length (  )  ;  final  list <  cigar element >  new cigar elements =  cigar util . soft clip end of read ( clip from old cigar . get cigar elements (  )  )  ;  new cigar = new  cigar ( new cigar elements )  ;   }   }  return new cigar ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AbstractAlignmentMerger.java,create new cigars if maps off end of reference,public static void   ( final sam record rec )  {  if  (  ! rec . get read unmapped flag (  )  )   {  final  cigar read cigar = create new cigar if maps off end of reference ( rec . get header (  )  rec . get read unmapped flag (  )  rec . get reference index (  )  rec . get alignment end (  )  rec . get read length (  )  rec . get cigar (  )  )  ;  if  ( null  !  =  read cigar )   {  rec . set cigar ( read cigar )  ;   }   }  if  ( sam utils . has mate cigar ( rec )  )   {   cigar mate cigar = sam utils . get mate cigar ( rec )  ;  mate cigar = create new cigar if maps off end of reference ( rec . get header (  )  rec . get mate unmapped flag (  )  rec . get mate reference index (  )  sam utils . get mate alignment end ( rec )  mate cigar . get read length (  )  mate cigar )  ;  if  ( null  !  =  mate cigar )   {  rec . set attribute ( sam tag . mc . name (  )  mate cigar . to string (  )  )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AbstractAlignmentMerger.java,encode mapping information,"static private  string   ( sam record rec )  {  return  string . join ( "" "" rec . get contig (  )   (  (  integer ) rec . get alignment start (  )  )  . to string (  )  rec . get cigar string (  )   (  (  integer ) rec . get mapping quality (  )  )  . to string (  )  get string of nullable ( rec . get integer attribute ( sam tag . nm . name (  )  )  )  )   +  "" ; "" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AbstractAlignmentMerger.java,filter out,"public boolean   ( final sam record first final sam record second )  {  throw new  unsupported operation exception ( "" paired  sam record filter not implemented ! "" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AbstractAlignmentMerger.java,fix nm md and uq,public static void   ( final sam record record final  reference sequence file walker ref seq walker final boolean is bisulfite sequence )  {  final byte[] reference bases = ref seq walker . get ( record . get reference index (  )  )  . get bases (  )  ;   sequence util . calculate md and nm tags ( record reference bases true  ! is bisulfite sequence )  ;  if  ( is bisulfite sequence )   {  record . set attribute ( sam tag . nm . name (  )   sequence util . calculate sam nm tag ( record reference bases 0 is bisulfite sequence )  )  ;   }  fix uq ( record ref seq walker is bisulfite sequence )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AbstractAlignmentMerger.java,fix uq,public static void   ( final sam record record final  reference sequence file walker ref seq walker final boolean is bisulfite sequence )  {  if  ( record . get base qualities (  )   !  =  sam record . null   quals )   {  final byte[] reference bases = ref seq walker . get ( record . get reference index (  )  )  . get bases (  )  ;  record . set attribute ( sam tag . uq . name (  )   sequence util . sum qualities of mismatches ( record reference bases 0 is bisulfite sequence )  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AbstractAlignmentMerger.java,get attributes to reverse,public  set <  string >    (  )  {  return attributes to reverse ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AbstractAlignmentMerger.java,get attributes to reverse complement,public  set <  string >    (  )  {  return attributes to reverse complement ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AddCommentsToBam.java,do work,"protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  if  ( input . get absolute path (  )  . ends with ( "" . sam"" )  )   {  throw new  picard exception ( ""sam files are not supported"" )  ;   }  final sam file header sam file header =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . get file header ( input )  ;  for  (  final  string comment : comment )   {  if  ( comment . contains ( ""\n"" )  )   {  throw new  picard exception ( "" comments can not contain a new line"" )  ;   }  sam file header . add comment ( comment )  ;   }   bam file io utils . reheader bam file ( sam file header input output create   md5   file create   index )  ;  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AddCommentsToBam.java,main,public static void   ( final  string[] args )  {  new  add comments to bam (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\reference\NonNFastaSize.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  final  reference sequence file ref =  reference sequence file factory . get reference sequence file ( input )  ;  final  r
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\reference\NonNFastaSize.java,main,public static void   ( final  string[] args )  {  new  nonn fasta size (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AddOrReplaceReadGroups.java,check tag value,"private  optional <  string >    ( final  string tag name final  string value )  {  if  ( value  =  =  null )   {  return  optional . empty (  )  ;   }  final  matcher matcher = pattern . matcher ( value )  ;  if  ( matcher . matches (  )  )   {  return  optional . empty (  )  ;   }  else  {  return  optional . of (  string . format ( "" the values of tags in a sam header must adhere to the regular expression '%s' ""  +  ""but the value provided for %s  '%s'  doesn't . "" readgroup   id   regex tag name value )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AddOrReplaceReadGroups.java,custom command line validation,"@ override protected  string[]   (  )  {  final  list <  string >  validation failures = new  array list <  >  (  )  ;  check tag value ( ""rgid"" rgid )  . if present ( validation failures::add )  ;  check tag value ( ""rglb"" rglb )  . if present ( validati"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\AddOrReplaceReadGroups.java,do work,"protected int   (  )  {  io util . assert input is valid ( input )  ;  io util . assert file is writable ( output )  ;  final  sam reader in =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . open (  sam input resource . of ( input )  )  ;  final sam read group record rg = new sam read group record ( rgid )  ;  rg . set library ( rglb )  ;  rg . set platform ( rgpl )  ;  rg . set sample ( rgsm )  ;  rg . set platform unit ( rgpu )  ;  if  ( rgcn  !  =  null )  rg . set sequencing center ( rgcn )  ;  if  ( rgds  !  =  null )  rg . set description ( rgds )  ;  if  ( rgdt  !  =  null )  rg . set run date ( rgdt )  ;  if  ( rgpi  !  =  null )  rg . set predicted median insert size ( rgpi )  ;  if  ( rgpg  !  =  null )  rg . set program group ( rgpg )  ;  if  ( rgpm  !  =  null )  rg . set platform model ( rgpm )  ;  if  ( rgks  !  =  null )  rg . set key sequence ( rgks )  ;  if  ( rgfo  !  =  null )  rg . set flow order ( rgfo )  ;  log . info (  string . format ( "" created read - group id = %s pl = %s lb = %s sm = %s%n"" rg . get id (  )  rg . get platform (  )  rg . get library (  )  rg . get sample (  )  )  )  ;  final sam file header in header = in . get file header (  )  ;  final sam file header out header = in header . clone (  )  ;  out header . set read groups (  collections . singleton list ( rg )  )  ;  if  ( sort   order  !  =  null )  out header . set sort order ( sort   order )  ;  final sam file writer out writer = new sam file writer factory (  )  . makesam orbam writer ( out header out header . get sort order (  )   =  =  in header . get sort order (  )  output )  ;  final  progress logger progress = new  progress logger ( log )  ;  for  (  final sam record read : in )   {  read . set attribute ( sam tag . rg . name (  )  rgid )  ;  out writer . add alignment ( read )  ;  progress . record ( read )  ;   }   closer util . close ( in )  ;  out writer . close (  )  ;  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\BestEndMapqPrimaryAlignmentStrategy.java,compare,public int   ( final sam record rec1 final sam record rec2 )  {  if  ( rec1 . get read unmapped flag (  )  )   {  if  ( rec2 . get read unmapped flag (  )  )  return 0 ;  else return 1 ;   }  else if  ( rec2 . get read unmapped flag (  )  )   {  return  - 1 ;   }  return  - sam utils . compare mapqs ( rec1 . get mapping quality (  )  rec2 . get mapping quality (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\BestEndMapqPrimaryAlignmentStrategy.java,pick primary alignment,"public void   ( final  hits for insert hits )  {  if  ( hits . num hits (  )   =  =  0 )  throw new  illegal argument exception ( "" no alignments to pick from"" )  ;   collections . sort ( hits . first of pair or fragment mapq   comparator )  ;   collections . sort ( hits . second of pair mapq   comparator )  ;  randomly select primary from best ( hits . first of pair or fragment )  ;  randomly select primary from best ( hits . second of pair )  ;  hits . set primary alignment ( 0 )  ;  if  (  ! hits . is paired (  )  )  return ;  if  ( hits . first of pair or fragment . size (  )   <  =  1 || hits . second of pair . size (  )   <  =  1 )  return ;  final int amount to slide = hits . first of pair or fragment . size (  )   -  1 ;  for  ( int i = 0 ;  i  <  amount to slide ;   +  + i )   {  hits . second of pair . add ( 1 null )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\BestEndMapqPrimaryAlignmentStrategy.java,randomly select primary from best,private void   (  list < sam record >  recs )  {  if  ( recs . is empty (  )  )  return ;  final int best mapq = recs . get ( 0 )  . get mapping quality (  )  ;  int i ;  for  ( i = 1 ;  i  <  recs . size (  )  && recs . get ( i )  . get mapping quality (  )   =  =  best mapq ;   +  + i )   {   }  final int best index = random . next int ( i )  ;  if  ( best index  =  =  0 )  return ;  final sam record tmp = recs . get ( 0 )  ;  recs . set ( 0 recs . get ( best index )  )  ;  recs . set ( best index tmp )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\BamIndexStats.java,do work,"protected int   (  )  {  if  ( input . get name (  )  . ends with ( bam index . bam index suffix )  )  log . warn ( ""input should be the bam file name  not its index file"" )  ;  io util . assert file is readable ( input )  ;  bam index meta data . print index stats ( input )  ;  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\BamIndexStats.java,main,public static void   ( final  string[] argv )  {   system . exit ( new  bam index stats (  )  . instance main ( argv )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CalculateReadGroupChecksum.java,do work,@ override protected int   (  )  {  final  file output = output  =  =  null  ?  new  file ( input . get parent file (  )  get output file name ( input )  )  : output ;  io util . assert file is writable ( output )  ;  final  string hash text = sam utils .
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CalculateReadGroupChecksum.java,get output file name,public static  string   ( final  file input file )  {  return input file . get name (  )   +  output   file   extension ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CalculateReadGroupChecksum.java,main,public static void   ( final  string[] args )  {  new  calculate read group checksum (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\BestMapqPrimaryAlignmentSelectionStrategy.java,pick primary alignment,"public void   ( final  hits for insert hits )  {  if  ( hits . num hits (  )   =  =  0 )  throw new  illegal argument exception ( "" no alignments to pick from"" )  ;  hits . coordinate by hit index (  )  ;  final  num primary alignment state first end alignment state = hits . tally primary alignments ( true )  ;  final  num primary alignment state second end alignment state = hits . tally primary alignments ( false )  ;  if  (  ( first end alignment state  =  =   num primary alignment state . none && second end alignment state  =  =   num primary alignment state . none )  || first end alignment state  =  =   num primary alignment state . more   than   one || second end alignment state  =  =   num primary alignment state . more   than   one )   {  final  list <  integer >  primary alignment indices = new  array list <  integer >  ( hits . num hits (  )  )  ;  int best mapq =  - 1 ;  for  ( int i = 0 ;  i  <  hits . num hits (  )  ;   +  + i )   {  final int first end mapq ;  if  ( hits . get first of pair ( i )   !  =  null )   {  first end mapq = hits . get first of pair ( i )  . get mapping quality (  )  ;   }  else  {  first end mapq = 0 ;   }  final int second end mapq ;  if  ( hits . get second of pair ( i )   !  =  null )   {  second end mapq = hits . get second of pair ( i )  . get mapping quality (  )  ;   }  else  {  second end mapq = 0 ;   }  int this mapq = sam utils . combine mapqs ( first end mapq second end mapq )  ;  if  ( this mapq  >  best mapq )   {  best mapq = this mapq ;  primary alignment indices . clear (  )  ;   }  if  ( this mapq  =  =  best mapq )  primary alignment indices . add ( i )  ;   }  final int primary alignment index ;  if  ( primary alignment indices . size (  )   =  =  1 )  primary alignment index = primary alignment indices . get ( 0 )  ;  else if  ( primary alignment indices . size (  )   >  1 )  primary alignment index = primary alignment indices . get ( random . next int ( primary alignment indices . size (  )  )  )  ;  else throw new  illegal state exception ( "" never found a best mapq  -  -  should never happen"" )  ;  hits . set primary alignment ( primary alignment index )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CheckTerminatorBlock.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  try  {  final  file termination term =  block compressed input stream . check termination ( input )  ;   system . err . println ( term . name (  )  )  ;  if  ( term  =  = 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CheckTerminatorBlock.java,main,public static void   ( final  string[] args )  {  new  check terminator block (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\BuildBamIndex.java,do work,"protected int   (  )  {  try  {  input url = new url ( input )  ;   }  catch  (  java . net .  malformedurl exception e )   {  input file = new  file ( input )  ;   }  if  ( output  =  =  null )   {  final  string base file name ;  if  ( input url  !  =  null )   {  final  string path = input url . get path (  )  ;  final int last slash = path . last index of ( ' / ' )  ;  base file name = path . substring ( last slash  +  1 path . length (  )  )  ;   }  else  {  base file name = input file . get absolute path (  )  ;   }  if  ( base file name . ends with (  bam file io utils . bam   file   extension )  )   {  final int index = base file name . last index of ( ' . ' )  ;  output = new  file ( base file name . substring ( 0 index )   +  bam index . bam index suffix )  ;   }  else  {  output = new  file ( base file name  +  bam index . bam index suffix )  ;   }   }  io util . assert file is writable ( output )  ;  final  sam reader bam ;  if  ( input url  !  =  null )   {  bam =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . disable (  sam reader factory .  option . eagerly   decode )  . enable (  sam reader factory .  option . include   source   in   records )  . open (  sam input resource . of ( input url )  )  ;   }  else  {  io util . assert file is readable ( input file )  ;  bam =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . enable (  sam reader factory .  option . include   source   in   records )  . open ( input file )  ;   }  if  ( bam . type (  )   !  =   sam reader .  type . bam   type )   {  throw new sam exception ( "" input file must be bam file  not sam file . "" )  ;   }  if  (  ! bam . get file header (  )  . get sort order (  )  . equals ( sam file header .  sort order . coordinate )  )   {  throw new sam exception ( "" input bam file must be sorted by coordinate"" )  ;   }  bam indexer . create index ( bam output )  ;  log . info ( "" successfully wrote bam index file ""  +  output )  ;   closer util . close ( bam )  ;  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\BuildBamIndex.java,main,public static void   ( final  string[] argv )  {   system . exit ( new  build bam index (  )  . instance main ( argv )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CreateSequenceDictionary.java, create sequence dictionary,"public   (  )  {  try  {  md5 =  message digest . get instance ( ""md5"" )  ;   }  catch  (   no such algorithm exception e )   {  throw new  picard exception ( ""md5 algorithm not found"" e )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CreateSequenceDictionary.java,clone,public  string codec   (  )  {  return new  string codec (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CreateSequenceDictionary.java,custom command line validation,"protected  string[]   (  )  {  if  ( uri  =  =  null )   {  uri = ""file:""  +  reference sequence . get reference file (  )  . get absolute path (  )  ;   }  if  ( output  =  =  null )   {  output =  reference sequence file factory . get default dictionary for reference sequence ( reference sequence . get reference file (  )  )  ;  logger . info ( "" output dictionary will be written in "" output )  ;   }  return super . custom command line validation (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CreateSequenceDictionary.java,decode,"public  string   (  )  {  try  {  return dis . readutf (  )  ;   }  catch  (  eof exception e )   {  return null ;   }  catch  (  io exception e )   {  throw new  picard exception ( "" exception reading sequence name from temporary file . "" e )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CreateSequenceDictionary.java,do work,"protected int   (  )  {  if  ( output . exists (  )  )   {  throw new  picard exception ( output . get absolute path (  )   +  "" already exists .   delete this file and try again  or specify a different output file . "" )  ;   }  final  sorting collection <  string >  sequence names = make sorting collection (  )  ;  try  (  buffered writer writer = make writer (  )  )  {  final  reference sequence file ref seq file =  reference sequence file factory . get reference sequence file ( reference   sequence truncate   names   at   whitespace )  ;  sam sequence dictionary codec sam dict codec = new sam sequence dictionary codec ( writer )  ;  sam dict codec . encode header line ( false )  ;  for  (  reference sequence ref seq = ref seq file . next sequence (  )  ;  ref seq  !  =  null ;  ref seq = ref seq file . next sequence (  )  )   {  final sam sequence record sam sequence record = make sequence record ( ref seq )  ;  sam dict codec . encode sequence record ( sam sequence record )  ;  sequence names . add ( ref seq . get name (  )  )  ;   }   }  catch  (   file not found exception e )   {  throw new  picard exception ( "" file ""  +  output . get absolute path (  )   +  "" not found"" )  ;   }  catch  (  io exception e )   {  throw new  picard exception ( "" can't write to or close output file ""  +  output . get absolute path (  )  )  ;   }  final  closeable iterator <  string >  iterator = sequence names . iterator (  )  ;  if  (  ! iterator . has next (  )  )  return 0 ;   string current = iterator . next (  )  ;  while  ( iterator . has next (  )  )   {  final  string next = iterator . next (  )  ;  if  ( current . equals ( next )  )   {  output . delete (  )  ;  throw new  picard exception ( "" sequence name ""  +  current  +  "" appears more than once in reference file"" )  ;   }  current = next ;   }  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CreateSequenceDictionary.java,encode,public void   ( final  string str )  {  try  {  dos . writeutf ( str )  ;   }  catch  (  io exception e )   {  throw new  runtimeio exception ( e )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CreateSequenceDictionary.java,get reference file,@ override public  file   (  )  {  return reference ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CreateSequenceDictionary.java,main,public static void   ( final  string[] argv )  {   system . exit ( new  create sequence dictionary (  )  . instance main ( argv )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CreateSequenceDictionary.java,make reference argument collection,@ override protected  reference argument collection   (  )  {  return new  create seq dict reference argument collection (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CreateSequenceDictionary.java,make sequence dictionary,@ deprecated public sam sequence dictionary   ( final  file reference file )  {  final  reference sequence file ref seq file =  reference sequence file factory . get reference sequence file ( reference file truncate   names   at   whitespace )  ;   refere
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CreateSequenceDictionary.java,make sequence record,private sam sequence record   ( final  reference sequence ref seq )  {  final sam sequence record ret = new sam sequence record ( ref seq . get name (  )  ref seq . length (  )  )  ;  final byte[] bases = ref seq . get bases (  )  ;  for  ( int i = 0 ;  i  <  bases . length ;   +  + i )   {  bases[i] =  string util . to upper case ( bases[i] )  ;   }  ret . set attribute ( sam sequence record . md5   tag md5 hash ( bases )  )  ;  if  ( genome   assembly  !  =  null )   {  ret . set attribute ( sam sequence record . assembly   tag genome   assembly )  ;   }  ret . set attribute ( sam sequence record . uri   tag uri )  ;  if  ( species  !  =  null )   {  ret . set attribute ( sam sequence record . species   tag species )  ;   }  return ret ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CreateSequenceDictionary.java,make sorting collection,private  sorting collection <  string >    (  )  {  final  string name = get class (  )  . get simple name (  )  ;  final  file tmp dir = io util . create temp dir ( name null )  ;  tmp dir . delete on exit (  )  ;  long max names in ram =  runtime . get runtime (  )  . max memory (  )   /  256  /  10 ;  return  sorting collection . new instance (  string . class new  string codec (  )   string::compare to  ( int )  math . min ( max names in ram  integer . max   value )  tmp dir )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CreateSequenceDictionary.java,make writer,"private  buffered writer   (  )  throws  file not found exception  {  return new  buffered writer ( new  ascii writer ( this . create   md5   file  ?  new  md5 calculating output stream ( new  file output stream ( output false )  new  file ( output . get absolute path (  )   +  "" . md5"" )  )  : new  file output stream ( output )  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CreateSequenceDictionary.java,md hash,"private  string   ( final byte[] bytes )  {  md5 . reset (  )  ;  md5 . update ( bytes )  ;   string s = new  big integer ( 1 md5 . digest (  )  )  . to string ( 16 )  ;  if  ( s . length (  )   !  =  32 )   {  final  string zeros = ""00000000000000000000000000000000"" ;  s = zeros . substring ( 0 32  -  s . length (  )  )   +  s ;   }  return s ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CreateSequenceDictionary.java,set input stream,public void   ( final  input stream is )  {  dis = new  data input stream ( is )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CreateSequenceDictionary.java,set output stream,public void   ( final  output stream os )  {  dos = new  data output stream ( os )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\DownsampleSam.java,custom command line validation,"@ override protected  string[]   (  )  {  if  ( probability  <  0 || probability  >  1 )  return new  string[] { "" downsampling requires 0 <  = probability <  = 1 .   found invalid value: ""  +  probability }  ;  return super . custom command line validati"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\DownsampleSam.java,do work,"@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  if  ( probability  =  =  1 )   {  log . warn ( "" running  downsample sam with probability = 1 !   this will likely just re"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\DownsampleSam.java,get reference file,@ override public  file   (  )  {  return reference   sequence ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\DownsampleSam.java,make reference argument collection,"@ override protected  reference argument collection   (  )  {  return new  reference argument collection (  )  {  @ argument ( doc = "" the reference sequence file . "" optional = true common = false )  public  file reference   sequence ;  @ override public"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\EarliestFragmentPrimaryAlignmentSelectionStrategy.java,get index of first aligned base,int   ( final sam record rec )  {  final  list <  alignment block >  alignment blocks = rec . get alignment blocks (  )  ;  if  ( rec . get read negative strand flag (  )  )   {  final  alignment block alignment block = alignment blocks . get ( alignment blocks . size (  )   -  1 )  ;  return rec . get read length (  )   -   coord math . get end ( alignment block . get read start (  )  alignment block . get length (  )  )   +  1 ;   }  else  {  return alignment blocks . get ( 0 )  . get read start (  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\EarliestFragmentPrimaryAlignmentSelectionStrategy.java,pick primary alignment,"public void   ( final  hits for insert hits for insert )  {  if  ( hits for insert . num hits (  )   =  =  0 )  throw new  illegal argument exception ( "" no alignments to pick from"" )  ;  final  list <  integer >  earliest alignments = new  array list <  integer >  (  )  ;  int earliest mapped base =  integer . max   value ;  int best mapq =  - 1 ;  for  ( int i = 0 ;  i  <  hits for insert . num hits (  )  ;   +  + i )   {  final sam record rec = hits for insert . get fragment ( i )  ;  if  ( rec . get read unmapped flag (  )  )  continue ;  final int this first mapped base = get index of first aligned base ( rec )  ;  final int this mapq = rec . get mapping quality (  )  ;  if  ( this first mapped base  <  earliest mapped base ||  ( this first mapped base  =  =  earliest mapped base && this mapq  >  best mapq )  )   {  earliest alignments . clear (  )  ;  earliest alignments . add ( i )  ;  earliest mapped base = this first mapped base ;  best mapq = this mapq ;   }  else if  ( this first mapped base  =  =  earliest mapped base && this mapq  =  =  best mapq )   {  earliest alignments . add ( i )  ;   }   }  if  ( earliest alignments . size (  )   =  =  1 )   {  hits for insert . set primary alignment ( earliest alignments . get ( 0 )  )  ;   }  else  {  hits for insert . set primary alignment ( earliest alignments . get ( random . next int ( earliest alignments . size (  )  )  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,are equal,public boolean   (  )  {  return are equal ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,compare alignment coordinates,private int   ( final sam record left final sam record right )  {  final  string left reference name = left . get reference name (  )  ;  final  string right reference name = right . get reference name (  )  ;  if  ( left reference name  =  =  null && right reference name  =  =  null )   {  return 0 ;   }  else if  ( left reference name  =  =  null )   {  return 1 ;   }  else if  ( right reference name  =  =  null )   {  return  - 1 ;   }  final int left reference index = sam readers[0] . get file header (  )  . get sequence index ( left reference name )  ;  final int right reference index = sam readers[0] . get file header (  )  . get sequence index ( right reference name )  ;  if  ( left reference index  !  =  right reference index )   {  return left reference index  -  right reference index ;   }  return left . get alignment start (  )   -  right . get alignment start (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,compare alignments,"private boolean   (  )  {  if  (  ! compare values ( sam readers[0] . get file header (  )  . get sort order (  )  sam readers[1] . get file header (  )  . get sort order (  )  "" sort  order"" )  )   {   system . out . println ( "" cannot compare alignments if sort orders differ . "" )  ;  return false ;   }  switch  ( sam readers[0] . get file header (  )  . get sort order (  )  )   {  case coordinate: if  ( sequence dictionaries differ )   {   system . out . println ( "" cannot compare coordinate - sorted sam files because sequence dictionaries differ . "" )  ;  return false ;   }  return compare coordinate sorted alignments (  )  ;  case queryname: return compare query name sorted alignments (  )  ;  case duplicate: case unsorted: return compare unsorted alignments (  )  ;  default : return false ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,compare coordinate sorted alignments,private boolean   (  )  {  final  secondary or supplementary skipping iterator it left = new  secondary or supplementary skipping iterator ( sam readers[0] . iterator (  )  )  ;  final  secondary or supplementary skipping iterator it right = new  secondary or supplementary skipping iterator ( sam readers[1] . iterator (  )  )  ;  final  map <  string sam record >  left unmatched = new  hash map <  string sam record >  (  )  ;  final  map <  string sam record >  right unmatched = new  hash map <  string sam record >  (  )  ;  boolean ret = true ;  while  ( it left . has current (  )  )   {  if  (  ! it right . has current (  )  )   {  for  (  ;  it left . has current (  )  ;  it left . advance (  )  )   {  final sam record left = it left . get current (  )  ;  final sam record right = right unmatched . remove ( get key for record ( left )  )  ;  if  ( right  =  =  null )   {   +  + missing right ;   }  else  {  tally alignment records ( left right )  ;   }   }  break ;   }  final sam record left = it left . get current (  )  ;  final  map <  string sam record >  left current coordinate = new  hash map <  string sam record >  (  )  ;  left current coordinate . put ( get key for record ( left )  left )  ;  while  ( it left . advance (  )  )   {  final sam record next left = it left . get current (  )  ;  if  ( compare alignment coordinates ( left next left )   =  =  0 )   {  left current coordinate . put ( get key for record ( next left )  next left )  ;   }  else  {  break ;   }   }  while  ( it right . has current (  )  && compare alignment coordinates ( left it right . get current (  )  )   >  0 )   {  final sam record right = it right . get current (  )  ;  right unmatched . put ( get key for record ( right )  right )  ;  it right . advance (  )  ;   }  for  (  ;  it right . has current (  )  && compare alignment coordinates ( left it right . get current (  )  )   =  =  0 ;  it right . advance (  )  )   {  final sam record right = it right . get current (  )  ;  final sam record matching left = left current coordinate . remove ( get key for record ( right )  )  ;  if  ( matching left  !  =  null )   {  ret = tally alignment records ( matching left right )  && ret ;   }  else  {  right unmatched . put ( get key for record ( right )  right )  ;   }   }  for  (  final sam record sam record : left current coordinate . values (  )  )   {  left unmatched . put ( get key for record ( sam record )  sam record )  ;   }   }  for  (  ;  it right . has current (  )  ;  it right . advance (  )  )   {  final sam record right = it right . get current (  )  ;  final sam record left = left unmatched . remove ( get key for record ( right )  )  ;  if  ( left  !  =  null )   {  tally alignment records ( left right )  ;   }  else  {   +  + missing left ;   }   }  for  (  final  map .  entry <  string sam record >  left entry : left unmatched . entry set (  )  )   {  final  string key = left entry . get key (  )  ;  final sam record left = left entry . get value (  )  ;  final sam record right = right unmatched . remove ( key )  ;  if  ( right  =  =  null )   {   +  + missing right ;  continue ;   }  tally alignment records ( left right )  ;   }  missing left +  = right unmatched . size (  )  ;  if  ( ret &&  ( missing left  >  0 || missing right  >  0 || mappings differ  >  0 || unmapped left  >  0 || unmapped right  >  0 )  )   {  ret = false ;   }  return ret ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,compare headers,"private boolean   (  )  {  final sam file header h1 = sam readers[0] . get file header (  )  ;  final sam file header h2 = sam readers[1] . get file header (  )  ;  boolean ret = compare values ( h1 . get version (  )  h2 . get version (  )  "" file format version"" )  ;  ret = compare values ( h1 . get creator (  )  h2 . get creator (  )  "" file creator"" )  && ret ;  ret = compare values ( h1 . get attribute ( ""so"" )  h2 . get attribute ( ""so"" )  "" sort order"" )  && ret ;  if  (  ! compare sequence dictionaries ( h1 h2 )  )   {  ret = false ;  sequence dictionaries differ = true ;   }  ret = compare read groups ( h1 h2 )  && ret ;  ret = compare program records ( h1 h2 )  && ret ;  return ret ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,compare program record,"private boolean   ( final sam program record program record1 final sam program record program record2 )  {  if  ( program record1  =  =  null && program record2  =  =  null )   {  return true ;   }  if  ( program record1  =  =  null )   {  report difference ( ""null"" program record2 . get program group id (  )  "" program  record"" )  ;  return false ;   }  if  ( program record2  =  =  null )   {  report difference ( program record1 . get program group id (  )  ""null"" "" program  record"" )  ;  return false ;   }  boolean ret = compare values ( program record1 . get program group id (  )  program record2 . get program group id (  )  "" program  name"" )  ;  final  string[] attributes =  { ""vn"" ""cl"" }  ;  for  (  final  string attribute : attributes )   {  ret = compare values ( program record1 . get attribute ( attribute )  program record2 . get attribute ( attribute )  attribute  +  ""  program  record attribute"" )  && ret ;   }  return ret ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,compare program records,"private boolean   ( final sam file header h1 final sam file header h2 )  {  final  list < sam program record >  l1 = h1 . get program records (  )  ;  final  list < sam program record >  l2 = h2 . get program records (  )  ;  if  (  ! compare values ( l1 . size (  )  l2 . size (  )  "" number of program records"" )  )   {  return false ;   }  boolean ret = true ;  for  ( int i = 0 ;  i  <  l1 . size (  )  ;   +  + i )   {  ret = compare program record ( l1 . get ( i )  l2 . get ( i )  )  && ret ;   }  return ret ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,compare query name sorted alignments,private boolean   (  )  {  final  secondary or supplementary skipping iterator it1 = new  secondary or supplementary skipping iterator ( sam readers[0] . iterator (  )  )  ;  final  secondary or supplementary skipping iterator it2 = new  secondary or supplementary skipping iterator ( sam readers[1] . iterator (  )  )  ;  boolean ret = true ;  while  ( it1 . has current (  )  )   {  if  (  ! it2 . has current (  )  )   {  missing right +  = count remaining ( it1 )  ;  return false ;   }  final int cmp = it1 . get current (  )  . get read name (  )  . compare to ( it2 . get current (  )  . get read name (  )  )  ;  if  ( cmp  <  0 )   {   +  + missing right ;  it1 . advance (  )  ;  ret = false ;   }  else if  ( cmp  >  0 )   {   +  + missing left ;  it2 . advance (  )  ;  ret = false ;   }  else  {  if  (  ! tally alignment records ( it1 . get current (  )  it2 . get current (  )  )  )   {  ret = false ;   }  it1 . advance (  )  ;  it2 . advance (  )  ;   }   }  if  ( it2 . has current (  )  )   {  missing left +  = count remaining ( it2 )  ;  return false ;   }  return ret ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,compare read group,"private boolean   ( final sam read group record sam read group record1 final sam read group record sam read group record2 )  {  boolean ret = compare values ( sam read group record1 . get read group id (  )  sam read group record2 . get read group id (  )  "" read  group id"" )  ;  ret = compare values ( sam read group record1 . get sample (  )  sam read group record2 . get sample (  )  "" sample for read group ""  +  sam read group record1 . get read group id (  )  )  && ret ;  ret = compare values ( sam read group record1 . get library (  )  sam read group record2 . get library (  )  "" library for read group ""  +  sam read group record1 . get read group id (  )  )  && ret ;  final  string[] attributes =  { ""ds"" ""pu"" ""pi"" ""cn"" ""dt"" ""pl"" }  ;  for  (  final  string attribute : attributes )   {  ret = compare values ( sam read group record1 . get attribute ( attribute )  sam read group record2 . get attribute ( attribute )  attribute  +  "" for read group ""  +  sam read group record1 . get read group id (  )  )  && ret ;   }  return ret ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,compare read groups,"private boolean   ( final sam file header h1 final sam file header h2 )  {  final  list < sam read group record >  l1 = h1 . get read groups (  )  ;  final  list < sam read group record >  l2 = h2 . get read groups (  )  ;  if  (  ! compare values ( l1 . size (  )  l2 . size (  )  "" number of read groups"" )  )   {  return false ;   }  boolean ret = true ;  for  ( int i = 0 ;  i  <  l1 . size (  )  ;   +  + i )   {  ret = compare read group ( l1 . get ( i )  l2 . get ( i )  )  && ret ;   }  return ret ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,compare sequence dictionaries,"private boolean   ( final sam file header h1 final sam file header h2 )  {  final  list < sam sequence record >  s1 = h1 . get sequence dictionary (  )  . get sequences (  )  ;  final  list < sam sequence record >  s2 = h2 . get sequence dictionary (  )  . get sequences (  )  ;  if  ( s1 . size (  )   !  =  s2 . size (  )  )   {  report difference ( s1 . size (  )  s2 . size (  )  "" length of sequence dictionaries"" )  ;  return false ;   }  boolean ret = true ;  for  ( int i = 0 ;  i  <  s1 . size (  )  ;   +  + i )   {  ret = compare sequence record ( s1 . get ( i )  s2 . get ( i )  i  +  1 )  && ret ;   }  return ret ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,compare sequence record,"private boolean   ( final sam sequence record sequence record1 final sam sequence record sequence record2 final int which )  {  if  (  ! sequence record1 . get sequence name (  )  . equals ( sequence record2 . get sequence name (  )  )  )   {  report difference ( sequence record1 . get sequence name (  )  sequence record2 . get sequence name (  )  "" name of sequence record ""  +  which )  ;  return false ;   }  boolean ret = compare values ( sequence record1 . get sequence length (  )  sequence record2 . get sequence length (  )  "" length of sequence ""  +  sequence record1 . get sequence name (  )  )  ;  ret = compare values ( sequence record1 . get species (  )  sequence record2 . get species (  )  "" species of sequence ""  +  sequence record1 . get sequence name (  )  )  && ret ;  ret = compare values ( sequence record1 . get assembly (  )  sequence record2 . get assembly (  )  "" assembly of sequence ""  +  sequence record1 . get sequence name (  )  )  && ret ;  ret = compare values ( sequence record1 . get attribute ( ""m5"" )  sequence record2 . get attribute ( ""m5"" )  ""md5 of sequence ""  +  sequence record1 . get sequence name (  )  )  && ret ;  ret = compare values ( sequence record1 . get attribute ( ""ur"" )  sequence record2 . get attribute ( ""ur"" )  ""uri of sequence ""  +  sequence record1 . get sequence name (  )  )  && ret ;  return ret ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,compare unsorted alignments,"private boolean   (  )  {  final  secondary or supplementary skipping iterator it1 = new  secondary or supplementary skipping iterator ( sam readers[0] . iterator (  )  )  ;  final  secondary or supplementary skipping iterator it2 = new  secondary or supplementary skipping iterator ( sam readers[1] . iterator (  )  )  ;  boolean ret = true ;  for  (  ;  it1 . has current (  )  ;  it1 . advance (  )   it2 . advance (  )  )   {  if  (  ! it2 . has current (  )  )   {  missing right +  = count remaining ( it1 )  ;  return false ;   }  final sam record s1 = it1 . get current (  )  ;  final sam record s2 = it2 . get current (  )  ;  if  (  ! compare values ( s1 . get read name (  )  s2 . get read name (  )  "" read names"" )  )   {   system . out . println ( "" read names cease agreeing in unsorted sam files  .   comparison aborting . "" )  ;   }  ret = tally alignment records ( s1 s2 )  && ret ;   }  if  ( it2 . has current (  )  )   {  missing left +  = count remaining ( it2 )  ;  return false ;   }  return ret ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,compare values,private  < t > boolean   ( final t v1 final t v2 final  string label )  {  if  ( v1  =  =  null )   {  if  ( v2  =  =  null )   {  return true ;   }  report difference ( v1 v2 label )  ;  return false ;   }  if  ( v2  =  =  null )   {  report difference ( v1 v2 label )  ;  return false ;   }  if  (  ! v1 . equals ( v2 )  )   {  report difference ( v1 v2 label )  ;  return false ;   }  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,count remaining,private int   ( final  secondary or supplementary skipping iterator it )  {  int i ;  for  ( i = 0 ;  it . has current (  )  ;   +  + i )   {  it . advance (  )  ;   }  return i ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,do work,@ override protected int   (  )  {  for  ( int i = 0 ;  i  <  sam files . size (  )  ;   +  + i )   {  sam readers[i] =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . open ( sam files . get ( i )  )  ;   }  are e
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,get key for record,"private  string   ( final sam record record )  {  final boolean is second of pair = record . get read paired flag (  )  && record . get second of pair flag (  )  ;  return record . get read name (  )   +  "" - ""  +   ( is second of pair  ?  ""second"" : ""first"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,get mappings differ,public int   (  )  {  return mappings differ ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,get mappings match,public int   (  )  {  return mappings match ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,get missing left,public int   (  )  {  return missing left ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,get missing right,public int   (  )  {  return missing right ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,get unmapped both,public int   (  )  {  return unmapped both ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,get unmapped left,public int   (  )  {  return unmapped left ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,get unmapped right,public int   (  )  {  return unmapped right ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,main,public static void   (  string[] argv )  {  new  comparesa ms (  )  . instance main with exit ( argv )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,print report,"private void   (  )  {   system . out . println ( "" match\t""  +  mappings match )  ;   system . out . println ( "" differ\t""  +  mappings differ )  ;   system . out . println ( "" unmapped   both\t""  +  unmapped both )  ;   system . out . println ( "" unmapped   left\t""  +  unmapped left )  ;   system . out . println ( "" unmapped   right\t""  +  unmapped right )  ;   system . out . println ( "" missing   left\t""  +  missing left )  ;   system . out . println ( "" missing   right\t""  +  missing right )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,report difference,"private void   (  object o1  object o2 final  string label )  {  if  ( o1  =  =  null )   {  o1 = ""null"" ;   }  if  ( o2  =  =  null )   {  o2 = ""null"" ;   }  report difference ( o1 . to string (  )  o2 . to string (  )  label )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CompareSAMs.java,tally alignment records,"private boolean   ( final sam record s1 final sam record s2 )  {  if  (  ! s1 . get read name (  )  . equals ( s2 . get read name (  )  )  )   {  throw new  picard exception ( "" read names do not match: ""  +  s1 . get read name (  )   +  "" : "" +  s2 . get read name (  )  )  ;   }  if  ( s1 . get read unmapped flag (  )  && s2 . get read unmapped flag (  )  )   {   +  + unmapped both ;  return true ;   }  if  ( s1 . get read unmapped flag (  )  )   {   +  + unmapped left ;  return false ;   }  if  ( s2 . get read unmapped flag (  )  )   {   +  + unmapped right ;  return false ;   }  final boolean ret =  ( s1 . get reference name (  )  . equals ( s2 . get reference name (  )  )  && s1 . get alignment start (  )   =  =  s2 . get alignment start (  )  && s1 . get read negative strand flag (  )   =  =  s1 . get read negative strand flag (  )  )  ;  if  (  ! ret )   {   +  + mappings differ ;   }  else  {   +  + mappings match ;   }  return ret ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CleanSam.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  final  sam reader factory factory =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\CleanSam.java,main,public static void   ( final  string[] argv )  {  new  clean sam (  )  . instance main with exit ( argv )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FixMateInformation.java,close,@ override public void   (  )  {  super . close (  )  ;  sorter . cleanup (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FixMateInformation.java,close writer,protected void   (  )  {  out . close (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FixMateInformation.java,create sam file writer,protected void   ( final sam file header header )  {  out = new sam file writer factory (  )  . makesam orbam writer ( header header . get sort order (  )   =  =   sort order . queryname output )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FixMateInformation.java,do work,"protected int   (  )  {  boolean all query name sorted = true ;  final  list <  sam reader >  readers = new  array list <  >  (  )  ;  for  (  final  file f : input )   {  io util . assert file is readable ( f )  ;  final  sam reader reader =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . open ( f )  ;  readers . add ( reader )  ;  if  ( reader . get file header (  )  . get sort order (  )   !  =   sort order . queryname )  all query name sorted = false ;   }  if  ( output  !  =  null )  output = output . get absolute file (  )  ;  final boolean different output specified = output  !  =  null ;  if  ( different output specified )   {  io util . assert file is writable ( output )  ;   }  else if  ( input . size (  )   !  =  1 )   {  throw new  picard exception ( "" must specify either an explicit output file or a single input file to be overridden . "" )  ;   }  else  {  final  file sole input = input . get ( 0 )  . get absolute file (  )  ;  final  file dir = sole input . get parent file (  )  . get absolute file (  )  ;  try  {  io util . assert file is writable ( sole input )  ;  io util . assert directory is writable ( dir )  ;  output =  file . create temp file ( sole input . get name (  )   +  "" . being   fixed . ""  bam file io utils . bam   file   extension dir )  ;   }  catch  (  final io exception ioe )   {  throw new  runtimeio exception ( "" could not create tmp file in ""  +  dir . get absolute path (  )  )  ;   }   }  final  peekable iterator < sam record >  iterator ;  final sam file header header ;   {  final  iterator < sam record >  tmp ;  if  ( input . size (  )   >  1 )   {  final  list < sam file header >  headers = new  array list <  >  ( readers . size (  )  )  ;  for  (  final  sam reader reader : readers )   {  headers . add ( reader . get file header (  )  )  ;   }  final  sort order sort order =  ( all query name sorted  ?   sort order . queryname :  sort order . unsorted )  ;  final  sam file header merger merger = new  sam file header merger ( sort order headers false )  ;  tmp = new  merging sam record iterator ( merger readers false )  ;  header = merger . get merged header (  )  ;   }  else  {  tmp = readers . get ( 0 )  . iterator (  )  ;  header = readers . get ( 0 )  . get file header (  )  ;   }  if  ( assume   sorted || all query name sorted )   {  iterator = new  sam pair util .  set mate info iterator ( new  peekable iterator <  >  ( tmp )  add   mate   cigar ignore   missing   mates )  ;   }  else  {  log . info ( "" sorting input into queryname order . "" )  ;  final  sorting collection < sam record >  sorter =  sorting collection . new instance ( sam record . class new bam record codec ( header )  new sam record query name comparator (  )  max   records   in   ram tmp   dir )  ;  while  ( tmp . has next (  )  )   {  sorter . add ( tmp . next (  )  )  ;   }  iterator = new  sam pair util .  set mate info iterator ( new  peekable iterator < sam record >  ( sorter . iterator (  )  )  {  @ override public void close (  )  {  super . close (  )  ;  sorter . cleanup (  )  ;   }   }   add   mate   cigar ignore   missing   mates )  ;  log . info ( "" sorting by queryname complete . "" )  ;   }  final  sort order output sort order = sort   order  =  =  null  ?  readers . get ( 0 )  . get file header (  )  . get sort order (  )  : sort   order ;  log . info ( "" output will be sorted by ""  +  output sort order )  ;  header . set sort order ( output sort order )  ;   }  if  ( create   index && header . get sort order (  )   !  =   sort order . coordinate )   {  throw new  picard exception ( "" can't create   index unless sort order is coordinate"" )  ;   }  create sam file writer ( header )  ;  log . info ( "" traversing query name sorted records and fixing up mate pair information . "" )  ;  final  progress logger progress = new  progress logger ( log )  ;  while  ( iterator . has next (  )  )   {  final sam record record = iterator . next (  )  ;  out . add alignment ( record )  ;  progress . record ( record )  ;   }  iterator . close (  )  ;  if  ( header . get sort order (  )   =  =   sort order . queryname )   {  log . info ( "" closing output file . "" )  ;   }  else  {  log . info ( "" finished processing reads ;  re - sorting output file . "" )  ;   }  close writer (  )  ;  if  (  ! different output specified )   {  log . info ( "" replacing input file with fixed file . "" )  ;  final  file sole input = input . get ( 0 )  . get absolute file (  )  ;  final  file old = new  file ( sole input . get parent file (  )  sole input . get name (  )   +  "" . old"" )  ;  if  (  ! old . exists (  )  && sole input . rename to ( old )  )   {  if  ( output . rename to ( sole input )  )   {  if  (  ! old . delete (  )  )   {  log . warn ( "" could not delete old file: ""  +  old . get absolute path (  )  )  ;  return 1 ;   }  if  ( create   index )   {  final  file new index = new  file ( output . get parent (  )  output . get name (  )  . substring ( 0 output . get name (  )  . length (  )   -  4 )   +  "" . bai"" )  ;  final  file old index = new  file ( sole input . get parent (  )  sole input . get name (  )  . substring ( 0 sole input . get name (  )  . length (  )   -  4 )   +  "" . bai"" )  ;  if  (  ! new index . rename to ( old index )  )   {  log . warn ( "" could not overwrite index file: ""  +  old index . get absolute path (  )  )  ;   }   }   }  else  {  log . error ( "" could not move new file to ""  +  sole input . get absolute path (  )  )  ;  log . error ( "" input file preserved as: ""  +  old . get absolute path (  )  )  ;  log . error ( "" new file preserved as: ""  +  output . get absolute path (  )  )  ;  return 1 ;   }   }  else  {  log . error ( "" could not move input file out of the way: ""  +  sole input . get absolute path (  )  )  ;  if  (  ! output . delete (  )  )   {  log . error ( "" could not delete temporary file: ""  +  output . get absolute path (  )  )  ;   }  return 1 ;   }   }   closer util . close ( readers )  ;  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FixMateInformation.java,main,public static void   ( final  string[] args )  {  new  fix mate information (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FixMateInformation.java,write alignment,protected void   ( final sam record sam )  {  out . add alignment ( sam )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FilterSamReads.java, filter,  ( final  string description )  {  this . description = description ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FilterSamReads.java,check inputs,"private  optional <  string >    ( final  list <  filter >  filters final  object input object final  string input file variable )  {  if  ( filters . contains ( filter )  && input object  =  =  null )  return  optional . of (  string . format ( ""%s must be specified when using filter = %s  but it was null . "" input file variable filter )  )  ;  if  (  ! filters . contains ( filter )  && input object  !  =  null )  return  optional . of (  string . format ( ""%s may only be specified when using filter from %s  filter value: %s  %s value: %s"" input file variable  string . join ( ""  "" filters . stream (  )  . map (  enum::to string )  . collect (  collectors . to list (  )  )  )  filter input file variable input object )  )  ;  return  optional . empty (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FilterSamReads.java,custom command line validation,"@ override protected  string[]   (  )  {   list <  string >  errors = new  array list <  >  (  )  ;  if  ( input . equals ( output )  )  errors . add ( ""input file and output file must differ ! "" )  ;   list <  filter >  tag filters =  arrays . as list ( "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FilterSamReads.java,do work,@ override protected int   (  )  {  try  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  if  ( write   reads   files )  write reads file ( input )  ;  final  sam reader sam reader =  sam reader factory .
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FilterSamReads.java,filter reads,"private void   ( final  filtering sam iterator filtering iterator )  {  final sam file header file header =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . get file header ( input )  ;  final sam file header .  sort order input sort order = file header . get sort order (  )  ;  if  ( sort   order  !  =  null )   {  file header . set sort order ( sort   order )  ;   }  if  ( filter  =  =   filter . include paired intervals && file header . get sort order (  )   !  =  sam file header .  sort order . coordinate )   {  throw new  unsupported operation exception ( "" input must be coordinate sorted to use include paired intervals"" )  ;   }  final boolean presorted = input sort order . equals ( file header . get sort order (  )  )  ;  log . info ( "" filtering [presorted = ""  +  presorted  +  ""] "" +  input . get name (  )  +  ""  -  >  output = "" +  output . get name (  )  +  "" [sortorder = "" +  file header . get sort order (  )  . name (  )  +  ""]"" )  ;  final sam file writer output writer = new sam file writer factory (  )  . makesam orbam writer ( file header presorted output )  ;  final  progress logger progress = new  progress logger ( log  ( int ) 1e6 "" written"" )  ;  while  ( filtering iterator . has next (  )  )   {  final sam record rec = filtering iterator . next (  )  ;  output writer . add alignment ( rec )  ;  progress . record ( rec )  ;   }  filtering iterator . close (  )  ;  output writer . close (  )  ;  log . info ( new  decimal format ( ""# ###"" )  . format ( progress . get count (  )  )   +  "" sam records written to ""  +  output . get name (  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FilterSamReads.java,get help doc,@ override public  string   (  )  {  return description ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FilterSamReads.java,get interval list,private  list <  interval >    ( final  file interval file )  throws io exception  {  io util . assert file is readable ( interval file )  ;  return  interval list . from file ( interval file )  . get intervals (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FilterSamReads.java,write reads file,"private void   ( final  file sam or bam file )  throws io exception  {  final  file reads file = new  file ( output . get parent file (  )  io util . basename ( sam or bam file )   +  "" . reads"" )  ;  io util . assert file is writable ( reads file )  ;  try  ( final  sam reader reader =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . open ( sam or bam file )  ; final  buffered writer bw = io util . open file for buffered writing ( reads file false )  )  {  for  (  final sam record rec : reader )   {  bw . write ( rec . to string (  )   +  ""\n"" )  ;   }   }  io util . assert file is readable ( reads file )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\GatherBamFiles.java,determine block copying status,private boolean   ( final  list <  file >  inputs )  {  boolean use block copying = true ;  for  (  final  file f : inputs )   {  if  (  !  bam file io utils . is bam file ( f )  )   {  use block copying = false ;   }   }  return use block copying ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\GatherBamFiles.java,do work,"@ override protected int   (  )  {  final  list <  file >  inputs = io util . unroll files ( input  bam file io utils . bam   file   extension "" . sam"" )  ;  for  (  final  file f : inputs )  io util . assert file is readable ( f )  ;  io util . assert fi"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\GatherBamFiles.java,gather normally,"private static void   ( final  list <  file >  inputs final  file output final boolean create index final boolean create md5 final  file reference fasta )  {  final sam file header header ;   {  header =  sam reader factory . make default (  )  . reference sequence ( reference fasta )  . get file header ( inputs . get ( 0 )  )  ;   }  final sam file writer out = new sam file writer factory (  )  . set create index ( create index )  . set create md5 file ( create md5 )  . makesam orbam writer ( header true output )  ;  for  (  final  file f : inputs )   {  log . info ( "" gathering ""  +  f . get absolute path (  )  )  ;  final  sam reader in =  sam reader factory . make default (  )  . reference sequence ( reference fasta )  . open ( f )  ;  for  (  final sam record rec : in )  out . add alignment ( rec )  ;   closer util . close ( in )  ;   }  out . close (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\GatherBamFiles.java,main,public static void   ( final  string[] args )  {  final  gather bam files gatherer = new  gather bam files (  )  ;  gatherer . create   index = true ;  gatherer . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FastqToSam.java,convert quality,void   ( final byte[] quals final  fastq quality format version )  {  switch  ( version )   {  case  standard: sam utils . fastq to phred ( quals )  ;  break ;  case  solexa: solexa quality converter . convert solexa quality chars to phred binary ( quals )  ;  break ;  case  illumina: solexa quality converter . convert solexa   1   3    quality chars to phred binary ( quals )  ;  break ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FastqToSam.java,create sam file header,public sam file header   (  )  {  final sam read group record rgroup = new sam read group record ( this . read   group   name )  ;  rgroup . set sample ( this . sample   name )  ;  if  ( this . library   name  !  =  null )  rgroup . set library ( this . library   name )  ;  if  ( this . platform  !  =  null )  rgroup . set platform ( this . platform )  ;  if  ( this . platform   unit  !  =  null )  rgroup . set platform unit ( this . platform   unit )  ;  if  ( this . sequencing   center  !  =  null )  rgroup . set sequencing center ( sequencing   center )  ;  if  ( this . predicted   insert   size  !  =  null )  rgroup . set predicted median insert size ( predicted   insert   size )  ;  if  ( this . description  !  =  null )  rgroup . set description ( this . description )  ;  if  ( this . run   date  !  =  null )  rgroup . set run date ( this . run   date )  ;  if  ( this . platform   model  !  =  null )  rgroup . set platform model ( this . platform   model )  ;  if  ( this . program   group  !  =  null )  rgroup . set program group ( this . program   group )  ;  final sam file header header = new sam file header (  )  ;  header . add read group ( rgroup )  ;  for  (  final  string comment : comment )   {  header . add comment ( comment )  ;   }  header . set sort order ( this . sort   order )  ;  return header ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FastqToSam.java,create sam record,"private sam record   ( final sam file header header final  string base name final  fastq record frec final boolean paired )  {  final sam record srec = new sam record ( header )  ;  srec . set read name ( base name )  ;  srec . set read string ( frec . get read string (  )  )  ;  srec . set read unmapped flag ( true )  ;  srec . set attribute (  reserved tag constants . read   group   id read   group   name )  ;  final byte[] quals =  string util . string to bytes ( frec . get base quality string (  )  )  ;  convert quality ( quals quality   format )  ;  for  (  final byte qual : quals )   {  final int u qual = qual & 0xff ;  if  ( u qual  <  min   q || u qual  >  max   q )   {  throw new  picard exception ( "" base quality ""  +  u qual  +  "" is not in the range "" +  min   q +  "" .  . "" +  max   q +  "" for read "" +  frec . get read header (  )  )  ;   }   }  srec . set base qualities ( quals )  ;  if  ( paired )   {  srec . set read paired flag ( true )  ;  srec . set mate unmapped flag ( true )  ;   }  return srec ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FastqToSam.java,custom command line validation,"@ override protected  string[]   (  )  {  if  ( min   q  <  0 )  return new  string[] { ""min   q must be  >  =  0"" }  ;  if  ( max   q  >  sam utils . max   phred   score )  return new  string[] { ""max   q must be  <  =  ""  +  sam utils . max   phred   sc"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FastqToSam.java,determine quality format,"public static  fastq quality format   ( final  fastq reader reader1 final  fastq reader reader2 final  fastq quality format expected quality )  {  final  quality encoding detector detector = new  quality encoding detector (  )  ;  if  ( reader2  =  =  null )   {  detector . add (  quality encoding detector . default   max   records   to   iterate reader1 )  ;   }  else  {  detector . add (  quality encoding detector . default   max   records   to   iterate reader1 reader2 )  ;  reader2 . close (  )  ;   }  reader1 . close (  )  ;  final  fastq quality format quality format = detector . generate best guess (  quality encoding detector .  file context . fastq expected quality )  ;  if  ( detector . is determination ambiguous (  )  )   {  log . warn ( "" making ambiguous determination about fastq's quality encoding ;  more than one format possible based on observed qualities . "" )  ;   }  log . info (  string . format ( "" auto - detected quality format as: %s . "" quality format )  )  ;  return quality format ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FastqToSam.java,do paired,"protected int   ( final  fastq reader freader1 final  fastq reader freader2 final sam file writer writer )  {  int read count = 0 ;  final  progress logger progress = new  progress logger ( log )  ;  for  (  ;  freader1 . has next (  )  && freader2 . has next (  )  ;  read count +  +  )   {  final  fastq record frec1 = freader1 . next (  )  ;  final  fastq record frec2 = freader2 . next (  )  ;  final  string frec1 name =  sequence util . get sam read name from fastq header ( frec1 . get read header (  )  )  ;  final  string frec2 name =  sequence util . get sam read name from fastq header ( frec2 . get read header (  )  )  ;  final  string base name = get base name ( frec1 name frec2 name freader1 freader2 )  ;  final sam record srec1 = create sam record ( writer . get file header (  )  base name frec1 true )  ;  srec1 . set first of pair flag ( true )  ;  srec1 . set second of pair flag ( false )  ;  writer . add alignment ( srec1 )  ;  progress . record ( srec1 )  ;  final sam record srec2 = create sam record ( writer . get file header (  )  base name frec2 true )  ;  srec2 . set first of pair flag ( false )  ;  srec2 . set second of pair flag ( true )  ;  writer . add alignment ( srec2 )  ;  progress . record ( srec2 )  ;   }  if  ( freader1 . has next (  )  || freader2 . has next (  )  )   {  throw new  picard exception ( "" input paired fastq files must be the same length"" )  ;   }  return read count ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FastqToSam.java,do unpaired,protected int   ( final  fastq reader freader final sam file writer writer )  {  int read count = 0 ;  final  progress logger progress = new  progress logger ( log )  ;  for  (  ;  freader . has next (  )  ;  read count +  +  )   {  final  fastq record frec = freader . next (  )  ;  final sam record srec = create sam record ( writer . get file header (  )   sequence util . get sam read name from fastq header ( frec . get read header (  )  )  frec false )  ;  srec . set read paired flag ( false )  ;  writer . add alignment ( srec )  ;  progress . record ( srec )  ;   }  return read count ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FastqToSam.java,do work,"protected int   (  )  {  io util . assert file is readable ( fastq )  ;  if  ( fastq2  !  =  null )   {  io util . assert file is readable ( fastq2 )  ;   }  io util . assert file is writable ( output )  ;  final sam file header header = create sam file header (  )  ;  final sam file writer writer = new sam file writer factory (  )  . makesam orbam writer ( header false output )  ;  quality   format =  fastq to sam . determine quality format ( file to fastq reader ( fastq )   ( fastq2  =  =  null )   ?  null : file to fastq reader ( fastq2 )  quality   format )  ;  final  list <  fastq reader >  readers1 = new  array list <  fastq reader >  (  )  ;  final  list <  fastq reader >  readers2 = new  array list <  fastq reader >  (  )  ;  if  ( use   sequential   fastqs )   {  for  (  final  file fastq : get sequential file list ( fastq )  )   {  readers1 . add ( file to fastq reader ( fastq )  )  ;   }  if  ( null  !  =  fastq2 )   {  for  (  final  file fastq : get sequential file list ( fastq2 )  )   {  readers2 . add ( file to fastq reader ( fastq )  )  ;   }  if  ( readers1 . size (  )   !  =  readers2 . size (  )  )   {  throw new  picard exception (  string . format ( "" found %d files for fastq and %d files for fastq2 . "" readers1 . size (  )  readers2 . size (  )  )  )  ;   }   }   }  else  {  readers1 . add ( file to fastq reader ( fastq )  )  ;  if  ( fastq2  !  =  null )   {  readers2 . add ( file to fastq reader ( fastq2 )  )  ;   }   }  for  ( int idx = 0 ;  idx  <  readers1 . size (  )  ;  idx +  +  )   {  make it so ( readers1 . get ( idx )   ( readers2 . is empty (  )  )   ?  null : readers2 . get ( idx )  writer )  ;   }  for  (  final  fastq reader reader : readers1 )  reader . close (  )  ;  for  (  final  fastq reader reader : readers2 )  reader . close (  )  ;  writer . close (  )  ;  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FastqToSam.java,error,"private  string   ( final  fastq reader freader final  string str )  {  return str  +  "" at line ""  +  freader . get line number (  )  +  "" in file "" +  freader . get file (  )  . get absolute path (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FastqToSam.java,file to fastq reader,private  fastq reader   ( final  file file )  {  return new  fastq reader ( file allow   and   ignore   empty   lines )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FastqToSam.java,get base name," string   ( final  string read name1 final  string read name2 final  fastq reader freader1 final  fastq reader freader2 )  {   string[] toks = get read name tokens ( read name1 1 freader1 )  ;  final  string base name1 = toks[0] ;  final  string num1 = toks[1] ;  toks = get read name tokens ( read name2 2 freader2 )  ;  final  string base name2 = toks[0] ;  final  string num2 = toks[1] ;  if  (  ! base name1 . equals ( base name2 )  )   {  throw new  picard exception (  string . format ( "" in paired mode  read name 1  ( %s )  does not match read name 2  ( %s ) "" base name1 base name2 )  )  ;   }  final boolean num1 blank =  string util . is blank ( num1 )  ;  final boolean num2 blank =  string util . is blank ( num2 )  ;  if  ( num1 blank || num2 blank )   {  if  (  ! num1 blank )  throw new  picard exception ( error ( freader1 "" pair 1 number is missing  ( ""  +  read name1  +  "" )  .   both pair numbers must be present or neither . "" )  )  ;  else if  (  ! num2 blank )  throw new  picard exception ( error ( freader2 "" pair 2 number is missing  ( ""  +  read name2  +  "" )  .   both pair numbers must be present or neither . "" )  )  ;   }  else  {  if  (  ! num1 . equals ( ""1"" )  )  throw new  picard exception ( error ( freader1 "" pair 1 number must be 1  ( ""  +  read name1  +  "" ) "" )  )  ;  if  (  ! num2 . equals ( ""2"" )  )  throw new  picard exception ( error ( freader2 "" pair 2 number must be 2  ( ""  +  read name2  +  "" ) "" )  )  ;   }  return base name1 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FastqToSam.java,get read name tokens,"private  string[]   ( final  string read name final int pair num final  fastq reader freader )  {  if  ( read name . equals ( """" )  )  throw new  picard exception ( error ( freader "" pair read name ""  +  pair num  +  "" cannot be empty: "" +  read name )  )  ;  final int idx = read name . last index of ( ' / ' )  ;  final  string[] result = new  string[2] ;  if  ( idx  =  =   - 1 )   {  result[0] = read name ;  result[1] = null ;   }  else  {  result[1] = read name . substring ( idx  +  1 read name . length (  )  )  ;  if  (  ! result[1] . equals ( ""1"" )  &&  ! result[1] . equals ( ""2"" )  )   {  result[0] = read name ;  result[1] = null ;   }  else  {  result[0] = read name . substring ( 0 idx )  ;   }   }  return result ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FastqToSam.java,get sequential file list,"protected static  list <  file >    ( final  file base fastq )  {  final  list <  file >  files = new  array list <  file >  (  )  ;  files . add ( base fastq )  ;   fastq extensions fastq extensions = null ;   string suffix = null ;  for  (  final  fastq extensions ext :  fastq extensions . values (  )  )   {  suffix = ""   001""  +  ext . get extension (  )  ;  if  ( base fastq . get absolute path (  )  . ends with ( suffix )  )   {  fastq extensions = ext ;  break ;   }   }  if  ( null  =  =  fastq extensions )   {  throw new  picard exception (  string . format ( "" could not parse the fastq extension  ( expected '   001'  +  '%s' ) : %s""  fastq extensions . values (  )  . to string (  )  base fastq )  )  ;   }  for  ( int idx = 2 ;  true ;  idx +  +  )   {   string fastq = base fastq . get absolute path (  )  ;  fastq =  string . format ( ""%s   %03d%s"" fastq . substring ( 0 fastq . length (  )   -  suffix . length (  )  )  idx fastq extensions . get extension (  )  )  ;  try  {  io util . assert file is readable ( new  file ( fastq )  )  ;   }  catch  (  final sam exception e )   {  break ;   }  files . add ( new  file ( fastq )  )  ;   }  return files ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FastqToSam.java,main,public static void   ( final  string[] argv )  {   system . exit ( new  fastq to sam (  )  . instance main ( argv )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\FastqToSam.java,make it so,"public void   ( final  fastq reader reader1 final  fastq reader reader2 final sam file writer writer )  {  final int read count =  ( reader2  =  =  null )   ?  do unpaired ( reader1 writer )  : do paired ( reader1 reader2 writer )  ;  log . info ( "" processed ""  +  read count  +  "" fastq reads"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\DuplicationMetrics.java,calculate derived fields,@ override public void   (  )  {  this . estimated   library   size = estimate library size ( this . read   pairs   examined  -  this . read   pair   optical   duplicates this . read   pairs   examined  -  this . read   pair   duplicates )  ;  percent   d
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\DuplicationMetrics.java,calculate derived metrics,@ deprecated public void   (  )  {  this . calculate derived fields (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\DuplicationMetrics.java,calculate roi histogram,public  histogram <  double >    (  )  {  if  ( estimated   library   size  =  =  null )   {  try  {  calculate derived fields (  )  ;  if  ( estimated   library   size  =  =  null )   {  return null ;   }   }  catch  (   illegal state exception ise )   {  return null ;   }   }  long unique pairs = read   pairs   examined  -  read   pair   duplicates ;   histogram <  double >  histo = new  histogram <  >  (  )  ;  for  ( double x = 1 ;  x  <  =  100 ;  x +  = 1 )   {  histo . increment ( x estimate roi ( estimated   library   size x read   pairs   examined unique pairs )  )  ;   }  return histo ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\DuplicationMetrics.java,estimate library size,"public static  long   ( final long read pairs final long unique read pairs )  {  final long read pair duplicates = read pairs  -  unique read pairs ;  if  ( read pairs  >  0 && read pair duplicates  >  0 )   {  double m = 1 . 0 ;  double m = 100 . 0 ;  if  ( unique read pairs  >  =  read pairs || f ( m * unique read pairs unique read pairs read pairs )   <  0 )   {  throw new  illegal state exception ( "" invalid values for pairs and unique pairs: ""  +  read pairs  +  ""  "" +  unique read pairs )  ;   }  while  ( f ( m * unique read pairs unique read pairs read pairs )   >  0 )   {  m* = 10 . 0 ;   }  for  ( int i = 0 ;  i  <  40 ;  i +  +  )   {  double r =  ( m  +  m )   /  2 . 0 ;  double u = f ( r * unique read pairs unique read pairs read pairs )  ;  if  ( u  =  =  0 )   {  break ;   }  else if  ( u  >  0 )   {  m = r ;   }  else if  ( u  <  0 )   {  m = r ;   }   }  return  ( long )  ( unique read pairs *  ( m  +  m )   /  2 . 0 )  ;   }  else  {  return null ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\DuplicationMetrics.java,estimate roi,public static double   ( long estimated library size double x long pairs long unique pairs )  {  return estimated library size *  ( 1  -   math . exp (  -  ( x * pairs )   /  estimated library size )  )   /  unique pairs ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\DuplicationMetrics.java,f,private static double   ( double x double c double n )  {  return c  /  x  -  1  +   math . exp (  - n  /  x )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\DuplicationMetrics.java,main,"public static void   (  string[] args )  {   duplication metrics m = new  duplication metrics (  )  ;  m . read   pairs   examined =  integer . parse int ( args[0] )  ;  m . read   pair   duplicates =  integer . parse int ( args[1] )  ;  m . calculate derived fields (  )  ;   system . out . println ( "" percent  duplication: ""  +  m . percent   duplication )  ;   system . out . println ( "" est .   library  size : ""  +  m . estimated   library   size )  ;   system . out . println (  )  ;   system . out . println ( ""x  seq\tx  unique"" )  ;  for  (   histogram .  bin <  double >  bin : m . calculate roi histogram (  )  . values (  )  )   {   system . out . println ( bin . get id (  )   +  ""\t""  +  bin . get value (  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,add first of pair or fragment,public void   ( final sam record rec )  {  first of pair or fragment . add ( rec )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,add second of pair,public void   ( final sam record rec )  {  second of pair . add ( rec )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,add supplemental first of pair or fragment,public void   ( final sam record rec )  {  supplemental first of pair or fragment . add ( rec )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,add supplemental second of pair,public void   ( final sam record rec )  {  supplemental second of pair . add ( rec )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,compare,public int   ( final sam record rec1 final sam record rec2 )  {  final  integer hi1 = rec1 . get integer attribute ( sam tag . hi . name (  )  )  ;  final  integer hi2 = rec2 . get integer attribute ( sam tag . hi . name (  )  )  ;  if  ( hi1  =  =  null )   {  if  ( hi2  =  =  null )  return 0 ;  else return 1 ;   }  else if  ( hi2  =  =  null )   {  return  - 1 ;   }  else  {  return hi1 . compare to ( hi2 )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,coordinate by hit index,public void   (  )  {   collections . sort ( first of pair or fragment comparator )  ;   collections . sort ( second of pair comparator )  ;  for  ( int i = 0 ;  i  <   math . min ( first of pair or fragment . size (  )  second of pair . size (  )  )  ;   +  + i )   {  final  integer left hi = first of pair or fragment . get ( i )  . get integer attribute ( sam tag . hi . name (  )  )  ;  final  integer right hi = second of pair . get ( i )  . get integer attribute ( sam tag . hi . name (  )  )  ;  if  ( left hi  !  =  null )   {  if  ( right hi  !  =  null )   {  if  ( left hi  <  right hi )  second of pair . add ( i null )  ;  else if  ( right hi  <  left hi )  first of pair or fragment . add ( i null )  ;   }   }  else if  ( right hi  !  =  null )   {  first of pair or fragment . add ( i null )  ;   }  else  {  second of pair . add ( i null )  ;   }   }  int hi = 0 ;  for  ( int i = 0 ;  i  <  num hits (  )  ;   +  + i )   {  final sam record first = get first of pair ( i )  ;  final sam record second = get second of pair ( i )  ;  if  ( first  !  =  null && second  !  =  null )   {  first . set attribute ( sam tag . hi . name (  )  i )  ;  second . set attribute ( sam tag . hi . name (  )  i )  ;   +  + hi ;   }  else if  ( first  !  =  null )   {  first . set attribute ( sam tag . hi . name (  )  null )  ;   }  else  {  second . set attribute ( sam tag . hi . name (  )  null )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,get first of pair,public sam record   ( final int i )  {  if  ( i  >  =  first of pair or fragment . size (  )  )   {  return null ;   }  else  {  return first of pair or fragment . get ( i )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,get fragment,"public sam record   ( final int i )  {  final sam record sam record = first of pair or fragment . get ( i )  ;  if  ( sam record . get read paired flag (  )  )  throw new  unsupported operation exception ( ""get fragment called for paired read"" )  ;  return sam record ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,get index of earliest primary,public int   (  )  {  for  ( int i = 0 ;  i  <  num hits (  )  ;  i +  +  )   {  final sam record first aligned = get first of pair ( i )  ;  final sam record second aligned = get second of pair ( i )  ;  final boolean is primary alignment =  ( first aligned  !  =  null &&  ! first aligned . is secondary or supplementary (  )  )  ||  ( second aligned  !  =  null &&  ! second aligned . is secondary or supplementary (  )  )  ;  if  ( is primary alignment )  return i ;   }  return  - 1 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,get read name,public  string   (  )  {  return get representative read (  )  . get read name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,get representative read,"public sam record   (  )  {  for  (  final sam record rec : first of pair or fragment )   {  if  ( rec  !  =  null )  return rec ;   }  for  (  final sam record rec : second of pair )   {  if  ( rec  !  =  null )  return rec ;   }  throw new  illegal state exception ( "" should not be called if num hits  =  =  0"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,get second of pair,public sam record   ( final int i )  {  if  ( i  >  =  second of pair . size (  )  )   {  return null ;   }  else  {  return second of pair . get ( i )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,get supplemental first of pair or fragment, list < sam record >    (  )  {  return supplemental first of pair or fragment ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,get supplemental second of pair, list < sam record >    (  )  {  return supplemental second of pair ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,has supplemental hits,public boolean   (  )  {  return  !  ( this . supplemental first of pair or fragment . is empty (  )  && this . supplemental second of pair . is empty (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,is paired,public boolean   (  )  {  return get representative read (  )  . get read paired flag (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,num hits,public int   (  )  {  return  math . max ( first of pair or fragment . size (  )  second of pair . size (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,set primary alignment,"public void   ( final int primary alignment index )  {  if  ( primary alignment index  <  0 || primary alignment index  >  =  this . num hits (  )  )   {  throw new  illegal argument exception ( ""primary alignment index ( ""  +  primary alignment index  +  "" )  out of range for num hits ( "" +  num hits (  )  +  "" ) "" )  ;   }  for  ( int i = 0 ;  i  <  this . num hits (  )  ;   +  + i )   {  final boolean not primary =  ( i  !  =  primary alignment index )  ;  if  ( this . get first of pair ( i )   !  =  null )   {  this . get first of pair ( i )  . set not primary alignment flag ( not primary )  ;   }  if  ( this . get second of pair ( i )   !  =  null )   {  this . get second of pair ( i )  . set not primary alignment flag ( not primary )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\HitsForInsert.java,tally primary alignments,public  num primary alignment state   ( final boolean first end )  {  if  ( first end )  return tally primary alignments ( first of pair or fragment )  ;  else return tally primary alignments ( second of pair )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcDuplicatesFinderResolver.java, elc duplicates finder resolver,  ( double max diff rate int max read length int min identical bases boolean use barcodes  optical duplicate finder optical duplicate finder )  {  this . use barcodes = use barcodes ;  this . hash based duplicates finder = new  elc hash based duplicates finder ( max diff rate max read length min identical bases optical duplicate finder )  ;  this . identical bases duplicate finder = new  elc identical bases duplicates finder ( max diff rate max read length min identical bases use barcodes optical duplicate finder )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcDuplicatesFinderResolver.java,resolve and search,void   (  list <  paired read sequence >  sequences  histogram <  integer >  duplication histo  histogram <  integer >  optical histo )  {  if  ( use barcodes || sequences . size (  )   <  boundary   library   size )   {  identical bases duplicate finder . search duplicates ( sequences duplication histo optical histo )  ;   }  else  {  hash based duplicates finder . search duplicates ( sequences duplication histo optical histo )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcDuplicatesFinder.java, elc duplicates finder,  ( double max diff rate int max read length int min identical bases  optical duplicate finder optical duplicate finder )  {  this . max diff rate = max diff rate ;  this . min identical bases = min identical bases ;  this . optical duplicate finder = optical duplicate finder ;  this . max read length =  ( max read length  <  =  0 )   ?   integer . max   value : max read length ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcDuplicatesFinder.java,fill histogram,protected void   (  histogram <  integer >  duplication histo  histogram <  integer >  optical histo  paired read sequence prs  list <  paired read sequence >  dupes )  {  if  (  ! dupes . is empty (  )  )   {  dupes . add ( prs )  ;  final int duplicate count = dupes . size (  )  ;  duplication histo . increment ( duplicate count )  ;  final boolean[] flags = optical duplicate finder . find optical duplicates ( dupes prs )  ;  for  (  final boolean b : flags )   {  if  ( b )  optical histo . increment ( duplicate count )  ;   }   }  else  {  duplication histo . increment ( 1 )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcDuplicatesFinder.java,min length,protected int   ( byte[] read1 byte[] read2 )  {  return  math . min (  math . min ( read1 . length read2 . length )  max read length )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcIdenticalBasesDuplicatesFinder.java, elc identical bases duplicates finder,  ( double max diff rate int max read length int min identical bases boolean use barcodes  optical duplicate finder optical duplicate finder )  {  super ( max diff rate max read length min identical bases optical duplicate finder )  ;  this . use barcodes = use barcodes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcIdenticalBasesDuplicatesFinder.java,matches,private boolean   ( final  paired read sequence lhs final  paired read sequence rhs final double max diff rate final boolean use barcodes )  {  final int read1 length = min length ( lhs . read1 rhs . read1 )  ;  final int read2 length = min length ( lhs . read2 rhs . read2 )  ;  final int max errors =  ( int )  math . floor (  ( read1 length  +  read2 length )  * max diff rate )  ;  int errors = 0 ;  if  ( use barcodes )   {  final  paired read sequence with barcodes lhs with barcodes =  (  paired read sequence with barcodes ) lhs ;  final  paired read sequence with barcodes rhs with barcodes =  (  paired read sequence with barcodes ) rhs ;  if  ( lhs with barcodes . barcode  !  =  rhs with barcodes . barcode || lhs with barcodes . read one barcode  !  =  rhs with barcodes . read one barcode || lhs with barcodes . read two barcode  !  =  rhs with barcodes . read two barcode )   {  return false ;   }   }  for  ( int i = min identical bases ;  i  <  read1 length ;   +  + i )   {  if  ( lhs . read1[i]  !  =  rhs . read1[i] &&  +  + errors  >  max errors )   {  return false ;   }   }  for  ( int i = min identical bases ;  i  <  read2 length ;   +  + i )   {  if  ( lhs . read2[i]  !  =  rhs . read2[i] &&  +  + errors  >  max errors )   {  return false ;   }   }  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcHashBasedDuplicatesFinder.java, elc hash based duplicates finder,  ( double max diff rate int max read length int min identical bases  optical duplicate finder optical duplicate finder )  {  super ( max diff rate max read length min identical bases optical duplicate finder )  ;  reads by hash in group = new  hash map <  >  (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcHashBasedDuplicatesFinder.java,compare hashes,private int   ( byte[] read1 byte[] read2 int hash number )  {  int errors = 0 ;  int position = min identical bases  +  hash number ;  while  ( position  <  min read len in group )   {  if  ( read1[position]  !  =  read2[position] )   {  errors +  +  ;   }  position +  = number of hashes in group ;   }  return errors ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcHashBasedDuplicatesFinder.java,compare read to read,private int   ( byte[] read1 int[] hashes1 byte[] read2 int[] hashes2 int max errors )  {  int errors = 0 ;  final int min read length = min length ( read1 read2 )  ;  for  ( int hash number = 0 ;  hash number  <  number of hashes in group ;   +  + hash number )   {  if  ( hashes1[hash number]  !  =  hashes2[hash number] )   {  errors +  = compare hashes ( read1 read2 hash number )  ;  if  ( errors  >  max errors )   {  return errors ;   }   }   }  if  ( min read length  >  min read len in group )   {  errors +  = compare tails ( read1 read2 min read len in group min read length )  ;   }  return errors ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcHashBasedDuplicatesFinder.java,compare tails,private int   ( byte[] read1 byte[] read2 int start int stop )  {  int errors = 0 ;  for  ( int i = start ;  i  <  stop ;   +  + i )   {  if  ( read1[i]  !  =  read2[i] )   {  errors +  +  ;   }   }  return errors ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcHashBasedDuplicatesFinder.java,fill hash values,private void   (  list <  paired read sequence >  sequences )  {  for  (   paired read sequence prs : sequences )   {  prs . init hashes ( number of hashes in group min identical bases min read len in group )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcHashBasedDuplicatesFinder.java,get similar reads,private  set <  paired read sequence >    ( final  paired read sequence pattern )  {  final  set <  paired read sequence >  to check = new  hash set <  >  (  )  ;  for  (  int[] hashes for read : new int[][] { pattern . hashes1 pattern . hashes2 }  )   {  for  (  int hash : hashes for read )   {   list <  paired read sequence >  reads with same hash = reads by hash in group . get ( hash )  ;  if  ( reads with same hash . size (  )   >  1 )   {  to check . add all ( reads with same hash )  ;   }   }   }  return to check ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcHashBasedDuplicatesFinder.java,init hash length,private void   (  list <  paired read sequence >  sequences )  {  for  (   paired read sequence prs : sequences )   {  int min read length =  math . min (  math . min ( prs . read1 . length prs . read2 . length )  max read length )  ;  int number of hashes =  ( int )  (  ( min read length  -  min identical bases )  * max diff rate )   +  1 ;  if  ( number of hashes  >  number of hashes in group )   {  number of hashes in group = number of hashes ;   }  if  ( min read len in group  >  min read length )   {  min read len in group = min read length ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcHashBasedDuplicatesFinder.java,is duplicate,private boolean   ( final  paired read sequence lhs final  paired read sequence rhs )  {  if  ( lhs  =  =  rhs )   {  return false ;   }  final int read1 length = min length ( lhs . read1 rhs . read1 )  ;  final int read2 length = min length ( lhs . read2 rhs . read2 )  ;  final int max errors =  ( int )  math . floor (  ( read1 length  +  read2 length )  * max diff rate )  ;  int errors = compare read to read ( lhs . read1 lhs . hashes1 rhs . read1 rhs . hashes1 max errors )  ;  if  ( errors  >  max errors )   {  return false ;   }  errors +  = compare read to read ( lhs . read2 lhs . hashes2 rhs . read2 rhs . hashes2 max errors )  ;  return errors  <  =  max errors ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcHashBasedDuplicatesFinder.java,populate dup candidates,private void   (  list <  paired read sequence >  seqs )  {  reads by hash in group . clear (  )  ;  for  (   paired read sequence prs : seqs )   {  int[][] read hash values =  { prs . hashes1 prs . hashes2 }  ;  for  (  int[] read hash value : read hash values )   {  for  (  int key : read hash value )   {  final  list <  paired read sequence >  dup candidates = reads by hash in group . compute if absent ( key k  -  >  new  array list <  >  (  )  )  ;  dup candidates . add ( prs )  ;   }   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcHashBasedDuplicatesFinder.java,search duplicates,@ override void   (  list <  paired read sequence >  sequences  histogram <  integer >  duplication histo  histogram <  integer >  optical histo )  {  init hash length ( sequences )  ;  fill hash values ( sequences )  ;  populate dup candidates ( sequence
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\ElcIdenticalBasesDuplicatesFinder.java,search duplicates,@ override void   (  list <  paired read sequence >  sequences  histogram <  integer >  duplication histo  histogram <  integer >  optical histo )  {  for  ( int i = 0 ;  i  <  sequences . size (  )  ;   +  + i )   {  final  paired read sequence lhs = seq
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java, duplicate type,  ( final  string code )  {  this . code = code ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java, mark duplicates,public   (  )  {  duplicate   scoring   strategy =  scoring strategy . sum   of   base   qualities ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java, read endsmd comparator,public   ( final boolean use barcodes )  {  this . use barcodes = use barcodes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,add index as duplicate,private void   ( final long bam index )  {  this . duplicate indexes . add ( bam index )  ;   +  + this . num duplicate indices ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,add representative read index,private void   ( final  list <  read ends for mark duplicates >  list )  {  short max score = 0 ;   read ends for mark duplicates best = null ;  for  (   read ends for mark duplicates end : list )   {  if  ( end . score  >  max score || best  =  =  null )   {  max score = end . score ;  best = end ;   }   }  for  (  final  read ends for mark duplicates end : list )   {  add representative read of duplicate set ( best . read1 index in file list . size (  )  end . read1 index in file )  ;  add representative read of duplicate set ( best . read1 index in file list . size (  )  end . read2 index in file )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,add representative read of duplicate set,private void   ( final long representative read index in file final int set size final long read1 index in file )  {  final  representative read indexer rri = new  representative read indexer (  )  ;  rri . representative read index in file =  ( int ) representative read index in file ;  rri . set size = set size ;  rri . read index in file =  ( int ) read1 index in file ;  this . representative read indices for duplicates . add ( rri )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,are comparable for duplicates,private boolean   ( final  read ends for mark duplicates lhs final  read ends for mark duplicates rhs final boolean compare read2 final boolean use barcodes )  {  boolean are comparable = lhs . library id  =  =  rhs . library id ;  if  ( use barcodes && are comparable )   {  final  read ends for mark duplicates with barcodes lhs with barcodes =  (  read ends for mark duplicates with barcodes ) lhs ;  final  read ends for mark duplicates with barcodes rhs with barcodes =  (  read ends for mark duplicates with barcodes ) rhs ;  are comparable = lhs with barcodes . barcode  =  =  rhs with barcodes . barcode && lhs with barcodes . read one barcode  =  =  rhs with barcodes . read one barcode && lhs with barcodes . read two barcode  =  =  rhs with barcodes . read two barcode ;   }  if  ( are comparable )   {  are comparable = lhs . read1 reference index  =  =  rhs . read1 reference index && lhs . read1 coordinate  =  =  rhs . read1 coordinate && lhs . orientation  =  =  rhs . orientation ;   }  if  ( are comparable && compare read2 )   {  are comparable = lhs . read2 reference index  =  =  rhs . read2 reference index && lhs . read2 coordinate  =  =  rhs . read2 coordinate ;   }  return are comparable ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,build read ends,private  read ends for mark duplicates   ( final sam file header header final long index final sam record rec final boolean use barcodes )  {  final  read ends for mark duplicates ends ;  if  ( use barcodes )   {  ends = new  read ends for mark duplicates with barcodes (  )  ;   }  else  {  ends = new  read ends for mark duplicates (  )  ;   }  ends . read1 reference index = rec . get reference index (  )  ;  ends . read1 coordinate = rec . get read negative strand flag (  )   ?  rec . get unclipped end (  )  : rec . get unclipped start (  )  ;  ends . orientation = rec . get read negative strand flag (  )   ?   read ends . r :  read ends . f ;  ends . read1 index in file = index ;  ends . score =  duplicate scoring strategy . compute duplicate score ( rec this . duplicate   scoring   strategy )  ;  if  ( rec . get read paired flag (  )  &&  ! rec . get mate unmapped flag (  )  )   {  ends . read2 reference index = rec . get mate reference index (  )  ;   }  ends . library id = library id generator . get library id ( rec )  ;  if  ( this . optical duplicate finder . add location information ( rec . get read name (  )  ends )  )   {  ends . read group = 0 ;  final  string rg =  (  string ) rec . get attribute (  reserved tag constants . read   group   id )  ;  final  list < sam read group record >  read groups = header . get read groups (  )  ;  if  ( rg  !  =  null && read groups  !  =  null )   {  for  (  final sam read group record read group : read groups )   {  if  ( read group . get read group id (  )  . equals ( rg )  )  break ;  else ends . read group +  +  ;   }   }   }  if  ( use barcodes )   {  final  read ends for mark duplicates with barcodes ends with barcode =  (  read ends for mark duplicates with barcodes ) ends ;  ends with barcode . barcode = get barcode value ( rec )  ;  if  (  ! rec . get read paired flag (  )  || rec . get first of pair flag (  )  )   {  ends with barcode . read one barcode = get read one barcode value ( rec )  ;   }  else  {  ends with barcode . read two barcode = get read two barcode value ( rec )  ;   }   }  return ends ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,build sorted read end lists,"private void   ( final boolean use barcodes )  {  final int size in bytes ;  if  ( use barcodes )   {  size in bytes =  read ends for mark duplicates with barcodes . get size of (  )  ;   }  else  {  size in bytes =  read ends for mark duplicates . get size of (  )  ;   }  max   records   in   ram =  ( int )  (  runtime . get runtime (  )  . max memory (  )   /  size in bytes )   /  2 ;  final int max in memory =  ( int )  (  (  runtime . get runtime (  )  . max memory (  )  * sorting   collection   size   ratio )   /  size in bytes )  ;  log . info ( "" will retain up to ""  +  max in memory  +  "" data points before spilling to disk . "" )  ;  final  read ends for mark duplicates codec frag codec  pair codec  disk codec ;  if  ( use barcodes )   {  frag codec = new  read ends for mark duplicates with barcodes codec (  )  ;  pair codec = new  read ends for mark duplicates with barcodes codec (  )  ;  disk codec = new  read ends for mark duplicates with barcodes codec (  )  ;   }  else  {  frag codec = new  read ends for mark duplicates codec (  )  ;  pair codec = new  read ends for mark duplicates codec (  )  ;  disk codec = new  read ends for mark duplicates codec (  )  ;   }  this . pair sort =  sorting collection . new instance (  read ends for mark duplicates . class pair codec new  read endsmd comparator ( use barcodes )  max in memory tmp   dir )  ;  this . frag sort =  sorting collection . new instance (  read ends for mark duplicates . class frag codec new  read endsmd comparator ( use barcodes )  max in memory tmp   dir )  ;  final  sam header and iterator header and iterator = open inputs ( true )  ;  final sam file header .  sort order assumed sort order = header and iterator . header . get sort order (  )  ;  final sam file header header = header and iterator . header ;  final  read ends for mark duplicates map tmp = new  disk based read ends for mark duplicates map ( max   file   handles   for   read   ends   map disk codec )  ;  long index = 0 ;  final  progress logger progress = new  progress logger ( log  ( int ) 1e6 "" read"" )  ;  final  closeable iterator < sam record >  iterator = header and iterator . iterator ;  if  ( null  =  =  this . library id generator )   {  this . library id generator = new  library id generator ( header )  ;   }   string duplicate query name = null ;  long duplicate index = no   such   index ;  while  ( iterator . has next (  )  )   {  final sam record rec = iterator . next (  )  ;  if  ( program   record   id  !  =  null )   {  pg ids seen . add ( rec . get string attribute ( sam tag . pg . name (  )  )  )  ;   }  if  ( assumed sort order  =  =  sam file header .  sort order . queryname &&  ! rec . get read name (  )  . equals ( duplicate query name )  )   {  duplicate query name = rec . get read name (  )  ;  duplicate index = index ;   }  if  ( rec . get read unmapped flag (  )  )   {  if  ( rec . get reference index (  )   =  =   - 1 && assumed sort order  =  =  sam file header .  sort order . coordinate )   {  break ;   }   }  else if  (  ! rec . is secondary or supplementary (  )  )   {  final long index for read = assumed sort order  =  =  sam file header .  sort order . queryname  ?  duplicate index : index ;  final  read ends for mark duplicates fragment end = build read ends ( header index for read rec use barcodes )  ;  this . frag sort . add ( fragment end )  ;  if  ( rec . get read paired flag (  )  &&  ! rec . get mate unmapped flag (  )  )   {  final  string key = rec . get attribute (  reserved tag constants . read   group   id )   +  "":""  +  rec . get read name (  )  ;   read ends for mark duplicates paired ends = tmp . remove ( rec . get reference index (  )  key )  ;  if  ( paired ends  =  =  null )   {  paired ends = fragment end . clone (  )  ;  tmp . put ( paired ends . read2 reference index key paired ends )  ;   }  else  {  final int mates ref index = fragment end . read1 reference index ;  final int mates coordinate = fragment end . read1 coordinate ;  if  ( rec . get first of pair flag (  )  )   {  paired ends . orientation for optical duplicates =  read ends . get orientation byte ( rec . get read negative strand flag (  )  paired ends . orientation  =  =   read ends . r )  ;  if  ( use barcodes )   (  (  read ends for mark duplicates with barcodes ) paired ends )  . read one barcode = get read one barcode value ( rec )  ;   }  else  {  paired ends . orientation for optical duplicates =  read ends . get orientation byte ( paired ends . orientation  =  =   read ends . r rec . get read negative strand flag (  )  )  ;  if  ( use barcodes )   (  (  read ends for mark duplicates with barcodes ) paired ends )  . read two barcode = get read two barcode value ( rec )  ;   }  if  ( mates ref index  >  paired ends . read1 reference index ||  ( mates ref index  =  =  paired ends . read1 reference index && mates coordinate  >  =  paired ends . read1 coordinate )  )   {  paired ends . read2 reference index = mates ref index ;  paired ends . read2 coordinate = mates coordinate ;  paired ends . read2 index in file = index for read ;  paired ends . orientation =  read ends . get orientation byte ( paired ends . orientation  =  =   read ends . r rec . get read negative strand flag (  )  )  ;  if  ( paired ends . read2 reference index  =  =  paired ends . read1 reference index && paired ends . read2 coordinate  =  =  paired ends . read1 coordinate && paired ends . orientation  =  =   read ends . rf )   {  paired ends . orientation =  read ends . fr ;   }   }  else  {  paired ends . read2 reference index = paired ends . read1 reference index ;  paired ends . read2 coordinate = paired ends . read1 coordinate ;  paired ends . read2 index in file = paired ends . read1 index in file ;  paired ends . read1 reference index = mates ref index ;  paired ends . read1 coordinate = mates coordinate ;  paired ends . read1 index in file = index for read ;  paired ends . orientation =  read ends . get orientation byte ( rec . get read negative strand flag (  )  paired ends . orientation  =  =   read ends . r )  ;   }  paired ends . score +  =  duplicate scoring strategy . compute duplicate score ( rec this . duplicate   scoring   strategy )  ;  this . pair sort . add ( paired ends )  ;   }   }   }   +  + index ;  if  ( progress . record ( rec )  )   {  log . info ( "" tracking ""  +  tmp . size (  )   +  "" as yet unmatched pairs .  "" +  tmp . size in ram (  )  +  "" records in ram . "" )  ;   }   }  log . info ( "" read ""  +  index  +  "" records .  "" +  tmp . size (  )  +  "" pairs never matched . "" )  ;  iterator . close (  )  ;  this . pair sort . done adding (  )  ;  this . frag sort . done adding (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,code,public  string   (  )  {  return this . code ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,compare,public int   ( final  read ends for mark duplicates lhs final  read ends for mark duplicates rhs )  {  int compare difference = lhs . library id  -  rhs . library id ;  if  ( use barcodes )   {  final  read ends for mark duplicates with barcodes lhs with barcodes =  (  read ends for mark duplicates with barcodes ) lhs ;  final  read ends for mark duplicates with barcodes rhs with barcodes =  (  read ends for mark duplicates with barcodes ) rhs ;  if  ( compare difference  =  =  0 )   {  compare difference =  integer . compare ( lhs with barcodes . barcode rhs with barcodes . barcode )  ;   }  if  ( compare difference  =  =  0 )   {  compare difference =  integer . compare ( lhs with barcodes . read one barcode rhs with barcodes . read one barcode )  ;   }  if  ( compare difference  =  =  0 )   {  compare difference =  integer . compare ( lhs with barcodes . read two barcode rhs with barcodes . read two barcode )  ;   }   }  if  ( compare difference  =  =  0 )   {  compare difference = lhs . read1 reference index  -  rhs . read1 reference index ;   }  if  ( compare difference  =  =  0 )   {  compare difference = lhs . read1 coordinate  -  rhs . read1 coordinate ;   }  if  ( compare difference  =  =  0 )   {  compare difference = lhs . orientation  -  rhs . orientation ;   }  if  ( compare difference  =  =  0 )   {  compare difference = lhs . read2 reference index  -  rhs . read2 reference index ;   }  if  ( compare difference  =  =  0 )   {  compare difference = lhs . read2 coordinate  -  rhs . read2 coordinate ;   }  if  ( compare difference  =  =  0 )   {  compare difference =  ( int )  ( lhs . read1 index in file  -  rhs . read1 index in file )  ;   }  if  ( compare difference  =  =  0 )   {  compare difference =  ( int )  ( lhs . read2 index in file  -  rhs . read2 index in file )  ;   }  return compare difference ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,do work,"protected int   (  )  {  io util . assert inputs are valid ( input )  ;  io util . assert file is writable ( output )  ;  io util . assert file is writable ( metrics   file )  ;  final boolean use barcodes =  ( null  !  =  barcode   tag || null  !  =  read   one   barcode   tag || null  !  =  read   two   barcode   tag )  ;  report memory stats ( "" start of do work"" )  ;  log . info ( "" reading input file and constructing read end information . "" )  ;  build sorted read end lists ( use barcodes )  ;  report memory stats ( "" after build sorted read end lists"" )  ;  generate duplicate indexes ( use barcodes this . remove   sequencing   duplicates || this . tagging   policy  !  =   duplicate tagging policy .  dont tag )  ;  report memory stats ( "" after generate duplicate indexes"" )  ;  log . info ( "" marking ""  +  this . num duplicate indices  +  "" records as duplicates . "" )  ;  if  ( this . read   name   regex  =  =  null )   {  log . warn ( "" skipped optical duplicate cluster discovery ;  library size estimation may be inaccurate ! "" )  ;   }  else  {  log . info ( "" found ""  +   ( this . library id generator . get number of optical duplicate clusters (  )  )   +  "" optical duplicate clusters . "" )  ;   }  final  sam header and iterator header and iterator = open inputs ( false )  ;  final sam file header header = header and iterator . header ;  final sam file header .  sort order sort order = header . get sort order (  )  ;  final sam file header output header = header . clone (  )  ;  log . info ( "" reads are assumed to be ordered by: ""  +  sort order )  ;  if  ( sort order  !  =  sam file header .  sort order . coordinate && sort order  !  =  sam file header .  sort order . queryname )   {  throw new  picard exception ( "" this program requires input that are either coordinate or query sorted .  ""  +  "" found ""  +  sort order )  ;   }  comment . for each ( output header::add comment )  ;  final  map <  string  string >  chained pg ids = get chained pg ids ( output header )  ;  final sam file writer out = new sam file writer factory (  )  . makesam orbam writer ( output header true output )  ;  long record in file index = 0 ;  long next optical duplicate index = this . optical duplicate indexes  !  =  null && this . optical duplicate indexes . has next (  )   ?  this . optical duplicate indexes . next (  )  : no   such   index ;  long next duplicate index =  ( this . duplicate indexes . has next (  )   ?  this . duplicate indexes . next (  )  : no   such   index )  ;   closeable iterator <  representative read indexer >  representative read iterator = null ;   representative read indexer rri = null ;  int representative read index in file =  - 1 ;  int duplicate set size =  - 1 ;  int next representative index =  - 1 ;  if  ( tag   duplicate   set   members )   {  representative read iterator = this . representative read indices for duplicates . iterator (  )  ;  if  ( representative read iterator . has next (  )  )   {  rri = representative read iterator . next (  )  ;  next representative index = rri . read index in file ;  representative read index in file = rri . representative read index in file ;  duplicate set size = rri . set size ;   }   }  final  progress logger progress = new  progress logger ( log  ( int ) 1e7 "" written"" )  ;  final  closeable iterator < sam record >  iterator = header and iterator . iterator ;   string duplicate query name = null ;   string optical duplicate query name = null ;  while  ( iterator . has next (  )  )   {  final sam record rec = iterator . next (  )  ;  final  string library =  library id generator . get library name ( header rec )  ;   duplication metrics metrics = library id generator . get metrics by library ( library )  ;  if  ( metrics  =  =  null )   {  metrics = new  duplication metrics (  )  ;  metrics . library = library ;  library id generator . add metrics by library ( library metrics )  ;   }  if  ( rec . get read unmapped flag (  )  )   {   +  + metrics . unmapped   reads ;   }  else if  ( rec . is secondary or supplementary (  )  )   {   +  + metrics . secondary   or   supplementary   rds ;   }  else if  (  ! rec . get read paired flag (  )  || rec . get mate unmapped flag (  )  )   {   +  + metrics . unpaired   reads   examined ;   }  else  {   +  + metrics . read   pairs   examined ;   }  final boolean need next duplicate index = record in file index  >  next duplicate index &&  ( sort order  =  =  sam file header .  sort order . coordinate ||  ! rec . get read name (  )  . equals ( duplicate query name )  )  ;  if  ( need next duplicate index )   {  next duplicate index =  ( this . duplicate indexes . has next (  )   ?  this . duplicate indexes . next (  )  : no   such   index )  ;   }  final boolean is duplicate = record in file index  =  =  next duplicate index ||  ( sort order  =  =  sam file header .  sort order . queryname && record in file index  >  next duplicate index && rec . get read name (  )  . equals ( duplicate query name )  )  ;  if  ( is duplicate )   {  duplicate query name = rec . get read name (  )  ;  rec . set duplicate read flag ( true )  ;  if  (  ! rec . is secondary or supplementary (  )  &&  ! rec . get read unmapped flag (  )  )   {  if  (  ! rec . get read paired flag (  )  || rec . get mate unmapped flag (  )  )   {   +  + metrics . unpaired   read   duplicates ;   }  else  {   +  + metrics . read   pair   duplicates ;   }   }   }  else  {  rec . set duplicate read flag ( false )  ;   }  final boolean need next optical duplicate index = record in file index  >  next optical duplicate index &&  ( sort order  =  =  sam file header .  sort order . coordinate ||  ! rec . get read name (  )  . equals ( optical duplicate query name )  )  ;  if  ( need next optical duplicate index )   {  next optical duplicate index =  ( this . optical duplicate indexes . has next (  )   ?  this . optical duplicate indexes . next (  )  : no   such   index )  ;   }  final boolean is optical duplicate = sort order  =  =  sam file header .  sort order . queryname && record in file index  >  next optical duplicate index && rec . get read name (  )  . equals ( optical duplicate query name )  || record in file index  =  =  next optical duplicate index ;  if  ( clear   dt )   {  rec . set attribute ( duplicate   type   tag null )  ;   }  if  ( this . tagging   policy  !  =   duplicate tagging policy .  dont tag && rec . get duplicate read flag (  )  )   {  if  ( is optical duplicate )   {  optical duplicate query name = rec . get read name (  )  ;  rec . set attribute ( duplicate   type   tag  duplicate type . sequencing . code (  )  )  ;   }  else if  ( this . tagging   policy  =  =   duplicate tagging policy .  all )   {  rec . set attribute ( duplicate   type   tag  duplicate type . library . code (  )  )  ;   }   }  if  ( tag   duplicate   set   members )   {  final boolean need next representative index = record in file index  >  next representative index ;  if  ( need next representative index && representative read iterator . has next (  )  )   {  rri = representative read iterator . next (  )  ;  next representative index = rri . read index in file ;  representative read index in file = rri . representative read index in file ;  duplicate set size = rri . set size ;   }  final boolean is in duplicate set = record in file index  =  =  next representative index ||  ( sort order  =  =  sam file header .  sort order . queryname && record in file index  >  next duplicate index )  ;  if  ( is in duplicate set )   {  if  (  ! rec . is secondary or supplementary (  )  &&  ! rec . get read unmapped flag (  )  )   {  if  ( tag   duplicate   set   members )   {  rec . set attribute ( duplicate   set   index   tag representative read index in file )  ;  rec . set attribute ( duplicate   set   size   tag duplicate set size )  ;   }   }   }   }  record in file index +  +  ;  if  ( this . remove   duplicates && rec . get duplicate read flag (  )  )   {  continue ;   }  if  ( this . remove   sequencing   duplicates && is optical duplicate )   {  continue ;   }  if  ( program   record   id  !  =  null && pg tag argument collection . add   pg   tag   to   reads )   {  rec . set attribute ( sam tag . pg . name (  )  chained pg ids . get ( rec . get string attribute ( sam tag . pg . name (  )  )  )  )  ;   }  out . add alignment ( rec )  ;  progress . record ( rec )  ;   }  iterator . close (  )  ;  this . duplicate indexes . cleanup (  )  ;  if  ( tag   duplicate   set   members )   {  this . representative read indices for duplicates . cleanup (  )  ;   }  report memory stats ( "" before output close"" )  ;  out . close (  )  ;  report memory stats ( "" after output close"" )  ;  finalize and write metrics ( library id generator )  ;  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,generate duplicate indexes,"private void   ( final boolean use barcodes final boolean index optical duplicates )  {  final int entry overhead ;  if  ( tag   duplicate   set   members )   {  entry overhead = 16 ;   }  else  {  entry overhead =  sorting long collection . sizeof ;   }  int max in memory =  ( int )  math . min (  (  runtime . get runtime (  )  . max memory (  )  * 0 . 25 )   /  entry overhead  ( double )  (  integer . max   value  -  5 )  )  ;  if  ( index optical duplicates )   {  max in memory /  =  (  ( entry overhead  +   sorting long collection . sizeof )   /  entry overhead )  ;  this . optical duplicate indexes = new  sorting long collection ( max in memory tmp   dir . to array ( new  file[tmp   dir . size (  ) ] )  )  ;   }  log . info ( "" will retain up to ""  +  max in memory  +  "" duplicate indices before spilling to disk . "" )  ;  this . duplicate indexes = new  sorting long collection ( max in memory tmp   dir . to array ( new  file[tmp   dir . size (  ) ] )  )  ;  if  ( tag   duplicate   set   members )   {  final  representative read indexer codec representative index codec = new  representative read indexer codec (  )  ;  this . representative read indices for duplicates =  sorting collection . new instance (  representative read indexer . class representative index codec  comparator . comparing ( read  -  >  read . read index in file )  max in memory tmp   dir )  ;   }   read ends for mark duplicates first of next chunk = null ;  final  list <  read ends for mark duplicates >  next chunk = new  array list <  >  ( 200 )  ;  log . info ( "" traversing read pair information and detecting duplicates . "" )  ;  for  (  final  read ends for mark duplicates next : this . pair sort )   {  if  ( first of next chunk  !  =  null && are comparable for duplicates ( first of next chunk next true use barcodes )  )   {  next chunk . add ( next )  ;   }  else  {  if  ( next chunk . size (  )   >  1 )   {  mark duplicate pairs ( next chunk )  ;  if  ( tag   duplicate   set   members )   {  add representative read index ( next chunk )  ;   }   }  next chunk . clear (  )  ;  next chunk . add ( next )  ;  first of next chunk = next ;   }   }  if  ( next chunk . size (  )   >  1 )   {  mark duplicate pairs ( next chunk )  ;  if  ( tag   duplicate   set   members )   {  add representative read index ( next chunk )  ;   }   }  this . pair sort . cleanup (  )  ;  this . pair sort = null ;  log . info ( "" traversing fragment information and detecting duplicates . "" )  ;  boolean contains pairs = false ;  boolean contains frags = false ;  first of next chunk = null ;  for  (  final  read ends for mark duplicates next : this . frag sort )   {  if  ( first of next chunk  !  =  null && are comparable for duplicates ( first of next chunk next false use barcodes )  )   {  next chunk . add ( next )  ;  contains pairs = contains pairs || next . is paired (  )  ;  contains frags = contains frags ||  ! next . is paired (  )  ;   }  else  {  if  ( next chunk . size (  )   >  1 && contains frags )   {  mark duplicate fragments ( next chunk contains pairs )  ;   }  next chunk . clear (  )  ;  next chunk . add ( next )  ;  first of next chunk = next ;  contains pairs = next . is paired (  )  ;  contains frags =  ! next . is paired (  )  ;   }   }  mark duplicate fragments ( next chunk contains pairs )  ;  this . frag sort . cleanup (  )  ;  this . frag sort = null ;  log . info ( "" sorting list of duplicate records . "" )  ;  this . duplicate indexes . done adding start iteration (  )  ;  if  ( this . optical duplicate indexes  !  =  null )   {  this . optical duplicate indexes . done adding start iteration (  )  ;   }  if  ( tag   duplicate   set   members )   {  this . representative read indices for duplicates . done adding (  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,get barcode value,private int   ( final sam record record )  {  return  estimate library complexity . get read barcode value ( record barcode   tag )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,get read one barcode value,private int   ( final sam record record )  {  return  estimate library complexity . get read barcode value ( record read   one   barcode   tag )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,get read two barcode value,private int   ( final sam record record )  {  return  estimate library complexity . get read barcode value ( record read   two   barcode   tag )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,main,public static void   ( final  string[] args )  {  new  mark duplicates (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,mark duplicate fragments,private void   ( final  list <  read ends for mark duplicates >  list final boolean contains pairs )  {  if  ( contains pairs )   {  for  (  final  read ends for mark duplicates end : list )   {  if  (  ! end . is paired (  )  )   {  add index as duplicate ( end . read1 index in file )  ;   }   }   }  else  {  short max score = 0 ;   read ends for mark duplicates best = null ;  for  (  final  read ends for mark duplicates end : list )   {  if  ( end . score  >  max score || best  =  =  null )   {  max score = end . score ;  best = end ;   }   }  for  (  final  read ends for mark duplicates end : list )   {  if  ( end  !  =  best )   {  add index as duplicate ( end . read1 index in file )  ;   }   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,mark duplicate pairs,private void   ( final  list <  read ends for mark duplicates >  list )  {  short max score = 0 ;   read ends for mark duplicates best = null ;  for  (   read ends for mark duplicates end : list )   {  if  ( end . score  >  max score || best  =  =  null )   {  max score = end . score ;  best = end ;   }   }  if  ( this . read   name   regex  !  =  null )   {   abstract mark duplicates command line program . track optical duplicates ( list best optical duplicate finder library id generator )  ;   }  for  (  final  read ends for mark duplicates end : list )   {  if  ( end  !  =  best )   {  add index as duplicate ( end . read1 index in file )  ;  if  ( end . read2 index in file  !  =  end . read1 index in file )   {  add index as duplicate ( end . read2 index in file )  ;   }  if  ( end . is optical duplicate && this . optical duplicate indexes  !  =  null )   {  this . optical duplicate indexes . add ( end . read1 index in file )  ;  this . optical duplicate indexes . add ( end . read2 index in file )  ;   }   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,num optical duplicates,long   (  )  {  return  (  ( long ) this . library id generator . get optical duplicates by library id map (  )  . get sum of values (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicates.java,report memory stats,"private void   ( final  string stage )  {   system . gc (  )  ;  final  runtime runtime =  runtime . get runtime (  )  ;  log . info ( stage  +  "" free memory: ""  +  runtime . free memory (  )  +  "" ;  total memory: "" +  runtime . total memory (  )  +  "" ;  max memory: "" +  runtime . max memory (  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java, estimate library complexity,public   (  )  {  final int size in bytes ;  if  ( null  !  =  barcode   tag || null  !  =  read   one   barcode   tag || null  !  =  read   two   barcode   tag )   {  size in bytes =  paired read sequence with barcodes . get size in bytes (  )  ;   }  else  {  size in bytes =  paired read sequence . get size in bytes (  )  ;   }  max   records   in   ram =  ( int )  (  runtime . get runtime (  )  . max memory (  )   /  size in bytes )   /  2 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java, paired read sequence with barcodes,"public   ( final  paired read sequence val )  {  if  ( null  =  =  val )  throw new  picard exception ( ""val was null"" )  ;  this . read group = val . get read group (  )  ;  this . tile = val . get tile (  )  ;  this . x = val . getx (  )  ;  this . y = val . gety (  )  ;  this . quality ok = val . quality ok ;  this . read1 = val . read1 . clone (  )  ;  this . read2 = val . read2 . clone (  )  ;  this . library id = val . get library id (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,clone,@ override public  sorting collection .  codec <  paired read sequence >    (  )  {  return new  paired read with barcodes codec (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,compare,public int   ( final  paired read sequence lhs final  paired read sequence rhs )  {  for  ( int i = 0 ;  i  <  bases ;   +  + i )   {  final int retval = lhs . read1[i]  -  rhs . read1[i] ;  if  ( retval  !  =  0 )  return retval ;   }  for  ( int i = 0 ;  i  <  bases ;   +  + i )   {  final int retval = lhs . read2[i]  -  rhs . read2[i] ;  if  ( retval  !  =  0 )  return retval ;   }  return 0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,custom command line validation,"@ override protected  string[]   (  )  {  final  list <  string >  error msgs = new  array list <  string >  (  )  ;  if  ( 0  <  max   read   length && max   read   length  <  min   identical   bases )   {  error msgs . add ( ""max   read   length must be"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,decode,@ override public  paired read sequence   (  )  {  try  {  final  paired read sequence parent val = super . decode (  )  ;  if  ( null  =  =  parent val )  return null ;  final  paired read sequence with barcodes val = new  paired read sequence with barco
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,do work,"@ override protected int   (  )  {  for  (  final  file f : input )  io util . assert file is readable ( f )  ;  log . info ( "" will store ""  +  max   records   in   ram  +  "" read pairs in memory before sorting . "" )  ;  final  list < sam read group reco"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,encode,"@ override public void   ( final  paired read sequence val )  {  if  (  !  ( val instanceof  paired read sequence with barcodes )  )   {  throw new  picard exception ( "" val was not a  paired read sequence with barcodes"" )  ;   }  final  paired read seque"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,get barcode value,public int   ( final sam record record )  {  return get read barcode value ( record barcode   tag )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,get codec,public static  sorting collection .  codec <  paired read sequence >    (  )  {  return new  paired read codec (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,get hashes,private int[]   ( byte[] read int number of hashes int skipped bases int min read length )  {  final int[] hash values = new int[number of hashes] ;  for  ( int i = 0 ;  i  <  number of hashes ;   +  + i )   {  hash values[i] = 1 ;  int position = skipped bases  +  i ;  while  ( position  <  min read length )   {  hash values[i] = 31 * hash values[i]  +  read[position] ;  position +  = number of hashes ;   }   }  return hash values ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,get library id,public short   (  )  {  return this . library id ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,get next group, list <  paired read sequence >    ( final  peekable iterator <  paired read sequence >  iterator )  {  final  list <  paired read sequence >  group = new  array list <  paired read sequence >  (  )  ;  final  paired read sequence first = iterator . next (  )  ;  group . add ( first )  ;  outer: while  ( iterator . has next (  )  )   {  final  paired read sequence next = iterator . peek (  )  ;  for  ( int i = 0 ;  i  <  min   identical   bases ;   +  + i )   {  if  ( first . read1[i]  !  =  next . read1[i] || first . read2[i]  !  =  next . read2[i] )  break outer ;   }  group . add ( iterator . next (  )  )  ;   }  return group ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,get read barcode value,public static int   ( final sam record record final  string tag )  {  if  ( null  =  =  tag )  return 0 ;  final  string attr = record . get string attribute ( tag )  ;  if  ( null  =  =  attr )  return 0 ;  else return attr . hash code (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,get read group,public short   (  )  {  return this . read group ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,get read one barcode value,private int   ( final sam record record )  {  return get read barcode value ( record read   one   barcode   tag )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,get read two barcode value,private int   ( final sam record record )  {  return get read barcode value ( record read   two   barcode   tag )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,get size in bytes,public static int   (  )  {  return  paired read sequence . get size in bytes (  )   +   ( 3 * 4 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,init hashes,void   ( int number of hashes int skipped bases int min read length )  {  hashes1 = get hashes ( read1 number of hashes skipped bases min read length )  ;  hashes2 = get hashes ( read2 number of hashes skipped bases min read length )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,main,public static void   ( final  string[] args )  {  new  estimate library complexity (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,passes quality check,boolean   ( final byte[] bases final byte[] quals final int seed length final int min quality )  {  if  ( bases . length  <  seed length )  return false ;  for  ( int i = 0 ;  i  <  seed length ;   +  + i )   {  if  (  sequence util . is no call ( bases[i] )  )  return false ;   }  final int max read length =  ( max   read   length  <  =  0 )   ?   integer . max   value : max   read   length ;  final int read length =  math . min ( bases . length max read length )  ;  int total = 0 ;  for  ( int i = 0 ;  i  <  read length ;  i +  +  )  total +  = quals[i] ;  return total  /  read length  >  =  min quality ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,set input stream,public void   ( final  input stream in )  {  this . in = new  data input stream ( in )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,set library id,public void   ( final short library id )  {  this . library id = library id ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,set output stream,public void   ( final  output stream out )  {  this . out = new  data output stream ( out )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,set read group,public void   ( final short read group )  {  this . read group = read group ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\EstimateLibraryComplexity.java,split by library," map <  string  list <  paired read sequence >  >    ( final  list <  paired read sequence >  input final  list < sam read group record >  rgs )  {  final  map <  string  list <  paired read sequence >  >  out = new  hash map <  >  (  )  ;  for  (  final  paired read sequence seq : input )   {   string library ;  if  ( seq . get read group (  )   !  =   - 1 )   {  library = rgs . get ( seq . get read group (  )  )  . get library (  )  ;  if  ( library  =  =  null )  library = "" unknown"" ;   }  else  {  library = "" unknown"" ;   }   list <  paired read sequence >  library seqs = out . get ( library )  ;  if  ( library seqs  =  =  null )   {  library seqs = new  array list <  >  (  )  ;  out . put ( library library seqs )  ;   }  library seqs . add ( seq )  ;   }  return out ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigar.java,do work,"protected int   (  )  {  io util . assert inputs are valid ( input )  ;  io util . assert file is writable ( output )  ;  io util . assert file is writable ( metrics   file )  ;  final  sam header and iterator header and iterator = open inputs ( true )  ;  final sam file header header = header and iterator . header ;  final sam file header output header = header . clone (  )  ;  if  ( output header . get sort order (  )   !  =  sam file header .  sort order . coordinate )   {  throw new  picard exception ( "" this program requires inputs in coordinate  sort order"" )  ;   }  comment . for each ( output header::add comment )  ;  setpg ids seen ( output header )  ;  final  map <  string  string >  chained pg ids = get chained pg ids ( output header )  ;  final sam file writer out = new sam file writer factory (  )  . makesam orbam writer ( output header true output )  ;  final  mark duplicates with mate cigar iterator iterator = new  mark duplicates with mate cigar iterator ( header and iterator . header header and iterator . iterator this . optical duplicate finder this . duplicate   scoring   strategy this . minimum   distance this . remove   duplicates this . skip   pairs   with   no   mate   cigar this . max   records   in   ram this . block   size this . tmp   dir )  ;  final  progress logger progress = new  progress logger ( log  ( int ) 1e6 "" read"" )  ;  for  (  final sam record record : new  iterable adapter < sam record >  ( iterator )  )   {  if  ( progress . record ( record )  )   {  iterator . log memory stats ( log )  ;   }  update program record ( record chained pg ids )  ;  out . add alignment ( record )  ;   }  iterator . close (  )  ;  out . close (  )  ;  final  histogram <  short >  optical dupes by library id = iterator . get optical dupes by library id (  )  ;  log . info ( "" processed ""  +  progress . get count (  )   +  "" records"" )  ;  log . info ( "" found ""  +  iterator . get num records with no mate cigar (  )   +  "" records with no mate cigar optional tag . "" )  ;  log . info ( "" marking ""  +  iterator . get num duplicates (  )   +  "" records as duplicates . "" )  ;  log . info ( "" found ""  +   (  ( long ) optical dupes by library id . get sum of values (  )  )   +  "" optical duplicate clusters . "" )  ;  finalize and write metrics ( iterator . get library id generator (  )  )  ;  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigar.java,main,public static void   ( final  string[] args )  {  new  mark duplicates with mate cigar (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigar.java,setpg ids seen,private void   ( final sam file header header )  {  final  set <  string >  pg ids seen as previous = new  hash set <  string >  (  )  ;  for  (  final sam program record sam program record : header . get program records (  )  )   {  final  string previous program groupid = sam program record . get previous program group id (  )  ;  if  ( null  !  =  previous program groupid )  pg ids seen as previous . add ( previous program groupid )  ;   }  for  (  final sam program record sam program record : header . get program records (  )  )   {  final  string pg id = sam program record . get id (  )  ;  if  (  ! pg ids seen as previous . contains ( pg id )  )  this . pg ids seen . add ( pg id )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigar.java,update program record,"private void   ( final sam record record final  map <  string  string >  chained pg ids )  {  if  ( program   record   id  !  =  null && pg tag argument collection . add   pg   tag   to   reads )   {  final  string pg id = record . get string attribute ( sam tag . pg . name (  )  )  ;  if  ( null  =  =  pg id )   {  if  (  ! warned null program records )   {  warned null program records = true ;  log . warn ( "" encountered a record with no program record  program group chaining will not occur for this read: ""  +  record )  ;   }   }  else if  (  ! chained pg ids . contains key ( pg id )  )   {  if  (  ! warned missing program records )   {  warned missing program records = true ;  log . warn ( "" encountered a record with an intermediate program record  program group chaining will not occur for this read: ""  +  record )  ;   }   }  else  {  record . set attribute ( sam tag . pg . name (  )  chained pg ids . get ( pg id )  )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\SimpleMarkDuplicatesWithMateCigar.java,do work,"protected int   (  )  {  io util . assert inputs are valid ( input )  ;  io util . assert file is writable ( output )  ;  io util . assert file is writable ( metrics   file )  ;  final  sam header and iterator header and iterator = open inputs ( true )  ;  final sam file header header = header and iterator . header ;  final sam file header output header = header . clone (  )  ;  if  ( output header . get sort order (  )   !  =  sam file header .  sort order . coordinate )   {  throw new  picard exception ( "" this program requires inputs in coordinate  sort order"" )  ;   }  comment . for each ( output header::add comment )  ;  final  map <  string  string >  chained pg ids = get chained pg ids ( output header )  ;  final sam file writer out = new sam file writer factory (  )  . makesam orbam writer ( output header false output )  ;  final sam record duplicate comparator comparator = new sam record duplicate comparator (  collections . singleton list ( header and iterator . header )  )  ;  comparator . set scoring strategy ( this . duplicate   scoring   strategy )  ;  final  closeable iterator <  duplicate set >  iterator = get duplicate set iterator ( header and iterator comparator )  ;  final  progress logger progress = new  progress logger ( log  ( int ) 1e6 "" read"" )  ;  int num duplicates = 0 ;  library id generator = new  library id generator ( header and iterator . header )  ;  for  (  final  duplicate set duplicate set : new  iterable adapter <  >  ( iterator )  )   {  final sam record representative = duplicate set . get representative (  )  ;  final boolean do optical duplicate tracking =  ( this . read   name   regex  !  =  null )  && is paired and both mapped ( representative )  && representative . get first of pair flag (  )  ;  final  set <  string >  duplicate read ends seen = new  hash set <  >  (  )  ;  final  list <  read ends >  duplicate read ends = new  array list <  >  (  )  ;  for  (  final sam record record : duplicate set . get records (  )  )   {  final  string library =  library id generator . get library name ( header record )  ;   duplication metrics metrics = library id generator . get metrics by library ( library )  ;  if  ( metrics  =  =  null )   {  metrics = new  duplication metrics (  )  ;  metrics . library = library ;  library id generator . add metrics by library ( library metrics )  ;   }  if  ( record . is secondary or supplementary (  )  )   {   +  + metrics . secondary   or   supplementary   rds ;   }  else  {  if  ( record . get read unmapped flag (  )  )   {   +  + metrics . unmapped   reads ;   }  else if  (  ! record . get read paired flag (  )  || record . get mate unmapped flag (  )  )   {   +  + metrics . unpaired   reads   examined ;   }  else  {   +  + metrics . read   pairs   examined ;   }  if  ( record . get duplicate read flag (  )  )   {  if  (  ! record . get read paired flag (  )  || record . get mate unmapped flag (  )  )   {   +  + metrics . unpaired   read   duplicates ;   }  else  {   +  + metrics . read   pair   duplicates ;   }  num duplicates +  +  ;   }  if  ( do optical duplicate tracking && is paired and both mapped ( record )  &&  ! duplicate read ends seen . contains ( record . get read name (  )  )  )   {  final  read ends for simple mark duplicates with mate cigar read end = new  read ends for simple mark duplicates with mate cigar (  )  ;  if  ( record . get first of pair flag (  )  )   {  read end . orientation for optical duplicates =  read ends . get orientation byte ( record . get read negative strand flag (  )  record . get mate negative strand flag (  )  )  ;   }  else  {  read end . orientation for optical duplicates =  read ends . get orientation byte ( record . get mate negative strand flag (  )  record . get read negative strand flag (  )  )  ;   }  if  ( optical duplicate finder . add location information ( record . get read name (  )  read end )  )   {  if  ( null  !  =  record . get read group (  )  )   {  final short index = library id generator . get library id ( record )  ;  read end . set library id ( index )  ;   }   }  duplicate read ends . add ( read end )  ;  duplicate read ends seen . add ( record . get read name (  )  )  ;   }   }  if  (  ! this . remove   duplicates ||  ! record . get duplicate read flag (  )  )   {  if  ( program   record   id  !  =  null )   {  record . set attribute ( sam tag . pg . name (  )  chained pg ids . get ( record . get string attribute ( sam tag . pg . name (  )  )  )  )  ;   }  out . add alignment ( record )  ;  progress . record ( record )  ;   }   }  if  ( this . read   name   regex  !  =  null && 1  <  duplicate read ends . size (  )  )   {   abstract mark duplicates command line program . track optical duplicates ( duplicate read ends duplicate read ends . get ( 0 )  optical duplicate finder library id generator )  ;   }   }  iterator . close (  )  ;  out . close (  )  ;  if  ( this . read   name   regex  =  =  null )   {  log . warn ( "" skipped optical duplicate cluster discovery ;  library size estimation may be inaccurate ! "" )  ;   }  else  {  log . info ( "" found ""  +   ( this . library id generator . get number of optical duplicate clusters (  )  )   +  "" optical duplicate clusters . "" )  ;   }  log . info ( "" processed ""  +  progress . get count (  )   +  "" records"" )  ;  log . info ( "" marking ""  +  num duplicates  +  "" records as duplicates . "" )  ;  finalize and write metrics ( library id generator )  ;  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\SimpleMarkDuplicatesWithMateCigar.java,get duplicate set iterator,protected  closeable iterator <  duplicate set >    ( final  sam header and iterator header and iterator final sam record duplicate comparator comparator )  {  return new  duplicate set iterator ( header and iterator . iterator header and iterator . header false comparator )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\SimpleMarkDuplicatesWithMateCigar.java,is paired and both mapped,private static boolean   ( final sam record record )  {  return record . get read paired flag (  )  &&  ! record . get read unmapped flag (  )  &&  ! record . get mate unmapped flag (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\SimpleMarkDuplicatesWithMateCigar.java,main,public static void   ( final  string[] args )  {  new  mark duplicates with mate cigar (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java, mark duplicates with mate cigar iterator,"public   ( final sam file header header final  closeable iterator < sam record >  iterator final  optical duplicate finder optical duplicate finder final  scoring strategy duplicate scoring strategy final int to mark queue minimum distance final boolean remove duplicates final boolean skip pairs with no mate cigar final int max records in ram final int block size final  list <  file >  tmp dirs )  throws  picard exception  {  if  ( header . get sort order (  )   !  =  sam file header .  sort order . coordinate )   {  throw new  picard exception ( get class (  )  . get name (  )   +  "" expects the input to be in coordinate sort order . "" )  ;   }  this . header = header ;  backing iterator = new  peekable iterator < sam record >  ( iterator )  ;  output buffer = new  sam record tracking buffer <  sam record with ordinal and set duplicate read flag >  ( max records in ram block size tmp dirs header  sam record with ordinal and set duplicate read flag . class )  ;  this . remove duplicates = remove duplicates ;  this . skip pairs with no mate cigar = skip pairs with no mate cigar ;  this . optical duplicate finder = optical duplicate finder ;  to mark queue = new  mark queue ( duplicate scoring strategy )  ;  library id generator = new  library id generator ( header )  ;  if  ( duplicate scoring strategy  =  =   scoring strategy . sum   of   base   qualities )  throw new  picard exception ( ""sum   of   base   qualities not supported as this may cause inconsistencies across ends in a pair .   please use a different scoring strategy . "" )  ;  for  (  final sam read group record read group : header . get read groups (  )  )   {  final  string library =  library id generator . get read group library name ( read group )  ;   duplication metrics metrics = library id generator . get metrics by library ( library )  ;  if  ( metrics  =  =  null )   {  metrics = new  duplication metrics (  )  ;  metrics . library = library ;  library id generator . add metrics by library ( library metrics )  ;   }   }  to mark queue . set to mark queue minimum distance ( to mark queue minimum distance )  ;  next record = mark duplicates and get the next available (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,add record to the output buffer,"private void   ( final  sam record with ordinal sam record with ordinal )  throws  picard exception  {  final int record reference index = sam record with ordinal . get record (  )  . get reference index (  )  ;  if  ( record reference index  <  reference index )   {  throw new  picard exception ( "" records out of order: ""  +  record reference index  +  ""  <  "" +  reference index )  ;   }  else if  ( reference index  <  record reference index )   {  try polling the to mark queue ( true null )  ;  reference index = record reference index ;   }  output buffer . add ( sam record with ordinal )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,assert sorted,"@ override public sam record iterator   ( final sam file header .  sort order sort order )  {  if  ( sort order  !  =  sam file header .  sort order . coordinate )   {  throw new  illegal state exception ( "" cannot assort ""  +  sort order  +  "" when expec"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,check cigar for skips,private boolean   ( final  cigar cigar )  {  final  list <  cigar element >  elements = cigar . get cigar elements (  )  ;  for  (  final  cigar element el : elements )   {  if  ( el . get operator (  )   =  =   cigar operator . n )  return true ;   }  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,check for minimum distance failure,"private void   ( final  read ends for mate cigar current )  {  if  (  ! to mark queue . is empty (  )  )   {  final  read ends for mate cigar other = to mark queue . peek (  )  ;  if  ( other . read1 reference index  =  =  current . read1 reference index && to mark queue . get to mark queue minimum distance (  )   <  =  other . read1 coordinate  -  current . read1 coordinate )   {  if  ( check cigar for skips ( other . get record (  )  . get cigar (  )  )  )   {  throw new  picard exception ( "" found a sam record with ordinal with sufficiently large code length that we may have\n""  +  "" missed including it in an early duplicate marking iteration .   alignment contains skipped""  +  "" reference bases  ( n's )  .   if this is an\n rn aseq aligned bam  please use  mark duplicates instead "" +  "" as this tool does not work well with spliced reads . \n  minimum distance set to ""  +  to mark queue . get to mark queue minimum distance (  )   +  "" but "" +   ( other . read1 coordinate  -  current . read1 coordinate  -  1 )  +  "" would be required . \n"" +  "" record was: "" +  other . get record (  )  . getsam string (  )  )  ;   }  else  {   system . err . print ( ""record #1: ""  +  other . get record (  )  . getsam string (  )  )  ;   system . err . print ( ""record #2: ""  +  current . get record (  )  . getsam string (  )  )  ;  throw new  picard exception ( "" found a sam record with ordinal with sufficiently large clipping that we may have\n""  +  "" missed including it in an early duplicate marking iteration .   please increase the""  +  "" minimum distance to at least ""  +   ( other . read1 coordinate  -  current . read1 coordinate  -  1 )   +  ""bp\nto ensure it is considered  ( was "" +  to mark queue . get to mark queue minimum distance (  )  +  "" )  . \n"" +  "" record was: "" +  other . get record (  )  . getsam string (  )  )  ;   }   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,close,@ override public void   (  )  {  backing iterator . close (  )  ;  output buffer . close (  )  ;  is closed = true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,enforce closed,"private void   (  )  {  if  (  ! is closed )  throw new  picard exception ( "" calling a method that assumes the iterator is closed"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,flush,private sam record   (  )  {  while  (  ! output buffer . is empty (  )  && output buffer . can emit (  )  )   {  final sam record record = output buffer . next (  )  . get record (  )  ;  if  (  ! remove duplicates ||  ! record . get duplicate read flag (  )  )   {  return record ;   }   }  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,get library id generator,public  library id generator   (  )  {  enforce closed (  )  ;  return library id generator ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,get metrics,private  duplication metrics   ( final sam record record )  {  final  string library =  library id generator . get library name ( header record )  ;   duplication metrics metrics = library id generator . get metrics by library ( library )  ;  if  ( metrics  =  =  null )   {  metrics = new  duplication metrics (  )  ;  metrics . library = library ;  library id generator . add metrics by library ( library metrics )  ;   }  return metrics ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,get num duplicates,public int   (  )  {  enforce closed (  )  ;  return to mark queue . get num duplicates (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,get num records with no mate cigar,public int   (  )  {  enforce closed (  )  ;  return num records with no mate cigar ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,get optical dupes by library id,public  histogram <  short >    (  )  {  enforce closed (  )  ;  return library id generator . get optical duplicates by library id map (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,has next,@ override public boolean   (  )  {  if  ( null  !  =  next record )  return true ;  return  ( backing iterator . has next (  )  ||  ! output buffer . is empty (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,ignore due to missing mate cigar,"private boolean   ( final  sam record with ordinal sam record with ordinal )  {  final sam record record = sam record with ordinal . get record (  )  ;  if  ( record . get read paired flag (  )  &&  ! record . get mate unmapped flag (  )  && null  =  =  sam utils . get mate cigar ( record )  )   {  final  duplication metrics metrics = get metrics ( record )  ;  if  ( record . is secondary or supplementary (  )  )   {   +  + metrics . secondary   or   supplementary   rds ;   }  else  {  if  ( record . get read unmapped flag (  )  )   {   +  + metrics . unmapped   reads ;   }  else if  (  ! record . get read paired flag (  )  || record . get mate unmapped flag (  )  )   {   +  + metrics . unpaired   reads   examined ;   }  else  {   +  + metrics . read   pairs   examined ;   }   }  if  ( skip pairs with no mate cigar )   {  add record to the output buffer ( sam record with ordinal )  ;  backing iterator record index +  +  ;  output buffer . set result state ( sam record with ordinal false )  ;  num records with no mate cigar +  +  ;  backing iterator . next (  )  ;  return true ;   }  else  {  throw new  picard exception ( "" read ""  +  record . get read name (  )   +  "" was mapped and had a mapped mate  but no mate cigar  ( \""mc\"" )  tag . "" )  ;   }   }  return false ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,log memory stats,"public void   ( final  log log )  {   system . gc (  )  ;  final  runtime runtime =  runtime . get runtime (  )  ;  log . info ( ""free memory: ""  +  runtime . free memory (  )   +  "" ;  total memory: "" +  runtime . total memory (  )  +  "" ;  max memory: "" +  runtime . max memory (  )  +  "" ;  output buffer size: "" +  output buffer . size (  )  +  "" ;  duplicate queue size: "" +  to mark queue . size (  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,mark duplicates and get the next available,private sam record   (  )  {   {  final sam record record = flush (  )  ;  if  ( null  !  =  record )  return record ;   }  if  (  ! backing iterator . has next (  )  )   {  if  ( to mark queue . is empty (  )  )   {  if  ( output buffer . is empty (  )  )   {  return null ;   }   }  else  {  try polling the to mark queue ( true null )  ;   }  reference index = header . get sequence dictionary (  )  . get sequences (  )  . size (  )  ;  return mark duplicates and get the next available (  )  ;   }  while  ( backing iterator . has next (  )  )   {  sam record record = backing iterator . peek (  )  ;  final  sam record with ordinal sam record with ordinal = new  sam record with ordinal and set duplicate read flag ( record backing iterator record index )  ;   read ends for mate cigar read ends = null ;  boolean performed chunk and mark the duplicates = false ;  record . set duplicate read flag ( false )  ;  if  ( ignore due to missing mate cigar ( sam record with ordinal )  )   {  continue ;   }  if  ( record . get read unmapped flag (  )  )   {  if  (  - 1  =  =  record . get reference index (  )  )   {  return next if record is unmapped ateof ( record )  ;   }  else if  (  ! record . is secondary or supplementary (  )  )   {  final  duplication metrics metrics = get metrics ( record )  ;   +  + metrics . unmapped   reads ;   }   }  else  {  if  (  - 1  =  =  to mark queue . get to mark queue minimum distance (  )  )   {  to mark queue . set to mark queue minimum distance (  math . max ( 2 * record . get read bases (  )  . length 100 )  )  ;   }  read ends = new  read ends for mate cigar ( header sam record with ordinal optical duplicate finder library id generator . get library id ( sam record with ordinal . get record (  )  )  )  ;  check for minimum distance failure ( read ends )  ;  performed chunk and mark the duplicates = try polling the to mark queue ( false read ends )  ;   }  backing iterator . next (  )  ;  add record to the output buffer ( sam record with ordinal )  ;  backing iterator record index +  +  ;  final  duplication metrics metrics = get metrics ( record )  ;  if  ( record . is secondary or supplementary (  )  || record . get read unmapped flag (  )  )   {  output buffer . set result state ( sam record with ordinal false )  ;  if  ( record . is secondary or supplementary (  )  )   {   +  + metrics . secondary   or   supplementary   rds ;   }   }  else  {  if  (  ! record . get read paired flag (  )  || record . get mate unmapped flag (  )  )   {   +  + metrics . unpaired   reads   examined ;   }  else  {   +  + metrics . read   pairs   examined ;   }  to mark queue . add ( read ends output buffer get metrics ( read ends . get record (  )  )  )  ;   }  if  ( performed chunk and mark the duplicates )   {  record = flush (  )  ;  if  ( null  !  =  record )  return record ;   }   }  return mark duplicates and get the next available (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,next,@ override public sam record   (  )  throws  picard exception  {  final sam record to return = next record ;  if  ( null  =  =  to return )   {  throw new  no such element exception (  )  ;   }  if  ( has next (  )  )   {  next record = mark duplicates an
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,next if record is unmapped ateof,"private sam record   ( final sam record record )  {  if  ( found unmappedeof reads )   {  final sam record unmapped record = backing iterator . next (  )  ;  if  (  ! record . is secondary or supplementary (  )  )   {  final  duplication metrics metrics = get metrics ( record )  ;   +  + metrics . unmapped   reads ;   }  if  (  ! output buffer . is empty (  )  )   {  throw new  picard exception ( "" encountered unmapped reads at the end of the file  but the alignment start buffer was not empty . "" )  ;   }  return unmapped record ;   }  else  {  found unmappedeof reads = true ;  reference index = header . get sequence dictionary (  )  . get sequences (  )  . size (  )  ;  try polling the to mark queue ( true null )  ;  return mark duplicates and get the next available (  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,remove,@ override public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarIterator.java,try polling the to mark queue,"private boolean   ( final boolean flush final  read ends for mate cigar current )  {  boolean performed chunk and mark the duplicates = false ;  if  (  ! flush && null  =  =  current )  throw new  picard exception ( "" flush cannot be false and current be null"" )  ;  if  ( to mark queue . is empty (  )  )  return false ;  if  (  ! to mark queue . is empty (  )  && output buffer . is empty (  )  )   {  throw new  picard exception ( ""0  <  to mark queue && output buffer . is empty (  ) "" )  ;   }  while  (  ! to mark queue . is empty (  )  &&  ( flush || reference index  !  =  current . read1 reference index || to mark queue . get to mark queue minimum distance (  )   <  current . read1 coordinate  -  to mark queue . peek (  )  . read1 coordinate )  )   {  final  read ends for mate cigar next = to mark queue . poll ( output buffer header optical duplicate finder library id generator )  ;  performed chunk and mark the duplicates = true ;  if  ( to mark queue . should be in locations ( next )  && next . get record (  )  . get first of pair flag (  )  )   {  final  set <  read ends >  locations = to mark queue . get locations ( next )  ;  if  (  ! locations . is empty (  )  )   {   abstract mark duplicates command line program . track optical duplicates ( new  array list <  read ends >  ( locations )  null optical duplicate finder library id generator )  ;   }   }   }  return performed chunk and mark the duplicates ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\UmiAwareDuplicateSetIterator.java, umi aware duplicate set iterator,  ( final  duplicate set iterator wrapped iterator final int max edit distance to join final  string umi tag final  string assigned umi tag final boolean allow missing umis final  umi metrics metrics )  {  this . wrapped iterator = wrapped iterator ;  this . max edit distance to join = max edit distance to join ;  this . umi tag = umi tag ;  this . inferred umi tag = assigned umi tag ;  this . allow missing umis = allow missing umis ;  this . metrics = metrics ;  is open = true ;  next sets iterator =  collections . empty iterator (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\UmiAwareDuplicateSetIterator.java,close,@ override public void   (  )  {  is open = false ;  wrapped iterator . close (  )  ;  metrics . calculate derived fields (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\UmiAwareDuplicateSetIterator.java,has next,@ override public boolean   (  )  {  if  (  ! is open )   {  return false ;   }  else  {  if  ( next sets iterator . has next (  )  || wrapped iterator . has next (  )  )   {  return true ;   }  else  {  is open = false ;  return false ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\UmiAwareDuplicateSetIterator.java,next,@ override public  duplicate set   (  )  {  if  (  ! next sets iterator . has next (  )  )   {  process ( wrapped iterator . next (  )  )  ;   }  return next sets iterator . next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\UmiAwareDuplicateSetIterator.java,process,"private void   ( final  duplicate set set )  {  if  ( next sets iterator . has next (  )  )   {  throw new  picard exception ( ""next sets iterator is expected to be empty  but already contains data . "" )  ;   }  final  umi graph umi graph = new  umi graph ( set umi tag inferred umi tag allow missing umis )  ;   list <  duplicate set >  duplicate sets = umi graph . join umis into duplicate sets ( max edit distance to join )  ;  for  (   duplicate set ds : duplicate sets )   {   list < sam record >  records = ds . get records (  )  ;  sam record representative read = ds . get representative (  )  ;   string inferred umi = representative read . get string attribute ( inferred umi tag )  ;  for  (  sam record rec : records )   {   string current umi =  umi util . get sanitizedumi ( rec umi tag )  ;  if  ( current umi  !  =  null )   {  if  ( current umi . contains ( ""n"" )  )   {  metrics . add umi observationn (  )  ;   }  else  {  if  (  ! have we seen first read )   {  metrics . mean   umi   length = current umi . length (  )  ;  have we seen first read = true ;   }  else  {  if  ( metrics . mean   umi   length  !  =  current umi . length (  )  )   {  throw new  picard exception ( ""um is of differing lengths were found . "" )  ;   }   }  metrics . observed   base   errors +  = hamming distance ( current umi inferred umi )  ;  observed umi bases +  = current umi . length (  )  ;  metrics . add umi observation ( current umi inferred umi )  ;   }   }   }   }  metrics . duplicate   sets   with   umi +  = duplicate sets . size (  )  ;  metrics . duplicate   sets   ignoring   umi +  +  ;  next sets iterator = duplicate sets . iterator (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\UmiGraph.java, umi graph,"public   (  duplicate set set  string umi tag  string assigned umi tag boolean allow missing umis )  {  this . umi tag = umi tag ;  this . assigned umi tag = assigned umi tag ;  this . allow missing umis = allow missing umis ;  records = set . get records (  )  ;  for  (  sam record rec : records )   {  if  (  umi util . get sanitizedumi ( rec umi tag )   =  =  null )   {  if  ( allow missing umis )   {  rec . set attribute ( umi tag """" )  ;   }  else  {  throw new  picard exception ( "" read ""  +  rec . get read name (  )   +  "" does not contain a umi with the "" +  umi tag +  "" attribute . "" )  ;   }   }   }  umi counts = records . stream (  )  . collect (  collectors . grouping by ( p  -  >   umi util . get sanitizedumi ( p umi tag )  counting (  )  )  )  ;  num umis = umi counts . size (  )  ;  umi = new  string[num umis] ;  duplicate setid =  int stream . range closed ( 0 num umis  -  1 )  . to array (  )  ;  int i = 0 ;  for  (   string key : umi counts . key set (  )  )   {  umi[i] = key ;  i +  +  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\UmiGraph.java,get duplicate sets from umis,private  map <  string  integer >    (  )  {  final  map <  string  integer >  duplicate sets from umis = new  hash map <  >  (  )  ;  for  ( int i = 0 ;  i  <  duplicate setid . length ;  i +  +  )   {  duplicate sets from umis . put ( umi[i] duplicate setid[i] )  ;   }  return duplicate sets from umis ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\UmiGraph.java,join umis into duplicate sets," list <  duplicate set >    ( final int max edit distance to join )  {   graph utils .  graph <  integer >  umi graph = new  graph utils .  graph <  >  (  )  ;  for  ( int i = 0 ;  i  <  num umis ;  i +  +  )   {  umi graph . add node ( i )  ;  for  ( int j = i  +  1 ;  j  <  num umis ;  j +  +  )   {  if  (  string util . is within hamming distance ( umi[i] umi[j] max edit distance to join )  )   {  umi graph . add edge ( i j )  ;   }   }   }  final  map <  integer  integer >  umi cluster map = umi graph . cluster (  )  ;  for  ( int i = 0 ;  i  <  num umis ;  i +  +  )   {  duplicate setid[i] = umi cluster map . get ( i )  ;   }  final  map <  integer  list < sam record >  >  duplicate sets = new  hash map <  >  (  )  ;  final  map <  string  integer >  duplicate sets from umis = get duplicate sets from umis (  )  ;  for  (  sam record rec : records )   {  final  string umi =  umi util . get sanitizedumi ( rec umi tag )  ;  final  integer duplicate set index = duplicate sets from umis . get ( umi )  ;  if  ( duplicate sets . contains key ( duplicate set index )  )   {  duplicate sets . get ( duplicate set index )  . add ( rec )  ;   }  else  {  final  list < sam record >  n = new  array list <  >  (  )  ;  n . add ( rec )  ;  duplicate sets . put ( duplicate set index n )  ;   }   }  final  list <  duplicate set >  duplicate set list = new  array list <  >  (  )  ;  for  (  final  map .  entry <  integer  list < sam record >  >  entry : duplicate sets . entry set (  )  )   {  final  duplicate set ds = new  duplicate set (  )  ;  final  list < sam record >  record list = entry . get value (  )  ;  record list . for each ( ds::add )  ;  long max count = 0 ;   string assigned umi = null ;   string fewestn umi = null ;  long n count = 0 ;  for  (  sam record rec : record list )   {  final  string umi =  umi util . get sanitizedumi ( rec umi tag )  ;  if  ( umi . contains ( ""n"" )  )   {  int count =  string utils . count matches ( umi ""n"" )  ;  if  ( n count  =  =  0 )   {  n count = count ;  fewestn umi = umi ;   }  else if  ( count  <  n count )   {  n count = count ;  fewestn umi = umi ;   }   }  else if  ( umi counts . get ( umi )   >  max count )   {  max count = umi counts . get ( umi )  ;  assigned umi = umi ;   }   }  if  ( assigned umi  =  =  null )   {  assigned umi = fewestn umi ;   }  for  (  final sam record rec : record list )   {  if  ( allow missing umis && rec . get string attribute ( umi tag )  . is empty (  )  )   {  rec . set attribute ( umi tag null )  ;   }  else  {  rec . set attribute ( assigned umi tag assigned umi )  ;   }   }  duplicate set list . add ( ds )  ;   }  return duplicate set list ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\UmiMetrics.java, umi metrics,public   ( final double length final int observed unique umis final int inferred unique umis final int observed base errors final int duplicate sets without umi final int duplicate sets with umi final double effective length of inferred umis final double effective length of observed umis final double estimated base quality of umis final double percent umi withn )  {  mean   umi   length = length ;  observed   unique   umis = observed unique umis ;  inferred   unique   umis = inferred unique umis ;  observed   base   errors = observed base errors ;  duplicate   sets   ignoring   umi = duplicate sets without umi ;  duplicate   sets   with   umi = duplicate sets with umi ;  inferred   umi   entropy = effective length of inferred umis ;  observed   umi   entropy = effective length of observed umis ;  umi   base   qualities = estimated base quality of umis ;  pct   umi   with   n = percent umi withn ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\UmiMetrics.java,add umi observation,public void   (  string observed umi  string inferred umi )  {  observed umis . increment ( observed umi )  ;  inferred umis . increment ( inferred umi )  ;  observed umi bases +  = observed umi . length (  )  ;  total observed umis without ns +  +  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\UmiMetrics.java,add umi observationn,public void   (  )  {  observed umi with ns +  +  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\UmiMetrics.java,calculate derived fields,public void   (  )  {  observed   unique   umis = observed umis . size (  )  ;  inferred   unique   umis = inferred umis . size (  )  ;  pct   umi   with   n =  ( double ) observed umi with ns  /   (  ( double ) observed umi with ns  +   ( double ) total observed umis without ns )  ;  observed   umi   entropy = effective number of bases ( observed umis )  ;  inferred   umi   entropy = effective number of bases ( inferred umis )  ;  umi   base   qualities =  quality util . get phred score from error probability (  ( double ) observed   base   errors  /   ( double ) observed umi bases )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\UmiMetrics.java,effective number of bases,private double   (  histogram <  ?  >  observations )  {  double total observations = observations . get sum of values (  )  ;  double entropy basee = observations . values (  )  . stream (  )  . collect (  collectors . summing double ( v  -  >   {  double p = v . get value (  )   /  total observations ;  return  - p *  math . log ( p )  ;   }   )  )  ;  return entropy basee  /   math util . log   4   base   e ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigar.java,do work,@ override protected int   (  )  {  io util . assert file is writable ( umi   metrics   file )  ;  int retval = super . do work (  )  ;   metrics file <  umi metrics  double >  metrics file = get metrics file (  )  ;  metrics file . add metric ( metrics )
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigar.java,get duplicate set iterator,@ override protected  closeable iterator <  duplicate set >    ( final  sam header and iterator header and iterator final sam record duplicate comparator comparator )  {  return new  umi aware duplicate set iterator ( new  duplicate set iterator ( header 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\UmiUtil.java,get sanitizedumi,"public static  string   ( final sam record record final  string umi tag )  {   string umi = record . get string attribute ( umi tag )  ;  if  ( umi  =  =  null )  return null ;  return umi . replace ( "" - "" """" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\DiskBasedReadEndsForMarkDuplicatesMap.java, codec,public   ( final  read ends for mark duplicates codec read ends for mark duplicates codec )  {  this . read ends for mark duplicates codec = read ends for mark duplicates codec ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\DiskBasedReadEndsForMarkDuplicatesMap.java, disk based read ends for mark duplicates map,public   ( int max open files final  read ends for mark duplicates codec read ends for mark duplicates codec )  {  pair info map = new  coordinate sorted pair info map <  string  read ends for mark duplicates >  ( max open files new  codec ( read ends for mark duplicates codec )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\DiskBasedReadEndsForMarkDuplicatesMap.java,decode,"public  map .  entry <  string  read ends for mark duplicates >    (  )  {  try  {  final  string key = read ends for mark duplicates codec . get input stream (  )  . readutf (  )  ;  final  read ends for mark duplicates record = read ends for mark duplicates codec . decode (  )  ;  return new  abstract map .  simple entry < java . lang .  string  read ends for mark duplicates >  ( key record )  ;   }  catch  (  io exception e )   {  throw new  picard exception ( "" error loading  read ends for mark duplicates map from disk"" e )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\DiskBasedReadEndsForMarkDuplicatesMap.java,encode,"public void   ( final  string key final  read ends for mark duplicates read ends )  {  try  {  read ends for mark duplicates codec . get output stream (  )  . writeutf ( key )  ;  read ends for mark duplicates codec . encode ( read ends )  ;   }  catch  (  io exception e )   {  throw new  picard exception ( "" error spilling  read ends for mark duplicates map to disk . "" e )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\DiskBasedReadEndsForMarkDuplicatesMap.java,put,public void   ( int mate sequence index  string key  read ends for mark duplicates read ends )  {  pair info map . put ( mate sequence index key read ends )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\DiskBasedReadEndsForMarkDuplicatesMap.java,remove,public  read ends for mark duplicates   ( int mate sequence index  string key )  {  return pair info map . remove ( mate sequence index key )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\DiskBasedReadEndsForMarkDuplicatesMap.java,set input stream,public void   ( final  input stream is )  {  read ends for mark duplicates codec . set input stream ( is )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\DiskBasedReadEndsForMarkDuplicatesMap.java,set output stream,public void   ( final  output stream os )  {  read ends for mark duplicates codec . set output stream ( os )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\DiskBasedReadEndsForMarkDuplicatesMap.java,size,public int   (  )  {  return pair info map . size (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\DiskBasedReadEndsForMarkDuplicatesMap.java,size in ram,public int   (  )  {  return pair info map . size in ram (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\AbstractMarkDuplicatesCommandLineProgram.java, sam header and iterator,public   ( final sam file header header final  closeable iterator < sam record >  iterator )  {  this . header = header ;  this . iterator = iterator ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\AbstractMarkDuplicatesCommandLineProgram.java,finalize and write metrics,protected void   ( final  library id generator library id generator )  {  final  map <  string  duplication metrics >  metrics by library = library id generator . get metrics by library map (  )  ;  final  histogram <  short >  optical duplicates by library id = library id generator . get optical duplicates by library id map (  )  ;  final  map <  string  short >  library ids = library id generator . get library ids map (  )  ;  final  metrics file <  duplication metrics  double >  file = get metrics file (  )  ;  for  (  final  map .  entry <  string  duplication metrics >  entry : metrics by library . entry set (  )  )   {  final  string library name = entry . get key (  )  ;  final  duplication metrics metrics = entry . get value (  )  ;  metrics . read   pairs   examined = metrics . read   pairs   examined  /  2 ;  metrics . read   pair   duplicates = metrics . read   pair   duplicates  /  2 ;  final  short library id = library ids . get ( library name )  ;  if  ( library id  !  =  null )   {  final  histogram .  bin <  short >  bin = optical duplicates by library id . get ( library id )  ;  if  ( bin  !  =  null )   {  metrics . read   pair   optical   duplicates =  ( long ) bin . get value (  )  ;   }   }  metrics . calculate derived fields (  )  ;  file . add metric ( metrics )  ;   }  if  ( metrics by library . size (  )   =  =  1 )   {  file . set histogram ( metrics by library . values (  )  . iterator (  )  . next (  )  . calculate roi histogram (  )  )  ;   }  file . write ( metrics   file )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\AbstractMarkDuplicatesCommandLineProgram.java,get chained pg ids,protected  map <  string  string >    ( final sam file header output header )  {  final  map <  string  string >  chained pg ids ;  if  ( program   record   id  !  =  null )   {  final sam file header .  pg id generator pg id generator = new sam file header .  pg id generator ( output header )  ;  if  ( program   group   version  =  =  null )   {  program   group   version = this . get version (  )  ;   }  if  ( program   group   command   line  =  =  null )   {  program   group   command   line = this . get command line (  )  ;   }  chained pg ids = new  hash map <  >  (  )  ;  for  (  final  string existing id : this . pg ids seen )   {  final  string new pg id = pg id generator . get non colliding id ( program   record   id )  ;  chained pg ids . put ( existing id new pg id )  ;  final sam program record program record = new sam program record ( new pg id )  ;  program record . set program version ( program   group   version )  ;  program record . set command line ( program   group   command   line )  ;  program record . set program name ( program   group   name )  ;  program record . set previous program group id ( existing id )  ;  output header . add program record ( program record )  ;   }   }  else  {  chained pg ids = null ;   }  return chained pg ids ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\AbstractMarkDuplicatesCommandLineProgram.java,open inputs,protected  sam header and iterator   ( boolean eagerly decode )  {  final  list < sam file header >  headers = new  array list <  >  ( input . size (  )  )  ;  final  list <  sam reader >  readers = new  array list <  >  ( input . size (  )  )  ;  for  (  final  string input : input )   {   sam reader factory reader factory =  sam reader factory . make default (  )  ;   sam reader reader = eagerly decode  ?  reader factory . enable (  sam reader factory .  option . eagerly   decode )  . open (  sam input resource . of ( input )  )  : reader factory . open (  sam input resource . of ( input )  )  ;  final sam file header header = reader . get file header (  )  ;  headers . add ( header )  ;  readers . add ( reader )  ;   }  if  ( assume   sort   order  !  =  null || assume   sorted )   {  if  ( assume   sort   order  =  =  null )   {  assume   sort   order = sam file header .  sort order . coordinate ;  assume   sorted = false ;   }  headers . get ( 0 )  . set sort order ( assume   sort   order )  ;   }  if  ( headers . size (  )   =  =  1 )   {  return new  sam header and iterator ( headers . get ( 0 )  readers . get ( 0 )  . iterator (  )  )  ;   }  else  {  final  sam file header merger header merger = new  sam file header merger ( headers . get ( 0 )  . get sort order (  )  headers false )  ;  final  merging sam record iterator iterator = new  merging sam record iterator ( header merger readers assume   sort   order  !  =  null )  ;  return new  sam header and iterator ( header merger . get merged header (  )  iterator )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\AbstractMarkDuplicatesCommandLineProgram.java,track optical duplicates,private static void   ( final  list <  ?  extends  read ends >  list final  read ends keeper final  optical duplicate finder optical duplicate finder final  histogram <  short >  optical duplicates by library id )  {  final boolean[] optical duplicate flags = optical duplicate finder . find optical duplicates ( list keeper )  ;  int optical duplicates = 0 ;  for  ( int i = 0 ;  i  <  optical duplicate flags . length ;   +  + i )   {  if  ( optical duplicate flags[i] )   {   +  + optical duplicates ;  list . get ( i )  . is optical duplicate = true ;   }   }  if  ( optical duplicates  >  0 )   {  optical duplicates by library id . increment ( list . get ( 0 )  . get library id (  )  optical duplicates )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\LibraryIdGenerator.java, library id generator,public   ( final sam file header header )  {  this . header = header ;  for  (  final sam read group record read group : header . get read groups (  )  )   {  final  string library =  library id generator . get read group library name ( read group )  ;   duplication metrics metrics = metrics by library . get ( library )  ;  if  ( metrics  =  =  null )   {  metrics = new  duplication metrics (  )  ;  metrics . library = library ;  metrics by library . put ( library metrics )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\LibraryIdGenerator.java,add metrics by library,public void   ( final  string library final  duplication metrics metrics )  {  this . metrics by library . put ( library metrics )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\LibraryIdGenerator.java,get library id,public short   ( final sam record rec )  {  final  string library = get library name ( this . header rec )  ;   short library id = this . library ids . get ( library )  ;  if  ( library id  =  =  null )   {  library id = this . next library id +  +  ;  this . library ids . put ( library library id )  ;   }  return library id ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\LibraryIdGenerator.java,get library ids map,public  map <  string  short >    (  )  {  return this . library ids ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\LibraryIdGenerator.java,get library name,public static  string   ( final sam file header header final sam record rec )  {  final  string read group id =  (  string ) rec . get attribute (  reserved tag constants . read   group   id )  ;  if  ( read group id  !  =  null )   {  final sam read group record rg = header . get read group ( read group id )  ;  if  ( rg  !  =  null )   {  final  string library name = rg . get library (  )  ;  if  ( null  !  =  library name )  return library name ;   }   }  return unknown   library ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\LibraryIdGenerator.java,get metrics by library,public  duplication metrics   ( final  string library )  {  return this . metrics by library . get ( library )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\LibraryIdGenerator.java,get metrics by library map,public  map <  string  duplication metrics >    (  )  {  return this . metrics by library ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\LibraryIdGenerator.java,get number of optical duplicate clusters,public long   (  )  {  return  ( long ) this . optical duplicates by library id . get sum of values (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\LibraryIdGenerator.java,get optical duplicates by library id map,public  histogram <  short >    (  )  {  return this . optical duplicates by library id ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\LibraryIdGenerator.java,get read group library name,public static  string   ( sam read group record read group )  {  return  optional . of nullable ( read group . get library (  )  )  . or else ( unknown   library )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\AbstractOpticalDuplicateFinderCommandLineProgram.java,custom command line validation,@ override protected  string[]   (  )  {  setup optical duplicate finder (  )  ;  return super . custom command line validation (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\AbstractOpticalDuplicateFinderCommandLineProgram.java,setup optical duplicate finder,public void   (  )  {  this . optical duplicate finder = new  optical duplicate finder ( read   name   regex optical   duplicate   pixel   distance max   optical   duplicate   set   size log )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MarkQueue.java, mark queue,public   ( final  scoring strategy duplicate scoring strategy )  {  comparator = new  read endsmc comparator ( duplicate scoring strategy )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MarkQueue.java, read endsmc comparator,public   ( final  scoring strategy duplicate scoring strategy )  {  this . duplicate scoring strategy = duplicate scoring strategy ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MarkQueue.java,add,"public void   ( final  read ends for mate cigar other final  sam record tracking buffer output buffer final  duplication metrics metrics )  {   physical location for mate cigar set location set = null ;  boolean add to location set = true ;   read ends for mate cigar duplicate = null ;  if  ( this . non duplicate read ends set . contains ( other )  )   {  final  sorted set <  read ends for mate cigar >  sorted set = this . non duplicate read ends set . sub set ( other true other true )  ;  if  ( 1  !  =  sorted set . size (  )  )  throw new  picard exception ( "" sorted set should have size one  ( has size ""  +  sorted set . size (  )   +  ""  ) "" )  ;  final  read ends for mate cigar current = sorted set . first (  )  ;  final  string other name = sam utils . get canonical record name ( other . get record (  )  )  ;  final  string current name = sam utils . get canonical record name ( current . get record (  )  )  ;  final int comparison = this . comparator . compare ( current other )  ;  if  ( current name . equals ( other name )  )   {  if  ( 0  <  comparison )   {  this . non duplicate read ends set . remove ( current )  ;  this . non duplicate read ends set . add ( other )  ;  this . other end of non duplicate read ends set . add ( current )  ;  if  ( should be in locations ( other )  )   {  location set = current . remove location set (  )  ;  location set . replace ( current other )  ;  other . set location set ( location set )  ;  add to location set = false ;   }   }  else  {  this . other end of non duplicate read ends set . add ( other )  ;  if  ( should be in locations ( current )  )   {  location set = current . get location set (  )  ;  add to location set = false ;   }   }   }  else  {  if  ( 0  <  comparison )   {  if  ( should be in locations ( current )  )   {  location set = current . remove location set (  )  ;   }  else  {  location set = new  physical location for mate cigar set (  )  ;   }  other . set location set ( location set )  ;  this . non duplicate read ends set . remove ( current )  ;  this . non duplicate read ends set . add ( other )  ;  if  ( this . other end of non duplicate read ends set . contains ( current )  )   {  final  read ends for mate cigar pair = this . other end of non duplicate read ends set . sub set ( current true current true )  . first (  )  ;  this . other end of non duplicate read ends set . remove ( current )  ;  output buffer . set result state ( pair . get sam record index (  )  true )  ;  update duplication metrics ( pair metrics )  ;   }  duplicate = current ;   }  else  {  if  ( should be in locations ( current )  )   {  location set = current . get location set (  )  ;   }  duplicate = other ;   }   }   }  else  {  if  ( should be in locations ( other )  )   {  location set = new  physical location for mate cigar set (  )  ;  other . set location set ( location set )  ;   }  this . non duplicate read ends set . add ( other )  ;   }  final sam record record = other . get record (  )  ;  if  ( record . get read paired flag (  )  &&  ! record . get read unmapped flag (  )  &&  ! record . get mate unmapped flag (  ) && add to location set )   {  if  ( null  =  =  location set )  throw new  picard exception ( ""location non duplicate read ends set was null: ""  +  record . getsam string (  )  )  ;  location set . add ( other )  ;   }  if  ( null  !  =  duplicate )   {  output buffer . set result state ( duplicate . get sam record index (  )  true )  ;  update duplication metrics ( duplicate metrics )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MarkQueue.java,compare,public int   ( final  read ends for mate cigar lhs final  read ends for mate cigar rhs )  {  int retval = lhs . library id  -  rhs . library id ;  if  ( retval  =  =  0 )  retval = lhs . read1 reference index  -  rhs . read1 reference index ;  if  ( retval  =  =  0 )  retval = lhs . read1 coordinate  -  rhs . read1 coordinate ;  if  ( retval  =  =  0 )  retval = rhs . orientation  -  lhs . orientation ;  if  ( retval  =  =  0 && lhs . is paired (  )   !  =  rhs . is paired (  )  )  return lhs . is paired (  )   ?   - 1 : 1 ;  if  ( retval  =  =  0 )  retval = lhs . has unmapped  -  rhs . has unmapped ;  if  ( retval  =  =  0 )  retval = lhs . read2 reference index  -  rhs . read2 reference index ;  if  ( retval  =  =  0 )  retval = lhs . read2 coordinate  -  rhs . read2 coordinate ;  if  ( retval  =  =  0 )  retval =  duplicate scoring strategy . compare ( lhs . get record (  )  rhs . get record (  )  this . duplicate scoring strategy true )  ;  if  ( retval  =  =  0 )  retval = lhs . get record read name (  )  . compare to ( rhs . get record read name (  )  )  ;  if  ( retval  =  =  0 && lhs . is paired (  )  && rhs . is paired (  )  && null  !  =  lhs . get sam record index (  )  )   {  if  ( lhs . get record (  )  . get first of pair flag (  )  )  retval =  - 1 ;  else retval = 1 ;   }  return retval ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MarkQueue.java,get locations,"public  set <  read ends >    ( final  read ends for mate cigar current )  {  if  (  ! should be in locations ( current )  )  throw new  picard exception ( "" not implemented"" )  ;  final  set <  read ends >  location set = current . get read end set for optical duplicates (  )  ;  if  ( null  =  =  location set )  throw new  picard exception ( "" locations was empty: unexpected error"" )  ;  return location set ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MarkQueue.java,get num duplicates,public int   (  )  {  return this . num duplicates ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MarkQueue.java,get to mark queue minimum distance,public int   (  )  {  return this . to mark queue minimum distance ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MarkQueue.java,is empty,public boolean   (  )  {  return this . non duplicate read ends set . is empty (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MarkQueue.java,peek,public  read ends for mate cigar   (  )  {  return this . non duplicate read ends set . first (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MarkQueue.java,poll,"public  read ends for mate cigar   ( final  sam record tracking buffer output buffer final sam file header header final  optical duplicate finder optical duplicate finder final  library id generator library id generator )  {  final  read ends for mate cigar current = this . non duplicate read ends set . poll first (  )  ;  if  ( current . is paired (  )  )   {  if  ( this . other end of non duplicate read ends set . contains ( current )  )   {  final  read ends for mate cigar pair = this . other end of non duplicate read ends set . sub set ( current true current true )  . first (  )  ;  output buffer . set result state ( pair . get sam record index (  )  false )  ;  this . other end of non duplicate read ends set . remove ( current )  ;   }  if  ( null  =  =  this . tmp read ends )   {  this . tmp read ends = new  read ends for mate cigar ( header current . get sam record index (  )  optical duplicate finder current . library id )  ;  this . tmp read ends . read2 reference index = this . tmp read ends . read2 coordinate =  - 1 ;  this . tmp read ends . sam record with ordinal = null ;   }  else  {  this . tmp read ends . read1 reference index = current . read1 reference index ;  this . tmp read ends . read1 coordinate = current . read1 coordinate ;   }  if  ( current . orientation  =  =   read ends . ff || current . orientation  =  =   read ends . fr || current . orientation  =  =   read ends . f )   {  this . tmp read ends . orientation =  read ends . f ;   }  else  {  this . tmp read ends . orientation =  read ends . r ;   }  if  ( this . non duplicate read ends set . contains ( this . tmp read ends )  )   {  final  sorted set <  read ends for mate cigar >  sorted set = this . non duplicate read ends set . sub set ( this . tmp read ends true this . tmp read ends true )  ;  if  ( 1  !  =  sorted set . size (  )  )  throw new  picard exception ( "" sorted set should have size one  ( has size ""  +  sorted set . size (  )   +  ""  ) "" )  ;  final  read ends for mate cigar duplicate = sorted set . first (  )  ;  output buffer . set result state ( duplicate . get sam record index (  )  true )  ;  this . non duplicate read ends set . remove ( this . tmp read ends )  ;  update duplication metrics ( duplicate library id generator . get metrics by library ( library id generator . get library name ( header duplicate . get record (  )  )  )  )  ;   }   }  output buffer . set result state ( current . get sam record index (  )  false )  ;  return current ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MarkQueue.java,set to mark queue minimum distance,public void   ( final int to mark queue minimum distance )  {  this . to mark queue minimum distance = to mark queue minimum distance ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MarkQueue.java,should be in locations,public boolean   ( final  read ends for mate cigar current )  {  return  ( current . is paired (  )  && 0  =  =  current . has unmapped )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MarkQueue.java,size,public int   (  )  {  return this . non duplicate read ends set . size (  )   +  this . other end of non duplicate read ends set . size (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MarkQueue.java,update duplication metrics,private void   ( final  read ends for mate cigar duplicate final  duplication metrics metrics )  {  if  (  ! duplicate . get record (  )  . get read paired flag (  )  || duplicate . get record (  )  . get mate unmapped flag (  )  )   {   +  + metrics . unpaired   read   duplicates ;   }  else  {   +  + metrics . read   pair   duplicates ;   }  this . num duplicates +  +  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\OpticalDuplicateFinder.java, optical duplicate finder,public   ( final  string read name regex final int optical duplicate pixel distance final long max duplicate set size final  log log )  {  super ( read name regex log )  ;  this . optical duplicate pixel distance = optical duplicate pixel distance ;  this . max duplicate set size = max duplicate set size ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\OpticalDuplicateFinder.java,close enough,private boolean   ( final  physical location lhs final  physical location rhs final int distance )  {  return lhs  !  =  rhs && lhs . has location (  )  && rhs . has location (  )  && lhs . get read group (  )   =  =  rhs . get read group (  )  && lhs . get tile (  )   =  =  rhs . get tile (  )  &&  math . abs ( lhs . getx (  )   -  rhs . getx (  )  )   <  =  distance &&  math . abs ( lhs . gety (  )   -  rhs . gety (  )  )   <  =  distance ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\OpticalDuplicateFinder.java,find optical duplicates,"public boolean[]   ( final  list <  ?  extends  physical location >  list final  physical location keeper )  {  final int length = list . size (  )  ;  final boolean[] optical duplicate flags = new boolean[length] ;  if  ( length  <  2 || length  >  max duplicate set size )   {  return optical duplicate flags ;   }  final int distance = this . optical duplicate pixel distance ;  final  physical location actual keeper = keeper or null ( list keeper )  ;  final  log log ;  final  progress logger progress logger for keeper  progress logger for rest ;  final boolean log progress = length  >  big duplicate set size ;  if  ( log progress )   {  log =  log . get instance (  optical duplicate finder . class )  ;  progress logger for keeper = new  progress logger ( log 10000 ""compared"" "" read ends to keeper"" )  ;  progress logger for rest = new  progress logger ( log 1000 ""compared"" "" read ends to others"" )  ;  log . info ( "" large duplicate set .  size  =  ""  +  length )  ;  log . debug ( "" about to compare to keeper:""  +  actual keeper )  ;   }  else  {  log = null ;  progress logger for keeper = null ;  progress logger for rest = null ;   }  if  ( actual keeper  !  =  null )   {  for  ( int i = 0 ;  i  <  length ;   +  + i )   {  final  physical location other = list . get ( i )  ;  optical duplicate flags[i] = close enough ( actual keeper other distance )  ;  if  ( log progress )  progress logger for keeper . record (  string . format ( ""%d"" other . get read group (  )  )  other . getx (  )  )  ;   }   }  if  ( log progress )  log . debug ( "" done with comparing to keeper  now the rest . "" )  ;  for  ( int i = 0 ;  i  <  length ;   +  + i )   {  final  physical location lhs = list . get ( i )  ;  if  ( lhs  =  =  actual keeper )  continue ;  if  ( log progress )  progress logger for rest . record (  string . format ( ""%d"" lhs . get read group (  )  )  lhs . getx (  )  )  ;  for  ( int j = i  +  1 ;  j  <  length ;   +  + j )   {  final  physical location rhs = list . get ( j )  ;  if  ( rhs  =  =  actual keeper )  continue ;  if  ( optical duplicate flags[i] && optical duplicate flags[j] )  continue ;  if  ( close enough ( lhs rhs distance )  )   {  final int index = optical duplicate flags[j]  ?  i : j ;  optical duplicate flags[index] = true ;   }   }   }  return optical duplicate flags ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\OpticalDuplicateFinder.java,keeper or null,private  physical location   ( final  list <  ?  extends  physical location >  list final  physical location keeper )  {  if  ( keeper  !  =  null && keeper . has location (  )  )   {  for  (  final  physical location loc : list )   {  if  ( loc  =  =  keeper )  return keeper ;   }   }  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\OpticalDuplicateFinder.java,set big duplicate set size,public void   ( final int big duplicate set size )  {  this . big duplicate set size = big duplicate set size ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\OpticalDuplicateFinder.java,set max duplicate set size,public void   ( final long max duplicate set size )  {  if  ( max duplicate set size  <  1 )   {  this . max duplicate set size =  long . max   value ;   }  this . max duplicate set size = max duplicate set size ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MemoryBasedReadEndsForMarkDuplicatesMap.java,put,public void   ( int mate sequence index  string key  read ends for mark duplicates read ends )  {  while  ( mate sequence index  >  =  map per sequence . size (  )  )   {  map per sequence . add ( new  hash map <  string  read ends for mark duplicates >  (  )  )  ;   }  map per sequence . get ( mate sequence index )  . put ( key read ends )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MemoryBasedReadEndsForMarkDuplicatesMap.java,remove,public  read ends for mark duplicates   ( int mate sequence index  string key )  {  if  ( mate sequence index  >  =  map per sequence . size (  )  )   {  return null ;   }  return map per sequence . get ( mate sequence index )  . remove ( key )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MemoryBasedReadEndsForMarkDuplicatesMap.java,size,public int   (  )  {  int total = 0 ;  for  (   map <  string  read ends for mark duplicates >  map : map per sequence )   {  total +  = map . size (  )  ;   }  return total ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\MemoryBasedReadEndsForMarkDuplicatesMap.java,size in ram,public int   (  )  {  return size (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\PhysicalLocationForMateCigar.java, physical location for mate cigar,public   ( final  physical location rec )  {  this . set read group ( rec . get read group (  )  )  ;  this . set tile ( rec . get tile (  )  )  ;  this . setx ( rec . getx (  )  )  ;  this . sety ( rec . gety (  )  )  ;  this . set library id ( rec . get library id (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\PhysicalLocationForMateCigar.java,equals,@ override public boolean   (  object other )  {  if  ( other instanceof  physical location for mate cigar )   {  int cmp ;   physical location for mate cigar loc =  (  physical location for mate cigar ) other ;  cmp = get library id (  )   -  loc . get l
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\PhysicalLocationForMateCigar.java,get library id,@ override public short   (  )  {  return this . library id ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\PhysicalLocationForMateCigar.java,get read group,@ override public short   (  )  {  return this . read group ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\PhysicalLocationForMateCigar.java,hash code,@ override public int   (  )  {  int result = get library id (  )  ;  result = 31 * result  +  get read group (  )  ;  result = 31 * result  +  get tile (  )  ;  result = 31 * result  +  gety (  )  ;  result = 31 * result  +  getx (  )  ;  return result ;
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\PhysicalLocationForMateCigar.java,set library id,@ override public void   ( final short library id )  {  this . library id = library id ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\PhysicalLocationForMateCigar.java,set read group,@ override public void   ( final short rg )  {  this . read group = rg ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\PhysicalLocationForMateCigarSet.java,add,public void   ( final  read ends for mate cigar end )  {  final  physical location for mate cigar location = new  physical location for mate cigar ( end )  ;  if  (  ! physical locations . contains ( location )  )   {  read ends . add ( end )  ;  physical locations . add ( new  physical location for mate cigar ( location )  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\PhysicalLocationForMateCigarSet.java,get read ends,public  set <  read ends >    (  )  {  return this . read ends ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\PhysicalLocationForMateCigarSet.java,remove,public void   ( final  read ends for mate cigar end )  {  final  physical location for mate cigar location = new  physical location for mate cigar ( end )  ;  if  ( physical locations . contains ( location )  )   {  read ends . remove ( end )  ;  physical locations . remove ( location )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\PhysicalLocationForMateCigarSet.java,replace,"public void   ( final  read ends for mate cigar current final  read ends for mate cigar other )  {  final  physical location for mate cigar location = new  physical location for mate cigar ( current )  ;  if  (  ! physical locations . contains ( location )  )   {  throw new  picard exception ( "" trying to replace something not in the set"" )  ;   }  this . remove ( current )  ;  this . add ( other )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\PhysicalLocationForMateCigarSet.java,size,public int   (  )  {  return physical locations . size (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEnds.java,get library id,@ override public short   (  )  {  return this . library id ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEnds.java,get orientation byte,public static byte   ( final boolean read1 negative strand final boolean read2 negative strand )  {  if  ( read1 negative strand )   {  if  ( read2 negative strand )  return  read ends . rr ;  else return  read ends . rf ;   }  else  {  if  ( read2 negative strand )  return  read ends . fr ;  else return  read ends . ff ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEnds.java,get read group,@ override public short   (  )  {  return this . read group ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEnds.java,is paired,public boolean   (  )  {  return this . read2 reference index  !  =   - 1 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEnds.java,set library id,@ override public void   ( final short library id )  {  this . library id = library id ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEnds.java,set read group,@ override public void   ( final short read group )  {  this . read group = read group ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMarkDuplicates.java, read ends for mark duplicates,public   ( final  read ends for mark duplicates read )  {  this . library id = read . get library id (  )  ;  this . orientation = read . orientation ;  this . read1 reference index = read . read1 reference index ;  this . read1 coordinate = read . read1 coordinate ;  this . read2 reference index = read . read2 reference index ;  this . read2 coordinate = read . read2 coordinate ;  this . read group = read . get read group (  )  ;  this . tile = read . get tile (  )  ;  this . x = read . x ;  this . y = read . y ;  this . orientation for optical duplicates = read . orientation for optical duplicates ;  this . score = read . score ;  this . read1 index in file = read . read1 index in file ;  this . read2 index in file = read . read2 index in file ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMarkDuplicates.java,clone,@ override public  read ends for mark duplicates   (  )  {  return new  read ends for mark duplicates ( this )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMarkDuplicates.java,get size of,public static int   (  )  {  return size   of ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMarkDuplicatesCodec.java,clone,public  sorting collection .  codec <  read ends for mark duplicates >    (  )  {  return new  read ends for mark duplicates codec (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMarkDuplicatesCodec.java,decode,"public  read ends for mark duplicates   (  )  {  final  read ends for mark duplicates read = new  read ends for mark duplicates (  )  ;  try  {  try  {  read . score = this . in . read short (  )  ;   }  catch  (  final eof exception eof )   {  return null ;   }  read . library id = this . in . read short (  )  ;  read . orientation = this . in . read byte (  )  ;  read . read1 reference index = this . in . read int (  )  ;  read . read1 coordinate = this . in . read int (  )  ;  read . read1 index in file = this . in . read long (  )  ;  read . read2 reference index = this . in . read int (  )  ;  if  ( read . orientation  >   read ends . r )   {  read . read2 coordinate = this . in . read int (  )  ;  read . read2 index in file = this . in . read long (  )  ;   }  read . read group = this . in . read short (  )  ;  read . tile = this . in . read short (  )  ;  read . x = this . in . read short (  )  ;  read . y = this . in . read short (  )  ;  read . orientation for optical duplicates = this . in . read byte (  )  ;  read . duplicate set size = this . in . read int (  )  ;  return read ;   }  catch  (  final io exception ioe )   {  throw new  picard exception ( "" exception writing  read ends to file . "" ioe )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMarkDuplicatesCodec.java,encode,"public void   ( final  read ends for mark duplicates read )  {  try  {  this . out . write short ( read . score )  ;  this . out . write short ( read . library id )  ;  this . out . write byte ( read . orientation )  ;  this . out . write int ( read . read1 reference index )  ;  this . out . write int ( read . read1 coordinate )  ;  this . out . write long ( read . read1 index in file )  ;  this . out . write int ( read . read2 reference index )  ;  if  ( read . orientation  >   read ends . r )   {  this . out . write int ( read . read2 coordinate )  ;  this . out . write long ( read . read2 index in file )  ;   }  this . out . write short ( read . read group )  ;  this . out . write short ( read . tile )  ;  this . out . write short (  ( short ) read . x )  ;  this . out . write short (  ( short ) read . y )  ;  this . out . write byte ( read . orientation for optical duplicates )  ;  this . out . write int ( read . duplicate set size )  ;   }  catch  (  final io exception ioe )   {  throw new  picard exception ( "" exception writing  read ends to file . "" ioe )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMarkDuplicatesCodec.java,get input stream,public  data input stream   (  )  {  return in ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMarkDuplicatesCodec.java,get output stream,public  data output stream   (  )  {  return out ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMarkDuplicatesCodec.java,set input stream,public void   ( final  input stream is )  {  this . in = new  data input stream ( is )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMarkDuplicatesCodec.java,set output stream,public void   ( final  output stream os )  {  this . out = new  data output stream ( os )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMarkDuplicatesWithBarcodesCodec.java,clone,@ override public  sorting collection .  codec <  read ends for mark duplicates >    (  )  {  return new  read ends for mark duplicates with barcodes codec (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMarkDuplicatesWithBarcodesCodec.java,decode,@ override public  read ends for mark duplicates   (  )  {  final  read ends for mark duplicates parent read = super . decode (  )  ;  if  ( null  =  =  parent read )  return null ;  final  read ends for mark duplicates with barcodes read = new  read ends
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMarkDuplicatesWithBarcodesCodec.java,encode,"@ override public void   ( final  read ends for mark duplicates read )  {  if  (  !  ( read instanceof  read ends for mark duplicates with barcodes )  )   {  throw new  picard exception ( "" read was not a  read ends for mark duplicates with barcodes"" )  ;"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMarkDuplicatesWithBarcodes.java, read ends for mark duplicates with barcodes,public   ( final  read ends for mark duplicates with barcodes read )  {  super ( read )  ;  barcode = read . barcode ;  read one barcode = read . read one barcode ;  read two barcode = read . read two barcode ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMarkDuplicatesWithBarcodes.java,clone,@ override public  read ends for mark duplicates with barcodes   (  )  {  return new  read ends for mark duplicates with barcodes ( this )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMarkDuplicatesWithBarcodes.java,get size of,public static int   (  )  {  return  read ends for mark duplicates . get size of (  )   +   ( 3 * 4 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\SamRecordWithOrdinalAndSetDuplicateReadFlag.java, sam record with ordinal and set duplicate read flag,public   ( final sam record record final long record index )  {  super ( record record index )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\SamRecordWithOrdinalAndSetDuplicateReadFlag.java,set result state,@ override public void   ( final boolean result state )  {  this . get record (  )  . set duplicate read flag ( result state )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\RepresentativeReadIndexerCodec.java,clone,public  sorting collection .  codec <  representative read indexer >    (  )  {  return new  representative read indexer codec (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\RepresentativeReadIndexerCodec.java,decode,"public  representative read indexer   (  )  {  final  representative read indexer rni = new  representative read indexer (  )  ;  try  {  try  {  rni . read index in file = this . in . read int (  )  ;   }  catch  (  final eof exception eof )   {  return null ;   }  rni . set size = this . in . read int (  )  ;  rni . representative read index in file = this . in . read int (  )  ;  return rni ;   }  catch  (  final io exception ioe )   {  throw new  picard exception ( "" exception writing  read ends to file . "" ioe )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\RepresentativeReadIndexerCodec.java,encode,"public void   ( final  representative read indexer rni )  {  try  {  this . out . write int ( rni . read index in file )  ;  this . out . write int ( rni . set size )  ;  this . out . write int ( rni . representative read index in file )  ;   }  catch  (  final io exception ioe )   {  throw new  picard exception ( "" exception writing  read ends to file . "" ioe )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\RepresentativeReadIndexerCodec.java,get input stream,public  data input stream   (  )  {  return in ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\RepresentativeReadIndexerCodec.java,get output stream,public  data output stream   (  )  {  return out ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\RepresentativeReadIndexerCodec.java,set input stream,public void   ( final  input stream is )  {  this . in = new  data input stream ( is )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\RepresentativeReadIndexerCodec.java,set output stream,public void   ( final  output stream os )  {  this . out = new  data output stream ( os )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MergeBamAlignment.java, primary alignment strategy,  ( final  class <  ?  >  clazz final  string description )  {  this . clazz =  (  class <  primary alignment selection strategy >  ) clazz ;  this . description = description ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MergeBamAlignment.java,custom command line validation,"protected  string[]   (  )  {  if  (  ( program   record   id  !  =  null || program   group   version  !  =  null || program   group   command   line  !  =  null )  &&  ( program   record   id  =  =  null || program   group   version  =  =  null || program   group   command   line  =  =  null )  )   {  return new  string[] { ""program   record   id  program   group   version  and ""  +  ""program   group   command   line must all be supplied or none should ""  +  ""be included . "" }  ;   }  final boolean r1s exist = read1   aligned   bam  !  =  null &&  ! read1   aligned   bam . is empty (  )  ;  final boolean r2s exist = read2   aligned   bam  !  =  null &&  ! read2   aligned   bam . is empty (  )  ;  if  (  ( r1s exist &&  ! r2s exist )  ||  ( r2s exist &&  ! r1s exist )  )   {  return new  string[] { ""read1   aligned   bam and read2   aligned   bam ""  +  ""must both be supplied or neither should be included .   for ""  +  ""single - end read use aligned   bam . "" }  ;   }  if  ( aligned   bam  =  =  null || aligned   bam . is empty (  )  &&  !  ( r1s exist && r2s exist )  )   {  return new  string[] { "" either aligned   bam or the combination of ""  +  ""read1   aligned   bam and read2   aligned   bam must be supplied . "" }  ;   }  return null ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMateCigar.java, read ends for mate cigar,public   ( final  read ends for mate cigar other final  sam record with ordinal sam record with ordinal )  {  this . read group = other . read group ;  this . tile = other . tile ;  this . x = other . x ;  this . y = other . y ;  this . read1 reference index = other . read1 reference index ;  this . read1 coordinate = other . read1 coordinate ;  this . read2 reference index = other . read2 reference index ;  this . read2 coordinate = other . read2 coordinate ;  this . has unmapped = other . has unmapped ;  this . sam record with ordinal = sam record with ordinal ;  this . orientation = other . orientation ;  this . library id = other . library id ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MergeBamAlignment.java,do work,@ override protected int   (  )  {  sam program record prod = null ;  if  ( program   record   id  !  =  null )   {  prod = new sam program record ( program   record   id )  ;  prod . set program version ( program   group   version )  ;  prod . set comman
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMateCigar.java,get location set,public  physical location for mate cigar set   (  )  {  return this . location set ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MergeBamAlignment.java,get help doc,public  string   (  )  {  return description ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMateCigar.java,get read end set for optical duplicates,"public  set <  read ends >    (  )  {  if  ( null  =  =  this . location set )  throw new  picard exception ( "" already called get read end set for optical duplicates"" )  ;  final  set <  read ends >  location set = this . location set . get read ends (  )  ;  this . location set = null ;  return location set ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MergeBamAlignment.java,new instance," primary alignment selection strategy   (  )  {  try  {  return clazz . new instance (  )  ;   }  catch  (   exception e )   {  throw new  picard exception ( "" trouble instantiating ""  +  clazz . get name (  )  e )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMateCigar.java,get record,public sam record   (  )  {  return this . sam record with ordinal . get record (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MergeBamAlignment.java,requires reference,@ override protected boolean   (  )  {  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMateCigar.java,get record read name,public  string   (  )  {  return this . sam record with ordinal . get record (  )  . get read name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMateCigar.java,get sam record index,public  sam record with ordinal   (  )  {  return this . sam record with ordinal ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMateCigar.java,is paired,@ override public boolean   (  )  {  return this . get record (  )  . get read paired flag (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMateCigar.java,remove location set,public  physical location for mate cigar set   (  )  {  final  physical location for mate cigar set location set = this . location set ;  this . location set = null ;  return location set ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\markduplicates\util\ReadEndsForMateCigar.java,set location set,public void   ( final  physical location for mate cigar set location set )  {  this . location set = location set ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MergeSamFiles.java,custom command line validation,"@ override protected  string[]   (  )  {  if  ( create   index && sort   order  !  =  sam file header .  sort order . coordinate )   {  return new  string[] { "" can't create   index unless sort   order is coordinate"" }  ;   }  return null ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MergeSamFiles.java,do work,@ override protected int   (  )  {  boolean matched sort orders = true ;  final  list <  interval >  interval list =  ( intervals  =  =  null  ?  null :  interval list . from file ( intervals )  . uniqued (  )  . get intervals (  )  )  ;  final  map <  sa
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MergeSamFiles.java,main,public static void   ( final  string[] argv )  {   system . exit ( new  merge sam files (  )  . instance main ( argv )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MostDistantPrimaryAlignmentSelectionStrategy.java,consider best,public void   ( final sam record first end final sam record second end )  {  final int this pair mapq = sam utils . combine mapqs ( first end . get mapping quality (  )  second end . get mapping quality (  )  )  ;  final int this distance =  coord math . get length (  math . min ( first end . get alignment start (  )  second end . get alignment start (  )  )   math . max ( first end . get alignment end (  )  second end . get alignment end (  )  )  )  ;  if  ( this distance  >  best distance ||  ( this distance  =  =  best distance && this pair mapq  >  best pair mapq )  )   {  best distance = this distance ;  best pair mapq = this pair mapq ;  best alignment pairs . clear (  )  ;  best alignment pairs . add ( new  abstract map .  simple entry < sam record sam record >  ( first end second end )  )  ;   }  else if  ( this distance  =  =  best distance && this pair mapq  =  =  best pair mapq )   {  best alignment pairs . add ( new  abstract map .  simple entry < sam record sam record >  ( first end second end )  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MostDistantPrimaryAlignmentSelectionStrategy.java,has best,public boolean   (  )  {  return best distance  !  =   - 1 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MostDistantPrimaryAlignmentSelectionStrategy.java,move to head,"private void   ( final  list < sam record >  list final sam record rec )  {  if  ( list . get ( 0 )   =  =  rec )  return ;  for  ( int i = 1 ;  i  <  list . size (  )  ;   +  + i )   {  if  ( list . get ( i )   =  =  rec )   {  list . remove ( i )  ;  list . add ( 0 rec )  ;  return ;   }   }  throw new  illegal state exception ( "" should not be reached"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\PositionBasedDownsampleSam.java, circle selector,"  ( final double fraction )  {  final double p ;  if  ( fraction  >  0 . 5 )   {  p = 1  -  fraction ;  positive selection = false ;   }  else  {  p = fraction ;  positive selection = true ;   }  radius squared = p  /   math . pi ;  if  ( p  <  0 )   {  throw new  picard exception ( "" this shouldn't happen .  .  . "" )  ;   }  offset =  math . sqrt ( radius squared  -  p * p  /  4 )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\PositionBasedDownsampleSam.java, coord,public   (  )  {  count = 0 ;  minx = 0 ;  miny = 0 ;  maxx = 0 ;  maxy = 0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MostDistantPrimaryAlignmentSelectionStrategy.java,pick primary alignment,@ override public void   ( final  hits for insert hits for insert )  {  final  best end alignments accumulator first end best = new  best end alignments accumulator (  )  ;  final  best end alignments accumulator second end best = new  best end alignments
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MostDistantPrimaryAlignmentSelectionStrategy.java,pick randomly from list,private  < t > t   ( final  list < t >  list )  {  return list . get ( random . next int ( list . size (  )  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\PositionBasedDownsampleSam.java,check program records,"private void   (  )  {  final  sam reader in =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . open ( input )  ;  for  (  final sam program record pg : in . get file header (  )  . get program records (  )  )   {  if  ( pg . get program name (  )   !  =  null && pg . get program name (  )  . equals ( pg   program   name )  )   {  final  string out text = "" found previous  program  record that indicates that this bam has been downsampled already with this program .   operation not supported !   previous pg: ""  +  pg . to string (  )  ;  if  ( allow   multiple   downsampling   despite   warnings )   {  log . warn ( out text )  ;   }  else  {  log . error ( out text )  ;  throw new  picard exception ( out text )  ;   }   }   }   closer util . close ( in )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\PositionBasedDownsampleSam.java,custom command line validation,"@ override protected  string[]   (  )  {  final  list <  string >  errors = new  array list <  >  (  )  ;  if  ( fraction  <  0 || fraction  >  1 )   {  errors . add ( ""fraction must be a value between 0 and 1  found: ""  +  fraction )  ;   }  if  (  ! err"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\PositionBasedDownsampleSam.java,do work,"@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  log . info ( "" checking to see if input file has been downsampled with this program before . "" )  ;  check program records"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\PositionBasedDownsampleSam.java,fill tile min max coord,"private void   (  )  {  final  sam reader in =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . open ( input )  ;  final  progress logger progress = new  progress logger ( log  ( int ) 1e7 "" read"" )  ;  int total = 0 ;  for  (  final sam record rec : in )   {  if  ( stop   after  !  =  null && total  >  =  stop   after )  break ;  total +  +  ;  progress . record ( rec )  ;  final  physical location int location = get sam record location ( rec )  ;  final  coord  pos = tile coord . get ( location . get tile (  )  )  ;   pos . maxx =  math . max (  pos . maxx location . getx (  )  )  ;   pos . minx =  math . min (  pos . minx location . getx (  )  )  ;   pos . maxy =  math . max (  pos . maxy location . gety (  )  )  ;   pos . miny =  math . min (  pos . miny location . gety (  )  )  ;   pos . count +  +  ;   }  for  (  final  coord coord : tile coord . values (  )  )   {  final int diffx = coord . maxx  -  coord . minx ;  final int diffy = coord . maxy  -  coord . miny ;  coord . maxx +  = diffx  /  coord . count ;  coord . minx -  = diffx  /  coord . count ;  coord . maxy +  = diffy  /  coord . count ;  coord . miny -  = diffy  /  coord . count ;   }   closer util . close ( in )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\PositionBasedDownsampleSam.java,get sam record location,private  physical location int   ( final sam record rec )  {  final  physical location int pos = new  physical location int (  )  ;  read name parser . add location information ( rec . get read name (  )  pos )  ;  return pos ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\PositionBasedDownsampleSam.java,output sam records,"private void   (  )  {  final  progress logger progress = new  progress logger ( log  ( int ) 1e7 )  ;  final  sam reader in =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . open ( input )  ;  final sam file header header = in . get file header (  )  . clone (  )  ;  final sam file header .  pg id generator pg id generator = new sam file header .  pg id generator ( header )  ;  final sam program record program record = new sam program record ( pg id generator . get non colliding id ( pg   program   name )  )  ;  program record . set program name ( pg   program   name )  ;  program record . set command line ( get command line (  )  )  ;  program record . set program version ( get version (  )  )  ;  header . add program record ( program record )  ;  final sam file writer out = new sam file writer factory (  )  . makesam orbam writer ( header true output )  ;  final  circle selector selector = new  circle selector ( fraction )  ;  for  (  final sam record rec : in )   {  if  ( stop   after  !  =  null && total  >  =  stop   after )  break ;  total +  +  ;  final  physical location int pos = get sam record location ( rec )  ;  if  (  ! x positions . contains key ( pos . get tile (  )  )  )   {  x positions . put ( pos . get tile (  )  new  histogram <  >  ( pos . get tile (  )   +  "" - xpos"" ""count"" )  )  ;   }  if  (  ! y positions . contains key ( pos . get tile (  )  )  )   {  y positions . put ( pos . get tile (  )  new  histogram <  >  ( pos . get tile (  )   +  "" - ypos"" ""count"" )  )  ;   }  final boolean keep record = selector . select ( pos tile coord . get ( pos . get tile (  )  )  )  ;  if  ( keep record )   {  if  ( remove   duplicate   information )  rec . set duplicate read flag ( false )  ;  out . add alignment ( rec )  ;  kept +  +  ;   }  progress . record ( rec )  ;   }  out . close (  )  ;   closer util . close ( in )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\PositionBasedDownsampleSam.java,rounded part,private double   ( final double x )  {  return x  -   math . round ( x )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\PositionBasedDownsampleSam.java,select,private boolean   ( final  physical location int coord final  coord tile coord )  {  final double distance squared =  math . pow ( rounded part (  (  ( coord . getx (  )   -  tile coord . minx )   /   ( double )  ( tile coord . maxx  -  tile coord . minx )  )   -  offset )  2 )   +   math . pow ( rounded part (  (  ( coord . gety (  )   -  tile coord . miny )   /   ( double )  ( tile coord . maxy  -  tile coord . miny )  )   -  offset )  2 )  ;  return  ( distance squared  >  radius squared )  ^ positive selection ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MultiHitAlignedReadIterator.java, multi hit aligned read iterator,  ( final  closeable iterator < sam record >  queryname order iterator final  primary alignment selection strategy primary alignment selection strategy )  {  this . primary alignment selection strategy = primary alignment selection strategy ;  peek iterator = new  peekable iterator < sam record >  ( new  filtering sam iterator ( queryname order iterator new  sam record filter (  )  {  public boolean filter out (  final sam record record )  {  return record . get read unmapped flag (  )  || sam utils . cigar maps no bases to ref ( record . get cigar (  )  )  ;   }  public boolean filter out (  final sam record first  final sam record second )  {  return  (  ( first . get read unmapped flag (  )  || sam utils . cigar maps no bases to ref ( first . get cigar (  )  )  )  &&  ( second . get read unmapped flag (  )  || sam utils . cigar maps no bases to ref ( second . get cigar (  )  )  )  )  ;   }   }   )  )  ;  advance (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MultiHitAlignedReadIterator.java,advance,private void   (  )  {  while  ( peek iterator . has next (  )  )   {  the next = next maybe empty (  )  ;  if  ( the next . num hits (  )   >  0 )  return ;   }  the next = null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MultiHitAlignedReadIterator.java,close,public void   (  )  {  peek iterator . close (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MultiHitAlignedReadIterator.java,filter out,public boolean   ( final sam record first final sam record second )  {  return  (  ( first . get read unmapped flag (  )  || sam utils . cigar maps no bases to ref ( first . get cigar (  )  )  )  &&  ( second . get read unmapped flag (  )  || sam utils . cigar maps no bases to ref ( second . get cigar (  )  )  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MultiHitAlignedReadIterator.java,has next,public boolean   (  )  {  return the next  !  =  null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MultiHitAlignedReadIterator.java,next,public  hits for insert   (  )  {  if  (  ! has next (  )  )  throw new  no such element exception (  )  ;  final  hits for insert ret = the next ;  advance (  )  ;  return ret ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MultiHitAlignedReadIterator.java,next maybe empty,"private  hits for insert   (  )  {  if  (  ! peek iterator . has next (  )  )  throw new  illegal state exception (  )  ;  final  string read name = peek iterator . peek (  )  . get read name (  )  ;  final  hits for insert hits = new  hits for insert (  )  ;   boolean is paired = null ;  do  {  final sam record rec = peek iterator . next (  )  ;  replace hard with soft clips ( rec )  ;  if  ( peek iterator . has next (  )  && query name comparator . file order compare ( rec peek iterator . peek (  )  )   >  0 )   {  throw new  illegal state exception ( "" underlying iterator is not queryname sorted: ""  +  rec  +  ""  >  "" +  peek iterator . peek (  )  )  ;   }  if  ( is paired  =  =  null )   {  is paired = rec . get read paired flag (  )  ;   }  else if  ( is paired  !  =  rec . get read paired flag (  )  )   {  throw new  picard exception ( "" got a mix of paired and unpaired alignments for read ""  +  read name )  ;   }  if  (  ! rec . get read paired flag (  )  || rec . get first of pair flag (  )  )   {  if  ( rec . get supplementary alignment flag (  )  )   {  hits . add supplemental first of pair or fragment ( rec )  ;   }  else  {  hits . add first of pair or fragment ( rec )  ;   }   }  else if  ( rec . get second of pair flag (  )  )   {  if  ( rec . get supplementary alignment flag (  )  )   {  hits . add supplemental second of pair ( rec )  ;   }  else  {  hits . add second of pair ( rec )  ;   }   }  else throw new  picard exception ( "" read is marked as pair but neither first or second: ""  +  read name )  ;   }  while  ( peek iterator . has next (  )  && peek iterator . peek (  )  . get read name (  )  . equals ( read name )  )  ;  if  ( hits . num hits (  )   <  =  1 )   {  if  ( hits . get first of pair ( 0 )   !  =  null )   {  hits . get first of pair ( 0 )  . set attribute ( sam tag . hi . name (  )  null )  ;  hits . get first of pair ( 0 )  . set not primary alignment flag ( false )  ;   }  if  ( hits . get second of pair ( 0 )   !  =  null )   {  hits . get second of pair ( 0 )  . set attribute ( sam tag . hi . name (  )  null )  ;  hits . get second of pair ( 0 )  . set not primary alignment flag ( false )  ;   }   }  else  {  primary alignment selection strategy . pick primary alignment ( hits )  ;   }  return hits ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MultiHitAlignedReadIterator.java,remove,public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\MultiHitAlignedReadIterator.java,replace hard with soft clips,private void   ( final sam record rec )  {  if  ( rec . get read unmapped flag (  )  )  return ;  if  ( rec . get cigar (  )  . is empty (  )  )  return ;   list <  cigar element >  elements = rec . get cigar (  )  . get cigar elements (  )  ;  final  cigar element first = elements . get ( 0 )  ;  final  cigar element last = elements . size (  )   =  =  1  ?  null : elements . get ( elements . size (  )   -  1 )  ;  final int start hard clip = first . get operator (  )   =  =   cigar operator . h  ?  first . get length (  )  : 0 ;  final int end hard clip =  ( last  !  =  null && last . get operator (  )   =  =   cigar operator . h )   ?  last . get length (  )  : 0 ;  if  ( start hard clip  +  end hard clip  >  0 )   {  final int len = rec . get read bases (  )  . length  +  start hard clip  +  end hard clip ;  final byte[] bases = new byte[len] ;   arrays . fill ( bases  ( byte ) 'n' )  ;   system . arraycopy ( rec . get read bases (  )  0 bases start hard clip rec . get read bases (  )  . length )  ;  final byte[] quals = new byte[len] ;   arrays . fill ( quals  ( byte ) 2 )  ;   system . arraycopy ( rec . get base qualities (  )  0 quals start hard clip rec . get base qualities (  )  . length )  ;  elements = new  array list <  cigar element >  ( elements )  ;  if  ( start hard clip  >  0 )  elements . set ( 0 new  cigar element ( first . get length (  )   cigar operator . s )  )  ;  if  ( end hard clip  >  0 )  elements . set ( elements . size (  )   -  1 new  cigar element ( last . get length (  )   cigar operator . s )  )  ;  rec . set read bases ( bases )  ;  rec . set base qualities ( quals )  ;  rec . set cigar ( new  cigar ( elements )  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ReplaceSamHeader.java,block copy reheader,private void   ( final sam file header replacement header )  {   bam file io utils . reheader bam file ( replacement header input output create   md5   file create   index )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ReplaceSamHeader.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is readable ( header )  ;  io util . assert file is writable ( output )  ;  final sam file header replacement header =  sam reader factory . make def
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ReplaceSamHeader.java,main,public static void   ( final  string[] argv )  {  new  replace sam header (  )  . instance main with exit ( argv )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ReplaceSamHeader.java,standard reheader,"private void   ( final sam file header replacement header )  {  final  sam reader record reader =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . validation stringency (  validation stringency . silent )  . open ( input )  ;  if  ( replacement header . get sort order (  )   !  =  record reader . get file header (  )  . get sort order (  )  )   {  throw new  picard exception ( "" sort orders of input  ( ""  +  record reader . get file header (  )  . get sort order (  )  . name (  )   +  "" )  and header  ( "" +  replacement header . get sort order (  )  . name (  )  +  "" )  do not agree . "" )  ;   }  final sam file writer writer = new sam file writer factory (  )  . makesam orbam writer ( replacement header true output )  ;  final  progress logger progress = new  progress logger (  log . get instance (  replace sam header . class )  )  ;  for  (  final sam record rec : record reader )   {  rec . set header ( replacement header )  ;  writer . add alignment ( rec )  ;  progress . record ( rec )  ;   }  writer . close (  )  ;   closer util . close ( record reader )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ReorderSam.java,build sequence dictionary map,"private  map <  integer  integer >    ( final sam sequence dictionary ref dict final sam sequence dictionary reads dict )  {   map <  integer  integer >  new order = new  hash map <  integer  integer >  (  )  ;  log . info ( "" reordering sam / bam file:"" )  ;  for  (  final sam sequence record ref rec : ref dict . get sequences (  )  )   {  final sam sequence record reads rec = reads dict . get sequence ( ref rec . get sequence name (  )  )  ;  if  ( reads rec  !  =  null )   {  if  ( ref rec . get sequence length (  )   !  =  reads rec . get sequence length (  )  )   {   string msg =  string . format ( "" discordant contig lengths: read %s ln = %d  ref %s ln = %d"" reads rec . get sequence name (  )  reads rec . get sequence length (  )  ref rec . get sequence name (  )  ref rec . get sequence length (  )  )  ;  if  ( allow   contig   length   discordance )   {  log . warn ( msg )  ;   }  else  {  throw new  picard exception ( msg )  ;   }   }  log . info (  string . format ( ""  reordering read contig %s [index = %d] to  =  >  ref contig %s [index = %d]%n"" reads rec . get sequence name (  )  reads rec . get sequence index (  )  ref rec . get sequence name (  )  ref rec . get sequence index (  )  )  )  ;  new order . put ( reads rec . get sequence index (  )  ref rec . get sequence index (  )  )  ;   }   }  for  (  sam sequence record reads rec : reads dict . get sequences (  )  )   {  if  (  ! new order . contains key ( reads rec . get sequence index (  )  )  )   {  if  ( allow   incomplete   dict   concordance )  new order . put ( reads rec . get sequence index (  )   - 1 )  ;  else throw new  picard exception ( "" new reference sequence does not contain a matching contig for ""  +  reads rec . get sequence name (  )  )  ;   }   }  return new order ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ReorderSam.java,do work,"protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is readable ( reference   sequence )  ;  io util . assert file is writable ( output )  ;  final  sam reader in =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . open ( input )  ;  final  reference sequence file reference =  reference sequence file factory . get reference sequence file ( reference   sequence )  ;  final sam sequence dictionary ref dict = reference . get sequence dictionary (  )  ;  if  ( ref dict  =  =  null )   {  log . error ( "" no reference sequence dictionary found .   aborting .   you can create a sequence dictionary for the reference fasta using  create sequence dictionary . jar . "" )  ;   closer util . close ( in )  ;  return 1 ;   }  print dictionary ( ""sam / bam file"" in . get file header (  )  . get sequence dictionary (  )  )  ;  print dictionary ( "" reference"" ref dict )  ;  final  map <  integer  integer >  new order = build sequence dictionary map ( ref dict in . get file header (  )  . get sequence dictionary (  )  )  ;  final sam file header out header = in . get file header (  )  . clone (  )  ;  out header . set sequence dictionary ( ref dict )  ;  log . info ( "" writing reads .  .  . "" )  ;  if  ( in . has index (  )  )   {  try  ( final sam file writer out = new sam file writer factory (  )  . makesam orbam writer ( out header true output )  )  {  for  (  final sam sequence record contig : ref dict . get sequences (  )  )   {  final sam record iterator it = in . query ( contig . get sequence name (  )  0 0 false )  ;  write reads ( out it new order contig . get sequence name (  )  )  ;   }  write reads ( out in . query unmapped (  )  new order ""unmapped"" )  ;   }   }  else  {  try  ( final sam file writer out = new sam file writer factory (  )  . makesam orbam writer ( out header false output )  )  {  write reads ( out in . iterator (  )  new order "" all reads"" )  ;   }   }   closer util . close ( in )  ;  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ReorderSam.java,get reference file,@ override public  file   (  )  {  return reference ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ReorderSam.java,make reference argument collection,@ override protected  reference argument collection   (  )  {  return new  reorder sam reference argument collection (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ReorderSam.java,new order index,"private int   ( sam record read int old index  map <  integer  integer >  new order )  {  if  ( old index  =  =   - 1 )  return  - 1 ;  else  {  final  integer n = new order . get ( old index )  ;  if  ( n  =  =  null )  throw new  picard exception ( ""bug: no mapping found for read ""  +  read . getsam string (  )  )  ;  else return n ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ReorderSam.java,print dictionary,"private void   (  string name sam sequence dictionary dict )  {  log . info ( name )  ;  for  (  final sam sequence record contig : dict . get sequences (  )  )   {  log . info ( "" sn = %s ln = %d%n"" contig . get sequence name (  )  contig . get sequence length (  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ReorderSam.java,write reads,"private void   ( final sam file writer out final sam record iterator it final  map <  integer  integer >  new order final  string name )  {  long counter = 0 ;  log . info ( ""  processing ""  +  name )  ;  while  ( it . has next (  )  )   {  counter +  +  ;  final sam record read = it . next (  )  ;  final int old ref index = read . get reference index (  )  ;  final int old mate index = read . get mate reference index (  )  ;  final int new ref index = new order index ( read old ref index new order )  ;  read . set header ( out . get file header (  )  )  ;  read . set reference index ( new ref index )  ;  final int new mate index = new order index ( read old mate index new order )  ;  if  ( old mate index  !  =   - 1 && new mate index  =  =   - 1 )   {  read . set mate alignment start ( 0 )  ;  read . set mate unmapped flag ( true )  ;  read . set attribute ( sam tag . mc . name (  )  null )  ;   }  read . set mate reference index ( new mate index )  ;  out . add alignment ( read )  ;   }  it . close (  )  ;  log . info ( "" wrote ""  +  counter  +  "" reads"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertOriginalBaseQualitiesAndAddMateCigar.java, can skip sam file,private   ( final  string format final boolean skip )  {  this . format = format ;  this . skip = skip ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertOriginalBaseQualitiesAndAddMateCigar.java, revert original base qualities and add mate cigar,public   (  )  {  this . create   index = true ;  this . create   md5   file = true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertOriginalBaseQualitiesAndAddMateCigar.java,can skip,public boolean   (  )  {  return this . skip ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertOriginalBaseQualitiesAndAddMateCigar.java,can skipsam file,public static  can skip sam file   ( final  file input file final int max records to examine boolean revert original base qualities final  file reference fasta )  {  final  sam reader in =  sam reader factory . make default (  )  . reference sequence ( reference fasta )  . enable (  sam reader factory .  option . eagerly   decode )  . open ( input file )  ;  final  iterator < sam record >  iterator = in . iterator (  )  ;  int num records examined = 0 ;   can skip sam file return type =  can skip sam file . found   no   evidence ;  while  ( iterator . has next (  )  && num records examined  <  max records to examine )   {  final sam record record = iterator . next (  )  ;  if  ( revert original base qualities && null  !  =  record . get original base qualities (  )  )   {  return type =  can skip sam file . cannot   skip   found   oq ;  break ;   }  if  ( record . get read paired flag (  )  &&  ! record . get mate unmapped flag (  )  )   {  if  ( null  =  =  sam utils . get mate cigar ( record )  )   {  return type =  can skip sam file . cannot   skip   found   no   mc ;  break ;   }  else  {  return type =  can skip sam file . can   skip ;  break ;   }   }  num records examined +  +  ;   }  if  (  ! iterator . has next (  )  &&  can skip sam file . found   no   evidence  =  =  return type )   {  return type =  can skip sam file . can   skip ;   }   closer util . close ( in )  ;  return return type ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertOriginalBaseQualitiesAndAddMateCigar.java,do work,"public int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  boolean found paired mapped reads = false ;  final  can skip sam file skip sam file =  revert original base qualities and add mate cigar . can skipsam file ( input max   records   to   examine restore   original   qualities reference   sequence )  ;  log . info ( skip sam file . get message ( max   records   to   examine )  )  ;  if  ( skip sam file . can skip (  )  )  return 0 ;  final  sam reader in =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . enable (  sam reader factory .  option . eagerly   decode )  . open ( input )  ;  final sam file header in header = in . get file header (  )  ;  final sam file header out header = in header . clone (  )  ;  if  ( null  =  =  sort   order )  this . sort   order = in header . get sort order (  )  ;  out header . set sort order ( sort   order )  ;  sam file writer factory . set default create index while writing ( create   index )  ;  sam file writer factory . set default create md5 file ( create   md5   file )  ;  final sam file writer out = new sam file writer factory (  )  . makesam orbam writer ( out header false output )  ;  final  sorting collection < sam record >  sorter =  sorting collection . new instance ( sam record . class new bam record codec ( out header )  new sam record query name comparator (  )  max   records   in   ram )  ;  final  progress logger reverting progress = new  progress logger ( log 1000000 "" reverted o qs"" )  ;  int num original qualities restored = 0 ;  for  (  final sam record record : in )   {   abstract alignment merger . create new cigars if maps off end of reference ( record )  ;  if  ( restore   original   qualities && null  !  =  record . get original base qualities (  )  )   {  record . set base qualities ( record . get original base qualities (  )  )  ;  record . set original base qualities ( null )  ;  num original qualities restored +  +  ;   }  if  (  ! found paired mapped reads && record . get read paired flag (  )  &&  ! record . get read unmapped flag (  )  )  found paired mapped reads = true ;  reverting progress . record ( record )  ;  sorter . add ( record )  ;   }   closer util . close ( in )  ;  log . info ( "" reverted the original base qualities for ""  +  num original qualities restored  +  "" records"" )  ;  final  sam pair util .  set mate info iterator sorter iterator = new  sam pair util .  set mate info iterator ( sorter . iterator (  )  true )  ;  final  progress logger sorter progress = new  progress logger ( log 1000000 "" mate cigars added"" )  ;  while  ( sorter iterator . has next (  )  )   {  final sam record record = sorter iterator . next (  )  ;  out . add alignment ( record )  ;  sorter progress . record ( record )  ;   }  sorter iterator . close (  )  ;   closer util . close ( out )  ;  log . info ( "" updated ""  +  sorter iterator . get num mate cigars added (  )   +  "" records with mate cigar"" )  ;  if  (  ! found paired mapped reads )  log . info ( "" did not find any paired mapped reads . "" )  ;  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertOriginalBaseQualitiesAndAddMateCigar.java,get message,public  string   ( final int max records to examine )  {  return  string . format ( this . format max records to examine )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertOriginalBaseQualitiesAndAddMateCigar.java,main,public static void   ( final  string[] args )  {  new  revert original base qualities and add mate cigar (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java, file type,  (  string descrition )  {  this . description = descrition ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java, revert sam sorter,  ( final boolean output by read group final  map <  string sam file header >  header map final sam file header single out header final int max records in ram )  {  this . output by read group = output by read group ;  if  ( output by read group )   {  for  (  final  map .  entry <  string sam file header >  entry : header map . entry set (  )  )   {  final  string read group id = entry . get key (  )  ;  final sam file header out header = entry . get value (  )  ;  final  sorting collection < sam record >  sorter =  sorting collection . new instance ( sam record . class new bam record codec ( out header )  new sam record query name comparator (  )  max records in ram )  ;  sorter map . put ( read group id sorter )  ;   }  single sorter = null ;   }  else  {  single sorter =  sorting collection . new instance ( sam record . class new bam record codec ( single out header )  new sam record query name comparator (  )  max records in ram )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java, revert sam writer,  ( final boolean output by read group final  map <  string sam file header >  header map final  map <  string  file >  output map final sam file header single out header final  file single output final boolean presorted final sam file writer factory factory final  file reference fasta )  {  this . output by read group = output by read group ;  if  ( output by read group )   {  single writer = null ;  for  (  final  map .  entry <  string  file >  output map entry : output map . entry set (  )  )   {  final  string read group id = output map entry . get key (  )  ;  final  file output = output map entry . get value (  )  ;  final sam file header header = header map . get ( read group id )  ;  final sam file writer writer = factory . make writer ( header presorted output reference fasta )  ;  writer map . put ( read group id writer )  ;   }   }  else  {  single writer = factory . make writer ( single out header presorted single output reference fasta )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,add,void   ( final sam record rec )  {  final  sorting collection < sam record >  sorter ;  if  ( output by read group )   {  sorter = sorter map . get ( rec . get read group (  )  . get id (  )  )  ;   }  else  {  sorter = single sorter ;   }  sorter . add ( rec )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,add alignment,void   ( final sam record rec )  {  final sam file writer writer ;  if  ( output by read group )   {  writer = writer map . get ( rec . get read group (  )  . get id (  )  )  ;   }  else  {  writer = single writer ;   }  writer . add alignment ( rec )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,assert all read groups mapped,"static void   ( final  map <  string  file >  output map final  list < sam read group record >  read groups )  {  for  (  final sam read group record read group : read groups )   {  final  string id = read group . get id (  )  ;  final  file output = output map . get ( id )  ;  if  ( output  =  =  null )   {  throw new  picard exception ( "" read group id ""  +  id  +  "" not found in output   map "" +  output map )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,assert writable,static void   ( final  file output final boolean output by read group )  {  if  ( output by read group )   {  if  ( output  !  =  null )   {  io util . assert directory is writable ( output )  ;   }   }  else  {  io util . assert file is writable ( output )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,close,void   (  )  {  if  ( output by read group )   {  writer map . values (  )  . for each ( sam file writer::close )  ;   }  else  {  single writer . close (  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,create header map,private  map <  string sam file header >    ( final sam file header in header final  sort order sort order final boolean remove alignment information )  {  final  map <  string sam file header >  header map = new  hash map <  >  (  )  ;  for  (  final sam read group record read group : in header . get read groups (  )  )   {  final sam file header header = create out header ( in header sort order remove alignment information )  ;  header . add read group ( read group )  ;  header map . put ( read group . get id (  )  header )  ;   }  return header map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,create out header,private sam file header   ( final sam file header in header final sam file header .  sort order sort order final boolean remove alignment information )  {  final sam file header out header = new sam file header (  )  ;  out header . set sort order ( sort order )  ;  if  (  ! remove alignment information )   {  out header . set sequence dictionary ( in header . get sequence dictionary (  )  )  ;  out header . set program records ( in header . get program records (  )  )  ;   }  return out header ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,create output map,private static  map <  string  file >    ( final  list < sam read group record >  read groups final  file output dir final  string extension )  {  final  map <  string  file >  output map = new  hash map <  >  (  )  ;  for  (  final sam read group record read group : read groups )   {  final  string id = read group . get id (  )  ;  final  string file name = id  +  extension ;  final  path output path =  paths . get ( output dir . to string (  )  file name )  ;  output map . put ( id output path . to file (  )  )  ;   }  return output map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,create output map from file,"private static  map <  string  file >    ( final  file output map file )  {  final  map <  string  file >  output map = new  hash map <  >  (  )  ;  final  tabbed text file with header parser parser = new  tabbed text file with header parser ( output map file )  ;  for  (  final  tabbed text file with header parser .  row row : parser )   {  final  string id = row . get field ( ""read   group   id"" )  ;  final  string output = row . get field ( ""output"" )  ;  final  file output path = new  file ( output )  ;  output map . put ( id output path )  ;   }   closer util . close ( parser )  ;  return output map ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,create read group format map,"private  map < sam read group record  fastq quality format >    ( final sam file header in header final  file reference sequence final  validation stringency validation stringency final  file input final boolean restore original qualities )  {  final  map < sam read group record  fastq quality format >  read group to format = new  hash map <  >  (  )  ;  for  (  final sam read group record rg : in header . get read groups (  )  )   {  final  sam reader reader =  sam reader factory . make default (  )  . reference sequence ( reference sequence )  . validation stringency ( validation stringency )  . open ( input )  ;  final  sam record filter filter = new  sam record filter (  )  {  public boolean filter out (  final sam record rec )  {  return  ! rec . get read group (  )  . get id (  )  . equals ( rg . get id (  )  )  ;   }  public boolean filter out (  final sam record first  final sam record second )  {  throw new  unsupported operation exception (  )  ;   }   }   ;  read group to format . put ( rg  quality encoding detector . detect (  quality encoding detector . default   max   records   to   iterate new  filtering sam iterator ( reader . iterator (  )  filter )  restore original qualities )  )  ;   closer util . close ( reader )  ;   }  for  (  final sam read group record r : read group to format . key set (  )  )   {  log . info ( "" detected quality format for ""  +  r . get read group id (  )   +  "": "" +  read group to format . get ( r )  )  ;   }  if  ( read group to format . values (  )  . contains (  fastq quality format .  solexa )  )   {  throw new  picard exception ( "" no quality score encoding conversion implemented for ""  +   fastq quality format .  solexa )  ;   }  return read group to format ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,custom command line validation,@ override protected  string[]   (  )  {  final  list <  string >  errors = new  array list <  >  (  )  ;   validation util . validate sanitize sort order ( sanitize sort   order errors )  ;   validation util . validate output params ( output   by   readg
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,do work,"protected int   (  )  {  io util . assert file is readable ( input )  ;   validation util . assert writable ( output output   by   readgroup )  ;  final boolean sanitizing = sanitize ;  final  sam reader in =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . validation stringency ( validation   stringency )  . open ( input )  ;  final sam file header in header = in . get file header (  )  ;   validation util . validate header overrides ( in header sample   alias library   name )  ;  final boolean presorted = is presorted ( in header sort   order sanitizing )  ;  if  ( sample   alias  !  =  null )  overwrite sample ( in header . get read groups (  )  sample   alias )  ;  if  ( library   name  !  =  null )  overwrite library ( in header . get read groups (  )  library   name )  ;  final sam file header single out header = create out header ( in header sort   order remove   alignment   information )  ;  in header . get read groups (  )  . for each ( read group  -  >  single out header . add read group ( read group )  )  ;  final  map <  string  file >  output map ;  final  map <  string sam file header >  header map ;  if  ( output   by   readgroup )   {  if  ( in header . get read groups (  )  . is empty (  )  )   {  throw new  picard exception ( input  +  "" does not contain  read  groups"" )  ;   }  final  string default extension ;  if  ( output   by   readgroup   file   format  =  =   file type . dynamic )   {  default extension = get default extension ( input . to string (  )  )  ;   }  else  {  default extension = "" . ""  +  output   by   readgroup   file   format . to string (  )  ;   }  output map = create output map ( output   map output default extension in header . get read groups (  )  )  ;   validation util . assert all read groups mapped ( output map in header . get read groups (  )  )  ;  header map = create header map ( in header sort   order remove   alignment   information )  ;   }  else  {  output map = null ;  header map = null ;   }  final sam file writer factory factory = new sam file writer factory (  )  ;  final  revert sam writer out = new  revert sam writer ( output   by   readgroup header map output map single out header output presorted factory reference   sequence )  ;  final  revert sam sorter sorter ;  if  ( sanitizing )  sorter = new  revert sam sorter ( output   by   readgroup header map single out header max   records   in   ram )  ;  else sorter = null ;  final  progress logger progress = new  progress logger ( log 1000000 "" reverted"" )  ;  for  (  final sam record rec : in )   {  if  ( rec . is secondary or supplementary (  )  )  continue ;  progress . record ( rec )  ;  revert sam record ( rec )  ;  if  ( sanitizing )  sorter . add ( rec )  ;  else out . add alignment ( rec )  ;   }   closer util . close ( in )  ;  if  (  ! sanitizing )   {  out . close (  )  ;   }  else  {  final  map < sam read group record  fastq quality format >  read group to format ;  try  {  read group to format = create read group format map ( in header reference   sequence validation   stringency input restore   original   qualities )  ;   }  catch  (  final  picard exception e )   {  log . error ( e . get message (  )  )  ;  return  - 1 ;   }  final long[] sanitize results = sanitize ( read group to format sorter out )  ;  final long discarded = sanitize results[0] ;  final long total = sanitize results[1] ;  out . close (  )  ;  final double discard rate = discarded  /   ( double ) total ;  final  number format fmt = new  decimal format ( ""0 . 000%"" )  ;  log . info ( "" discarded ""  +  discarded  +  "" out of "" +  total +  ""  ( "" +  fmt . format ( discard rate )  +  "" )  reads in order to sanitize output . "" )  ;  if  ( discard rate  >  max   discard   fraction )   {  throw new  picard exception ( "" discarded ""  +  fmt . format ( discard rate )   +  "" which is above max   discard   fraction of "" +  fmt . format ( max   discard   fraction )  )  ;   }   }  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,fetch by read name,private  list < sam record >    ( final  peekable iterator < sam record >  iterator )  {  final  list < sam record >  out = new  array list <  >  (  )  ;  if  ( iterator . has next (  )  )   {  final sam record first = iterator . next (  )  ;  out . add ( first )  ;  while  ( iterator . has next (  )  && iterator . peek (  )  . get read name (  )  . equals ( first . get read name (  )  )  )   {  out . add ( iterator . next (  )  )  ;   }   }  return out ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,filter out,public boolean   ( final sam record first final sam record second )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,get default extension,"static  string   ( final  string input )  {  if  ( input . ends with ( "" . sam"" )  )   {  return "" . sam"" ;   }  if  ( input . ends with ( "" . cram"" )  )   {  return "" . cram"" ;   }  return "" . bam"" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,get help doc,@ override public  string   (  )  {  return description ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,is output map header valid,"static boolean   ( final  list <  string >  column labels )  {  if  ( column labels . size (  )   <  2 )   {  return false ;   }  if  (  ! ""read   group   id"" . equals ( column labels . get ( 0 )  )  )   {  return false ;   }  if  (  ! ""output"" . equals ( column labels . get ( 1 )  )  )   {  return false ;   }  return true ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,is presorted,private boolean   ( final sam file header in header final  sort order sort order final boolean sanitizing )  {  return  ( in header . get sort order (  )   =  =  sort order )  ||  ( sort order  =  =   sort order . queryname && sanitizing )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,iterators, list <  peekable iterator < sam record >  >    (  )  {  final  list <  peekable iterator < sam record >  >  iterators = new  array list <  >  (  )  ;  if  ( output by read group )   {  for  (  final  sorting collection < sam record >  sorter : sorter map . values (  )  )   {  final  peekable iterator < sam record >  iterator = new  peekable iterator <  >  ( sorter . iterator (  )  )  ;  iterators . add ( iterator )  ;   }   }  else  {  final  peekable iterator < sam record >  iterator = new  peekable iterator <  >  ( single sorter . iterator (  )  )  ;  iterators . add ( iterator )  ;   }  return iterators ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,overwrite library,private void   ( final  list < sam read group record >  read groups final  string library name )  {  read groups . for each ( rg  -  >  rg . set library ( library name )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,overwrite sample,private void   ( final  list < sam read group record >  read groups final  string sample alias )  {  read groups . for each ( rg  -  >  rg . set sample ( sample alias )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,revert sam record,public void   ( final sam record rec )  {  if  ( restore   original   qualities )   {  final byte[] oq = rec . get original base qualities (  )  ;  if  ( oq  !  =  null )   {  rec . set base qualities ( oq )  ;  rec . set original base qualities ( null )  ;   }   }  if  ( remove   duplicate   information )   {  rec . set duplicate read flag ( false )  ;   }  if  ( remove   alignment   information )   {  if  ( rec . get read negative strand flag (  )  )   {  rec . reverse complement ( true )  ;  rec . set read negative strand flag ( false )  ;   }  rec . set reference index ( sam record . no   alignment   reference   index )  ;  rec . set alignment start ( sam record . no   alignment   start )  ;  rec . set cigar string ( sam record . no   alignment   cigar )  ;  rec . set mapping quality ( sam record . no   mapping   quality )  ;  rec . set inferred insert size ( 0 )  ;  rec . set not primary alignment flag ( false )  ;  rec . set proper pair flag ( false )  ;  rec . set read unmapped flag ( true )  ;  rec . set mate alignment start ( sam record . no   alignment   start )  ;  rec . set mate negative strand flag ( false )  ;  rec . set mate reference index ( sam record . no   alignment   reference   index )  ;  rec . set mate unmapped flag ( rec . get read paired flag (  )  )  ;  attribute   to   clear . for each ( tag  -  >  rec . set attribute ( tag null )  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,sanitize,"private long[]   ( final  map < sam read group record  fastq quality format >  read group to format final  revert sam sorter sorter final  revert sam writer out )  {  long total = 0  discarded = 0 ;  final  progress logger sanitizer progress = new  progress logger ( log 1000000 "" sanitized"" )  ;  final  list <  peekable iterator < sam record >  >  iterators = sorter . iterators (  )  ;  for  (  final  peekable iterator < sam record >  iterator : iterators )   {  read name loop: while  ( iterator . has next (  )  )   {   list < sam record >  recs = fetch by read name ( iterator )  ;  total +  = recs . size (  )  ;  for  (  final sam record rec : recs )   {  if  ( rec . get read bases (  )  . length  !  =  rec . get base qualities (  )  . length )   {  log . debug ( "" discarding "" recs . size (  )  "" reads with name "" rec . get read name (  )  "" for mismatching bases and quals length . "" )  ;  discarded +  = recs . size (  )  ;  continue read name loop ;   }   }  int firsts = 0  seconds = 0  unpaired = 0 ;  sam record first record = null  second record = null  unpaired record = null ;  for  (  final sam record rec : recs )   {  if  (  ! rec . get read paired flag (  )  )   {  if  ( unpaired record  =  =  null )   {  unpaired record = rec ;   }   +  + unpaired ;   }  else  {  if  ( rec . get first of pair flag (  )  )   {  if  ( first record  =  =  null )   {  first record = rec ;   }   +  + firsts ;   }  if  ( rec . get second of pair flag (  )  )   {  if  ( second record  =  =  null )   {  second record = rec ;   }   +  + seconds ;   }   }   }  if  ( firsts  >  0 || seconds  >  0 )   {  if  ( firsts  !  =  1 || seconds  !  =  1 )   {  if  ( keep   first   duplicate && firsts  >  =  1 && seconds  >  =  1 )   {  discarded +  = recs . size (  )   -  2 ;  recs =  arrays . as list ( first record second record )  ;   }  else  {  log . debug ( "" discarding "" recs . size (  )  "" reads with name "" recs . get ( 0 )  . get read name (  )  "" because we found "" firsts "" r1s "" seconds "" r2s and "" unpaired "" unpaired reads . "" )  ;  discarded +  = recs . size (  )  ;  continue read name loop ;   }   }   }  else if  ( unpaired  >  1 )   {  if  ( keep   first   duplicate )   {  discarded +  = recs . size (  )   -  1 ;  recs =  collections . singleton list ( unpaired record )  ;   }  else  {  log . debug ( "" discarding "" recs . size (  )  "" reads with name "" recs . get ( 0 )  . get read name (  )  "" because we found "" unpaired "" unpaired reads . "" )  ;  discarded +  = recs . size (  )  ;  continue read name loop ;   }   }  for  (  final sam record rec : recs )   {  final  fastq quality format record format = read group to format . get ( rec . get read group (  )  )  ;  if  ( record format  !  =  null &&  ! record format . equals (  fastq quality format .  standard )  )   {  final byte[] quals = rec . get base qualities (  )  ;  for  ( int i = 0 ;  i  <  quals . length ;  i +  +  )   {  quals[i] -  =  solexa quality converter . illumina   to   phred   subtrahend ;   }  rec . set base qualities ( quals )  ;   }  out . add alignment ( rec )  ;  sanitizer progress . record ( rec )  ;   }   }   }  return new long[] { discarded total }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,validate header overrides,"static void   ( final sam file header in header final  string sample alias final  string library name )  {  final  list < sam read group record >  rgs = in header . get read groups (  )  ;  if  ( sample alias  !  =  null || library name  !  =  null )   {  boolean all sample aliases identical = true ;  boolean all library names identical = true ;  for  ( int i = 1 ;  i  <  rgs . size (  )  ;  i +  +  )   {  if  (  ! rgs . get ( 0 )  . get sample (  )  . equals ( rgs . get ( i )  . get sample (  )  )  )   {  all sample aliases identical = false ;   }  if  (  ! rgs . get ( 0 )  . get library (  )  . equals ( rgs . get ( i )  . get library (  )  )  )   {  all library names identical = false ;   }   }  if  ( sample alias  !  =  null &&  ! all sample aliases identical )   {  throw new  picard exception ( "" read groups have multiple values for sample .  ""  +  ""a value for sample   alias cannot be supplied . "" )  ;   }  if  ( library name  !  =  null &&  ! all library names identical )   {  throw new  picard exception ( "" read groups have multiple values for library name .  ""  +  ""a value for library name cannot be supplied . "" )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,validate output params,static void   ( final boolean output by read group final  file output final  file output map final  list <  string >  errors )  {  if  ( output by read group )   {  validate output params by read group ( output output map errors )  ;   }  else  {  validate output params not by read group ( output output map errors )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,validate output params by read group,"static void   ( final  file output final  file output map final  list <  string >  errors )  {  if  ( output  !  =  null )   {  if  (  !  files . is directory ( output . to path (  )  )  )   {  errors . add ( "" when output   by   readgroup = true and output is provided  it must be a directory: ""  +  output )  ;   }  return ;   }  if  ( output map  =  =  null )   {  errors . add ( "" must provide either output or output   map when output   by   readgroup = true . "" )  ;  return ;   }  if  (  !  files . is readable ( output map . to path (  )  )  )   {  errors . add ( "" cannot read output   map ""  +  output map )  ;  return ;   }  final  tabbed text file with header parser parser = new  tabbed text file with header parser ( output map )  ;  if  (  !  validation util . is output map header valid ( parser . column labels list (  )  )  )   {  errors . add ( "" invalid header: ""  +  output map  +  "" .   must be a tab - separated file with read   group   id as first column and output as second column . "" )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,validate output params not by read group,"static void   ( final  file output final  file output map final  list <  string >  errors )  {  if  ( output map  !  =  null )   {  errors . add ( "" cannot provide output   map when output   by   readgroup = false .   provide output instead . "" )  ;   }  if  ( output  =  =  null )   {  errors . add ( ""output is required when output   by   readgroup = false"" )  ;  return ;   }  if  (  files . is directory ( output . to path (  )  )  )   {  errors . add ( ""output ""  +  output  +  "" should not be a directory when output   by   readgroup = false"" )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\RevertSam.java,validate sanitize sort order,"static void   ( final boolean sanitize final sam file header .  sort order sort order final  list <  string >  errors )  {  if  ( sanitize && sort order  !  =  sam file header .  sort order . queryname )   {  errors . add ( ""sort   order must be queryname when sanitization is enabled with sanitize = true . "" )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamFormatConverter.java,do work,"protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  final  sam reader reader =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . open ( input )  ;  final sam file writer writer = new sam file writer factory (  )  . make writer ( reader . get file header (  )  true output reference   sequence )  ;  if  ( create   index && writer . get file header (  )  . get sort order (  )   !  =  sam file header .  sort order . coordinate )   {  throw new  picard exception ( "" can't create   index unless sort order is coordinate"" )  ;   }  final  progress logger progress = new  progress logger (  log . get instance (  sam format converter . class )  )  ;  for  (  final sam record rec : reader )   {  writer . add alignment ( rec )  ;  progress . record ( rec )  ;   }   closer util . close ( reader )  ;  writer . close (  )  ;  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamFormatConverter.java,main,public static void   ( final  string[] argv )  {  new  sam format converter (  )  . instance main with exit ( argv )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastq.java, fastq writers,private   ( final  fastq writer first of pair final  fastq writer second of pair final  fastq writer unpaired )  {  this ( first of pair new  lazy <  >  (  (  )   -  >  second of pair )  unpaired )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastq.java,assert paired mates,"protected static void   ( final sam record record1 final sam record record2 )  {  if  (  !  ( record1 . get first of pair flag (  )  && record2 . get second of pair flag (  )  || record2 . get first of pair flag (  )  && record1 . get second of pair flag (  )  )  )   {  throw new  picard exception ( "" illegal mate state: ""  +  record1 . get read name (  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastq.java,clip,private static  string   ( final  string src final int point final  character replacement final boolean pos strand )  {  final int len = src . length (  )  ;   string builder result = new  string builder ( pos strand  ?  src . substring ( 0 point  -  1 )  : src . substring ( len  -  point  +  1 )  )  ;  if  ( replacement  !  =  null )   {  if  ( pos strand )   {  for  ( int i = point ;  i  <  =  len ;  i +  +  )   {  result . append ( replacement )  ;   }   }  else  {  for  ( int i = 0 ;  i  <  =  len  -  point ;  i +  +  )   {  result . insert ( 0 replacement )  ;   }   }   }  return result . to string (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastq.java,close all,private void   (  )  {  final  set <  fastq writer >  fastq writers = new  hash set <  >  (  )  ;  fastq writers . add ( first of pair )  ;  fastq writers . add ( unpaired )  ;  if  ( second of pair . is initialized (  )  )   {  fastq writers . add ( second of pair . get (  )  )  ;   }  for  (  final  fastq writer fastq writer : fastq writers )   {  fastq writer . close (  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastq.java,custom command line validation,"protected  string[]   (  )  {   list <  string >  errors = new  array list <  >  (  )  ;  if  ( interleave && second   end   fastq  !  =  null )   {  errors . add ( "" cannot set interleave to true and pass in a second   end   fastq"" )  ;   }  if  ( unpaired   fastq  !  =  null && second   end   fastq  =  =  null )   {  errors . add ( ""unpaired   fastq may only be set when also emitting read1 and read2 fastqs  ( so second   end   fastq must also be set )  . "" )  ;   }  if  (  ( clipping   attribute  !  =  null && clipping   action  =  =  null )  ||  ( clipping   attribute  =  =  null && clipping   action  !  =  null )  )   {  errors . add ( "" both or neither of clipping   attribute and clipping   action should be set . "" )  ;   }  if  ( clipping   action  !  =  null )   {  if  (  ! clipping   action . equals ( clip   to   n )  &&  ! clipping   action . equals ( clip   trim )  )   {  try  {   integer . parse int ( clipping   action )  ;   }  catch  (   number format exception nfe )   {  errors . add ( ""clipping action must be one of: n  x  or an integer"" )  ;   }   }   }  if  (  ( output   per   rg && output   dir  =  =  null )  ||  (  (  ! output   per   rg )  && output   dir  !  =  null )  )   {  errors . add ( "" if output   per   rg is true  then output   dir should be set .   if "" )  ;   }  if  ( output   per   rg )   {  if  ( rg   tag  =  =  null )   {  errors . add ( "" if output   per   rg is true  then rg   tag should be set . "" )  ;   }  else if  (  !  ( rg   tag . equals ignore case ( ""pu"" )  || rg   tag . equals ignore case ( ""id"" )  )  )   {  errors . add ( ""rg   tag must be: pu or id"" )  ;   }   }  return errors . is empty (  )   ?  super . custom command line validation (  )  : errors . to array ( new  string[errors . size (  ) ] )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastq.java,do work,"protected int   (  )  {  io util . assert file is readable ( input )  ;  final  sam reader reader =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . open ( input )  ;  final  map <  string sam record >  first seen mates = new  hash map <  >  (  )  ;  final  fastq writer factory factory = new  fastq writer factory (  )  ;  factory . set create md5 ( create   md5   file )  ;  initialize additional writers (  )  ;  final  map < sam read group record  fastq writers >  writers = generate writers ( reader . get file header (  )  . get read groups (  )  factory )  ;  final  map < sam read group record  list <  fastq writer >  >  additional writers = generate additional writers ( reader . get file header (  )  . get read groups (  )  factory )  ;  if  ( writers . is empty (  )  )   {  final  string msg base = input  +  "" does not contain  read  groups"" ;  final  string msg = output   per   rg  ?  msg base  +  ""  consider not using the output   per   rg option"" : msg base ;  throw new  picard exception ( msg )  ;   }  final  progress logger progress = new  progress logger ( log )  ;  for  (  final sam record current record : reader )   {  handle record ( current record writers additional writers first seen mates )  ;  progress . record ( current record )  ;   }   closer util . close ( reader )  ;  for  (  final  fastq writers writer mapping : new  hash set <  >  ( writers . values (  )  )  )   {  writer mapping . close all (  )  ;   }  final  set <  fastq writer >  additional writer set = new  hash set <  >  (  )  ;  additional writers . values (  )  . for each ( additional writer set::add all )  ;  for  (  final  fastq writer fastq writer : additional writer set )   {  fastq writer . close (  )  ;   }  if  (  ! first seen mates . is empty (  )  )   {  sam utils . process validation error ( new sam validation error ( sam validation error .  type . mate   not   found "" found ""  +  first seen mates . size (  )   +  "" unpaired mates"" null )  validation   stringency )  ;   }  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastq.java,generate additional writers,protected  map < sam read group record  list <  fastq writer >  >    (  list < sam read group record >  read groups  fastq writer factory factory )  {  return  collections . empty map (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastq.java,generate writers,"private  map < sam read group record  fastq writers >    (  list < sam read group record >  sam read group records  fastq writer factory factory )  {  final  map < sam read group record  fastq writers >  writer map = new  hash map <  >  (  )  ;  final  fastq writers fastq writers ;  if  (  ! output   per   rg )   {  io util . assert file is writable ( fastq )  ;  final  fastq writer first of pair writer = factory . new writer ( fastq )  ;  final  fastq writer second of pair writer ;  if  ( interleave )   {  second of pair writer = first of pair writer ;   }  else if  ( second   end   fastq  !  =  null )   {  io util . assert file is writable ( second   end   fastq )  ;  second of pair writer = factory . new writer ( second   end   fastq )  ;   }  else  {  second of pair writer = null ;   }  final  fastq writer unpaired writer = unpaired   fastq  =  =  null  ?  first of pair writer : factory . new writer ( unpaired   fastq )  ;  fastq writers = new  fastq writers ( first of pair writer second of pair writer unpaired writer )  ;  writer map . put ( null fastq writers )  ;  for  (  final sam read group record rg : sam read group records )   {  writer map . put ( rg fastq writers )  ;   }   }  else  {  for  (  final sam read group record rg : sam read group records )   {  final  fastq writer first of pair writer = factory . new writer ( make read group file ( rg ""   1"" )  )  ;  final  lazy <  fastq writer >  lazy second of pair writer = new  lazy <  >  (  (  )   -  >  interleave  ?  first of pair writer : factory . new writer ( make read group file ( rg ""   2"" )  )  )  ;  writer map . put ( rg new  fastq writers ( first of pair writer lazy second of pair writer first of pair writer )  )  ;   }   }  return writer map ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastq.java,get first of pair,private  fastq writer   (  )  {  return first of pair ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastq.java,get second of pair,private  fastq writer   (  )  {  return second of pair . get (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastq.java,get unpaired,private  fastq writer   (  )  {  return unpaired ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastq.java,handle record,"private void   ( final sam record current record final  map < sam read group record  fastq writers >  writers final  map < sam read group record  list <  fastq writer >  >  additional writers final  map <  string sam record >  first seen mates )  {  if  ( current record . is secondary or supplementary (  )  &&  ! include   non   primary   alignments )   {  return ;   }  if  ( current record . get read fails vendor quality check flag (  )  &&  ! include   non   pf   reads )   {  return ;   }  final  fastq writers fq = writers . get ( current record . get read group (  )  )  ;  sam record read1 = null ;  sam record read2 = null ;  if  ( current record . get read paired flag (  )  )   {  final  string current read name = current record . get read name (  )  ;  final sam record first record = first seen mates . remove ( current read name )  ;  if  ( first record  =  =  null )   {  first seen mates . put ( current read name current record )  ;   }  else  {  assert paired mates ( first record current record )  ;  read1 = current record . get first of pair flag (  )   ?  current record : first record ;  read2 = current record . get first of pair flag (  )   ?  first record : current record ;  write record ( read1 1 fq . get first of pair (  )  read1   trim read1   max   bases   to   write )  ;  final  fastq writer second of pair writer = fq . get second of pair (  )  ;  if  ( second of pair writer  =  =  null )   {  throw new  picard exception ( "" input contains paired reads but no second   end   fastq specified . "" )  ;   }  write record ( read2 2 second of pair writer read2   trim read2   max   bases   to   write )  ;   }   }  else  {  write record ( current record null fq . get unpaired (  )  read1   trim read1   max   bases   to   write )  ;   }  handle additional records ( current record additional writers read1 read2 )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastq.java,main,public static void   ( final  string[] argv )  {   system . exit ( new  sam to fastq (  )  . instance main ( argv )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastq.java,make read group file,"private  file   ( final sam read group record read group final  string pre ext suffix )  {   string file name = null ;  if  ( rg   tag . equals ignore case ( ""pu"" )  )   {  file name = read group . get platform unit (  )  ;   }  else if  ( rg   tag . equals ignore case ( ""id"" )  )   {  file name = read group . get read group id (  )  ;   }  if  ( file name  =  =  null )   {  throw new  picard exception ( "" the selected rg   tag: ""  +  rg   tag  +  "" is not present in the bam header . "" )  ;   }  file name = io util . make file name safe ( file name )  ;  if  ( pre ext suffix  !  =  null )   {  file name +  = pre ext suffix ;   }  file name +  = compress   outputs   per   rg  ?  "" . fastq . gz"" : "" . fastq"" ;  final  file result =  ( output   dir  !  =  null )   ?  new  file ( output   dir file name )  : new  file ( file name )  ;  io util . assert file is writable ( result )  ;  return result ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastq.java,write record,"private void   ( final sam record read final  integer mate number final  fastq writer writer final int bases to trim final  integer max bases to write )  {  final  string seq header = mate number  =  =  null  ?  read . get read name (  )  : read . get read name (  )   +  "" / ""  +  mate number ;   string read string = read . get read string (  )  ;   string base qualities = read . get base quality string (  )  ;  if  ( clipping   attribute  !  =  null )   {   integer clip point =  (  integer ) read . get attribute ( clipping   attribute )  ;  if  ( clip point  !  =  null && clip point  <  clipping   min   length )   {  clip point =  math . min ( read string . length (  )  clipping   min   length )  ;   }  if  ( clip point  !  =  null )   {  if  ( clipping   action . equals ignore case ( clip   trim )  )   {  read string = clip ( read string clip point null  ! read . get read negative strand flag (  )  )  ;  base qualities = clip ( base qualities clip point null  ! read . get read negative strand flag (  )  )  ;   }  else if  ( clipping   action . equals ignore case ( clip   to   n )  )   {  read string = clip ( read string clip point clip   to   n . char at ( 0 )   ! read . get read negative strand flag (  )  )  ;   }  else  {  final char new qual = sam utils . phred to fastq ( new byte[] {  ( byte )  integer . parse int ( clipping   action )  }  )  . char at ( 0 )  ;  base qualities = clip ( base qualities clip point new qual  ! read . get read negative strand flag (  )  )  ;   }   }   }  if  ( re   reverse && read . get read negative strand flag (  )  )   {  read string =  sequence util . reverse complement ( read string )  ;  base qualities =  string util . reverse string ( base qualities )  ;   }  if  ( bases to trim  >  0 )   {  read string = read string . substring ( bases to trim )  ;  base qualities = base qualities . substring ( bases to trim )  ;   }  if  ( quality  !  =  null )   {  final byte[] quals = sam utils . fastq to phred ( base qualities )  ;  final int quality trim index =  math . max ( 1  trimming util . find quality trim point ( quals quality )  )  ;  if  ( quality trim index  <  quals . length )   {  read string = read string . substring ( 0 quality trim index )  ;  base qualities = base qualities . substring ( 0 quality trim index )  ;   }   }  if  ( max bases to write  !  =  null && max bases to write  <  read string . length (  )  )   {  read string = read string . substring ( 0 max bases to write )  ;  base qualities = base qualities . substring ( 0 max bases to write )  ;   }  writer . write ( new  fastq record ( seq header read string """" base qualities )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamAlignmentMerger.java, sam alignment merger,"public   ( final  file unmapped bam file final  file target bam file final  file reference fasta final sam program record program record final boolean clip adapters final boolean bisulfite sequence final boolean aligned reads only final  list <  file >  aligned sam file final int max gaps final  list <  string >  attributes to retain final  list <  string >  attributes to remove final  integer read1 bases trimmed final  integer read2 bases trimmed final  list <  file >  read1 aligned sam file final  list <  file >  read2 aligned sam file final  list <  sam pair util .  pair orientation >  expected orientations final  sort order sort order final  primary alignment selection strategy primary alignment selection strategy final boolean add mate cigar final boolean unmap contaminant reads final int min unclipped bases final  unmapping read strategy unmapping read strategy final  list <  string >  required matching dictionary tags )  {  super ( unmapped bam file target bam file reference fasta clip adapters bisulfite sequence aligned reads only program record attributes to retain attributes to remove read1 bases trimmed read2 bases trimmed expected orientations sort order primary alignment selection strategy add mate cigar unmap contaminant reads unmapping read strategy )  ;  if  (  ( aligned sam file  =  =  null || aligned sam file . is empty (  )  )  &&  ( read1 aligned sam file  =  =  null || read1 aligned sam file . is empty (  )  || read2 aligned sam file  =  =  null || read2 aligned sam file . is empty (  )  )  )   {  throw new  illegal argument exception ( "" either aligned sam file or both of read1 aligned sam file and ""  +  ""read2 aligned sam file must be specified . "" )  ;   }  if  ( aligned sam file  !  =  null )   {  aligned sam file . for each ( io util::assert file is readable )  ;   }  else  {  read1 aligned sam file . for each ( io util::assert file is readable )  ;  read2 aligned sam file . for each ( io util::assert file is readable )  ;   }  this . aligned sam file = aligned sam file ;  this . read1 aligned sam file = read1 aligned sam file ;  this . read2 aligned sam file = read2 aligned sam file ;  this . max gaps = max gaps ;  this . min unclipped bases = min unclipped bases ;  this . contamination filter = new  overclipped read filter ( min unclipped bases false )  ;  this . required matching dictionary tags = required matching dictionary tags ;  log . info ( "" processing sam file ( s ) : ""  +   (  ( aligned sam file  !  =  null )   ?  aligned sam file :  ( read1 aligned sam file  +  "" ""  +  read2 aligned sam file )  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamAlignmentMerger.java, separate end alignment iterator,"public   ( final  list <  file >  read1 alignments final  list <  file >  read2 alignments  file reference fasta )  {  final  list < sam file header >  headers = new  array list <  >  (  )  ;  final  list <  sam reader >  read1 = new  array list <  >  ( read1 alignments . size (  )  )  ;  final  list <  sam reader >  read2 = new  array list <  >  ( read2 alignments . size (  )  )  ;  for  (  final  file f : read1 alignments )   {  final  sam reader r =  sam reader factory . make default (  )  . reference sequence ( reference fasta )  . open ( f )  ;  headers . add ( r . get file header (  )  )  ;  read1 . add ( r )  ;   }  for  (  final  file f : read2 alignments )   {  final  sam reader r =  sam reader factory . make default (  )  . reference sequence ( reference fasta )  . open ( f )  ;  headers . add ( r . get file header (  )  )  ;  read2 . add ( r )  ;   }  final  sam file header merger header merger = new  sam file header merger ( sam file header .  sort order . coordinate headers false )  ;  read1 iterator = new  peekable iterator <  >  ( new  suffix triming sam record iterator ( new  merging sam record iterator ( header merger read1 true )  "" / 1"" )  )  ;  read2 iterator = new  peekable iterator <  >  ( new  suffix triming sam record iterator ( new  merging sam record iterator ( header merger read2 true )  "" / 2"" )  )  ;  header = header merger . get merged header (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamAlignmentMerger.java, suffix triming sam record iterator,private   ( final  closeable iterator < sam record >  underlying iterator final  string suffix to trim )  {  this . underlying iterator = underlying iterator ;  this . suffix to trim = suffix to trim ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamAlignmentMerger.java,close,public void   (  )  {  read1 iterator . close (  )  ;  read2 iterator . close (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamAlignmentMerger.java,get dictionary for merged bam,@ override protected sam sequence dictionary   (  )  {  sam sequence dictionary reference dict = sam sequence dictionary extractor . extract dictionary ( reference fasta . to path (  )  )  ;  if  ( reference dict  =  =  null )   {  throw new  picard excep
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamAlignmentMerger.java,get force sort,public boolean   (  )  {  return this . force sort ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamAlignmentMerger.java,get header,public sam file header   (  )  {  return this . header ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamAlignmentMerger.java,get queryname sorted aligned records,"protected  closeable iterator < sam record >    (  )  {  final  closeable iterator < sam record >  merging iterator ;  final sam file header header ;  if  ( aligned sam file  !  =  null &&  ! aligned sam file . is empty (  )  )   {  final  list < sam file header >  headers = new  array list <  >  ( aligned sam file . size (  )  )  ;  final  list <  sam reader >  readers = new  array list <  >  ( aligned sam file . size (  )  )  ;  for  (  final  file f : this . aligned sam file )   {  final  sam reader r =  sam reader factory . make default (  )  . reference sequence ( reference fasta )  . open ( f )  ;  headers . add ( r . get file header (  )  )  ;  readers . add ( r )  ;  if  ( get program record (  )   =  =  null && r . get file header (  )  . get program records (  )  . size (  )   =  =  1 )   {  set program record ( r . get file header (  )  . get program records (  )  . iterator (  )  . next (  )  )  ;   }   }  aligned sam dictionary = headers . get ( 0 )  . get sequence dictionary (  )  ;  headers . stream (  )  . map ( sam file header::get sequence dictionary )  . for each ( aligned sam dictionary::assert same dictionary )  ;  final  sam file header merger header merger = new  sam file header merger (  sort order . queryname headers false )  ;  merging iterator = new  merging sam record iterator ( header merger readers true )  ;  header = header merger . get merged header (  )  ;   }  else  {  merging iterator = new  separate end alignment iterator ( this . read1 aligned sam file this . read2 aligned sam file reference fasta )  ;  header =  (  (  separate end alignment iterator ) merging iterator )  . get header (  )  ;  aligned sam dictionary = header . get sequence dictionary (  )  ;  if  ( get program record (  )   =  =  null && header . get program records (  )  . size (  )   =  =  1 )   {  set program record ( header . get program records (  )  . iterator (  )  . next (  )  )  ;   }   }  if  (  ! force sort )   {  return merging iterator ;   }  final  sorting collection < sam record >  alignment sorter =  sorting collection . new instance ( sam record . class new bam record codec ( header )  new sam record query name comparator (  )  max   records   in   ram )  ;  int count = 0 ;  while  ( merging iterator . has next (  )  )   {  alignment sorter . add ( merging iterator . next (  )  )  ;  count +  +  ;  if  ( count  >  0 && count % 1000000  =  =  0 )   {  log . info ( "" read ""  +  count  +  "" records from alignment sam / bam . "" )  ;   }   }  log . info ( "" finished reading ""  +  count  +  "" total records from alignment sam / bam . "" )  ;  merging iterator . close (  )  ;  return new  delegating iterator < sam record >  ( alignment sorter . iterator (  )  )  {  @ override public void close (  )  {  super . close (  )  ;  alignment sorter . cleanup (  )  ;   }   }   ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamAlignmentMerger.java,has next,public boolean   (  )  {  return read1 iterator . has next (  )  || read2 iterator . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamAlignmentMerger.java,ignore alignment,protected boolean   ( final sam record sam )  {  if  ( max gaps  =  =   - 1 )  return false ;  int gaps = 0 ;  for  (  final  cigar element el : sam . get cigar (  )  . get cigar elements (  )  )   {  if  ( el . get operator (  )   =  =   cigar operator . i || el . get operator (  )   =  =   cigar operator . d )   {  gaps +  +  ;   }   }  return gaps  >  max gaps ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamAlignmentMerger.java,is contaminant,"protected boolean   ( final  hits for insert hits )  {  boolean is contaminant = false ;  if  ( hits . num hits (  )   >  0 )   {  final int primary index = hits . get index of earliest primary (  )  ;  if  ( primary index  <  0 )  throw new  illegal state exception ( "" no primary alignment was found  despite having nonzero hits . "" )  ;  final sam record primary read1 = hits . get first of pair ( primary index )  ;  final sam record primary read2 = hits . get second of pair ( primary index )  ;  if  ( primary read1  !  =  null && primary read2  !  =  null )  is contaminant = contamination filter . filter out ( primary read1 primary read2 )  ;  else if  ( primary read1  !  =  null )  is contaminant = contamination filter . filter out ( primary read1 )  ;  else if  ( primary read2  !  =  null )  is contaminant = contamination filter . filter out ( primary read2 )  ;  else throw new  illegal state exception ( "" neither read1 or read2 exist for chosen primary alignment"" )  ;   }  return is contaminant ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamAlignmentMerger.java,merge alignment,"public void   ( final  file reference fasta )  {  try  {  super . merge alignment ( reference fasta )  ;   }  catch  (  final  illegal state exception ise )   {  log . warn ( "" exception merging bam alignment  -  attempting to sort aligned reads and try again: "" ise . get message (  )  )  ;  force sort = true ;  reset ref seq file walker (  )  ;  super . merge alignment ( reference fasta )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamAlignmentMerger.java,next,public sam record   (  )  {  if  ( read1 iterator . has next (  )  )   {  if  ( read2 iterator . has next (  )  )   {  return  ( read1 iterator . peek (  )  . get read name (  )  . compare to ( read2 iterator . peek (  )  . get read name (  )  )   <  =  0 )   ?  set pair flags ( read1 iterator . next (  )  true )  : set pair flags ( read2 iterator . next (  )  false )  ;   }  else  {  return set pair flags ( read1 iterator . next (  )  true )  ;   }   }  else  {  return set pair flags ( read2 iterator . next (  )  false )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamAlignmentMerger.java,remove,"public void   (  )  {  throw new  unsupported operation exception ( ""remove (  )  not supported"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamAlignmentMerger.java,set pair flags,private sam record   ( final sam record sam final boolean first of pair )  {  sam . set read paired flag ( true )  ;  sam . set first of pair flag ( first of pair )  ;  sam . set second of pair flag (  ! first of pair )  ;  return sam ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastqWithTags.java,assert tag exists,"private  string   ( final sam record record final  string tag )  {   string value = record . get string attribute ( tag )  ;  if  ( value  =  =  null )   {  throw new  picard exception ( "" record: ""  +  record . get read name (  )   +  "" does have a value for tag: "" +  tag )  ;   }  return value ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastqWithTags.java,custom command line validation,"@ override protected  string[]   (  )  {   list <  string >  errors = new  array list <  >  (  )  ;  if  (  ! quality   tag   group . is empty (  )  && sequence   tag   group . size (  )   !  =  quality   tag   group . size (  )  )   {  errors . add ( ""qu"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastqWithTags.java,generate additional writers,@ override protected  map < sam read group record  list <  fastq writer >  >    (  list < sam read group record >  read groups  fastq writer factory factory )  {  return generate tag writers ( read groups factory )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastqWithTags.java,generate tag writers,private  map < sam read group record  list <  fastq writer >  >    ( final  list < sam read group record >  sam read group records final  fastq writer factory factory )  {  final  map < sam read group record  list <  fastq writer >  >  writer map = new  hash map <  >  (  )  ;  if  (  ! output   per   rg )   {  final  list <  fastq writer >  tag fastq writers = make tag writers ( null factory )  ;  writer map . put ( null tag fastq writers )  ;  for  (  final sam read group record rg : sam read group records )   {  writer map . put ( rg tag fastq writers )  ;   }   }  else  {  for  (  final sam read group record rg : sam read group records )   {  final  list <  fastq writer >  tag writers = make tag writers ( rg factory )  ;  writer map . put ( rg tag writers )  ;   }   }  return writer map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastqWithTags.java,handle additional records,@ override protected void   ( sam record current record  map < sam read group record  list <  fastq writer >  >  tag writers sam record read1 sam record read2 )  {  final  list <  fastq writer >  rg tag writers = tag writers . get ( current record . get r
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastqWithTags.java,initialize additional writers,@ override protected void   (  )  {  setup tag split values (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastqWithTags.java,make tag writers,"private  list <  fastq writer >    ( final sam read group record read group final  fastq writer factory factory )  {   string base filename = null ;  if  ( read group  !  =  null )   {  if  ( rg   tag . equals ignore case ( ""pu"" )  )   {  base filename = read group . get platform unit (  )   +  ""   "" ;   }  else if  ( rg   tag . equals ignore case ( ""id"" )  )   {  base filename = read group . get read group id (  )   +  ""   "" ;   }  if  ( base filename  =  =  null )   {  throw new  picard exception ( "" the selected rg   tag: ""  +  rg   tag  +  "" is not present in the bam header . "" )  ;   }   }  else  {  base filename = """" ;   }   list <  file >  tag files = new  array list <  >  (  )  ;  for  (   string tag split : sequence   tag   group )   {   string file name = base filename  +  tag split . replace ( "" "" ""   "" )  ;  file name = io util . make file name safe ( file name )  ;  file name +  = compress   outputs   per   tag   group  ?  "" . fastq . gz"" : "" . fastq"" ;  final  file result =  ( output   dir  !  =  null )   ?  new  file ( output   dir file name )  : new  file ( fastq . get parent (  )  file name )  ;  io util . assert file is writable ( result )  ;  tag files . add ( result )  ;   }  return tag files . stream (  )  . map ( factory::new writer )  . collect (  collectors . to list (  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastqWithTags.java,setup tag split values,"private void   (  )  {  split   sequence   tags = new  array list <  >  (  )  ;  split   quality   tags = new  array list <  >  (  )  ;  split   separator   tags = new  array list <  >  (  )  ;  for  ( int i = 0 ;  i  <  sequence   tag   group . size (  )  ;  i +  +  )   {  split   sequence   tags . add ( sequence   tag   group . get ( i )  . trim (  )  . split ( "" "" )  )  ;  split   quality   tags . add ( quality   tag   group . is empty (  )   ?  null : quality   tag   group . get ( i )  . trim (  )  . split ( "" "" )  )  ;  split   separator   tags . add ( tag   group   seperator . is empty (  )   ?  tag   split   default   sep : tag   group   seperator . get ( i )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SamToFastqWithTags.java,write tag records,"private void   ( final sam record read final  integer mate number final  list <  fastq writer >  tag writers )  {  if  ( sequence   tag   group . is empty (  )  )   {  return ;   }  final  string seq header = mate number  =  =  null  ?  read . get read name (  )  : read . get read name (  )   +  "" / ""  +  mate number ;  for  ( int i = 0 ;  i  <  sequence   tag   group . size (  )  ;  i +  +  )   {  final  string tmp tag sep = split   separator   tags . get ( i )  ;  final  string[] sequence tags to write = split   sequence   tags . get ( i )  ;  final  string new sequence =  string . join ( tmp tag sep  arrays . stream ( sequence tags to write )  . map ( tag  -  >  assert tag exists ( read tag )  )  . collect (  collectors . to list (  )  )  )  ;  final  string tmp qual sep =  string utils . repeat ( tag   split   qual tmp tag sep . length (  )  )  ;  final  string[] quality tags to write = split   quality   tags . get ( i )  ;  final  string new qual = quality   tag   group . is empty (  )   ?   string utils . repeat ( tag   split   qual new sequence . length (  )  )  :  string . join ( tmp qual sep  arrays . stream ( quality tags to write )  . map ( tag  -  >  assert tag exists ( read tag )  )  . collect (  collectors . to list (  )  )  )  ;   fastq writer writer = tag writers . get ( i )  ;  writer . write ( new  fastq record ( seq header new sequence """" new qual )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SetNmMdAndUqTags.java,do work,"protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  final  sam reader reader =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . open ( input )  ;  if  ( reader . get file header (  )  . get sort order (  )   !  =  sam file header .  sort order . coordinate )   {  throw new sam exception ( "" input must be coordinate - sorted for this program to run .   found: ""  +  reader . get file header (  )  . get sort order (  )  )  ;   }  final sam file writer writer = new sam file writer factory (  )  . makesam orbam writer ( reader . get file header (  )  true output )  ;  writer . set progress logger ( new  progress logger ( log  ( int ) 1e7 "" wrote"" ""records"" )  )  ;  final  reference sequence file walker ref seq walker = new  reference sequence file walker ( reference   sequence )  ;   stream support . stream ( reader . spliterator (  )  false )  . peek ( rec  -  >  fix record ( rec ref seq walker )  )  . for each ( writer::add alignment )  ;   closer util . close ( reader )  ;  writer . close (  )  ;  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SetNmMdAndUqTags.java,fix record,private void   ( sam record record  reference sequence file walker ref seq walker )  {  if  (  ! record . get read unmapped flag (  )  )   {  if  ( set   only   uq )   {   abstract alignment merger . fix uq ( record ref seq walker is   bisulfite   sequence )  ;   }  else  {   abstract alignment merger . fix nm md and uq ( record ref seq walker is   bisulfite   sequence )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SetNmMdAndUqTags.java,main,public static void   ( final  string[] argv )  {  new  set nm md and uq tags (  )  . instance main with exit ( argv )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SetNmMdAndUqTags.java,requires reference,@ override protected boolean   (  )  {  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SplitSamByLibrary.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert directory is writable ( output )  ;   sam reader reader =  sam reader factory . make default (  )  . open ( input )  ;   map <  string sam file writer >  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SplitSamByLibrary.java,main,public static void   (  string[] args )  {   system . exit ( new  split sam by library (  )  . instance main ( args )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SplitSamByNumberOfReads.java,custom command line validation,"protected  string[]   (  )  {  if  ( total   reads   in   input  <  0 )   {  return new  string[] {  string . format ( "" cannot set total   reads   in   input to a number less than 1  found %d . "" total   reads   in   input )  }  ;   }  if  ( split   to   n   files  <  =  1 && split   to   n   reads  <  =  1 )   {  return new  string[] {  string . format ( "" one of split   to   n   files or split   to   n   reads must be greater than 0 .  ""  +  "" found split   to   n   files is %d and split   to   n   reads is %d . "" split   to   n   files split   to   n   reads )  }  ;   }  return null ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SplitSamByNumberOfReads.java,do work,"protected int   (  )  {  io util . assert file is readable ( input )  ;  if  ( total   reads   in   input  =  =  0 &&  !  files . is regular file ( input . to path (  )  )  )   {  log . error (  string . format ( ""input is not a regular file: %s .  ""  +  "" if total   reads   in   input is not supplied  input cannot be a stream . "" input )  )  ;  return 1 ;   }  io util . assert directory is writable ( output )  ;  final  sam reader factory reader factory =  sam reader factory . make default (  )  ;  final  sam reader reader = reader factory . reference sequence ( reference   sequence )  . open ( input )  ;  final sam file header header = reader . get file header (  )  ;  if  ( header . get sort order (  )   =  =  sam file header .  sort order . coordinate )   {  log . warn ( "" splitting a coordinate sorted bam may result in invalid bams ""  +  ""that do not always contain each read's mate in the same bam . "" )  ;   }  if  (  ! header . get version (  )  . equals ( sam file header . current   version )  )   {  log . warn (  string . format ( "" input file's version is %s  but the current sam format version is %s .   outputs will be written ""  +  ""with current version . "" header . get version (  )  sam file header . current   version )  )  ;   }  final  progress logger first pass progress = new  progress logger ( log 1000000 "" counted"" )  ;  if  ( total   reads   in   input  =  =  0 )   {  final  sam reader first pass reader = reader factory . reference sequence ( reference   sequence )  . open ( input )  ;  log . info ( "" first pass traversal to count number of reads is beginning .   if number of reads ""  +  ""is known  use total   reads   in   input to skip first traversal . "" )  ;  for  (  sam record rec : first pass reader )   {  first pass progress . record ( rec )  ;   }   closer util . close ( first pass reader )  ;  log . info (  string . format ( "" first pass traversal to count number of reads ended  found %d total reads . "" first pass progress . get count (  )  )  )  ;   }  final long total reads = total   reads   in   input  =  =  0  ?  first pass progress . get count (  )  : total   reads   in   input ;  final sam file writer factory writer factory = new sam file writer factory (  )  ;  final  decimal format file name formatter = new  decimal format ( out   prefix  +  ""   ""  +   string . format ( ""0000"" )  +   bam file io utils . bam   file   extension )  ;  final int split ton files = split   to   n   files  !  =  0  ?  split   to   n   files :  ( int )  math . ceil ( total reads  /   ( double ) split   to   n   reads )  ;  final int reads per file =  ( int )  math . ceil ( total reads  /   ( double ) split ton files )  ;  int reads written = 0 ;  int file index = 1 ;  sam file writer current writer = writer factory . makesam orbam writer ( header true new  file ( output file name formatter . format ( file index +  +  )  )  )  ;   string last read name = """" ;  final  progress logger progress = new  progress logger ( log )  ;  for  (  sam record current record : reader )   {  if  ( reads written  >  =  reads per file &&  ! last read name . equals ( current record . get read name (  )  )  )   {  current writer . close (  )  ;  current writer = writer factory . makesam orbam writer ( header true new  file ( output file name formatter . format ( file index +  +  )  )  )  ;  reads written = 0 ;   }  current writer . add alignment ( current record )  ;  last read name = current record . get read name (  )  ;  reads written +  +  ;  progress . record ( current record )  ;   }  current writer . close (  )  ;   closer util . close ( reader )  ;  if  ( progress . get count (  )   !  =  total reads )   {  log . warn (  string . format ( "" the total reads  ( %d )  provided does not match the reads found in the ""  +  ""input file  ( %d )  .   files may not be split evenly or number of files may not ""  +  ""match what was requested .   there were %d files generated each with around %d "" +  ""reads except the last file which contained %d reads . "" total reads progress . get count (  )  file index  -  1 reads per file reads written )  )  ;   }  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SortSam.java, sort order,  (  string description )  {  this . description = description ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SortSam.java,do work,"protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  final  sam reader reader =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . open ( input )  ;   ;  reader . get file header (  )  . set sort order ( sort   order . get sort order (  )  )  ;  final sam file writer writer = new sam file writer factory (  )  . makesam orbam writer ( reader . get file header (  )  false output )  ;  writer . set progress logger ( new  progress logger ( log  ( int ) 1e7 "" wrote"" ""records from a sorting collection"" )  )  ;  final  progress logger progress = new  progress logger ( log  ( int ) 1e7 "" read"" )  ;  for  (  final sam record rec : reader )   {  writer . add alignment ( rec )  ;  progress . record ( rec )  ;   }  log . info ( "" finished reading inputs  merging and writing to output now . "" )  ;   closer util . close ( reader )  ;  writer . close (  )  ;  return 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SortSam.java,get help doc,@ override public  string   (  )  {  return description ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\SortSam.java,get sort order,public sam file header .  sort order   (  )  {  return sam file header .  sort order . value of ( this . name (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\util\PhysicalLocationInt.java,get library id,"public short   (  )  {  throw new  picard exception ( "" not  implemented"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\util\PhysicalLocationInt.java,get read group,"public short   (  )  {  throw new  picard exception ( "" not  implemented"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\util\PhysicalLocationInt.java,get tile,public short   (  )  {  return tile ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\util\PhysicalLocationInt.java,getx,public int   (  )  {  return x ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\util\PhysicalLocationInt.java,gety,public int   (  )  {  return y ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\util\PhysicalLocationInt.java,set library id,"public void   ( final short library id )  {  throw new  picard exception ( "" not  implemented"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\util\PhysicalLocationInt.java,set read group,"public void   ( final short read group )  {  throw new  picard exception ( "" not  implemented"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\util\PhysicalLocationInt.java,set tile,public void   ( final short tile )  {  this . tile = tile ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\util\PhysicalLocationInt.java,setx,public void   ( final int x )  {  this . x = x ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\util\PhysicalLocationInt.java,sety,public void   ( final int y )  {  this . y = y ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\util\PhysicalLocationShort.java,setx,@ override public void   ( final int x )  {  super . setx (  ( short ) x )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\util\PhysicalLocationShort.java,sety,@ override public void   ( final int y )  {  super . sety (  ( short ) y )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ValidateSamFile.java, return types,  ( final int value )  {  this . value = value ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ValidateSamFile.java,custom command line validation,@ override protected  string[]   (  )  {  if  (  (  ! validate   index && index   validation   stringency  !  =   index validation stringency . none )  ||  ( validate   index && index   validation   stringency  =  =   index validation stringency . none ) 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ValidateSamFile.java,do work,@ override protected int   (  )  {  try  {  io util . assert file is readable ( input )  ;   reference sequence file reference = null ;  if  ( reference   sequence  !  =  null )   {  io util . assert file is readable ( reference   sequence )  ;  reference
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ValidateSamFile.java,main,public static void   ( final  string[] args )  {   system . exit ( new  validate sam file (  )  . instance main ( args )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ValidateSamFile.java,value,int   (  )  {  return value ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\util\ReadNameParser.java, read name parser,public   ( final  string read name regex final  log log )  {  this . read name regex = read name regex ;  this . log = log ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\util\ReadNameParser.java,add location information,"public boolean   ( final  string read name final  physical location loc )  {  try  {  if  ( this . read name regex  =  =   read name parser . default   read   name   regex )   {  final int fields = get last three fields ( read name ':' tmp location fields )  ;  if  (  !  ( fields  =  =  5 || fields  =  =  7 )  )   {  if  ( null  !  =  log &&  ! this . warned about regex not matching )   {  this . log . warn (  string . format ( "" default read   name   regex '%s' did not match read name '%s' .  ""  +  "" you may need to specify a read   name   regex in order to correctly identify optical duplicates .  ""  +  "" note that this message will not be emitted again even if other read names do not match the regex . "" this . read name regex read name )  )  ;  this . warned about regex not matching = true ;   }  return false ;   }  loc . set tile (  ( short ) tmp location fields[0] )  ;  loc . setx ( tmp location fields[1] )  ;  loc . sety ( tmp location fields[2] )  ;  return true ;   }  else if  ( this . read name regex  =  =  null )   {  return false ;   }  else  {  if  ( this . read name pattern  =  =  null )  this . read name pattern =  pattern . compile ( this . read name regex )  ;  final  matcher m = this . read name pattern . matcher ( read name )  ;  if  ( m . matches (  )  )   {  loc . set tile (  ( short )  integer . parse int ( m . group ( 1 )  )  )  ;  loc . setx (  integer . parse int ( m . group ( 2 )  )  )  ;  loc . sety (  integer . parse int ( m . group ( 3 )  )  )  ;  return true ;   }  else  {  if  ( null  !  =  log &&  ! this . warned about regex not matching )   {  this . log . warn (  string . format ( ""read   name   regex '%s' did not match read name '%s' .   your regex may not be correct .  ""  +  "" note that this message will not be emitted again even if other read names do not match the regex . "" this . read name regex read name )  )  ;  warned about regex not matching = true ;   }  return false ;   }   }   }  catch  (   number format exception nfe )   {  if  ( log  !  =  null &&  ! this . warned about regex not matching )   {  this . log . warn ( ""a field field parsed out of a read name was expected to contain an integer and did not .  "" "" read name: "" read name "" .   cause: "" nfe . get message (  )  )  ;  warned about regex not matching = true ;   }  return false ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\util\ReadNameParser.java,get last three fields,public static int   ( final  string read name final char delim final int[] tokens )  throws  number format exception  {  int tokens idx = 2 ;  int num fields = 0 ;  int i  end idx ;  end idx = read name . length (  )  ;  for  ( i = read name . length (  )   -  1 ;  0  <  =  i && 0  <  =  tokens idx ;  i -  -  )   {  if  ( read name . char at ( i )   =  =  delim || 0  =  =  i )   {  num fields +  +  ;  tokens[tokens idx] = rapid parse int ( read name . substring (  ( 0  =  =  i )   ?  0 :  ( i  +  1 )  end idx )  )  ;  tokens idx -  -  ;  end idx = i ;   }   }  while  ( 0  <  =  i )   {  if  ( read name . char at ( i )   =  =  delim || 0  =  =  i )  num fields +  +  ;  i -  -  ;   }  if  ( num fields  <  3 )   {  tokens[0] = tokens[1] = tokens[2] =  - 1 ;  return  - 1 ;   }  else  {  return num fields ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\util\ReadNameParser.java,rapid parse int,"public static int   ( final  string input )  throws  number format exception  {  final int len = input . length (  )  ;  int val = 0 ;  int i = 0 ;  boolean is negative = false ;  if  ( 0  <  len && ' - '  =  =  input . char at ( 0 )  )   {  i = 1 ;  is negative = true ;   }  boolean has digits = false ;  for  (  ;  i  <  len ;   +  + i )   {  final char ch = input . char at ( i )  ;  if  (  character . is digit ( ch )  )   {  val =  ( val * 10 )   +   ( ch  -  48 )  ;  has digits = true ;   }  else  {  break ;   }   }  if  (  ! has digits )  throw new  number format exception ( "" string '""  +  input  +  ""' did not start with a parsable number . "" )  ;  if  ( is negative )  val =  - val ;  return val ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ViewSam.java,custom command line validation,"@ override protected  string[]   (  )  {  if  ( header   only && records   only )   {  return new  string[] { "" cannot specify both header   only = true and records   only = true . "" }  ;   }  return super . custom command line validation (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ViewSam.java,do work,@ override protected int   (  )  {  return write sam text (  system . out )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ViewSam.java,main,public static void   ( final  string[] args )  {  new  view sam (  )  . instance main ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\sam\ViewSam.java,write sam text,"int   (  print stream print stream )  {  try  {  final  closeable iterator < sam record >  sam records iterator ;  final  sam reader sam reader =  sam reader factory . make default (  )  . reference sequence ( reference   sequence )  . open (  sam input resource . of ( input )  )  ;  if  ( header   only || interval   list  =  =  null )   {  sam records iterator = sam reader . iterator (  )  ;   }  else  {  io util . assert file is readable ( interval   list )  ;  final  list <  interval >  intervals =  interval list . from file ( interval   list )  . uniqued (  )  . get intervals (  )  ;  sam records iterator = new  sam record interval iterator factory (  )  . make sam record interval iterator ( sam reader intervals sam reader . has index (  )  )  ;   }  final  ascii writer writer = new  ascii writer ( print stream )  ;  final sam file header header = sam reader . get file header (  )  ;  if  (  ! records   only )   {  if  ( header . get text header (  )   !  =  null )   {  writer . write ( header . get text header (  )  )  ;   }  else  {  new sam text header codec (  )  . encode ( writer header true )  ;   }   }  if  (  ! header   only )   {  while  ( sam records iterator . has next (  )  )   {  final sam record rec = sam records iterator . next (  )  ;  if  ( print stream . check error (  )  )   {  return 1 ;   }  if  ( this . alignment   status  =  =   alignment status .  aligned && rec . get read unmapped flag (  )  )  continue ;  if  ( this . alignment   status  =  =   alignment status .  unaligned &&  ! rec . get read unmapped flag (  )  )  continue ;  if  ( this . pf   status  =  =   pf status . pf && rec . get read fails vendor quality check flag (  )  )  continue ;  if  ( this . pf   status  =  =   pf status .  nonpf &&  ! rec . get read fails vendor quality check flag (  )  )  continue ;  writer . write ( rec . getsam string (  )  )  ;   }   }  writer . flush (  )  ;  if  ( print stream . check error (  )  )   {  return 1 ;   }   closer util . close ( writer )  ;   closer util . close ( sam records iterator )  ;  return 0 ;   }  catch  (  io exception e )   {  throw new  picard exception ( "" exception writing sam text"" e )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\Test.java,main,public static void   (  string[] args )  {  new  test (  )  . run (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\Test.java,run,"public void   (  )  {  final int iterations = 1000000 ;  final  string[] fields = new  string[10000] ;  final  stop watch watch = new  stop watch (  )  ;  watch . start (  )  ;  for  ( int i = 0 ;  i  <  iterations ;   +  + i )   {  if  (  string util . split ( text fields '\t' )   >  100 )   {   system . out . println ( "" mama  mia that's a lot of tokens !  ! "" )  ;   }   }  watch . stop (  )  ;   system . out . println ( "" string util . split (  )  took ""  +  watch . get elapsed time (  )  )  ;  watch . reset (  )  ;  watch . start (  )  ;  for  ( int i = 0 ;  i  <  iterations ;   +  + i )   {  if  ( split ( text fields ""\t"" )   >  100 )   {   system . out . println ( "" mama  mia that's a lot of tokens !  ! "" )  ;   }   }  watch . stop (  )  ;   system . out . println ( "" string tokenizer took ""  +  watch . get elapsed time (  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\Test.java,split,public int   ( final  string s final  string[] tokens final  string token )  {  final  string tokenizer tokenizer = new  string tokenizer ( s token false )  ;  int i = 0 ;  while  ( tokenizer . has more tokens (  )  )   {  tokens[i +  + ] = tokenizer . next token (  )  ;   }  return i ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java, adapter marker,"public   ( final int adapter length final  adapter pair .  .  .  original adapters )  {  final  array list <  truncated adapter pair >  truncated adapters = new  array list <  truncated adapter pair >  (  )  ;  for  (  final  adapter pair adapter : original adapters )   {  final  truncated adapter pair truncated adapter = make truncated adapter pair ( adapter adapter length )  ;  final int matching index = truncated adapters . index of ( truncated adapter )  ;  if  ( matching index  =  =   - 1 )   {  truncated adapters . add ( truncated adapter )  ;   }  else  {  final  truncated adapter pair matching adapter = truncated adapters . get ( matching index )  ;  matching adapter . set name ( matching adapter . get name (  )   +  ""|""  +  adapter . get name (  )  )  ;   }   }  adapters . set ( truncated adapters . to array ( new  adapter pair[truncated adapters . size (  ) ] )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java, truncated adapter pair,private   ( final  string name final  string three prime read order final  string five prime read order )  {  this . name = name ;  this . three prime = three prime read order ;  this . three prime bytes =  string util . string to bytes ( three prime read order )  ;  this . five prime read order = five prime read order ;  this . five prime read order bytes =  string util . string to bytes ( five prime read order )  ;  this . five prime =  sequence util . reverse complement ( five prime read order )  ;  this . five prime bytes =  string util . string to bytes ( this . five prime )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,adapter trim illumina paired reads,public  adapter pair   ( final sam record read1 final sam record read2 final int min match bases final double max error rate )  {  final  adapter pair ret =  clipping utility . adapter trim illumina paired reads ( read1 read2 min match bases max error rate adapters . get (  )  )  ;  tally and fix adapters ( ret read1 read2 )  ;  return ret ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,adapter trim illumina single read,public  adapter pair   ( final sam record read final int min match bases final double max error rate )  {  final  adapter pair ret =  clipping utility . adapter trim illumina single read ( read min match bases max error rate adapters . get (  )  )  ;  tally and fix adapters ( ret read )  ;  return ret ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,compare,@ override public int   ( final  integer integer final  integer integer2 )  {  return integer2 . compare to ( integer )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,equals,@ override public boolean   ( final  object o )  {  if  ( this  =  =  o )  return true ;  if  ( o  =  =  null || get class (  )   !  =  o . get class (  )  )  return false ;  final  truncated adapter pair that =  (  truncated adapter pair ) o ;  if  (  ! 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,fix already seen reads,private void   (  )  {   arrays . stream ( adapters . get (  )  )  . for each ( adapter  -  >  pre adapter pruned records . remove ( adapter )  )  ;  pre adapter pruned records . values (  )  . for each ( read list  -  >  read list . parallel stream (  )  . for each ( read  -  >   {   stream < sam record . sam tag and value >  filter attributes = read . get attributes (  )  . stream (  )  . filter ( tag  -  >   ! tag . tag . equals (  reserved tag constants . xt )  )  ;  read . clear attributes (  )  ;  filter attributes . for each ( tag  -  >  read . set attribute ( tag . tag tag . value )  )  ;   }   )  )  ;  pre adapter pruned records . clear (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,get prime adapter,public  string   (  )  {  return three prime ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,get prime adapter bytes,public byte[]   (  )  {  return three prime bytes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,get prime adapter bytes in read order,public byte[]   (  )  {  return three prime bytes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,get prime adapter in read order,public  string   (  )  {  return three prime ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,get prime adapter,public  string   (  )  {  return five prime ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,get prime adapter bytes,public byte[]   (  )  {  return five prime bytes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,get prime adapter bytes in read order,public byte[]   (  )  {  return five prime read order bytes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,get prime adapter in read order,public  string   (  )  {  return five prime read order ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,get adapters, adapter pair[]   (  )  {  return adapters . get (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,get max pair error rate,public double   (  )  {  return max pair error rate ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,get max single end error rate,public double   (  )  {  return max single end error rate ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,get min pair match bases,public int   (  )  {  return min pair match bases ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,get min single end match bases,public int   (  )  {  return min single end match bases ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,get name,public  string   (  )  {  return this . name ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,get num adapters to keep,public int   (  )  {  return num adapters to keep ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,get threshold for selecting adapters to keep,public int   (  )  {  return threshold for selecting adapters to keep ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,hash code,@ override public int   (  )  {  int result = five prime . hash code (  )  ;  result = 31 * result  +  three prime . hash code (  )  ;  return result ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,make truncated adapter pair,"private  truncated adapter pair   ( final  adapter pair adapter pair final int adapter length )  {  return new  truncated adapter pair ( ""truncated ""  +  adapter pair . get name (  )  substring and remove trailing ns ( adapter pair . get3 prime adapter in read order (  )  adapter length )  substring and remove trailing ns ( adapter pair . get5 prime adapter in read order (  )  adapter length )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,set max pair error rate,public synchronized  adapter marker   ( final double max pair error rate )  {  this . max pair error rate = max pair error rate ;  return this ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,set max single end error rate,public synchronized  adapter marker   ( final double max single end error rate )  {  this . max single end error rate = max single end error rate ;  return this ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,set min pair match bases,public synchronized  adapter marker   ( final int min pair match bases )  {  this . min pair match bases = min pair match bases ;  return this ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,set min single end match bases,public synchronized  adapter marker   ( final int min single end match bases )  {  this . min single end match bases = min single end match bases ;  return this ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,set name,public void   ( final  string name )  {  this . name = name ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,set num adapters to keep,"public synchronized  adapter marker   ( final int num adapters to keep )  {  if  ( num adapters to keep  <  =  0 )   {  throw new  illegal argument exception (  string . format ( ""num adapters to keep should be positive: %d"" num adapters to keep )  )  ;   }  this . num adapters to keep = num adapters to keep ;  return this ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,set threshold for selecting adapters to keep,public synchronized  adapter marker   ( final int threshold for selecting adapters to keep )  {  this . threshold for selecting adapters to keep = threshold for selecting adapters to keep ;  return this ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,substring and remove trailing ns,private  string   ( final  string s int length )  {  length =  math . min ( length s . length (  )  )  ;  final byte[] bytes =  string util . string to bytes ( s )  ;  while  ( length  >  0 &&  sequence util . is no call ( bytes[length  -  1] )  )   {  length -  -  ;   }  return s . substring ( 0 length )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,tally and fix adapters,private void   (  adapter pair ret sam record .  .  .  reads )  {  if  ( ret  !  =  null &&  ! threshold reached )   {  if  (  ! pre adapter pruned records . contains key ( ret )  )   {  pre adapter pruned records . put ( ret new  array list <  >  (  )  )  ;   }   arrays . stream ( reads )  . for each ( read  -  >  pre adapter pruned records . get ( ret )  . add ( read )  )  ;  tally found adapter ( ret )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,tally found adapter,private void   ( final  adapter pair found adapter )  {  if  ( threshold for selecting adapters to keep  <  1 )  return ;  synchronized  ( this )   {  seen counts . put ( found adapter seen counts . get ( found adapter )   +  1 )  ;  num adapters seen +  = 1 ;  if  ( num adapters seen  >  =  threshold for selecting adapters to keep )   {  final  tree map <  integer  adapter pair >  sorted adapters = new  tree map <  integer  adapter pair >  ( new  comparator <  integer >  (  )  {  @ override public int compare (  final  integer integer  final  integer integer2 )  {  return integer2 . compare to ( integer )  ;   }   }   )  ;  for  (  final  map .  entry <  adapter pair  integer >  entry : seen counts . entry set (  )  )   {  sorted adapters . put ( entry . get value (  )  entry . get key (  )  )  ;   }  final  array list <  adapter pair >  best adapters = new  array list <  adapter pair >  ( num adapters to keep )  ;  int count of last adapter =  integer . max   value ;  for  (  final  map .  entry <  integer  adapter pair >  entry : sorted adapters . entry set (  )  )   {  if  ( best adapters . size (  )   >  =  num adapters to keep )   {  if  ( entry . get key (  )   =  =  count of last adapter )   {  best adapters . add ( entry . get value (  )  )  ;   }  else  {  break ;   }   }  else  {  count of last adapter = entry . get key (  )  ;  best adapters . add ( entry . get value (  )  )  ;   }   }  threshold reached = true ;  adapters . set ( best adapters . to array ( new  adapter pair[best adapters . size (  ) ] )  )  ;  fix already seen reads (  )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AdapterMarker.java,to string,"@ override public  string   (  )  {  return "" truncated adapter pair { ""  +  ""five prime read order = '""  +  five prime read order  +  '\'' +  ""  three prime = '"" +  three prime +  '\'' +  ""  name = '"" +  name +  '\'' +  ' } ' ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AbstractInputParser.java,advance,@ override protected  string[]   (  )  {  byte[] next line ;  do  {  next line = read next line (  )  ;   }  while  ( next line  !  =  null &&  (  ( this . skip blank lines && is blank ( next line )  )  || is comment ( next line )  )  )  ;  return next li
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AbstractInputParser.java,calculate word count,protected void   ( final byte[] line )  {  int words = 0 ;  boolean delimiter = true ;  for  (  final byte b : line )   {  if  ( is delimiter ( b )  )   {  if  ( delimiter &&  ! is treat grouped delimiters as one (  )  )  words +  +  ;  delimiter = true ;   }  else  {  if  ( delimiter )  words +  +  ;  delimiter = false ;   }   }  if  ( delimiter &&  ! is treat grouped delimiters as one (  )  )   {  words +  = 1 ;   }  set word count ( words )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AsyncIterator.java, async iterator,public   ( final  closeable iterator < t >  underlying iterator final int queue size final  string thread name prefix )  {  this . underlying iterator = underlying iterator ;  this . queue = new  array blocking queue < t >  ( queue size )  ;  this . reader runnable = new  reader runnable (  )  ;  this . reader = new  thread ( reader runnable thread name prefix  +  threads created +  +  )  ;  this . reader . set daemon ( true )  ;  this . reader . start (  )  ;  get next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AsyncIterator.java,assert open,"private void   (  )  {  if  ( this . is closed . get (  )  )   {  throw new  runtime exception ( "" async iterator already closed . "" )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AsyncIterator.java,check and rethrow,private void   (  )  {  final  throwable t = this . ex . get (  )  ;  if  ( t  !  =  null )   {  if  ( t instanceof  error )  throw  (  error ) t ;  if  ( t instanceof  runtime exception )  throw  (  runtime exception ) t ;  else throw new  runtime exception ( t )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AsyncIterator.java,close,"public void   (  )  {  check and rethrow (  )  ;  assert open (  )  ;  this . is closed . set ( true )  ;  try  {  this . reader . join (  )  ;   }  catch  (   interrupted exception ie )   {  throw new  runtime exception ( "" interrupted waiting on reader thread . "" ie )  ;   }  underlying iterator . close (  )  ;  check and rethrow (  )  ;  this . queue . clear (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AsyncIterator.java,get next,"private void   (  )  {  assert open (  )  ;  check and rethrow (  )  ;  try  {  the next = null ;  while  (  ! this . queue . is empty (  )  ||  ! this . reader runnable . is done (  )  )   {  the next = this . queue . poll ( 5  time unit . seconds )  ;  check and rethrow (  )  ;  if  ( the next  !  =  null )  break ;   }   }  catch  (   interrupted exception ie )   {  throw new  runtime exception ( "" interrupted queueing item for writing . "" ie )  ;   }  check and rethrow (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AsyncIterator.java,has next,public boolean   (  )  {  assert open (  )  ;  return the next  !  =  null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AsyncIterator.java,is done,public boolean   (  )  {  return reader done . get (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AsyncIterator.java,next,public t   (  )  {  assert open (  )  ;  if  (  ! has next (  )  )  throw new  no such element exception (  )  ;  final t ret = the next ;  get next (  )  ;  return ret ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AsyncIterator.java,remove,public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AsyncIterator.java,run,public void   (  )  {  try  {  boolean is eof = false ;  while  (  ! is closed . get (  )  &&  ! is eof )   {  try  {  if  (  ! underlying iterator . has next (  )  )   {  is eof = true ;   }  else  {  final t item = underlying iterator . next (  )  ;  while  (  ! is closed . get (  )  &&  ! queue . offer ( item 2  time unit . seconds )  )   {   }   }   }  catch  (   interrupted exception ie )   {   }   }   }  catch  (   throwable t )   {  ex . compare and set ( null t )  ;   }  finally  {  reader done . set ( true )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AlleleSubsettingUtils.java,non empty,"private static  < i t extends  collection < i >  > t   ( t collection  string message )  {  non null ( collection "" the collection is null: ""  +  message )  ;  if  ( collection . is empty (  )  )   {  throw new  illegal argument exception ( "" the collection is empty: ""  +  message )  ;   }  else  {  return collection ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AlleleSubsettingUtils.java,non null,private static  < t > t   ( final t object  string message )  {  if  ( object  =  =  null )   {  throw new  illegal argument exception ( message )  ;   }  return object ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AlleleSubsettingUtils.java,subset alleles,"public static  genotypes context   ( final  genotypes context original gs final  list <  allele >  original alleles final  list <  allele >  alleles to keep )  {  non null ( original gs ""original  genotypes context must not be null . "" )  ;  non null ( alleles to keep ""alleles to keep is null . "" )  ;  non empty ( alleles to keep ""must keep at least one allele . "" )  ;  validate true ( alleles to keep . get ( 0 )  . is reference (  )  "" first allele must be the reference allele . "" )  ;  validate true ( alleles to keep . stream (  )  . all match ( original alleles::contains )  "" original alleles must contain alleles to keep . "" )  ;  int index of last =  - 1 ;  for  (   allele a : alleles to keep )   {  validate true ( index of last  <  original alleles . index of ( a )  ""alleles to keep must maintain the order of the original alleles . "" )  ;  index of last = original alleles . index of ( a )  ;   }  final int[] alleles index = alleles to keep . stream (  )  . map to int ( original alleles::index of )  . to array (  )  ;  final  genotypes context newg ts =  genotypes context . create ( original gs . size (  )  )  ;  int[] subsetted likelihood indices = subsettedpl indices ( original alleles alleles to keep )  ;  for  (  final  genotype g : original gs )   {  validate true ( g . get ploidy (  )   =  =  2 ""only implemented for ploidy 2 for now . "" )  ;  final int expected num likelihoods =  genotype likelihoods . num likelihoods ( alleles to keep . size (  )  2 )  ;  int[] newp ls = null ;  double new log10gq =  - 1 ;  if  ( g . has likelihoods (  )  )   {  int[] originalp ls = g . getpl (  )  ;  if  ( originalp ls . length  !  =  expected num likelihoods )   {  newp ls =  arrays . stream ( subsetted likelihood indices )  . map ( idx  -  >  originalp ls[idx] )  . to array (  )  ;  final int min likelihood =  math util . min ( newp ls )  ;  for  ( int i = 0 ;  i  <  expected num likelihoods ;  i +  +  )   {  newp ls[i] = newp ls[i]  -  min likelihood ;   }  final int index of most likely =  math util . index of min ( newp ls )  ;  new log10gq =  genotype likelihoods . getgq log10 from likelihoods ( index of most likely  genotype likelihoods . fromp ls ( newp ls )  . get as vector (  )  )  ;   }  else  {  newp ls = null ;   }   }  final  genotype builder gb ;  if  ( newp ls  =  =  null )   {  gb = new  genotype builder ( g )  . nopl (  )  . nogq (  )  . alleles ( diploid   no   call )  ;   }  else  {  gb = new  genotype builder ( g )  . pl ( newp ls )  . log10p error ( new log10gq )  ;  final  list <  integer >  original diploid alleles =  genotype likelihoods . get alleles (  math util . index of min ( newp ls )  2 )  ;  gb . alleles ( original diploid alleles . stream (  )  . map ( alleles to keep::get )  . collect (  collectors . to list (  )  )  )  ;   }  if  ( g . hasad (  )  )   {  final int[] oldad = g . getad (  )  ;  final int[] newad =  int stream . range ( 0 alleles to keep . size (  )  )  . map ( n  -  >  oldad[alleles index[n]] )  . to array (  )  ;  gb . ad ( newad )  ;   }  newg ts . add ( gb . make (  )  )  ;   }  return newg ts ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AlleleSubsettingUtils.java,subsetvc to match snp,public static  variant context   ( final  variant context ctx final  snp snp )  {  if  ( ctx . is filtered (  )  )  return null ;  if  ( ctx . get reference (  )  . length (  )   !  =  1 )  return null ;  final  optional <  byte >  reference allele maybe =  stream . of ( snp . get allele1 (  )  snp . get allele2 (  )  )  . filter ( b  -  >   string util . to upper case ( b )   =  =   string util . to upper case ( ctx . get reference (  )  . get bases (  ) [0] )  )  . find any (  )  ;  if  (  ! reference allele maybe . is present (  )  )  return null ;  final byte ref allele = reference allele maybe . get (  )  ;  final byte other allele = snp . get allele1 (  )   =  =  ref allele  ?  snp . get allele2 (  )  : snp . get allele1 (  )  ;  final  optional <  allele >  alt allele maybe = ctx . get alternate alleles (  )  . stream (  )  . filter ( a  -  >  a . length (  )   =  =  1 &&  string util . to upper case ( a . get bases (  ) [0] )   =  =   string util . to upper case ( other allele )  )  . find any (  )  ;  if  ( alt allele maybe . is present (  )  )   {  if  ( ctx . is biallelic (  )  )  return ctx ;  return  allele subsetting utils . subset alleles ( ctx  arrays . as list ( ctx . get reference (  )  alt allele maybe . get (  )  )  )  ;   }  final  optional <  allele >  non ref allele maybe = ctx . get alternate alleles (  )  . stream (  )  . filter ( a  -  >  a . equals ( non   ref   allele )  )  . find any (  )  ;  if  ( non ref allele maybe . is present (  )  )   {  final  variant context vc subsetted = ctx . is biallelic (  )   ?  ctx :  allele subsetting utils . subset alleles ( ctx  arrays . as list ( ctx . get reference (  )  non ref allele maybe . get (  )  )  )  ;  return  allele subsetting utils . swap alleles ( vc subsetted non   ref   allele  allele . create ( other allele )  )  ;   }  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AlleleSubsettingUtils.java,subsettedpl indices,public static int[]   ( final  list <  allele >  original alleles final  list <  allele >  new alleles )  {  final int[] result = new int[ genotype likelihoods . num likelihoods ( new alleles . size (  )  2 ) ] ;  for  ( int oldpl index = 0 ;  oldpl index  <   genotype likelihoods . num likelihoods ( original alleles . size (  )  2 )  ;  oldpl index +  +  )   {  final  genotype likelihoods .  genotype likelihoods allele pair allele pair frompl index =  genotype likelihoods . get allele pair ( oldpl index )  ;  final  allele allele1 = original alleles . get ( allele pair frompl index . allele index1 )  ;  final  allele allele2 = original alleles . get ( allele pair frompl index . allele index2 )  ;  final boolean contains only new alleles = new alleles . contains ( allele1 )  && new alleles . contains ( allele2 )  ;  if  ( contains only new alleles )   {  final int newpl index =  genotype likelihoods . calculatep lindex ( new alleles . index of ( allele1 )  new alleles . index of ( allele2 )  )  ;  result[newpl index] = oldpl index ;   }   }  return result ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AlleleSubsettingUtils.java,swap alleles,"public static  variant context   ( final  variant context original vc final  allele old allele final  allele new allele )  throws  illegal argument exception  {  if  (  ! original vc . get alleles (  )  . contains ( old allele )  )  throw new  illegal argument exception ( "" couldn't find allele ""  +  old allele  +  "" in  variant context "" +  original vc )  ;  final  list <  allele >  alleles = new  array list <  >  ( original vc . get alleles (  )  )  ;  alleles . set ( alleles . index of ( old allele )  new allele )  ;   variant context builder vc builder = new  variant context builder ( original vc )  . alleles ( alleles )  ;   genotypes context newg ts =  genotypes context . create ( original vc . get genotypes (  )  . size (  )  )  ;  for  (  final  genotype g : original vc . get genotypes (  )  )   {  if  (  ! g . get alleles (  )  . contains ( old allele )  )   {  newg ts . add ( g )  ;   }  else  {  final  genotype builder gb = new  genotype builder ( g )  ;  gb . alleles ( g . get alleles (  )  . stream (  )  . map ( a  -  >  a . equals ( old allele )   ?  new allele : a )  . collect (  collectors . to list (  )  )  )  ;  newg ts . add ( gb . make (  )  )  ;   }   }  vc builder . genotypes ( newg ts )  ;  return vc builder . make (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\AlleleSubsettingUtils.java,validate true,private static void   ( final boolean condition final  string msg )  {  if  (  ! condition )   {  throw new  illegal argument exception ( msg )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\BaitDesigner.java, bait,public   ( final  string sequence final int start final int end final boolean negative final  string name )  {  super ( sequence start end negative name )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\BaitDesigner.java,add bases,public void   ( final  reference sequence reference final boolean use strand info )  {  final byte[] tmp = new byte[length (  ) ] ;   system . arraycopy ( reference . get bases (  )  get start (  )   -  1 tmp 0 length (  )  )  ;  if  ( use strand info && is negative strand (  )  )   {   sequence util . reverse complement ( tmp )  ;   }  set bases ( tmp )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\BaitDesigner.java,calculate statistics,void   ( final  interval list targets final  interval list baits )  {  this . target   territory =  ( int ) targets . get unique base count (  )  ;  this . target   count = targets . size (  )  ;  this . bait   territory =  ( int ) baits . get unique base count (  )  ;  this . bait   count = baits . size (  )  ;  this . design   efficiency = this . target   territory  /   ( double ) this . bait   territory ;  final  interval list tmp = new  interval list ( targets . get header (  )  )  ;  final  overlap detector <  interval >  detector = new  overlap detector <  interval >  ( 0 0 )  ;  detector . add all ( baits . get intervals (  )  baits . get intervals (  )  )  ;  for  (  final  interval target : targets )   {  final  collection <  interval >  overlaps = detector . get overlaps ( target )  ;  if  ( overlaps . is empty (  )  )   {  this . zero   bait   targets +  +  ;   }  else  {  for  (  final  interval i : overlaps )  tmp . add ( target . intersect ( i )  )  ;   }   }  tmp . uniqued (  )  ;  this . bait   target   territory   intersection =  ( int ) tmp . get base count (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\BaitDesigner.java,custom command line validation,"@ override protected  string[]   (  )  {  final  list <  string >  errors = new  array list <  string >  (  )  ;  final  pattern p =  pattern . compile ( ""^[acg tacgt]*$"" )  ;  if  ( left   primer  !  =  null &&  ! p . matcher ( left   primer )  . matches"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\BasicInputParser.java, basic input parser,public   ( final boolean treat grouped delimiters as one final int word count final  file .  .  .  files )  {  this ( treat grouped delimiters as one files )  ;  set word count ( word count )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\BasicInputParser.java,advance file,protected void   (  )  {  current file name =  ! file names . is empty (  )   ?  file names . remove ( 0 )  : null ;  next line number = 0 ;  next line = null ;  reader = new  buffered line reader ( inputs . remove ( 0 )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\BasicInputParser.java,close,public void   (  )  {  if  ( reader  !  =  null )   {  reader . close (  )  ;   }  for  (  final  input stream stream : inputs )   {   closer util . close ( stream )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\BasicInputParser.java,files to input streams,private static  input stream[]   ( final  file[] files )  {  final  input stream[] result = new  input stream[files . length] ;  for  ( int i = 0 ;  i  <  files . length ;  i +  +  )   {  result[i] = io util . open file for reading ( files[i] )  ;   }  return result ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\BasicInputParser.java,get current line,public  string   (  )  {  return this . current line ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\BasicInputParser.java,get current line number,public int   (  )  {  return current line number ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\BasicInputParser.java,get file name,"public  string   (  )  {  return this . current file name  !  =  null  ?  this . current file name : "" ( file name unavailable ) "" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\BasicInputParser.java,read next line,"protected byte[]   (  )  {  try  {  final  string line = reader . read line (  )  ;  if  ( next line  !  =  null &&  ! is comment ( next line . get bytes (  )  )  )   {  current line number = next line number ;  current line = next line ;   }  if  ( line  !  =  null )   {  next line number +  +  ;  next line = line ;  return line . get bytes (  )  ;   }  if  (  ! inputs . is empty (  )  )   {  advance file (  )  ;  return read next line (  )  ;   }  return null ;   }  catch  (   runtimeio exception ioe )   {  throw new  picard exception ( "" error reading from file ""  +  current file name ioe )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\CsvInputParser.java, csv input parser,public   ( final boolean treat grouped delimiters as one final  file .  .  .  file )  {  super ( treat grouped delimiters as one file )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\CsvInputParser.java,is delimiter,@ override protected boolean   ( final byte b )  {  return b  =  =  ' ' ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\ClippingUtility.java,adapter trim illumina paired reads,public static  adapter pair   ( final sam record read1 final sam record read2 final int min match bases final double max error rate final  adapter pair .  .  .  adapters )  {   adapter pair matched = null ;  for  (  final  adapter pair adapter pair : adapters )   {  final int index1 = find index of clip sequence ( get read bases ( read1 )  adapter pair . get3 prime adapter bytes (  )  min match bases max error rate )  ;  final int index2 = find index of clip sequence ( get read bases ( read2 )  adapter pair . get5 prime adapter bytes in read order (  )  min match bases max error rate )  ;  if  ( index1  =  =  index2 )   {  if  ( index1  !  =  no   match )   {  read1 . set attribute (  reserved tag constants . xt index1  +  1 )  ;  read2 . set attribute (  reserved tag constants . xt index2  +  1 )  ;  return adapter pair ;   }  else  {   }   }  else if  ( index1  =  =  no   match || index2  =  =  no   match )   {  if  ( attempt one sided match ( read1 read2 index1 index2 2 * min match bases )  )   {  matched = adapter pair ;   }   }  else  {   }   }  return matched ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\ClippingUtility.java,adapter trim illumina single read,public static  adapter pair   ( final sam record read final int min match bases final double max error rate final  adapter pair .  .  .  adapters )  {  for  (   adapter pair adapter : adapters )   {  final int index of adapter sequence = find index of clip sequence ( get read bases ( read )  adapter . get3 prime adapter bytes (  )  min match bases max error rate )  ;  if  ( index of adapter sequence  !  =  no   match )   {  read . set attribute (  reserved tag constants . xt index of adapter sequence  +  1 )  ;  return adapter ;   }   }  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\ClippingUtility.java,attempt one sided match,private static boolean   ( final sam record read1 final sam record read2 final int index1 final int index2 final int stricter min match bases )  {  final int matched index = index1  =  =  no   match  ?  index2 : index1 ;  final sam record matched read = index1  =  =  no   match  ?  read2 : read1 ;  if  ( matched read . get read length (  )   -  matched index  >  =  stricter min match bases )   {  if  ( read1 . get read bases (  )  . length  >  matched index )   {  read1 . set attribute (  reserved tag constants . xt matched index  +  1 )  ;   }  if  ( read2 . get read bases (  )  . length  >  matched index )   {  read2 . set attribute (  reserved tag constants . xt matched index  +  1 )  ;   }  return true ;   }  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\ClippingUtility.java,find index of clip sequence,public static int   ( final byte[] read final byte[] adapter sequence final int min match final double max error rate )  {  if  ( read  =  =  null || read . length  <  min match )  return no   match ;  final int min clip position = 0 ;  read   loop: for  ( int start = read . length  -  min match ;  start  >  min clip position  -  1 ;   -  - start )   {  final int length =  math . min ( read . length  -  start adapter sequence . length )  ;  final int mismatches allowed =  ( int )  ( length * max error rate )  ;  int mismatches = 0 ;  for  ( int i = 0 ;  i  <  length ;   +  + i )   {  if  (  !  sequence util . is no call ( adapter sequence[i] )  &&  !  sequence util . bases equal ( adapter sequence[i] read[start  +  i] )  &&  +  + mismatches  >  mismatches allowed )   {  continue read   loop ;   }   }  return start ;   }  return no   match ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\ClippingUtility.java,get read bases,private static byte[]   ( final sam record read )  {  if  (  ! read . get read negative strand flag (  )  )   {  return read . get read bases (  )  ;   }  else  {  final byte[] reverse complemented bases = new byte[read . get read bases (  )  . length] ;   system . arraycopy ( read . get read bases (  )  0 reverse complemented bases 0 reverse complemented bases . length )  ;   sequence util . reverse complement ( reverse complemented bases )  ;  return reverse complemented bases ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\CircularByteBuffer.java, circular byte buffer,public   ( final int size )  {  this . bytes = new byte[size] ;  this . capacity = this . bytes . length ;  this . bytes available to write = this . capacity ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\CircularByteBuffer.java,close,synchronized public void   (  )  {  this . closed = true ;  notify (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\CircularByteBuffer.java,get bytes available to read,synchronized public int   (  )  {  return this . bytes available to read ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\CircularByteBuffer.java,get capacity,public int   (  )  {  return this . capacity ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\CircularByteBuffer.java,is closed,synchronized public boolean   (  )  {  return this . closed ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\CircularByteBuffer.java,read,"synchronized public int   ( final byte[] bytes final int start final int size )  {  try  {  if  ( this . bytes available to read  =  =  0 &&  ! closed )  wait (  )  ;   }  catch  (  final  interrupted exception ie )   {  throw new  picard exception ( "" interrupted while waiting to read from fifo . "" ie )  ;   }  final int read pos = this . next read pos ;  final int distance to end = this . capacity  -  read pos ;  final int available = distance to end  <  this . bytes available to read  ?  distance to end : this . bytes available to read ;  final int length = available  <  size  ?  available : size ;   system . arraycopy ( this . bytes read pos bytes start length )  ;  this . bytes available to read -  = length ;  this . bytes available to write +  = length ;  this . next read pos =  ( read pos  +  length )  % this . capacity ;  notify (  )  ;  return length ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\CircularByteBuffer.java,write,"synchronized public int   ( final byte[] bytes final int start final int size )  {  if  ( closed )  throw new  illegal state exception ( "" cannot write to closed buffer . "" )  ;  try  {  if  ( this . bytes available to write  =  =  0 )  wait (  )  ;   }  catch  (  final  interrupted exception ie )   {  throw new  picard exception ( "" interrupted while waiting to write to fifo . "" ie )  ;   }  final int write pos = this . next write pos ;  final int distance to end = this . capacity  -  write pos ;  final int available = distance to end  <  this . bytes available to write  ?  distance to end : this . bytes available to write ;  final int length = available  <  size  ?  available : size ;   system . arraycopy ( bytes start this . bytes write pos length )  ;  this . bytes available to write -  = length ;  this . bytes available to read +  = length ;  this . next write pos =  ( write pos  +  length )  % this . capacity ;  notify (  )  ;  return length ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\BedToIntervalList.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is readable ( sequence   dictionary )  ;  io util . assert file is writable ( output )  ;  try  {  final sam file header header = new sam file header
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\BedToIntervalList.java,main,public static void   ( final  string[] args )  {  new  bed to interval list (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DbSnpBitSetUtil.java, db snp bit set util,"public   ( final  file db snp file final sam sequence dictionary sequence dictionary final  collection <  variant type >  variants to match final  interval list intervals final  optional <  log >  log )  {  if  ( db snp file  =  =  null )  throw new  illegal argument exception ( ""null db snp file"" )  ;  final  map <  db snp bit set util  set <  variant type >  >  tmp = new  hash map <  >  (  )  ;  tmp . put ( this  enum set . copy of ( variants to match )  )  ;  load vcf ( db snp file sequence dictionary tmp intervals log )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DbSnpBitSetUtil.java,create snp and indel bit sets,public static  db snp bit sets   ( final  file db snp file final sam sequence dictionary sequence dictionary final  interval list intervals final  optional <  log >  log )  {  final  db snp bit sets sets = new  db snp bit sets (  )  ;  sets . snps = new  db snp bit set util (  )  ;  sets . indels = new  db snp bit set util (  )  ;  final  map <  db snp bit set util  set <  variant type >  >  map = new  hash map <  >  (  )  ;  map . put ( sets . snps  enum set . of (  variant type . snp )  )  ;  map . put ( sets . indels  enum set . of (  variant type . insertion  variant type . deletion )  )  ;  load vcf ( db snp file sequence dictionary map intervals log )  ;  return sets ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DbSnpBitSetUtil.java,is db snp site,public boolean   ( final  string sequence name final int pos )  {  return sequence to bit set . get ( sequence name )   !  =  null && pos  <  =  sequence to bit set . get ( sequence name )  . length (  )  && sequence to bit set . get ( sequence name )  . get ( pos )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DbSnpBitSetUtil.java,load vcf,"private static void   ( final  file db snp file final sam sequence dictionary sequence dictionary final  map <  db snp bit set util  set <  variant type >  >  bit sets to variant types final  interval list intervals final  optional <  log >  log )  {  final  optional <  progress logger >  progress = log . map ( l  -  >  new  progress logger ( l  ( int ) 1e5 "" read"" ""variants"" )  )  ;  final vcf file reader variant reader = new vcf file reader ( db snp file intervals  !  =  null )  ;  final  iterator <  variant context >  variant iterator ;  if  ( intervals  !  =  null )   {  variant iterator = new  by interval list variant context iterator ( variant reader intervals )  ;   }  else  {  variant iterator = variant reader . iterator (  )  ;   }  while  ( variant iterator . has next (  )  )   {  final  variant context kv = variant iterator . next (  )  ;  for  (  final  map .  entry <  db snp bit set util  set <  variant type >  >  tuple : bit sets to variant types . entry set (  )  )   {  final  db snp bit set util bitset = tuple . get key (  )  ;  final  set <  variant type >  variants to match = tuple . get value (  )  ;   bit set bits = bitset . sequence to bit set . get ( kv . get contig (  )  )  ;  if  ( bits  =  =  null )   {  final int n bits ;  if  ( sequence dictionary  =  =  null )  n bits = kv . get end (  )   +  1 ;  else n bits = sequence dictionary . get sequence ( kv . get contig (  )  )  . get sequence length (  )   +  1 ;  bits = new  bit set ( n bits )  ;  bitset . sequence to bit set . put ( kv . get contig (  )  bits )  ;   }  if  ( variants to match . is empty (  )  ||  ( kv . issnp (  )  && variants to match . contains (  variant type . snp )  )  ||  ( kv . is indel (  )  && variants to match . contains (  variant type . insertion )  ) ||  ( kv . is indel (  )  && variants to match . contains (  variant type . deletion )  )  )   {  for  ( int i = kv . get start (  )  ;  i  <  =  kv . get end (  )  ;  i +  +  )  bits . set ( i true )  ;   }   }  progress . map ( p  -  >  p . record ( kv . get contig (  )  kv . get start (  )  )  )  ;   }   closer util . close ( variant reader )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DelimitedTextFileWithHeaderIterator.java, delimited text file with header iterator,"public   ( final  basic input parser parser )  {  this . parser = parser ;  if  (  ! parser . has next (  )  )   {  throw new  picard exception ( "" no header line found in file ""  +  parser . get file name (  )  )  ;   }  final  string[] column labels = parser . next (  )  ;  for  ( int i = 0 ;  i  <  column labels . length ;   +  + i )   {  column label indices . put ( column labels[i] i )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DelimitedTextFileWithHeaderIterator.java, row,  ( final  string[] fields final  string source )  {  this . fields = fields ;  this . current line = source ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DelimitedTextFileWithHeaderIterator.java,close,@ override public void   (  )  {  parser . close (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DelimitedTextFileWithHeaderIterator.java,column labels,public  set <  string >    (  )  {  return column label indices . key set (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DelimitedTextFileWithHeaderIterator.java,get column names,public  set <  string >    (  )  {  return  collections . unmodifiable set ( this . column label indices . key set (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DelimitedTextFileWithHeaderIterator.java,get current line,public  string   (  )  {  return this . current line ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DelimitedTextFileWithHeaderIterator.java,get current line number,public int   (  )  {  return parser . get current line number (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DelimitedTextFileWithHeaderIterator.java,get field,"public  string   ( final  string column label )  {  final  integer key = column label indices . get ( column label )  ;  if  ( key  =  =  null )  throw new  no such element exception (  string . format ( ""column %s in %s"" column label parser . get file name (  )  )  )  ;  return fields[key] ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DelimitedTextFileWithHeaderIterator.java,get fields,public  string[]   (  )  {  return fields ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DelimitedTextFileWithHeaderIterator.java,get integer field,public  integer   ( final  string column label )  {  if  ( fields[column label indices . get ( column label ) ]  =  =  null )  return null ;  return  integer . parse int ( fields[column label indices . get ( column label ) ] )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DelimitedTextFileWithHeaderIterator.java,has column,public boolean   ( final  string column label )  {  return column label indices . contains key ( column label )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DelimitedTextFileWithHeaderIterator.java,has next,@ override public boolean   (  )  {  return parser . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DelimitedTextFileWithHeaderIterator.java,next,@ override public  row   (  )  {  final  string[] fields = parser . next (  )  ;  final  string source = parser . get current line (  )  ;  return new  row ( fields source )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\DelimitedTextFileWithHeaderIterator.java,remove,@ override public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\FifoBuffer.java, fifo buffer,public   (  )  {  this (  system . in  system . out )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\FifoBuffer.java,do work,@ override protected int   (  )  {  final  circular byte buffer fifo = new  circular byte buffer ( buffer   size )  ;  final  thread input = new  thread ( new  runnable (  )  {  @ override public void run (  )  {  try  {  final byte[] buffer = new byte[io
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\FifoBuffer.java,main,public static void   ( final  string[] args )  {  new  fifo buffer (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\FifoBuffer.java,run,"@ override public void   (  )  {  final  number format p fmt =  number format . get percent instance (  )  ;  final  number format i fmt = new  decimal format ( ""# ##0"" )  ;  while  ( true )   {  final int capacity = fifo . get capacity (  )  ;  final int"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\FifoBuffer.java,uncaught exception,"@ override public void   ( final  thread t final  throwable e )  {  this . throwable = e ;  log . error ( e "" exception caught on thread "" t . get name (  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\GraphUtils.java, graph,public   (  )  {  nodes = new  array list <  >  (  )  ;  neighbors = new  array list <  >  (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\GraphUtils.java,add edge,public void   (  node left  node right )  {  final int left index = add node ( left )  ;  if  ( left  =  =  right )  return ;  final int right index = add node ( right )  ;  add neighbor ( left index right index )  ;  add neighbor ( right index left index )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\GraphUtils.java,add neighbor,private void   ( final  integer from node final  integer to node )  {  final  list <  integer >  from nodes neighbors = neighbors . get ( from node )  ;  if  (  ! from nodes neighbors . contains ( to node )  )   {  from nodes neighbors . add ( to node )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\GraphUtils.java,add node,public  integer   ( final  node singleton )  {  if  (  ! nodes . contains ( singleton )  )   {  nodes . add ( singleton )  ;  neighbors . add ( new  array list <  >  (  )  )  ;   }  return nodes . index of ( singleton )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\GraphUtils.java,cluster,public  map <  node  integer >    (  )  {  final int[] cluster =  int stream . range ( 0 nodes . size (  )  )  . to array (  )  ;   int stream . range ( 0 neighbors . size (  )  )  . for each ( i  -  >  neighbors . get ( i )  . stream (  )  . for each ( j  -  >  join nodes ( cluster j i )  )  )  ;  return nodes . stream (  )  . collect (  collectors . to map ( n  -  >  n n  -  >  cluster[nodes . index of ( n ) ] )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\GraphUtils.java,find rep node,private static int   ( final int[] grouping int node id )  {  int representative umi = node id ;  while  ( representative umi  !  =  grouping[representative umi] )   {  representative umi = grouping[representative umi] ;   }  while  ( node id  !  =  representative umi )   {  int new umiid = grouping[node id] ;  grouping[node id] = representative umi ;  node id = new umiid ;   }  return representative umi ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\GraphUtils.java,join nodes,private static void   ( int[] grouping final int node id1 final int node id2 )  {  final int rep node1 = find rep node ( grouping node id1 )  ;  final int rep node2 = find rep node ( grouping node id2 )  ;  if  ( rep node1  =  =  rep node2 )  return ;  grouping[rep node1] = rep node2 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\help\HelpConstants.java,get super category map,public static  map <  string  string >    (  )  {  if  ( group to super category  =  =  null )   {  group to super category = new  hash map <  >  (  )  ;  group to super category . put ( doc   cat   base   calling doc   supercat   tools )  ;  group to super category . put ( doc   cat   diagnostics   and   qc doc   supercat   tools )  ;  group to super category . put ( doc   cat   intervals   manipulation doc   supercat   tools )  ;  group to super category . put ( doc   cat   other doc   supercat   tools )  ;  group to super category . put ( doc   cat   read   data   manipulation doc   supercat   tools )  ;  group to super category . put ( doc   cat   reference doc   supercat   tools )  ;  group to super category . put ( doc   cat   read   data   manipulation doc   supercat   tools )  ;  group to super category . put ( doc   cat   variant   filtering doc   supercat   tools )  ;  group to super category . put ( doc   cat   variant   evaluation doc   supercat   tools )  ;  group to super category . put ( doc   cat   variant   manipulation doc   supercat   tools )  ;  group to super category . put ( doc   cat   test doc   supercat   exclude )  ;   }  return group to super category ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\help\HelpConstants.java,get super category property,"public static  string   ( final  string group name )  {  return get super category map (  )  . get or default ( group name ""other"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\help\PicardHelpDoclet.java,create work unit,@ override protected  doc work unit   ( final  documented feature documented feature final  class doc class doc final  class <  ?  >  clazz )  {  return new  doc work unit ( new  picard help doc work unit handler ( this )  documented feature class doc cla
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\help\PicardHelpDoclet.java,get group map,"@ override protected final  map <  string  string >    ( final  doc work unit doc work unit )  {  final  map <  string  string >  root = super . get group map ( doc work unit )  ;  root . put ( ""supercat""  help constants . get super category property ( do"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\help\PicardHelpDoclet.java,get index template name,@ override public  string   (  )  {  return picard   freemarker   index   template   name ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\help\PicardHelpDoclet.java,start,public static boolean   ( final  root doc root doc )  throws io exception  {  return new picard . util . help .  picard help doclet (  )  . start process docs ( root doc )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\help\PicardHelpDocWorkUnitHandler.java, picard help doc work unit handler,public   ( final  help doclet doclet )  {  super ( doclet )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\help\PicardHelpDocWorkUnitHandler.java,get tag filter prefix,@ override protected  string   (  )  {  return picard   javadoc   tag   prefix ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\help\PicardHelpDocWorkUnitHandler.java,get template name,@ override public  string   ( final  doc work unit work unit )  {  return picard   freemarker   template   name ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IlluminaUtil.java, illumina adapter pair,private   ( final  string five prime final  string three prime )  {  this . three prime = three prime ;  this . three prime bytes =  string util . string to bytes ( three prime )  ;  this . five prime = five prime ;  this . five prime read order =  sequence util . reverse complement ( five prime )  ;  this . five prime bytes =  string util . string to bytes ( five prime )  ;  this . five prime read order bytes =  string util . string to bytes ( five prime read order )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IlluminaUtil.java,barcode seqs to string,public static  string   ( final byte[][] barcodes )  {  return byte array to string ( barcodes barcode   delimiter )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IlluminaUtil.java,byte array to string,public static  string   ( final byte[][] barcodes  string delim )  {  final  string[] bcs = new  string[barcodes . length] ;  for  ( int i = 0 ;  i  <  barcodes . length ;  i +  +  )   {  bcs[i] =  string util . bytes to string ( barcodes[i] )  ;   }  return string seqs to string ( bcs delim )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IlluminaUtil.java,convert solexa quality ascii          to phred binary,public static void   ( final byte[] solexa qualities )  {   solexa quality converter . get singleton (  )  . convert solexa quality chars to phred binary ( solexa qualities )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IlluminaUtil.java,get prime adapter,public  string   (  )  {  return three prime ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IlluminaUtil.java,get prime adapter bytes,public byte[]   (  )  {  return three prime bytes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IlluminaUtil.java,get prime adapter bytes in read order,public byte[]   (  )  {  return three prime bytes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IlluminaUtil.java,get prime adapter in read order,public  string   (  )  {  return three prime ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IlluminaUtil.java,get prime adapter,public  string   (  )  {  return five prime ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IlluminaUtil.java,get prime adapter bytes,public byte[]   (  )  {  return five prime bytes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IlluminaUtil.java,get prime adapter bytes in read order,public byte[]   (  )  {  return five prime read order bytes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IlluminaUtil.java,get prime adapter in read order,public  string   (  )  {  return five prime read order ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IlluminaUtil.java,get name,public  string   (  )  {  return this . name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IlluminaUtil.java,get solexa quality char from four qualities,"public static byte   ( final  string[] qualities final int cycle number final  format util formatter )  {  int best quality =  integer . min   value ;  final int start offset =  ( cycle number  -  1 )  * 4 ;  for  ( int i = start offset ;  i  <  start offset  +  4 ;   +  + i )   {  final int quality = formatter . parse int ( qualities[i] )  ;  if  ( quality  >  best quality )   {  best quality = quality ;   }   }  final int quality as character = best quality  +   solexa quality converter . solexa   addend ;  if  ( quality as character  >  255 )   {  throw new  picard exception ( "" quality too large: ""  +  best quality )  ;   }  return  ( byte )  ( quality as character & 0xff )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IlluminaUtil.java,get tile from read name,public static  integer   ( final  string read name )  {  final int first = read name . index of ( ':' )  ;  if  ( first  >  0 )   {  final int second = read name . index of ( ':' first  +  1 )  ;  if  ( second  >  0 )   {  final int third = read name . index of ( ':' second  +  1 )  ;  if  ( third  >  0 )   {  return  integer . parse int ( read name . substring ( second  +  1 third )  )  ;   }   }   }  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IlluminaUtil.java,make phred binary from solexa quality ascii      ,public static byte[]   ( final  string solexa qualities final int offset final int length )  {  final byte[] quals =  string util . string to bytes ( solexa qualities offset length )  ;   solexa quality converter . get singleton (  )  . convert solexa   1   3    quality chars to phred binary ( quals )  ;  return quals ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IlluminaUtil.java,string seqs to string,public static  string   ( final  string[] barcodes  string delim )  {  final  string builder sb = new  string builder (  )  ;  for  (  final  string bc : barcodes )   {  if  ( sb . length (  )   >  0 )  sb . append ( delim )  ;  sb . append ( bc )  ;   }  return sb . to string (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IntervalListScatterer.java, interval list scatterer,public   ( final  mode mode )  {  this . mode = mode ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IntervalListScatterer.java,deduce ideal split length,private int   ( final  interval list uniqued list final int scatter count )  {  final int split width =  math . max (  ( int )  math . floor ( uniqued list . get base count (  )   /   ( 1 . 0 * scatter count )  )  1 )  ;  switch  ( mode )   {  case interval   subdivision: return split width ;  case balancing   without   interval   subdivision: case balancing   without   interval   subdivision   with   overflow: final int widest interval length =  collections . max ( uniqued list . get intervals (  )   ( o1 o2 )   -  >   integer . value of ( o1 . length (  )  )  . compare to ( o2 . length (  )  )  )  . length (  )  ;  return  math . max ( widest interval length split width )  ;  default : throw new  illegal state exception (  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IntervalListScatterer.java,scatter,"public  list <  interval list >    ( final  interval list source interval list final int scatter count final boolean is uniqued )  {  if  ( scatter count  <  1 )  throw new  illegal argument exception ( ""scatter count  <  1"" )  ;  final  interval list uniqued list = is uniqued  ?  source interval list : source interval list . uniqued (  )  ;  final long ideal split length = deduce ideal split length ( uniqued list scatter count )  ;   system . err . println ( ""ideal split length = ""  +  ideal split length )  ;  final  list <  interval list >  accumulated interval lists = new  array list <  >  (  )  ;   interval list running interval list = new  interval list ( uniqued list . get header (  )  )  ;  final  array deque <  interval >  interval queue = new  array deque <  >  ( uniqued list . get intervals (  )  )  ;  long num bases left = uniqued list . get base count (  )  ;  while  (  ! interval queue . is empty (  )  && accumulated interval lists . size (  )   <  scatter count  -  1 )   {  final  interval interval = interval queue . poll first (  )  ;  final long projected size = running interval list . get base count (  )   +  interval . length (  )  ;  final double projected size of remaining divisions =  ( num bases left  -  running interval list . get base count (  )  )   /   (  ( double )  ( scatter count  -  accumulated interval lists . size (  )   -  1 )  )  ;  if  ( should add to running interval list ( ideal split length projected size projected size of remaining divisions )  )   {  running interval list . add ( interval )  ;   }  else  {  switch  ( mode )   {  case interval   subdivision: final int amount to consume =  ( int )  ( ideal split length  -  running interval list . get base count (  )  )  ;  final  interval left = new  interval ( interval . get contig (  )  interval . get start (  )  interval . get start (  )   +  amount to consume  -  1 interval . is negative strand (  )  interval . get name (  )  )  ;  final  interval right = new  interval ( interval . get contig (  )  interval . get start (  )   +  amount to consume interval . get end (  )  interval . is negative strand (  )  interval . get name (  )  )  ;  running interval list . add ( left )  ;  interval queue . add first ( right )  ;  break ;  case balancing   without   interval   subdivision: case balancing   without   interval   subdivision   with   overflow: if  ( running interval list . get intervals (  )  . is empty (  )  )   {  running interval list . add ( interval )  ;   }  else  {  interval queue . add first ( interval )  ;  num bases left -  = running interval list . get base count (  )  ;  accumulated interval lists . add ( running interval list . uniqued (  )  )  ;  running interval list = new  interval list ( uniqued list . get header (  )  )  ;   }  break ;   }   }  if  ( running interval list . get base count (  )   >  =  ideal split length )   {  num bases left -  = running interval list . get base count (  )  ;  accumulated interval lists . add ( running interval list . uniqued (  )  )  ;  running interval list = new  interval list ( uniqued list . get header (  )  )  ;   }   }  while  (  ! interval queue . is empty (  )  )   {  running interval list . add ( interval queue . poll first (  )  )  ;   }  if  (  ! running interval list . get intervals (  )  . is empty (  )  )   {  accumulated interval lists . add ( running interval list . uniqued (  )  )  ;   }  long maximum interval size =  - 1  minimum interval size =  integer . max   value ;  for  ( final  interval list interval list : accumulated interval lists )   {  final long base count = interval list . get base count (  )  ;  if  ( base count  <  minimum interval size )  minimum interval size = base count ;  if  ( maximum interval size  <  base count )  maximum interval size = base count ;   }  return accumulated interval lists ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IntervalListScatterer.java,should add to running interval list,private boolean   ( final long ideal split length final long projected size final double projected size of remaining divisions )  {  switch  ( mode )   {  case balancing   without   interval   subdivision   with   overflow: return  ( projected size  <  =  ideal split length || ideal split length  <  projected size of remaining divisions )  ;  default : return  ( projected size  <  =  ideal split length )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IntervalListToBed.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;   interval list intervals =  interval list . from file ( input )  ;  if  ( sort )  intervals = intervals . sorted (  )  ;  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\Iterators.java,atomic iterator of,public static  < e >  atomic iterator < e >    ( final  iterator < e >  backing iterator )  {  final  object monitor = new  object (  )  ;  return  (  )   -  >   {  synchronized  ( monitor )   {  return backing iterator . has next (  )   ?   optional . of nullable ( backing iterator . next (  )  )  :  optional . empty (  )  ;   }   }   ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IntervalListTools.java, action,  ( final  string helpdoc boolean takes second input )  {  this . helpdoc = helpdoc ;  this . takes second input = takes second input ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\IntervalListTools.java, interval list input type,  ( final  collection <  string >  extensions )  {  applicable extensions = extensions ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\LiftOverIntervalList.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is readable ( sequence   dictionary )  ;  io util . assert file is readable ( chain )  ;  io util . assert file is writable ( output )  ;  if  ( reje
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\LiftoverUtils.java,alleles to string list,protected static  list <  string >    ( final  list <  allele >  alleles )  {  final  list <  string >  ret = new  array list <  >  (  )  ;  alleles . for each ( a  -  >  ret . add ( a . is no call (  )   ?   allele . no   call   string : a . get display string (  )  )  )  ;  return ret ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\LiftoverUtils.java,extend one base,private static byte[]   ( final byte[] bases final byte base )  {  final byte[] new bases = new byte[bases . length  +  1] ;   system . arraycopy ( bases 0 new bases 1 bases . length )  ;  new bases[0] = base ;  return new bases ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\LiftoverUtils.java,fix genotypes,"protected static  genotypes context   ( final  genotypes context originals final  list <  allele >  original alleles final  list <  allele >  new alleles )  {  if  ( original alleles . equals ( new alleles )  )   {  return originals ;   }  if  ( original alleles . size (  )   !  =  new alleles . size (  )  )   {  throw new  illegal state exception ( "" error in allele lists: the original and new allele lists are not the same length: ""  +  original alleles . to string (  )   +  ""  /  "" +  new alleles . to string (  )  )  ;   }  final  map <  allele  allele >  allele map = new  hash map <  >  (  )  ;  for  ( int idx = 0 ;  idx  <  original alleles . size (  )  ;  idx +  +  )   {  allele map . put ( original alleles . get ( idx )  new alleles . get ( idx )  )  ;   }  final  genotypes context fixed genotypes =  genotypes context . create ( originals . size (  )  )  ;  for  (  final  genotype genotype : originals )   {  final  list <  allele >  fixed alleles = new  array list <  >  (  )  ;  for  (  final  allele allele : genotype . get alleles (  )  )   {  if  ( allele . is no call (  )  )   {  fixed alleles . add ( allele )  ;   }  else  {   allele new allele = allele map . get ( allele )  ;  if  ( new allele  =  =  null )   {  throw new  illegal state exception ( "" allele not found: ""  +  allele . to string (  )   +  ""  "" +  original alleles +  "" /  "" +  new alleles )  ;   }  fixed alleles . add ( new allele )  ;   }   }  fixed genotypes . add ( new  genotype builder ( genotype )  . alleles ( fixed alleles )  . make (  )  )  ;   }  return fixed genotypes ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\LiftoverUtils.java,left align variant,"protected static void   ( final  variant context builder builder final int start final int end final  list <  allele >  alleles final  reference sequence reference sequence )  {  if  (  ! reference allele matches reference for indel ( alleles reference sequence start end )  )   {  throw new  illegal argument exception (  string . format ( "" reference allele doesn't match reference at %s:%d - %d"" reference sequence . get name (  )  start end )  )  ;   }  boolean changes in alleles = true ;  final  map <  allele byte[] >  allele bases map = new  hash map <  >  (  )  ;  alleles . for each ( a  -  >  allele bases map . put ( a a . get bases (  )  )  )  ;  int the start = start ;  int the end = end ;  while  ( changes in alleles )   {  changes in alleles = false ;  if  ( allele bases map . values (  )  . stream (  )  . collect (  collectors . grouping by ( a  -  >  a[a . length  -  1]  collectors . to set (  )  )  )  . size (  )   =  =  1 && the end  >  1 )   {  for  (  final  allele allele : allele bases map . key set (  )  )   {  allele bases map . put ( allele truncate base ( allele bases map . get ( allele )  true )  )  ;   }  changes in alleles = true ;  the end -  -  ;   }  if  ( allele bases map . values (  )  . stream (  )  . map ( a  -  >  a . length )  . any match ( l  -  >  l  =  =  0 )  )   {  for  (  final  allele allele : allele bases map . key set (  )  )   {  final byte extra base =  ( the start  >  1 )   ?  reference sequence . get bases (  ) [the start  -  2] : reference sequence . get bases (  ) [the end] ;  allele bases map . put ( allele extend one base ( allele bases map . get ( allele )  extra base )  )  ;   }  changes in alleles = true ;  the start -  -  ;   }   }  while  ( allele bases map . values (  )  . stream (  )  . all match ( a  -  >  a . length  >  =  2 )  && allele bases map . values (  )  . stream (  )  . collect (  collectors . grouping by ( a  -  >  a[0]  collectors . to set (  )  )  )  . size (  )   =  =  1 )   {  for  (  final  allele allele : allele bases map . key set (  )  )   {  allele bases map . put ( allele truncate base ( allele bases map . get ( allele )  false )  )  ;   }  the start +  +  ;   }  builder . start ( the start )  ;  builder . stop ( the end )  ;  final  map <  allele  allele >  fixed allele map = allele bases map . entry set (  )  . stream (  )  . collect (  collectors . to map (  map .  entry::get key me  -  >   allele . create ( me . get value (  )  me . get key (  )  . is reference (  )  )  )  )  ;   list <  allele >  fixed alleles = alleles . stream (  )  . map ( fixed allele map::get )  . collect (  collectors . to list (  )  )  ;  builder . alleles ( fixed alleles )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\LiftoverUtils.java,lift simple variant context,protected static  variant context builder   (  variant context source  interval target )  {  if  ( target  =  =  null || source . get reference (  )  . length (  )   !  =  target . length (  )  )   {  return null ;   }  final  variant context builder builder = new  variant context builder ( source )  ;  builder . chr ( target . get contig (  )  )  ;  builder . start ( target . get start (  )  )  ;  builder . stop ( target . get end (  )  )  ;  return builder ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\LiftoverUtils.java,lift variant,public static  variant context   ( final  variant context source final  interval target final  reference sequence ref seq final boolean write original position final boolean write original alleles )  {  if  ( target  =  =  null )   {  return null ;   }  final  variant context builder builder ;  if  ( target . is negative strand (  )  )   {  builder = reverse complement variant context ( source target ref seq )  ;   }  else  {  builder = lift simple variant context ( source target )  ;   }  if  ( builder  =  =  null )   {  return null ;   }  builder . filters ( source . get filters (  )  )  ;  builder . log10p error ( source . get log10p error (  )  )  ;  builder . attributes ( source . get attributes (  )  )  ;  builder . rm attribute ( swapped   alleles )  ;  if  ( target . is negative strand (  )  )   {  builder . attribute ( rev   comped   alleles true )  ;   }  else  {  builder . rm attribute ( rev   comped   alleles )  ;   }  builder . id ( source . getid (  )  )  ;  if  ( write original position )   {  builder . attribute (  liftover vcf . original   contig source . get contig (  )  )  ;  builder . attribute (  liftover vcf . original   start source . get start (  )  )  ;   }  if  ( write original alleles &&  ! source . get alleles (  )  . equals ( builder . get alleles (  )  )  )   {  builder . attribute (  liftover vcf . original   alleles alleles to string list ( source . get alleles (  )  )  )  ;   }  return builder . make (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\LiftoverUtils.java,reference allele matches reference for indel,"protected static boolean   ( final  list <  allele >  alleles final  reference sequence reference sequence final int start final int end )  {  final  string ref string =  string util . bytes to string ( reference sequence . get bases (  )  start  -  1 end  -  start  +  1 )  ;  final  allele ref allele = alleles . stream (  )  . filter (  allele::is reference )  . find any (  )  . or else throw (  (  )   -  >  new  illegal state exception ( "" error: no reference allele was present"" )  )  ;  return  ( ref string . equals ignore case ( ref allele . get base string (  )  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\LiftoverUtils.java,reverse complement,private static  allele   ( final  allele old allele final  interval target final  reference sequence reference sequence final boolean is bi allelic indel final boolean add to start )  {  if  ( old allele . is symbolic (  )  || old allele . is no call (  )  )   {  return old allele ;   }  else if  ( is bi allelic indel )   {  final  string builder allele builder = new  string builder ( target . get end (  )   -  target . get start (  )   +  1 )  ;  if  ( add to start )   {  allele builder . append (  ( char ) reference sequence . get bases (  ) [target . get start (  )   -  2] )  ;   }  allele builder . append (  sequence util . reverse complement ( old allele . get base string (  )  . substring ( 1 old allele . length (  )  )  )  )  ;  if  (  ! add to start )   {  allele builder . append (  ( char ) reference sequence . get bases (  ) [target . get end (  )   -  1] )  ;   }  return  allele . create ( allele builder . to string (  )  old allele . is reference (  )  )  ;   }  else  {  return  allele . create (  sequence util . reverse complement ( old allele . get base string (  )  )  old allele . is reference (  )  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\LiftoverUtils.java,reverse complement alleles,private static  list <  allele >    ( final  list <  allele >  original alleles final  interval target final  reference sequence ref seq final boolean is bi allelic indel final boolean add to start )  {  final  list <  allele >  alleles = new  array list <  >  (  )  ;  for  (  final  allele old allele : original alleles )   {  alleles . add (  liftover utils . reverse complement ( old allele target ref seq is bi allelic indel add to start )  )  ;   }  return alleles ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\LiftoverUtils.java,reverse complement variant context,"protected static  variant context builder   ( final  variant context source final  interval target final  reference sequence ref seq )  {  if  ( target . is positive strand (  )  )   {  throw new  illegal argument exception ( "" this should only be called for negative strand liftovers"" )  ;   }  if  ( source . is indel (  )  &&  ! source . is biallelic (  )  )   {  return null ;   }  final  list <  allele >  orig alleles = new  array list <  >  ( source . get alleles (  )  )  ;  final  variant context builder vcb = new  variant context builder ( source )  ;  vcb . chr ( target . get contig (  )  )  ;  final boolean add to start = source . is indel (  )  && target . get start (  )   >  1 ;  final int start = target . get start (  )   -   ( add to start  ?  1 : 0 )  ;  vcb . start ( start )  ;  final int stop = target . get end (  )   -   ( add to start  ?  1 : 0 )  ;  vcb . stop ( stop )  ;  vcb . alleles ( reverse complement alleles ( orig alleles target ref seq source . is indel (  )  add to start )  )  ;  if  ( source . is indel (  )  )   {  if  (  ! reference allele matches reference for indel ( vcb . get alleles (  )  ref seq start stop )  )   {  return null ;   }  left align variant ( vcb start stop vcb . get alleles (  )  ref seq )  ;   }  vcb . genotypes ( fix genotypes ( source . get genotypes (  )  orig alleles vcb . get alleles (  )  )  )  ;  return vcb ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\LiftoverUtils.java,swap ref alt,"public static  variant context   ( final  variant context vc final  collection <  string >  annotations to reverse final  collection <  string >  annotations to drop )  {  if  (  ! vc . is biallelic (  )  ||  ! vc . issnp (  )  )   {  throw new  illegal argument exception ( ""swap ref alt can only process biallelic  snps  found ""  +  vc . to string (  )  )  ;   }  final  variant context builder swapped builder = new  variant context builder ( vc )  ;  swapped builder . attribute ( swapped   alleles true )  ;  swapped builder . alleles (  arrays . as list ( vc . get alleles (  )  . get ( 1 )  . get base string (  )  vc . get alleles (  )  . get ( 0 )  . get base string (  )  )  )  ;  final  map <  allele  allele >  allele map = new  hash map <  >  (  )  ;  allele map . put ( vc . get alleles (  )  . get ( 0 )  swapped builder . get alleles (  )  . get ( 1 )  )  ;  allele map . put ( vc . get alleles (  )  . get ( 1 )  swapped builder . get alleles (  )  . get ( 0 )  )  ;  final  genotypes context swapped genotypes =  genotypes context . create ( vc . get genotypes (  )  . size (  )  )  ;  for  (  final  genotype genotype : vc . get genotypes (  )  )   {  final  list <  allele >  swapped alleles = new  array list <  >  (  )  ;  for  (  final  allele allele : genotype . get alleles (  )  )   {  if  ( allele . is no call (  )  )   {  swapped alleles . add ( allele )  ;   }  else  {  swapped alleles . add ( allele map . get ( allele )  )  ;   }   }  final  genotype builder builder = new  genotype builder ( genotype )  . alleles ( swapped alleles )  ;  if  ( genotype . hasad (  )  && genotype . getad (  )  . length  =  =  2 )   {  final int[] ad =  array utils . clone ( genotype . getad (  )  )  ;   array utils . reverse ( ad )  ;  builder . ad ( ad )  ;   }  else  {  builder . noad (  )  ;   }  if  ( genotype . haspl (  )  && genotype . getpl (  )  . length  =  =  3 )   {  final int[] pl =  array utils . clone ( genotype . getpl (  )  )  ;   array utils . reverse ( pl )  ;  builder . pl ( pl )  ;   }  else  {  builder . nopl (  )  ;   }  swapped genotypes . add ( builder . make (  )  )  ;   }  swapped builder . genotypes ( swapped genotypes )  ;  for  (  final  string key : vc . get attributes (  )  . key set (  )  )   {  if  ( annotations to drop . contains ( key )  )   {  swapped builder . rm attribute ( key )  ;   }  else if  ( annotations to reverse . contains ( key )  &&  ! vc . get attribute as string ( key """" )  . equals ( vcf constants . missing   value   v4 )  )   {  final double attribute to reverse = vc . get attribute as double ( key  - 1 )  ;  if  ( attribute to reverse  <  0 || attribute to reverse  >  1 )   {  log . warn ( "" trying to reverse attribute ""  +  key  +  "" but found value that isn't between 0 and 1:  ( "" +  attribute to reverse +  "" )  in variant "" +  vc +  "" .   results might be wrong . "" )  ;   }  swapped builder . attribute ( key 1  -  attribute to reverse )  ;   }   }  return swapped builder . make (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\LiftoverUtils.java,truncate base,private static byte[]   ( final byte[] allele final boolean truncate rightmost )  {  return  arrays . copy of range ( allele truncate rightmost  ?  0 : 1 truncate rightmost  ?  allele . length  -  1 : allele . length )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java, log math,private   ( final double base )  {  this . base = base ;  this . log   of   base =  math . log ( base )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,compare,public static int   ( final int v1 final int v2 )  {  return  ( v1  <  v2  ?   - 1 :  ( v1  =  =  v2  ?  0 : 1 )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,divide,"public static double[]   ( final double[] numerators final double[] denominators )  {  if  ( numerators . length  !  =  denominators . length )  throw new  illegal argument exception ( "" arrays must be of same length . "" )  ;  final int len = numerators . length ;  final double[] result = new double[len] ;  for  ( int i = 0 ;  i  <  len ;   +  + i )  result[i] = numerators[i]  /  denominators[i] ;  return result ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,get log value,public double[]   ( final double[] non log array )  {  final double[] log array = new double[non log array . length] ;  for  ( int i = 0 ;  i  <  non log array . length ;  i +  +  )   {  log array[i] = get log value ( non log array[i] )  ;   }  return log array ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,get log   of   base,public double   (  )  {  return log   of   base ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,get non log value,public double   ( final double log value )  {  return  math . pow ( base log value )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,index of max,public static int   ( final long[] nums )  {  long max = nums[0] ;  int index = 0 ;  for  ( int i = 1 ;  i  <  nums . length ;   +  + i )   {  if  ( nums[i]  >  max )   {  max = nums[i] ;  index = i ;   }   }  return index ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,index of min,public static int   ( final double[] nums )  {  double min = nums[0] ;  int index = 0 ;  for  ( int i = 1 ;  i  <  nums . length ;   +  + i )   {  if  ( nums[i]  <  min )   {  min = nums[i] ;  index = i ;   }   }  return index ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,log   p,public static double   ( final double x )  {  return log1p ( x )   /  log   10   math . log   of   base ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,log likelihoods to probs,@ deprecated public static double[]   ( final double[] likelihoods )  {  return p normalize log probability ( likelihoods )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,max,public static long   ( final long[] nums )  {  return nums[index of max ( nums ) ] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,mean,public double   ( final double .  .  .  log values )  {  return sum ( log values )   -  get log value ( log values . length )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,median,"public static double   ( final double .  .  .  in )  {  if  ( in . length  =  =  0 )   {  throw new  illegal argument exception ( "" attempting to find the median of an empty array"" )  ;   }  final double[] data =  arrays . copy of ( in in . length )  ;   arrays . sort ( data )  ;  final int middle = data . length  /  2 ;  return data . length % 2  =  =  1  ?  data[middle] :  ( data[middle  -  1]  +  data[middle] )   /  2 . 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,min,public static byte   ( final byte[] nums )  {  byte min = nums[0] ;  for  ( int i = 1 ;  i  <  nums . length ;   +  + i )   {  if  ( nums[i]  <  min )  min = nums[i] ;   }  return min ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,multiply,"public static double[]   ( final double[] lhs final double[] rhs )  {  if  ( lhs . length  !  =  rhs . length )  throw new  illegal argument exception ( "" arrays must be of same length . "" )  ;  final int len = lhs . length ;  final double[] result = new double[len] ;  for  ( int i = 0 ;  i  <  len ;   +  + i )  result[i] = lhs[i] * rhs[i] ;  return result ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,p normalize log probability,public static double[]   ( final double[] l posterior )  {  final double max likelihood = max ( l posterior )  ;  final double bump = 300  -  max likelihood ;  final double[] tmp = new double[l posterior . length] ;  double total = 0 ;  for  ( int i = 0 ;  i  <  l posterior . length ;   +  + i )   {  tmp[i] = pow ( 10 l posterior[i]  +  bump )  ;  total +  = tmp[i] ;   }  final double maxp = max   prob   below   one ;  final double minp =  ( 1  -  max   prob   below   one )   /   ( tmp . length  -  1 )  ;  for  ( int i = 0 ;  i  <  l posterior . length ;   +  + i )   {  tmp[i] /  = total ;  if  ( tmp[i]  >  maxp )  tmp[i] = maxp ;  else if  ( tmp[i]  <  minp )  tmp[i] = minp ;   }  return tmp ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,p normalize vector,public static double[]   ( final double[] p posterior )  {  final double[] tmp = new double[p posterior . length] ;  final double total = sum ( p posterior )  ;  final double maxp = max   prob   below   one ;  final double minp =  ( 1  -  max   prob   below   one )   /   ( tmp . length  -  1 )  ;  for  ( int i = 0 ;  i  <  p posterior . length ;   +  + i )   {  tmp[i] = p posterior[i]  /  total ;  if  ( tmp[i]  >  maxp )  tmp[i] = maxp ;  else if  ( tmp[i]  <  minp )  tmp[i] = minp ;   }  return tmp ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,percentage or null,public static  double   ( final  long numerator final  long denominator )  {  if  ( numerator  !  =  null && denominator  !  =  null && denominator  !  =  0 )   {  return numerator . double value (  )   /  denominator . double value (  )  ;   }  else  {  return null ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,product,public double   ( final double .  .  .  log values )  {  return  math util . sum ( log values )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,promote,public static double[]   ( final int[] is )  {  final double[] ds = new double[is . length] ;  for  ( int i = 0 ;  i  <  is . length ;   +  + i )  ds[i] = is[i] ;  return ds ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,round,public static double   ( final double num final int precision )  {   big decimal bd = new  big decimal ( num )  ;  bd = bd . set scale ( precision  big decimal . round   half   up )  ;  return bd . double value (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,seq,public static double[]   ( final double from final double to final double by )  {  if  ( from  <  to && by  <  =  0 )  return new double[0] ;  if  ( from  >  to && by  >  =  0 )  return new double[0] ;  final int values = 1  +   ( int )  math . floor (  ( to  -  from )   /  by )  ;  final double[] results = new double[values] ;   big decimal value = new  big decimal ( from )  ;   big decimal increment = new  big decimal ( by )  ;  for  ( int i = 0 ;  i  <  values ;   +  + i )   {  results[i] = value . double value (  )  ;  value = value . add ( increment )  ;   }  return results ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,stddev,public static double   ( final double[] in final int start final int stop final double mean )  {  double total = 0 ;  for  ( int i = start ;  i  <  stop ;   +  + i )   {  total +  =  ( in[i] * in[i] )  ;   }  return  math . sqrt (  ( total  /   ( stop  -  start )  )   -   ( mean * mean )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\MathUtil.java,sum,public double   ( final double .  .  .  log values )  {  final double scaling factor = max ( log values )  ;  double simple addition result = 0 ;  for  (  final double v : log values )   {  simple addition result +  = get non log value ( v  -  scaling factor )  ;   }  return get log value ( simple addition result )   +  scaling factor ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\QuerySortedReadPairIteratorUtil.java,get next read pair,public static  read pair   ( final  peekable iterator < sam record >  iterator )  {  final  read pair read pair = new  read pair (  )  ;  read pair . read1 = get next usable read ( iterator false )  ;  if  ( read pair . read1  =  =  null )   {  return null ;   }  final sam record peeked next read = get next usable read ( iterator true )  ;  if  ( peeked next read  !  =  null && peeked next read . get read name (  )  . equals ( read pair . read1 . get read name (  )  )  )   {  read pair . read2 = get next usable read ( iterator false )  ;   }  return read pair ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\QuerySortedReadPairIteratorUtil.java,get next usable read,private static sam record   ( final  peekable iterator < sam record >  iterator final boolean just peek )  {  while  ( iterator . has next (  )  )   {  final sam record next read = iterator . peek (  )  ;  if  ( next read . get read fails vendor quality check flag (  )  || next read . is secondary or supplementary (  )  )   {  iterator . next (  )  ;   }  else  {  return just peek  ?  next read : iterator . next (  )  ;   }   }  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\PropertyUtils.java,load properties file,"public static  properties   ( final  string property file path final  class <  ?  >  clazz )  {   utils . non null ( property file path )  ;  try  ( final  input stream input stream = clazz . get class loader (  )  . get resource as stream ( property file path )  )  {  if  ( input stream  !  =  null )   {  final  properties properties = new  properties (  )  ;  properties . load ( input stream )  ;  return properties ;   }  else  {  return null ;   }   }  catch  (  io exception ex )   {  throw new  runtime exception (  string . format ( ""io exception loading properties file %s"" property file path )  ex )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\ReflectionUtil.java,copy from base class,"static public  < t s extends t > void   ( final t base final s derived )  {  final  class < t >  base clazz =  (  class < t >  ) base . get class (  )  ;  for  (   field f : base clazz . get fields (  )  )   {  try  {  f . set ( derived f . get ( base )  )  ;   }  catch  (   illegal access exception e )   {  throw new  runtime exception ( e . get message (  )   +  ""when trying to access""  +  f . get name (  )  )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedInputParser.java, tabbed input parser,public   ( boolean treat grouped delimiters as one  file .  .  .  file )  {  super ( treat grouped delimiters as one file )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedInputParser.java,is delimiter,@ override protected boolean   ( final byte b )  {  return b  =  =  '\t' ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedTextFileWithHeaderParser.java, row,  ( final  string[] fields final  string source )  {  this . fields = fields ;  this . current line = source ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedTextFileWithHeaderParser.java, tabbed text file with header parser,"public   ( final  file file final  string[] column headers )  {  parser = new  tabbed input parser ( false file )  ;  if  (  ! parser . has next (  )  )   {  throw new  picard exception ( "" no header line found in file ""  +  file )  ;   }  for  ( int i = 0 ;  i  <  column headers . length ;   +  + i )   {  column label indices . put ( column headers[i] i )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedTextFileWithHeaderParser.java,close,public void   (  )  {  parser . close (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedTextFileWithHeaderParser.java,column labels,public  set <  string >    (  )  {  return column label indices . key set (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedTextFileWithHeaderParser.java,column labels list,public  list <  string >    (  )  {  return  collections . unmodifiable list ( new  array list <  string >  ( column label indices . key set (  )  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedTextFileWithHeaderParser.java,get column names,public  set <  string >    (  )  {  return  collections . unmodifiable set ( this . column label indices . key set (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedTextFileWithHeaderParser.java,get current line,public  string   (  )  {  return this . current line ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedTextFileWithHeaderParser.java,get current line number,public int   (  )  {  return parser . get current line number (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedTextFileWithHeaderParser.java,get field,"public  string   ( final  string column label )  {  final  integer key = column label indices . get ( column label )  ;  if  ( key  =  =  null )  throw new  no such element exception (  string . format ( ""column %s in %s"" column label parser . get file name (  )  )  )  ;  return fields[key] ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedTextFileWithHeaderParser.java,get fields,public  string[]   (  )  {  return fields ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedTextFileWithHeaderParser.java,get integer field,public  integer   ( final  string column label )  {  if  ( fields[column label indices . get ( column label ) ]  =  =  null )  return null ;  return  integer . parse int ( fields[column label indices . get ( column label ) ] )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedTextFileWithHeaderParser.java,has column,public boolean   ( final  string column label )  {  return column label indices . contains key ( column label )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedTextFileWithHeaderParser.java,has next,@ override public boolean   (  )  {  return parser . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedTextFileWithHeaderParser.java,iterator,"@ override public  closeable iterator <  row >    (  )  {  if  ( extant iterator  !  =  null )   {  throw new  concurrent modification exception ( "" only one iterator allowed at a time . "" )  ;   }  extant iterator = new  the iterator (  )  ;  return exta"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedTextFileWithHeaderParser.java,next,@ override public  row   (  )  {  final  string[] fields = parser . next (  )  ;  final  string source = parser . get current line (  )  ;  return new  row ( fields source )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\TabbedTextFileWithHeaderParser.java,remove,@ override public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\ScatterIntervalsByNs.java, output type,  ( final  string .  .  .  strings )  {  accepted types = new  hash set <  >  (  )  ;   collections . add all ( accepted types strings )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\ScatterIntervalsByNs.java,accepts,public  boolean   ( final  string string )  {  return accepted types . contains ( string )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\ScatterIntervalsByNs.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( reference   sequence )  ;  io util . assert file is writable ( output )  ;  final  reference sequence file ref file =  reference sequence file factory . get reference sequence file ( 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\ScatterIntervalsByNs.java,get reference file,@ override public  file   (  )  {  return reference ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\ScatterIntervalsByNs.java,main,public static void   ( final  string[] args )  {  new  scatter intervals by ns (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\ScatterIntervalsByNs.java,make reference argument collection,@ override protected  reference argument collection   (  )  {  return new  scatter intervals byn reference argument collection (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\ScatterIntervalsByNs.java,segregate reference,static  interval list   ( final  reference sequence file ref file final int max nmer to merge )  {  final  list <  interval >  preliminary intervals = new  linked list <  >  (  )  ;  final sam file header header = new sam file header (  )  ;  header . set sequence dictionary ( ref file . get sequence dictionary (  )  )  ;  header . set sort order ( sam file header .  sort order . coordinate )  ;  final  interval list final intervals = new  interval list ( header )  ;  for  (  final sam sequence record rec : ref file . get sequence dictionary (  )  . get sequences (  )  )   {  final  reference sequence ref = ref file . get sequence ( rec . get sequence name (  )  )  ;  final byte[] bytes = ref . get bases (  )  ;   string util . to upper case ( bytes )  ;  boolean n block is open =  sequence util . is no call ( bytes[0] )  ;  int start = 0 ;  for  ( int i = 0 ;  i  <  bytes . length ;   +  + i )   {  locus progress . record ( rec . get sequence name (  )  i )  ;  final boolean current base isn =  sequence util . is no call ( bytes[i] )  ;  if  ( n block is open  !  =  current base isn )   {  preliminary intervals . add ( new  interval ( rec . get sequence name (  )  start  +  1 i false n block is open  ?   nmer : acg tmer )  )  ;  start = i ;  n block is open =  ! n block is open ;   }   }  preliminary intervals . add ( new  interval ( rec . get sequence name (  )  start  +  1 bytes . length false n block is open  ?   nmer : acg tmer )  )  ;   }  while  (  ! preliminary intervals . is empty (  )  )   {  if  ( preliminary intervals . size (  )   >  =  3 && preliminary intervals . get ( 0 )  . get name (  )   =  =  acg tmer && preliminary intervals . get ( 1 )  . get name (  )   =  =   nmer && preliminary intervals . get ( 2 )  . get name (  )   =  =  acg tmer && preliminary intervals . get ( 0 )  . abuts ( preliminary intervals . get ( 1 )  )  && preliminary intervals . get ( 1 )  . abuts ( preliminary intervals . get ( 2 )  )  && preliminary intervals . get ( 1 )  . length (  )   <  =  max nmer to merge )   {  final  interval temp = new  interval ( preliminary intervals . get ( 0 )  . get contig (  )  preliminary intervals . get ( 0 )  . get start (  )  preliminary intervals . get ( 2 )  . get end (  )  false acg tmer )  ;  for  ( int i = 0 ;  i  <  3 ;   +  + i )   {  preliminary intervals . remove ( 0 )  ;   }  preliminary intervals . add ( 0 temp )  ;   }  else  {  final  interval remove = preliminary intervals . remove ( 0 )  ;  final intervals . add ( remove )  ;  interval progress . record ( remove . get contig (  )  remove . get start (  )  )  ;   }   }  return final intervals ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\ThreadPoolExecutorWithExceptions.java, thread pool executor with exceptions,public   ( final int threads )  {  super ( threads threads 0  time unit . seconds new  linked blocking deque <  >  (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\ThreadPoolExecutorWithExceptions.java,after execute,@ override protected void   ( final  runnable r  throwable t )  {  if  ( t  =  =  null && r instanceof  future <  ?  >  )   {  try  {  final  future <  ?  >  future =  (  future <  ?  >  ) r ;  if  ( future . is done (  )  )   {  future . get (  )  ;   } 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\ThreadPoolExecutorWithExceptions.java,before execute,"@ override protected void   (  thread t  runnable r )  {  super . before execute ( t r )  ;  t . set uncaught exception handler (  ( t1 e )   -  >   {  throw new  picard exception ( "" uncaught exception in thread: ""  +  t1 . get name (  )   +  "" : "" +  e "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\RExecutor.java,execute from classpath,public static int   ( final  string r script name final  string .  .  .  arguments )  {  final  file script file = write script file ( r script name )  ;  final int return code = execute from file ( script file arguments )  ;  htsjdk . samtools . util . io util . delete files ( script file )  ;  return return code ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\RExecutor.java,execute from file,"public static int   ( final  file script file final  string .  .  .  arguments )  {  final  string[] command = new  string[arguments . length  +  2] ;  command[0] = r   exe ;  command[1] = script file . get absolute path (  )  ;   system . arraycopy ( arguments 0 command 2 arguments . length )  ;  log . info (  string . format ( "" executing r script via command: %s""  collection util . join (  arrays . as list ( command )  "" "" )  )  )  ;  return  process executor . execute ( command )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\RExecutor.java,write script file,"private static  file   ( final  string r script name )  {   input stream script stream = null ;   output stream script file stream = null ;  try  {  script stream = r executor . class . get class loader (  )  . get resource as stream ( r script name )  ;  if  ( script stream  =  =  null )   {  throw new  illegal argument exception ( "" script [""  +  r script name  +  ""] not found in classpath"" )  ;   }  final  file script file =  file . create temp file ( ""script"" "" . r"" )  ;  script file stream = io util . open file for writing ( script file )  ;  io util . copy stream ( script stream script file stream )  ;  return script file ;   }  catch  (  io exception e )   {  throw new  picard exception ( "" unexpected exception creating r script file [""  +  r script name  +  ""]"" e )  ;   }  finally  {  if  ( script stream  !  =  null )   {  try  {  script stream . close (  )  ;   }  catch  (  io exception ignored )   {   }   }  if  ( script file stream  !  =  null )   {  try  {  script file stream . close (  )  ;   }  catch  (  io exception ignored )   {   }   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\UnsignedTypeUtil.java,u byte to int,public static int   ( final byte unsigned byte )  {  return unsigned byte & 0xff ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\UnsignedTypeUtil.java,u byte to short,public static int   ( final byte unsigned byte )  {  return  ( short ) unsigned byte & 0xff ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\UnsignedTypeUtil.java,u int to float,public static float   ( final int unsigned int )  {  return  float . int bits to float ( unsigned int )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\UnsignedTypeUtil.java,u int to long,public static long   ( final int unsigned int )  {  return unsigned int & 0xffffffffl ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\UnsignedTypeUtil.java,u short to int,public static int   ( final short unsigned short )  {  return unsigned short & 0xffff ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\AccumulateVariantCallingMetrics.java,do work,"@ override protected int   (  )  {  final  string output prefix = output . get absolute path (  )   +  "" . "" ;  final  file detail output file = new  file ( output prefix  +   collect variant calling metrics .  variant calling detail metrics . get file ex"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\ByIntervalListVariantContextIterator.java, by interval list variant context iterator,public   ( final vcf file reader reader final  interval list intervals )  {  this . reader = reader ;  this . intervals = intervals . uniqued (  )  . iterator (  )  ;  this . advance (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\ByIntervalListVariantContextIterator.java,advance,private void   (  )  {  while  (  ( current iterator  =  =  null ||  ! current iterator . has next (  )  )  && this . intervals . has next (  )  )   {  if  ( current iterator  !  =  null )  current closeable iterator . close (  )  ;  final  interval interval = this . intervals . next (  )  ;  final  interval previous interval = this . last interval ;  this . current closeable iterator = this . reader . query ( interval . get contig (  )  interval . get start (  )  interval . get end (  )  )  ;  this . current iterator = this . current closeable iterator . stream (  )  . filter ( ctx  -  >  null  =  =  previous interval ||  ! overlaps interval ( ctx previous interval )  )  . iterator (  )  ;  this . last interval = interval ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\ByIntervalListVariantContextIterator.java,has next,@ override public boolean   (  )  {  return  ( this . current iterator  !  =  null && this . current iterator . has next (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\ByIntervalListVariantContextIterator.java,next,@ override public  variant context   (  )  {  final  variant context ctx = this . current iterator . next (  )  ;  advance (  )  ;  return ctx ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\ByIntervalListVariantContextIterator.java,overlaps interval,private boolean   ( final  variant context ctx final  interval interval )  {  if  (  ! ctx . get contig (  )  . equals ( interval . get contig (  )  )  )  return false ;  else if  (  coord math . overlaps ( ctx . get start (  )  ctx . get end (  )  interval . get start (  )  interval . get end (  )  )  )  return true ;  else return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\ByIntervalListVariantContextIterator.java,remove,@ override public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\util\VariantType.java,get variant type from ordinal,public static  variant type   ( int ordinal )  {  return  variant type . class . get enum constants (  ) [ordinal] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\CollectVariantCallingMetrics.java,calculate derived fields,@ override public void   (  )  {  super . calculate derived fields (  )  ;  het   homvar   ratio = num hets  /   ( double ) num hom var ;  pct   gq0   variants = total   gq0   variants  /   ( double )  ( num hets  +  num hom var )  ;  total   het   depth 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\CollectVariantCallingMetrics.java,calculate from derived fields,public void   (  )  {  num hom var = invert from ratio ( total   snps het   homvar   ratio )  ;  num hets = total   snps  -  num hom var ;  calculate from derived fields ( total   het   depth )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\CollectVariantCallingMetrics.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is readable ( dbsnp )  ;  if  ( target   intervals  !  =  null )  io util . assert file is readable ( target   intervals )  ;  if  ( sequence   dicti
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\CollectVariantCallingMetrics.java,fold into,public static  < t extends  variant calling summary metrics > void   ( final t target final  collection < t >  metrics )  {  metrics . for each ( target::merge )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\CollectVariantCallingMetrics.java,get file extension,"public static  string   (  )  {  return ""variant   calling   detail   metrics"" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\CollectVariantCallingMetrics.java,invert from ratio,private static long   ( final long sum final  double ratio )  {  return ratio . is nan (  )   ?  0l :  math . round ( sum  /   ( ratio  +  1 . 0 )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\CollectVariantCallingMetrics.java,main,public static void   ( final  string[] args )  {  new  collect variant calling metrics (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\DepthFilter.java, depth filter,public   ( final int min depth )  {  this . min depth = min depth ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\DepthFilter.java,filter,"@ override public  string   ( final  variant context ctx final  genotype gt )  {  if  ( gt . getdp (  )   <  min depth )  return "" lowdp"" ;  else return null ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\CallingMetricAccumulator.java, calling metric accumulator,public   ( final  db snp bit set util .  db snp bit sets dbsnp )  {  this . dbsnp = dbsnp ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\CallingMetricAccumulator.java, result,  ( final  variant calling summary metrics summary final  collection <  variant calling detail metrics >  details )  {  this . summary = summary ;  this . details = details ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\CallingMetricAccumulator.java,accumulate,@ override public void   ( final  variant context vc )  {  progress . record ( vc . get contig (  )  vc . get start (  )  )  ;  if  (  ! is variant excluded ( vc )  )   {  final  string singleton sample = get singleton sample ( vc )  ;  update summary met
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\CallingMetricAccumulator.java,get singleton sample,protected static  string   ( final  variant context vc )  {  final  string[] sample name = new  string[1] ;  if  ( vc . get genotypes (  )  . stream (  )  . filter ( genotype  -  >  genotype . is het (  )  || genotype . is hom var (  )  )  . limit ( 2 )  . peek ( genotype  -  >  sample name[0] = genotype . get sample name (  )  )  . map to int ( genotype  -  >  genotype . is het (  )   ?  1 : 2 )  . reduce (  integer::sum )  . or else ( 0 )   =  =  1 )   {  return sample name[0] ;   }  else  {  return null ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\CallingMetricAccumulator.java,is variant excluded,static private boolean   ( final  variant context vc )  {  return  ! vc . is variant (  )  || vc . get genotypes (  )  . stream (  )  . all match (  genotype::is hom ref )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\CallingMetricAccumulator.java,merge,public static  result   ( final  collection <  result >  results )  {  final  collection <  variant calling detail metrics >  details = new  array list <  >  (  )  ;  final  collection <  variant calling summary metrics >  summaries = new  array list <  >  (  )  ;  results . stream (  )  . for each ( result  -  >   {  summaries . add ( result . summary )  ;  details . add all ( result . details )  ;   }   )  ;  final  map <  string  list <  variant calling detail metrics >  >  sample details map = details . stream (  )  . collect (  collectors . grouping by ( vc detail metrics  -  >  vc detail metrics . sample   alias )  )  ;  final  collection <  collect variant calling metrics .  variant calling detail metrics >  collapsed details = new  array list <  >  (  )  ;  sample details map . values (  )  . stream (  )  . for each ( sample details  -  >   {  final  variant calling detail metrics collapsed = new  variant calling detail metrics (  )  ;   variant calling detail metrics . fold into ( collapsed sample details )  ;  collapsed details . add ( collapsed )  ;  collapsed . calculate derived fields (  )  ;   }   )  ;  final  variant calling summary metrics collapsed summary = new  variant calling summary metrics (  )  ;   variant calling summary metrics . fold into ( collapsed summary summaries )  ;  collapsed summary . calculate derived fields (  )  ;  return new  result ( collapsed summary collapsed details )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\CallingMetricAccumulator.java,result,public  result   (  )  {  final  collection <  variant calling detail metrics >  values = sample metrics map . values (  )  ;  values . for each (  collect variant calling metrics .  variant calling detail metrics::calculate derived fields )  ;  summary metric . calculate derived fields (  )  ;  return new  result ( summary metric values )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\CallingMetricAccumulator.java,setup,public void   ( final vcf header vcf header )  {  vcf header . get genotype samples (  )  . stream (  )  . for each ( sample name  -  >  sample metrics map . get ( sample name )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\CallingMetricAccumulator.java,update detail metric,private void   ( final  variant calling detail metrics metric final  genotype genotype final  variant context vc final boolean has singleton sample )  {  update summary metric ( metric genotype vc has singleton sample )  ;  if  ( genotype  !  =  null &&  ! vc . is filtered (  )  )   {  if  ( genotype . getgq (  )   =  =  0 )   {   +  + metric . total   gq0   variants ;   }  if  ( genotype . is het (  )  )   {   +  + metric . num hets ;   }  else if  ( genotype . is hom var (  )  )   {   +  + metric . num hom var ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\CallingMetricAccumulator.java,update summary metric,"private void   ( final  variant calling summary metrics metric final  genotype genotype final  variant context vc final boolean has singleton sample )  {  if  ( genotype  !  =  null && genotype . is no call (  )  )  return ;  if  ( vc . is filtered (  )  )   {  if  ( vc . issnp (  )  )  metric . filtered   snps +  +  ;  else if  ( vc . is indel (  )  )  metric . filtered   indels +  +  ;  return ;   }  if  ( has singleton sample )   {   +  + metric . num   singletons ;   }  if  ( vc . is biallelic (  )  && vc . issnp (  )  )   {  final boolean is in db snp = dbsnp . snps . is db snp site ( vc . get contig (  )  vc . get start (  )  )  ;  final boolean is transition =  variant context utils . is transition ( vc )  ;  metric . total   snps +  +  ;  if  ( is in db snp )   {  metric . num   in   db   snp +  +  ;  if  ( is transition )  metric . db snp transitions +  +  ;  else metric . db snp transversions +  +  ;   }  else  {  if  ( is transition )  metric . novel transitions +  +  ;  else metric . novel transversions +  +  ;   }  if  ( genotype  !  =  null && genotype . is het (  )  )   {  final int[] allele depths = genotype . getad (  )  ;  if  ( allele depths  !  =  null )   {  final int index of ref = vc . get allele index ( vc . get reference (  )  )  ;  final int index of alt =  ( index of ref  +  1 )  % 2 ;  metric . ref allele obs +  = allele depths[index of ref] ;  metric . alt allele obs +  = allele depths[index of alt] ;  summary metric . ref allele obs +  = allele depths[index of ref] ;  summary metric . alt allele obs +  = allele depths[index of alt] ;   }  else  {  log . debug ( "" skipping aggregation of genotype due to missing allele depth data: "" genotype "" . "" )  ;   }   }   }  else if  ( vc . issnp (  )  && vc . get alternate alleles (  )  . size (  )   >  1 )   {  metric . total   multiallelic   snps +  +  ;  if  ( dbsnp . snps . is db snp site ( vc . get contig (  )  vc . get start (  )  )  )  metric . num   in   db   snp   multiallelic +  +  ;   }  else if  ( vc . is indel (  )  &&  ! vc . is complex indel (  )  )   {  final boolean is in db snp = dbsnp . indels . is db snp site ( vc . get contig (  )  vc . get start (  )  )  ;  final boolean is insertion = vc . is simple insertion (  )  ;  metric . total   indels +  +  ;  if  ( is in db snp )   {  metric . num   in   db   snp   indels +  +  ;  if  ( is insertion )  metric . db snp insertions +  +  ;  else metric . db snp deletions +  +  ;   }  else  {  if  ( is insertion )  metric . novel insertions +  +  ;  else  {  metric . novel deletions +  +  ;   }   }   }  else if  ( vc . is complex indel (  )  )   {  metric . total   complex   indels +  +  ;  if  ( dbsnp . indels . is db snp site ( vc . get contig (  )  vc . get start (  )  )  )  metric . num   in   db   snp   complex   indels +  +  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\FilterApplyingVariantIterator.java, filter applying variant iterator,public   ( final  iterator <  variant context >  iterator final  collection <  variant filter >  filters final  collection <  genotype filter >  gt filters )  {  this . iterator = iterator ;  this . filters = filters . to array ( new  variant filter[filters . size (  ) ] )  ;  this . gt filters = gt filters . to array ( new  genotype filter[gt filters . size (  ) ] )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\FilterApplyingVariantIterator.java,close,@ override public void   (  )  {   closer util . close ( this . iterator )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\FilterApplyingVariantIterator.java,has next,@ override public boolean   (  )  {  return this . iterator . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\FilterApplyingVariantIterator.java,next,@ override public  variant context   (  )  {  final  variant context ctx = this . iterator . next (  )  ;  final  set <  string >  filter strings = new  hash set <  string >  (  )  ;  for  (  final  variant filter filter : this . filters )   {  final  str
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\FilterApplyingVariantIterator.java,remove,"@ override public void   (  )  {  throw new  unsupported operation exception ( ""remove (  )  not supported by  filter applying variant iterator . "" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\FilterVcf.java, filter vcf,public   (  )  {  this . create   index = true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\FilterVcf.java, variant context javascript filter,"private   ( final  file script file final vcf header header )  throws io exception  {  super ( script file header )  ;  this . script file = script file ;   string fname = io util . basename ( script file )  ;  if  ( fname . is empty (  )  )  fname = ""jsfilter"" ;  this . filter name = fname ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\FilterVcf.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  vcf file reader in = null ;   variant context writer out = null ;  try  {  in = new vcf file reader ( input false )  ;  fi
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\FilterVcf.java,filter,@ override public  string   ( final  variant context ctx )  {  return  ( super . accept ( ctx )   ?  null : this . filter name )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\FilterVcf.java,header lines,"@ override public  list < vcf filter header line >    (  )  {  return  collection util . make list ( new vcf filter header line ( this . filter name "" variant  filtered by  javascript file ""  +  this . script file )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\FilterVcf.java,is vcf or bcf,private boolean   ( final  file file )  {  final  string file name = file . get name (  )  ;  return file name . ends with ( io util . vcf   file   extension )  || file name . ends with ( io util . bcf   file   extension )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\FilterVcf.java,main,public static void   ( final  string[] args )  {  new  filter vcf (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\FisherStrandFilter.java, fisher strand filter,public   ( final double max phred scalep value )  {  this . max phred scalep value = max phred scalep value ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\FisherStrandFilter.java,filter,"@ override public  string   ( final  variant context ctx )  {  final double fs = ctx . get attribute as double ( ""fs"" 0 )  ;  return  ( fs  >  max phred scalep value )   ?  "" strand bias"" : null ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\FisherStrandFilter.java,header lines,"@ override public  list < vcf filter header line >    (  )  {  return  collection util . make list ( new vcf filter header line ( "" strand bias"" "" site exhibits excessive allele / strand correlation . "" )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\AlleleBalanceFilter.java, allele balance filter,public   ( final double het allele balance )  {  this . het allele balance = het allele balance ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\AlleleBalanceFilter.java,filter,@ override public  string   ( final  variant context ctx )  {  if  ( ctx . get het count (  )   =  =  0 )  return null ;  final  map <  list <  allele >   counts >  counts map = new  hash map <  list <  allele >   counts >  (  )  ;  for  (  final  genotyp
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\AlleleBalanceFilter.java,header lines,"@ override public  list < vcf filter header line >    (  )  {  return  collection util . make list ( new vcf filter header line ( ab   filter "" heterozygote allele balance below required threshold . "" )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\QdFilter.java, qd filter,public   ( final double minimum qd )  {  this . minimum qd = minimum qd ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\QdFilter.java,filter,"@ override public  string   ( final  variant context ctx )  {  final double qd = ctx . get attribute as double ( ""qd""  - 1d )  ;  if  ( qd  >  =  0 && qd  <  minimum qd )   {  return filter   name ;   }  else  {  return null ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\QdFilter.java,header lines,"@ override public  list < vcf filter header line >    (  )  {  return  collection util . make list ( new vcf filter header line ( filter   name "" site exhibits qd value below a hard limit . "" )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\FixVcfHeader.java,custom command line validation,"@ override protected  string[]   (  )  {  if  ( header  !  =  null && 0  <  =  check   first   n   records )  return new  string[] { ""check   first   n   records should no be specified when header is specified"" }  ;  return super . custom command line val"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\FixVcfHeader.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  if  ( header  !  =  null )  io util . assert file is readable ( header )  ;  io util . assert file is writable ( output )  ;  final vcf file reader reader = new vcf file r
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\GenotypeQualityFilter.java, genotype quality filter,public   ( final int min gq )  {  this . min gq = min gq ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\filter\GenotypeQualityFilter.java,filter,"@ override public  string   ( final  variant context ctx final  genotype gt )  {  if  ( gt . getgq (  )   <  min gq )  return "" lowgq"" ;  else return null ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GA4GHScheme.java,initiate scheme,@ override protected void   (  )  {  add row (  call state . missing na tn   only tn   fn fn   only fn   only empty empty empty empty empty empty )  ;  add row (  call state . hom   ref tn   only tn   only tn   fn fn   only fn   only empty empty empty emp
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GA4GHSchemeWithMissingAsHomRef.java,initiate scheme,@ override protected void   (  )  {  add row (  call state . missing tn   only tn   only tn   fn fn   only fn   only empty empty empty empty empty empty )  ;  add row (  call state . hom   ref tn   only tn   only tn   fn fn   only fn   only empty empty em
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\FixVcfHeader.java,enforce same samples,"private void   ( final vcf header reader header final vcf header input header )  {  final  array list <  string >  reader samples = reader header . get sample names in order (  )  ;  final  array list <  string >  input samples = input header . get sample names in order (  )  ;  if  ( reader samples . size (  )   !  =  input samples . size (  )  )   {  throw new  picard exception ( "" the input vcf had a different # of samples than the input vcf header . "" )  ;   }  for  ( int i = 0 ;  i  <  reader samples . size (  )  ;  i +  +  )   {  if  (  ! reader samples . get ( i )  . equals ( input samples . get ( i )  )  )   {  throw new  picard exception (  string . format ( "" mismatch in the %dth sample: '%s'  !  =  '%s'"" i reader samples . get ( i )  input samples . get ( i )  )  )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\FixVcfHeader.java,main,public static void   ( final  string[] args )  {  new  fix vcf header (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceContingencyMetrics.java, genotype concordance contingency metrics,public   ( final  variant context .  type variant type final  genotype concordance counts concordance counts final  string truth sample final  string call sample final boolean missing sites flag )  {  this . variant   type = variant type ;  this . truth   sample = truth sample ;  this . call   sample = call sample ;  final  genotype concordance scheme factory scheme factory = new  genotype concordance scheme factory (  )  ;  final  genotype concordance scheme scheme = scheme factory . get scheme ( missing sites flag )  ;  scheme . validate scheme (  )  ;  concordance counts . validate counts against scheme ( scheme )  ;   map <  contingency state  long >  counts = concordance counts . get contingency state counts ( scheme )  ;  this . tp   count = counts . get (  contingency state . tp )  ;  this . tn   count = counts . get (  contingency state . tn )  ;  this . fp   count = counts . get (  contingency state . fp )  ;  this . fn   count = counts . get (  contingency state . fn )  ;  this . empty   count = counts . get (  contingency state . empty )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GatherVcfs.java, gather vcfs,public   (  )  {  create   index = true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GatherVcfs.java,are all block compressed,private boolean   ( final  list <  file >  input )  {  for  (  final  file f : input )   {  if  ( vcf file reader . isbcf ( f )  ||  !  abstract feature reader . has block compressed extension ( f )  )   {  return false ;   }   }  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GatherVcfs.java,assert same samples and valid ordering,"private static void   ( final  list <  file >  input files )  {  final vcf header header = new vcf file reader ( input files . get ( 0 )  false )  . get file header (  )  ;  final sam sequence dictionary dict = header . get sequence dictionary (  )  ;  final  variant context comparator comparator = new  variant context comparator ( header . get sequence dictionary (  )  )  ;  final  list <  string >  samples = header . get genotype samples (  )  ;   file last file = null ;   variant context last context = null ;  for  (  final  file f : input files )   {  final vcf file reader in = new vcf file reader ( f false )  ;  try  {  dict . assert same dictionary ( in . get file header (  )  . get sequence dictionary (  )  )  ;   }  catch  (  final  assertion error e )   {  log . error ( "" file #1: ""  +  input files . get ( 0 )  )  ;  log . error ( "" file #2: ""  +  f )  ;  throw e ;   }  final  list <  string >  these samples = in . get file header (  )  . get genotype samples (  )  ;  if  (  ! samples . equals ( these samples )  )   {  final  sorted set <  string >  s1 = new  tree set <  >  ( samples )  ;  final  sorted set <  string >  s2 = new  tree set <  >  ( these samples )  ;  s1 . remove all ( these samples )  ;  s2 . remove all ( samples )  ;  throw new  illegal argument exception ( ""vc fs do not have identical sample lists . ""  +  ""  samples unique to first file: ""  +  s1  +  "" .   samples unique to "" +  f . get absolute path (  )  +  "": "" +  s2 +  "" . "" )  ;   }  final  closeable iterator <  variant context >  variant iterator = in . iterator (  )  ;  if  ( variant iterator . has next (  )  )   {  final  variant context current context = variant iterator . next (  )  ;  if  ( last context  !  =  null && comparator . compare ( last context current context )   >  =  0 )   {  throw new  illegal argument exception ( "" first record in file ""  +  f . get absolute path (  )   +  "" is not after first record in "" +  ""previous file "" +  last file . get absolute path (  )  )  ;   }  last context = current context ;  last file = f ;   }   closer util . close ( in )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GatherVcfs.java,do work,"@ override protected int   (  )  {  log . info ( "" checking inputs . "" )  ;  input = io util . unroll files ( input io util . vcf   extensions )  ;  for  (  final  file f : input )  io util . assert file is readable ( f )  ;  io util . assert file is writ"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GatherVcfs.java,gather conventionally,"private static void   ( final sam sequence dictionary sequence dictionary final boolean create index final  list <  file >  input files final  file output file )  {  final  enum set <  options >  options =  enum set . copy of (  variant context writer builder . default   options )  ;  if  ( create index )   {  options . add (  options . index   on   the   fly )  ;   }  else  {  options . remove (  options . index   on   the   fly )  ;   }  final  variant context writer out = new  variant context writer builder (  )  . set options ( options )  . set output file ( output file )  . set reference dictionary ( sequence dictionary )  . build (  )  ;  final  progress logger progress = new  progress logger ( log 10000 )  ;   variant context last context = null ;   file last file = null ;  vcf header first header = null ;   variant context comparator comparator = null ;  for  (  final  file f : input files )   {  log . debug ( "" gathering from file: "" f . get absolute path (  )  )  ;  final vcf file reader variant reader = new vcf file reader ( f false )  ;  final  peekable iterator <  variant context >  variant iterator = new  peekable iterator <  >  ( variant reader . iterator (  )  )  ;  final vcf header header = variant reader . get file header (  )  ;  if  ( first header  =  =  null )   {  first header = header ;  out . write header ( first header )  ;  comparator = new  variant context comparator ( first header . get contig lines (  )  )  ;   }  if  ( last context  !  =  null && variant iterator . has next (  )  )   {  final  variant context vc = variant iterator . peek (  )  ;  if  ( comparator . compare ( vc last context )   <  =  0 )   {  throw new  illegal argument exception ( "" first variant in file ""  +  f . get absolute path (  )   +  "" is at "" +  vc . get contig (  )  +  "":"" +  vc . get start (  )  +  "" but last variant in earlier file "" +  last file . get absolute path (  )  +  "" is at "" +  last context . get contig (  )  +  "":"" +  last context . get start (  )  )  ;   }   }  while  ( variant iterator . has next (  )  )   {  last context = variant iterator . next (  )  ;  out . add ( last context )  ;  progress . record ( last context . get contig (  )  last context . get start (  )  )  ;   }  last file = f ;   closer util . close ( variant iterator )  ;   closer util . close ( variant reader )  ;   }  out . close (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GatherVcfs.java,gather with block copying,"private static void   ( final  list <  file >  vcfs final  file output )  {  try  {  final  file output stream out = new  file output stream ( output )  ;  boolean is first file = true ;  for  (  final  file f : vcfs )   {  log . info ( "" gathering ""  +  f . get absolute path (  )  )  ;  final  file input stream in = new  file input stream ( f )  ;  final  block compressed input stream .  file termination term =  block compressed input stream . check termination ( f )  ;  if  ( term  =  =   block compressed input stream .  file termination . defective )   {  throw new  picard exception ( f . get absolute path (  )   +  "" does not have a valid gzip block at the end of the file . "" )  ;   }  if  (  ! is first file )   {  final  block compressed input stream block in = new  block compressed input stream ( in false )  ;  boolean last byte newline = true ;  while  ( block in . available (  )   >  0 )   {  final int block length = block in . available (  )  ;  final byte[] block contents = new byte[block length] ;  final int read = block in . read ( block contents )  ;  if  ( block length  =  =  0 || read  !  =  block length )  throw new  illegal state exception ( "" could not read available bytes from  block compressed input stream . "" )  ;  int first non header byte index =  - 1 ;  for  ( int i = 0 ;  i  <  read ;   +  + i )   {  final byte b = block contents[i] ;  final boolean this byte newline =  ( b  =  =  '\n' || b  =  =  '\r' )  ;  if  ( last byte newline &&  ! this byte newline && b  !  =  '#' )   {  first non header byte index = i ;  break ;   }  last byte newline = this byte newline ;   }  if  ( first non header byte index  >  =  0 )   {  final  block compressed output stream block out = new  block compressed output stream ( out null )  ;  block out . write ( block contents first non header byte index block contents . length  -  first non header byte index )  ;  block out . flush (  )  ;  break ;   }   }   }  final long current pos = in . get channel (  )  . position (  )  ;  final long length = f . length (  )  ;  final long skip last =  ( term  =  =   block compressed input stream .  file termination . has   terminator   block )   ?   block compressed stream constants . empty   gzip   block . length : 0 ;  final long bytes to write = length  -  skip last  -  current pos ;  io util . transfer by stream ( in out bytes to write )  ;  in . close (  )  ;  is first file = false ;   }  out . write (  block compressed stream constants . empty   gzip   block )  ;  out . close (  )  ;   }  catch  (  final io exception ioe )   {  throw new  runtimeio exception ( ioe )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GatherVcfs.java,main,public static void   ( final  string[] args )  {  new  gather vcfs (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceSchemeFactory.java,get scheme,public  genotype concordance scheme   ( final boolean is missing hom ref )  {  if  ( is missing hom ref )   {  return new ga4gh scheme with missing as hom ref (  )  ;   }  else  {  return new ga4gh scheme (  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceScheme.java, genotype concordance scheme,public   (  )  {  initiate scheme (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceScheme.java,add row,"protected void   ( final  call state call state final  contingency state[] .  .  .  concordance state arrays )  {  if  ( concordance state arrays . length  !  =   truth state . values (  )  . length )   {  throw new  picard exception ( "" length mismatch between concordance state arrays and  truth state . values (  ) "" )  ;   }  for  ( int i = 0 ;  i  <  concordance state arrays . length ;  i +  +  )   {  scheme . put ( new  truth and call states (  truth state . values (  ) [i] call state )  concordance state arrays[i] )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceScheme.java,get concordance state array,public  contingency state[]   ( final  truth and call states truth and call states )  {  return this . scheme . get ( truth and call states )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceScheme.java,get contingency state set,public  set <  contingency state >    ( final  contingency state[] contingency state array )  {  final  set <  contingency state >  contingency state set = new  hash set <  contingency state >  (  )  ;   collections . add all ( contingency state set contingency state array )  ;  return contingency state set ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceScheme.java,get contingency state string,"public  string   ( final  truth state truth state final  call state call state )  {  final  contingency state[] contingency state array = get concordance state array ( truth state call state )  ;  return  ( contingency state array . length  =  =  0 )   ?  ""empty"" :  string util . join ( "" "" contingency state array )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceCounts.java, ppv,public double   ( final  genotype concordance scheme scheme final  call state[] call state list )  {  double numerator = 0 . 0 ;  double denominator = 0 . 0 ;  scheme . validate scheme (  )  ;  for  (  final  call state call state : call state list )   {  for  (  final  truth state truth state :  truth state . values (  )  )   {  final  truth and call states truth and call states = new  truth and call states ( truth state call state )  ;  final long count = get count ( truth and call states )  ;  for  (  final  contingency state contingency state : scheme . get concordance state array ( truth and call states )  )   {  if  (  contingency state . tp  =  =  contingency state )   {  numerator +  = count ;  denominator +  = count ;   }  else if  (  contingency state . fp  =  =  contingency state )   {  denominator +  = count ;   }   }   }   }  return  ( numerator  /  denominator )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceCounts.java,calculate genotype concordance,public double   ( final  genotype concordance scheme scheme final boolean missing sites flag )  {  return calculate genotype concordance util ( scheme missing sites flag true )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceCounts.java,calculate genotype concordance util,private double   ( final  genotype concordance scheme scheme final boolean missing sites flag final boolean include hom ref )  {  double numerator = 0 . 0 ;  double denominator = 0 . 0 ;  scheme . validate scheme (  )  ;  final  truth state[] all truth states =  truth state . values (  )  ;  final  call state[] all call states =  call state . values (  )  ;  for  (  final  truth state truth state : all truth states )   {  for  (  final  call state call state : all call states )   {  if  (  ! missing sites flag && is missing ( truth state call state )  )   {  continue ;   }  else if  ( include hom ref || is var ( truth state call state )  )   {  final  truth and call states truth and call states = new  truth and call states ( truth state call state )  ;  final long count = get count ( truth and call states )  ;  if  ( truth state . get code (  )   =  =  call state . get code (  )  )   {  numerator +  = count ;   }  denominator +  = count ;   }   }   }  return  ( denominator  >  0 . 0  ?   ( numerator  /  denominator )  :  double .  nan )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceCounts.java,calculate non ref genotype concordance,public double   ( final  genotype concordance scheme scheme final boolean missing sites flag )  {  return calculate genotype concordance util ( scheme missing sites flag false )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceCounts.java,get contingency state counts,public  map <  contingency state  long >    ( final  genotype concordance scheme scheme )  {  scheme . validate scheme (  )  ;  final  map <  contingency state  long >  counts = new  enum map <  contingency state  long >  (  contingency state . class )  ;  for  (  final  contingency state contingency state :  contingency state . values (  )  )   {  counts . put ( contingency state 0l )  ;   }  for  (  final  truth state truth state :  truth state . values (  )  )   {  for  (  final  call state call state :  call state . values (  )  )   {  final  truth and call states truth and call states = new  truth and call states ( truth state call state )  ;  final  contingency state[] contingency state array = scheme . get concordance state array ( truth and call states )  ;  for  (  final  contingency state contingency state : contingency state array )   {  final long new count = counts . get ( contingency state )   +  get count ( truth and call states )  ;  counts . put ( contingency state new count )  ;   }   }   }  return counts ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceCounts.java,get contingency state set,private  set <  contingency state >    ( final  contingency state[] contingency state array )  {  final  set <  contingency state >  contingency state set = new  hash set <  contingency state >  (  )  ;   collections . add all ( contingency state set contingency state array )  ;  return contingency state set ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceCounts.java,get count,public long   ( final  truth and call states truth and call states )  {  final  histogram .  bin <  truth and call states >  bin = this . counter . get ( truth and call states )  ;  return  ( bin  =  =  null  ?  0l :  ( long ) bin . get value (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceCounts.java,get counter size,public double   (  )  {  return this . counter . get count (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceCounts.java,get sensitivity,public double   ( final  genotype concordance scheme scheme final  truth state[] truth state array )  {  double numerator = 0 . 0 ;  double denominator = 0 . 0 ;  scheme . validate scheme (  )  ;  for  (  final  truth state truth state : truth state array )   {  for  (  final  call state call state :  call state . values (  )  )   {  final  truth and call states truth and call states = new  truth and call states ( truth state call state )  ;  final long count = get count ( truth and call states )  ;  for  (  final  contingency state contingency state : scheme . get concordance state array ( truth and call states )  )   {  if  (  contingency state . tp  =  =  contingency state )   {  numerator +  = count ;  denominator +  = count ;   }  else if  (  contingency state . fn  =  =  contingency state )   {  denominator +  = count ;   }   }   }   }  return  ( numerator  /  denominator )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceCounts.java,get specificity,public double   ( final  genotype concordance scheme scheme final  truth state[] truth state array )  {  double numerator = 0 . 0 ;  double denominator = 0 . 0 ;  scheme . validate scheme (  )  ;  for  (  final  truth state truth state : truth state array )   {  for  (  final  call state call state :  call state . values (  )  )   {  final  truth and call states truth and call states = new  truth and call states ( truth state call state )  ;  final long count = get count ( truth and call states )  ;  for  (  final  contingency state contingency state : scheme . get concordance state array ( truth and call states )  )   {  if  (  contingency state . tn  =  =  contingency state )   {  numerator +  = count ;  denominator +  = count ;   }  else if  (  contingency state . fp  =  =  contingency state )   {  denominator +  = count ;   }   }   }   }  return  ( numerator  /  denominator )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceCounts.java,get sum,public long   (  )  {  return get sum ( new  hash set <  truth state >  (  arrays . as list (  truth state . values (  )  )  )  new  hash set <  call state >  (  arrays . as list (  call state . values (  )  )  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceCounts.java,increment,public void   ( final  truth and call states truth and call states final double count )  {  this . counter . increment ( truth and call states count )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceCounts.java,is missing,public boolean   ( final  truth state truth state final  call state call state )  {  return truth state  =  =   truth state . missing || call state  =  =   call state . missing ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceCounts.java,is var,public boolean   ( final  truth state truth state final  call state call state )  {  final  list <  truth state >  list of truth states =  arrays . as list (  truth state . hom   var1  truth state . het   ref   var1  truth state . het   var1   var2 )  ;  final  list <  call state >  list of call states =  arrays . as list (  call state . het   ref   var1  call state . het   ref   var2  call state . het   ref   var3  call state . het   var1   var2  call state . het   var1   var3  call state . het   var3   var4  call state . hom   var1  call state . hom   var2  call state . hom   var3 )  ;  return list of truth states . contains ( truth state )  || list of call states . contains ( call state )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceCounts.java,validate counts against scheme,"public void   ( final  genotype concordance scheme scheme )  {  final  set <  contingency state >  na contingency states = get contingency state set (  genotype concordance scheme . na )  ;  for  (  final  truth state truth state :  truth state . values (  )  )   {  for  (  final  call state call state :  call state . values (  )  )   {  final  truth and call states truth and call states = new  truth and call states ( truth state call state )  ;  if  ( 0  <  get count ( truth and call states )  )   {  final  set <  contingency state >  contingency states = get contingency state set ( scheme . get concordance state array ( truth and call states )  )  ;  if  ( contingency states . contains all ( na contingency states )  )   {  throw new  picard exception (  string . format ( "" found counts for an illegal set of states: [%s  %s]"" truth state . name (  )  call state . name (  )  )  )  ;   }   }   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceStates.java, call state,private   ( final int code )  {  this . code = code ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceStates.java, truth and call states,public   ( final  truth state truth state final  call state call state )  {  this . truth state = truth state ;  this . call state = call state ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceStates.java, truth state,  ( final int code )  {  this . code = code ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceStates.java,compare to,@ override public int   ( final  truth and call states that )  {  int result = this . truth state . compare to ( that . truth state )  ;  if  ( result  =  =  0 )  result = this . call state . compare to ( that . call state )  ;  return result ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceStates.java,equals,@ override public boolean   ( final  object o )  {  if  ( this  =  =  o )  return true ;  if  ( o  =  =  null || get class (  )   !  =  o . get class (  )  )  return false ;  return compare to (  (  truth and call states ) o )   =  =  0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceStates.java,get code,public int   (  )  {  return this . code ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceStates.java,get code map,static  map <  integer  call state >    (  )  {  final  map <  integer  call state >  map = new  hash map <  >  (  )  ;  final  call state call values[] =  call state . values (  )  ;  for  ( int i = 0 ;  i  <  call values . length ;  i +  +  )   {  map . put ( call values[i] . code call values[i] )  ;   }  return map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceStates.java,get het,public static  call state   ( int allele0idx int allele1idx )  {  if  ( allele0idx  >  allele1idx )   {  final int temp = allele0idx ;  allele0idx = allele1idx ;  allele1idx = temp ;   }  if  ( allele0idx  =  =  0 )   {  if  ( allele1idx  =  =  1 )  return het   ref   var1 ;  if  ( allele1idx  =  =  2 )  return het   ref   var2 ;  if  ( allele1idx  =  =  3 )  return het   ref   var3 ;  assert false ;  return null ;   }  if  ( allele0idx  =  =  1 )   {  if  ( allele1idx  =  =  2 )  return het   var1   var2 ;  if  ( allele1idx  =  =  3 )  return het   var1   var3 ;  assert false ;  return null ;   }  if  ( allele0idx  =  =  2 && allele1idx  =  =  3 )  return het   var3   var4 ;  if  ( allele0idx  =  =  3 && allele1idx  =  =  4 )  return het   var3   var4 ;  assert false ;  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceStates.java,get hom,public static  call state   ( final int allele idx )  {  if  ( allele idx  =  =  0 )  return hom   ref ;  if  ( allele idx  =  =  1 )  return hom   var1 ;  if  ( allele idx  =  =  2 )  return hom   var2 ;  if  ( allele idx  =  =  3 )  return hom   var3 ;  assert false ;  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceStates.java,get var,public static  truth state   ( final int allele0idx final int allele1idx )  {  if  ( allele0idx  =  =  0 && allele1idx  =  =  1 )  return het   ref   var1 ;  if  ( allele0idx  =  =  1 && allele1idx  =  =  0 )  return het   ref   var1 ;  if  ( allele0idx  =  =  1 && allele1idx  =  =  2 )  return het   var1   var2 ;  if  ( allele0idx  =  =  2 && allele1idx  =  =  1 )  return het   var1   var2 ;  assert false ;  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceStates.java,hash code,@ override public int   (  )  {  int result = truth state . hash code (  )  ;  result = 31 * result  +  call state . hash code (  )  ;  return result ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordanceSummaryMetrics.java, genotype concordance summary metrics,public   ( final  variant context .  type variant type final  genotype concordance counts concordance counts final  string truth sample final  string call sample final boolean missing sites flag )  {  this . variant   type = variant type ;  this . truth   sample = truth sample ;  this . call   sample = call sample ;  final  genotype concordance scheme factory scheme factory = new  genotype concordance scheme factory (  )  ;  final  genotype concordance scheme scheme = scheme factory . get scheme ( missing sites flag )  ;  scheme . validate scheme (  )  ;  concordance counts . validate counts against scheme ( scheme )  ;  this . het   sensitivity = concordance counts . get sensitivity ( scheme  genotype concordance counts . het   truth   states )  ;  this . het   ppv = concordance counts .  ppv ( scheme  genotype concordance counts . het   call   states )  ;  this . het   specificity =  double .  nan ;  this . homvar   sensitivity = concordance counts . get sensitivity ( scheme  genotype concordance counts . hom   var   truth   states )  ;  this . homvar   ppv = concordance counts .  ppv ( scheme  genotype concordance counts . hom   var   call   states )  ;  this . homvar   specificity =  double .  nan ;  this . var   sensitivity = concordance counts . get sensitivity ( scheme  genotype concordance counts . var   truth   states )  ;  this . var   ppv = concordance counts .  ppv ( scheme  genotype concordance counts . var   call   states )  ;  this . var   specificity = concordance counts . get specificity ( scheme  genotype concordance counts . var   truth   states )  ;  this . genotype   concordance = concordance counts . calculate genotype concordance ( scheme missing sites flag )  ;  this . non   ref   genotype   concordance = concordance counts . calculate non ref genotype concordance ( scheme missing sites flag )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GvcfMetricAccumulator.java, gvcf metric accumulator,public   ( final  db snp bit set util .  db snp bit sets dbsnp )  {  super ( dbsnp )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GvcfMetricAccumulator.java,accumulate,@ override public void   ( final  variant context vc )  {  final  variant context sub context = vc . sub context from sample ( sample )  ;  super . accumulate ( sub context )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GvcfMetricAccumulator.java,setup,"@ override public void   ( final vcf header vcf header )  {  final  list <  string >  samples = vcf header . get genotype samples (  )  ;  if  ( samples  =  =  null || samples . size (  )   !  =  1 )   {  throw new  illegal argument exception ( "" expected"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java, alleles,"public   ( final  ordered set <  string >  all alleles final  string truth allele1 final  string truth allele2 final  string call allele1 final  string call allele2 )  {  if  ( truth allele1  =  =  null && truth allele2  !  =  null )   {  throw new  illegal state exception ( ""truth allele2 should be null if truth allele1 is null . "" )  ;   }  if  ( call allele1  =  =  null && call allele2  !  =  null )   {  throw new  illegal state exception ( ""call allele2 should be null if call allele1 is null . "" )  ;   }  this . all alleles = all alleles ;  this . truth allele1 =  ( truth allele1  =  =  null )   ?  null : this . all alleles . get ( all alleles . index of ( truth allele1 )  )  ;  this . truth allele2 =  ( truth allele2  =  =  null )   ?  null : this . all alleles . get ( all alleles . index of ( truth allele2 )  )  ;  this . call allele1 =  ( call allele1  =  =  null )   ?  null : this . all alleles . get ( all alleles . index of ( call allele1 )  )  ;  this . call allele2 =  ( call allele2  =  =  null )   ?  null : this . all alleles . get ( all alleles . index of ( call allele2 )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,add missing truth and missing call states,public static void   ( final double num variants final long interval base count final  genotype concordance counts counter )  {  final double count missing missing = interval base count  -  num variants ;  final  truth and call states missing missing = new  truth and call states (  truth state . missing  call state . missing )  ;  counter . increment ( missing missing count missing missing )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,add to genotypes,private void   ( final  list <  genotype >  genotypes final  variant context ctx final  string input sample name final  string output sample name final  list <  allele >  all alleles final  list <  allele >  ctx alleles final boolean missing sites hom ref )  {  if  ( ctx  !  =  null &&  ! ctx alleles . is empty (  )  )   {  final  genotype genotype = ctx . get genotype ( input sample name )  ;  final  genotype builder genotype builder = new  genotype builder ( genotype )  ;  genotype builder . name ( output sample name )  ;  genotype builder . alleles ( ctx alleles )  ;  if  (  ! genotype . has any attribute ( vcf constants . genotype   key )  )   {  genotype builder . attribute ( vcf constants . genotype   key missing   value   v4 )  ;   }  genotypes . add ( genotype builder . make (  )  )  ;   }  else  {  final  genotype builder genotype builder = new  genotype builder ( output sample name )  ;  if  ( missing sites hom ref )   {  genotype builder . alleles (  arrays . as list ( all alleles . get ( 0 )  all alleles . get ( 0 )  )  )  ;   }  else  {  genotype builder . alleles (  arrays . as list (  allele . no   call  allele . no   call )  )  ;   }  genotypes . add ( genotype builder . make (  )  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,as list,public  list <  allele >    (  )  {  if  ( all alleles . is empty (  )  )   {  return  collections . empty list (  )  ;   }  else  {  final  list <  allele >  alleles = new  array list <  >  ( this . all alleles . size (  )  )  ;  for  ( int idx = 0 ;  idx  <  this . all alleles . size (  )  ;  idx +  +  )   {  alleles . add (  allele . create ( this . all alleles . get ( idx )  idx  =  =  0 )  )  ;   }  return alleles ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,call alleles,public  list <  allele >    (  )  {  if  ( all alleles . is empty (  )  || this . call allele1  =  =  null )   {  return  collections . empty list (  )  ;   }  else  {  final  allele call allele1 =  allele . create ( this . call allele1 this . all alleles . index of ( this . call allele1 )   =  =  0 )  ;  final  allele call allele2 =  allele . create ( this . call allele2 this . all alleles . index of ( this . call allele2 )   =  =  0 )  ;  return  arrays . as list ( call allele1 call allele2 )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,classify variants,public static boolean   ( final  optional <  variant context >  truth context final  string truth sample final  optional <  variant context >  call context final  string call sample final  optional <  genotype concordance counts >  snp counter final  optional <  genotype concordance counts >  indel counter final int min gq final int min dp final boolean ignore filtered status )  {  final  variant context .  type truth variant context type = truth context . map (  variant context::get type )  . or else ( no   variation )  ;  final  variant context .  type call variant context type = call context . map (  variant context::get type )  . or else ( no   variation )  ;  final  truth and call states truth and call states = determine state ( truth context . or else ( null )  truth sample call context . or else ( null )  call sample min gq min dp ignore filtered status )  ;  if  ( truth variant context type  =  =  snp )   {  if  (  ( call variant context type  =  =  snp )  ||  ( call variant context type  =  =  mixed )  ||  ( call variant context type  =  =  no   variation )  )   {  snp counter . if present ( counter  -  >  counter . increment ( truth and call states )  )  ;  return true ;   }   }  else if  ( truth variant context type  =  =  indel )   {  if  (  ( call variant context type  =  =  indel )  ||  ( call variant context type  =  =  mixed )  ||  ( call variant context type  =  =  no   variation )  )   {  indel counter . if present ( counter  -  >  counter . increment ( truth and call states )  )  ;  return true ;   }   }  else if  ( truth variant context type  =  =  mixed )   {  if  ( call variant context type  =  =  snp )   {  snp counter . if present ( counter  -  >  counter . increment ( truth and call states )  )  ;  return true ;   }  else if  ( call variant context type  =  =  indel )   {  indel counter . if present ( counter  -  >  counter . increment ( truth and call states )  )  ;  return true ;   }   }  else if  ( truth variant context type  =  =  no   variation )   {  if  ( call variant context type  =  =  snp )   {  snp counter . if present ( counter  -  >  counter . increment ( truth and call states )  )  ;  return true ;   }  else if  ( call variant context type  =  =  indel )   {  indel counter . if present ( counter  -  >  counter . increment ( truth and call states )  )  ;  return true ;   }   }  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,custom command line validation,@ override protected  string[]   (  )  {  io util . assert file is readable ( truth   vcf )  ;  io util . assert file is readable ( call   vcf )  ;  final boolean using intervals = this . intervals  !  =  null &&  ! this . intervals . is empty (  )  ;  fi
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,determine state,"final public static  truth and call states   ( final  variant context truth context final  string truth sample final  variant context call context final  string call sample final int min gq final int min dp final  boolean ignore filtered status )  {   truth state truth state = null ;   call state call state = null ;  final  genotype concordance state codes truth state code = get state code ( truth context truth sample min gq min dp )  ;  if  ( null  !  =  truth state code )   {  truth state =  genotype concordance states . truth map . get ( truth state code . ordinal (  )  )  ;   }   genotype concordance state codes call state code = get state code ( call context call sample min gq min dp )  ;  if  ( ignore filtered status && call state code  =  =   genotype concordance state codes . vc   filtered   code )   {  call state code = null ;   }  if  ( null  !  =  call state code )   {  call state =  genotype concordance states . call map . get ( call state code . ordinal (  )  )  ;   }  final  alleles alleles = normalize alleles ( truth state  =  =  null  ?  truth context : null truth sample call state  =  =  null  ?  call context : null call sample ignore filtered status )  ;  final  ordered set <  string >  all alleles = alleles . all alleles ;  final  string truth allele1 = alleles . truth allele1 ;  final  string truth allele2 = alleles . truth allele2 ;  final  string call allele1 = alleles . call allele1 ;  final  string call allele2 = alleles . call allele2 ;  if  ( null  =  =  truth state )   {  final int allele0idx = all alleles . index of ( truth allele1 )  ;  final int allele1idx = all alleles . index of ( truth allele2 )  ;  if  ( allele0idx  =  =  allele1idx )   {  truth state =  truth state . get hom ( allele0idx )  ;   }  else  {  truth state =  truth state . get var ( allele0idx allele1idx )  ;   }   }  if  ( null  =  =  call state )   {  final int allele0idx = all alleles . index of ( call allele1 )  ;  final int allele1idx = all alleles . index of ( call allele2 )  ;  if  ( allele0idx  =  =  allele1idx )   {  call state =  call state . get hom ( allele0idx )  ;   }  else  {  call state =  call state . get het ( allele0idx allele1idx )  ;   }  if  ( null  =  =  call state )   {  throw new  illegal state exception ( "" this should never happen .  .  .   could not classify the call variant: ""  +  call context . get genotype ( call sample )  )  ;   }   }  return new  truth and call states ( truth state call state )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,do work,@ override protected int   (  )  {  final  file summary metrics file = new  file ( output  +  summary   metrics   file   extension )  ;  final  file detailed metrics file = new  file ( output  +  detailed   metrics   file   extension )  ;  final  file con
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,get indel counter,public  genotype concordance counts   (  )  {  return indel counter ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,get snp counter,public  genotype concordance counts   (  )  {  return snp counter ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,get state code,private static  genotype concordance state codes   ( final  variant context ctx final  string sample final int min gq final int min dp )  {  if  ( ctx  =  =  null )  return missing   code ;  else if  ( ctx . is mixed (  )  )  return is   mixed   code ;  else if  ( ctx . is filtered (  )  )  return vc   filtered   code ;  else  {  final  genotype genotype = ctx . get genotype ( sample )  ;  if  ( genotype . is no call (  )  )  return no   call   code ;  else if  ( genotype . is filtered (  )  )  return gt   filtered   code ;  else if  (  ( genotype . getgq (  )   !  =   - 1 )  &&  ( genotype . getgq (  )   <  min gq )  )  return low   gq   code ;  else if  (  ( genotype . getdp (  )   !  =   - 1 )  &&  ( genotype . getdp (  )   <  min dp )  )  return low   dp   code ;  else if  (  ( genotype . is mixed (  )  )  )  return no   call   code ;   }  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,get string suffix,final static  string   ( final  string longer string final  string shorter string final  string error msg )  {  if  (  ! longer string . starts with ( shorter string )  )   {  throw new  illegal state exception ( error msg )  ;   }  return longer string . substring ( shorter string . length (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,get variant context writer,private  optional <  variant context writer >    ( final vcf file reader truth reader final vcf file reader call reader )  {  if  ( output   vcf )   {  final  file output vcf file = new  file ( output  +  output   vcf   file   extension )  ;  final  variant context writer builder builder = new  variant context writer builder (  )  . set output file ( output vcf file )  . set reference dictionary ( call reader . get file header (  )  . get sequence dictionary (  )  )  . set option (  options . allow   missing   fields   in   header )  . set option (  options . index   on   the   fly )  ;  final  variant context writer writer = builder . build (  )  ;  final  list <  string >  sample names =  arrays . as list ( output   vcf   call   sample   name output   vcf   truth   sample   name )  ;  final  set < vcf header line >  header lines = new  hash set <  >  (  )  ;  header lines . add all ( call reader . get file header (  )  . get meta data in input order (  )  )  ;  header lines . add all ( truth reader . get file header (  )  . get meta data in input order (  )  )  ;  header lines . add ( contingency   state   header   line )  ;  writer . write header ( new vcf header ( header lines sample names )  )  ;  return  optional . of ( writer )  ;   }  else  {  return  optional . empty (  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,index exists,private boolean   ( final  file vcf )  {  return  tribble . index file ( vcf )  . exists (  )  ||  tribble . tabix index file ( vcf )  . exists (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,main,public static void   ( final  string[] args )  {  new  genotype concordance (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,normalize alleles,"final protected static  alleles   ( final  variant context truth context final  string truth sample final  variant context call context final  string call sample final  boolean ignore filtered status )  {  final  genotype truth genotype  call genotype ;  if  ( truth context  =  =  null || truth context . is mixed (  )  || truth context . is filtered (  )  )  truth genotype = null ;  else truth genotype = truth context . get genotype ( truth sample )  ;  if  ( call context  =  =  null || call context . is mixed (  )  ||  (  ! ignore filtered status && call context . is filtered (  )  )  )  call genotype = null ;  else call genotype = call context . get genotype ( call sample )  ;   string truth ref =  ( truth genotype  !  =  null )   ?  truth context . get reference (  )  . get base string (  )  : null ;   string call ref =  ( call genotype  !  =  null )   ?  call context . get reference (  )  . get base string (  )  : null ;   string truth allele1 = null ;   string truth allele2 = null ;  if  ( null  !  =  truth genotype )   {  if  ( truth genotype . get alleles (  )  . size (  )   !  =  2 )   {  throw new  illegal state exception ( "" genotype for  variant  context: ""  +  truth context  +  "" does not have exactly 2 alleles"" )  ;   }  truth allele1 = truth genotype . get allele ( 0 )  . get base string (  )  ;  truth allele2 = truth genotype . get allele ( 1 )  . get base string (  )  ;   }   string call allele1 = null ;   string call allele2 = null ;  if  ( null  !  =  call genotype )   {  if  ( call genotype . get alleles (  )  . size (  )   !  =  2 )   {  throw new  illegal state exception ( "" genotype for  variant  context: ""  +  call context  +  "" does not have exactly 2 alleles"" )  ;   }  call allele1 = call genotype . get allele ( 0 )  . get base string (  )  ;  call allele2 = call genotype . get allele ( 1 )  . get base string (  )  ;   }  if  (  ( truth ref  !  =  null && call ref  !  =  null )  &&  (  ! truth ref . equals ( call ref )  )  )   {  if  ( truth ref . length (  )   <  call ref . length (  )  )   {  final  string suffix = get string suffix ( call ref truth ref "" ref alleles mismatch between: ""  +  truth context  +  "" and "" +  call context )  ;  final int insert idx = truth ref . length (  )  ;  truth allele1 = truth allele1 . equals (  allele . no   call   string )   ?  truth allele1 : splice or append string ( truth allele1 suffix insert idx )  ;  truth allele2 = truth allele2 . equals (  allele . no   call   string )   ?  truth allele2 : splice or append string ( truth allele2 suffix insert idx )  ;  truth ref = truth ref  +  suffix ;   }  else if  ( truth ref . length (  )   >  call ref . length (  )  )   {  final  string suffix = get string suffix ( truth ref call ref "" ref alleles mismatch between: ""  +  truth context  +  "" and "" +  call context )  ;  final int insert idx = call ref . length (  )  ;  call allele1 = call allele1 . equals (  allele . no   call   string )   ?  call allele1 : splice or append string ( call allele1 suffix insert idx )  ;  call allele2 = call allele2 . equals (  allele . no   call   string )   ?  call allele2 : splice or append string ( call allele2 suffix insert idx )  ;  call ref = call ref  +  suffix ;   }  else  {  throw new  illegal state exception ( "" ref alleles mismatch between: ""  +  truth context  +  "" and "" +  call context )  ;   }   }  final  ordered set <  string >  all alleles = new  ordered set <  string >  (  )  ;  if  ( truth genotype  !  =  null || call genotype  !  =  null )   {  all alleles . smart add ( truth genotype  =  =  null  ?  call ref : truth ref )  ;   }  if  ( null  !  =  truth genotype )   {  all alleles . smart add ( truth allele1 )  ;  all alleles . smart add ( truth allele2 )  ;   }  if  ( null  !  =  call genotype )   {  if  ( all alleles . index of ( call allele1 )   >  1 || all alleles . index of ( call allele2 )   >  1 )   {  all alleles . remove ( 2 )  ;  all alleles . remove ( 1 )  ;  all alleles . smart add ( truth allele2 )  ;  all alleles . smart add ( truth allele1 )  ;   }  all alleles . smart add ( call allele1 )  ;  all alleles . smart add ( call allele2 )  ;   }  return new  alleles ( all alleles truth allele1 truth allele2 call allele1 call allele2 )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,output detail metrics file,public static void   ( final  variant context .  type variant type final  metrics file <  genotype concordance detail metrics  ?  >  genotype concordance detail metrics file final  genotype concordance counts counter final  string truth sample name final  string call sample name final boolean missing sites hom ref final boolean output all rows )  {  final  genotype concordance scheme factory scheme factory = new  genotype concordance scheme factory (  )  ;  final  genotype concordance scheme scheme = scheme factory . get scheme ( missing sites hom ref )  ;  scheme . validate scheme (  )  ;  for  (  final  truth state truth state :  truth state . values (  )  )   {  for  (  final  call state call state :  call state . values (  )  )   {  final long count = counter . get count ( truth state call state )  ;  final  string contingency values = scheme . get contingency state string ( truth state call state )  ;  if  ( count  >  0 || output all rows )   {  final  genotype concordance detail metrics detail metrics = new  genotype concordance detail metrics (  )  ;  detail metrics . variant   type = variant type ;  detail metrics . truth   sample = truth sample name ;  detail metrics . call   sample = call sample name ;  detail metrics . truth   state = truth state ;  detail metrics . call   state = call state ;  detail metrics . count = count ;  detail metrics . contingency   values = contingency values ;  genotype concordance detail metrics file . add metric ( detail metrics )  ;   }   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,smart add,public boolean   ( final t o )  {  if  (  ! this . contains ( o )  )   {  return add ( o )  ;   }  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,smart index of,public int   ( final t o )  {  smart add ( o )  ;  return super . index of ( o )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,splice or append string,static  string   ( final  string destination final  string to insert final int insert idx )  {  if  ( insert idx  <  =  destination . length (  )  )   {  return destination . substring ( 0 insert idx )   +  to insert  +  destination . substring ( insert idx )  ;   }  else  {  if  ( destination . length (  )   >  0 && destination . substring ( destination . length (  )   -  1 )  . equals (  allele . span   del   string )  )   {  return destination ;   }  else  {  return destination  +  to insert ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,truth alleles,public  list <  allele >    (  )  {  if  ( all alleles . is empty (  )  || this . truth allele1  =  =  null )   {  return  collections . empty list (  )  ;   }  else  {  final  allele truth allele1 =  allele . create ( this . truth allele1 this . all alleles . index of ( this . truth allele1 )   =  =  0 )  ;  final  allele truth allele2 =  allele . create ( this . truth allele2 this . all alleles . index of ( this . truth allele2 )   =  =  0 )  ;  return  arrays . as list ( truth allele1 truth allele2 )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\GenotypeConcordance.java,write vcf tuple,"private void   ( final  vcf tuple tuple final  variant context writer writer final  genotype concordance scheme scheme )  {   variant context truth context = null  call context = null ;  final  list <  genotype >  genotypes = new  array list <  >  ( 2 )  ;  if  ( tuple . left variant context . is present (  )  )   {  truth context = tuple . left variant context . get (  )  ;   }  if  ( tuple . right variant context . is present (  )  )   {  call context = tuple . right variant context . get (  )  ;   }  if  ( truth context  !  =  null && truth context . is symbolic (  )  || call context  !  =  null && call context . is symbolic (  )  )   {  return ;   }  final  alleles alleles = normalize alleles ( truth context truth   sample call context call   sample ignore   filter   status )  ;  if  (  ! alleles . all alleles . is empty (  )  )   {  if  ( truth context  =  =  null && call context  =  =  null )   {  throw new  illegal state exception ( "" both truth and call contexts are null ! "" )  ;   }  final  variant context builder builder ;  final  list <  allele >  all alleles = alleles . as list (  )  ;  final  list <  allele >  truth alleles = alleles . truth alleles (  )  ;  final  list <  allele >  call alleles = alleles . call alleles (  )  ;  final  set <  allele >  site alleles = new  hash set <  >  (  )  ;  site alleles . add all ( all alleles )  ;  site alleles . remove (  allele . no   call )  ;  final  variant context initial context =  ( call context  =  =  null )   ?  truth context : call context ;  builder = new  variant context builder ( initial context . get source (  )  initial context . get contig (  )  initial context . get start (  )  initial context . get end (  )  site alleles )  ;  builder . compute end from alleles ( all alleles initial context . get start (  )  )  ;  builder . log10p error ( initial context . get log10p error (  )  )  ;  add to genotypes ( genotypes truth context truth   sample output   vcf   truth   sample   name all alleles truth alleles missing   sites   hom   ref )  ;  add to genotypes ( genotypes call context call   sample output   vcf   call   sample   name all alleles call alleles false )  ;  builder . genotypes ( genotypes )  ;  final  truth and call states state =  genotype concordance . determine state ( truth context truth   sample call context call   sample min   gq min   dp ignore   filter   status )  ;  final  contingency state[] state array = scheme . get concordance state array ( state . truth state state . call state )  ;  builder . attribute ( contingency   state   tag  arrays . as list ( state array )  )  ;  writer . add ( builder . make (  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\FindMendelianViolations.java,build detector,private  mendelian violation detector   (  )  {  return new  mendelian violation detector (  immutable set . copy of ( skip   chroms )   immutable set . copy of ( male   chroms )   immutable set . copy of ( female   chroms )  min   het   fraction min   gq min   dp generate trio metrics base (  )   immutable list . copy of ( par intervals . get (  )  )  progress logger )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\FindMendelianViolations.java,custom command line validation,@ override protected  string[]   (  )  {  final  list <  string >  errors = new  array list <  >  (  )  ;  final  set <  string >  sex chroms = new  hash set <  >  (  )  ;  sex chroms . add all ( female   chroms )  ;  sex chroms . retain all ( male   chro
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\FindMendelianViolations.java,do work,@ override protected int   (  )  {  final boolean output vcfs = vcf   dir  !  =  null ;  io util . assert file is readable ( input )  ;  io util . assert file is readable ( trios )  ;  io util . assert file is writable ( output )  ;  if  ( output vcfs )  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\FindMendelianViolations.java,generate trio metrics base,"private  list <  mendelian violation metrics >    (  )  {  final  list <  mendelian violation metrics >  metrics = new  array list <  >  (  )  ;  for  (  final  ped file .  ped trio trio : ped file . get (  )  . values (  )  )   {  final  mendelian violation metrics m = new  mendelian violation metrics (  )  ;  m . mother = trio . get maternal id (  )  ;  m . father = trio . get paternal id (  )  ;  m . offspring = trio . get individual id (  )  ;  m . family   id = trio . get family id (  )  ;  m . offspring   sex = trio . get sex (  )  ;  metrics . add ( m )  ;   }  final  set <  string >  all samples = new  hash set <  >  ( input header . get (  )  . get sample names in order (  )  )  ;  final  iterator <  mendelian violation metrics >  trio iterator = metrics . iterator (  )  ;  while  ( trio iterator . has next (  )  )   {  final  mendelian violation metrics m = trio iterator . next (  )  ;  final  set <  string >  trio =  collection util . make set ( m . mother m . father m . offspring )  ;  trio . remove all ( all samples )  ;  if  (  ! trio . is empty (  )  )   {  log . warn ( "" removing trio due to the following missing samples in vcf: ""  +  trio )  ;  trio iterator . remove (  )  ;   }   }  return metrics ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\FindMendelianViolations.java,parse interval lists,"private  set <  interval >    ( final  set <  string >  interval lists )  {  final  set <  interval >  intervals = new  hash set <  >  ( interval lists . size (  )  )  ;  for  (  final  string par : interval lists )   {  final  string[] splits1 = par . split ( "":"" )  ;  final  string[] splits2 = splits1[1] . split ( "" - "" )  ;  intervals . add ( new  interval ( splits1[0]  integer . parse int ( splits2[0] )   integer . parse int ( splits2[1] )  )  )  ;   }  return intervals ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\FindMendelianViolations.java,write all violations,"private void   ( final  mendelian violation detector .  result result )  {  if  ( vcf   dir  !  =  null )   {  log . info (  string . format ( "" writing family violation vc fs to %s / "" vcf   dir . get absolute path (  )  )  )  ;  final  variant context comparator vc comparator = new  variant context comparator ( input header . get (  )  . get contig lines (  )  )  ;  final  set < vcf header line >  header lines = new  linked hash set <  >  ( input header . get (  )  . get meta data in input order (  )  )  ;  header lines . add ( new vcf info header line (  mendelian violation detector . mendelian   violation   key 1 vcf header line type .  string "" type of mendelian violation . "" )  )  ;  header lines . add ( new vcf info header line (  mendelian violation detector . original   ac vcf header line count . a vcf header line type .  integer "" original ac"" )  )  ;  header lines . add ( new vcf info header line (  mendelian violation detector . original   af vcf header line count . a vcf header line type .  float "" original af"" )  )  ;  header lines . add ( new vcf info header line (  mendelian violation detector . original   an 1 vcf header line type .  integer "" original an"" )  )  ;  for  (  final  ped file .  ped trio trio : ped file . get (  )  . values (  )  )   {  final  file output file = new  file ( vcf   dir io util . make file name safe ( trio . get family id (  )   +  io util . vcf   file   extension )  )  ;  log . info (  string . format ( "" writing %s violation vcf to %s"" trio . get family id (  )  output file . get absolute path (  )  )  )  ;  final  variant context writer out = new  variant context writer builder (  )  . set output file ( output file )  . unset option ( index   on   the   fly )  . build (  )  ;  final vcf header new header = new vcf header ( header lines  collection util . make list ( trio . get maternal id (  )  trio . get paternal id (  )  trio . get individual id (  )  )  )  ;  final  tree set <  variant context >  ordered violations = new  tree set <  >  ( vc comparator )  ;  ordered violations . add all ( result . violations (  )  . get ( trio . get family id (  )  )  )  ;  out . write header ( new header )  ;  ordered violations . for each ( out::add )  ;  out . close (  )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\LiftoverVcf.java,add and track,private void   ( final  variant context to add final  variant context source )  {  track lifted variant contig ( lifted by source contig source . get contig (  )  )  ;  track lifted variant contig ( lifted by dest contig to add . get contig (  )  )  ;  sorter . add ( to add )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\LiftoverVcf.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is readable ( reference   sequence )  ;  io util . assert file is readable ( chain )  ;  io util . assert file is writable ( output )  ;  io util . a
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\LiftoverVcf.java,get reference file,@ override public  file   (  )  {  return reference   sequence ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\LiftoverVcf.java,make reference argument collection,"@ override protected  reference argument collection   (  )  {  return new  reference argument collection (  )  {  @ argument ( short name =  standard option definitions . reference   short   name common = false doc = "" the reference sequence  ( fasta )  f"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\LiftoverVcf.java,reject variant,private void   ( final  variant context ctx final  string reason )  {  rejects . add ( new  variant context builder ( ctx )  . filter ( reason )  . make (  )  )  ;  failed liftover +  +  ;  track lifted variant contig ( rejects by contig ctx . get contig (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\LiftoverVcf.java,track lifted variant contig,private void   (  map <  string  long >  map  string contig )  {   long val = map . get ( contig )  ;  if  ( val  =  =  null )   {  val = 0l ;   }  map . put ( contig  +  + val )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\LiftoverVcf.java,try to add variant,"private void   ( final  variant context vc final  reference sequence ref seq final  variant context source )  {  if  (  ! ref seq . get name (  )  . equals ( vc . get contig (  )  )  )   {  throw new  illegal state exception ( "" the contig of the  variant context  ""  +  vc . get contig (  )   +  ""  doesnt match the  reference sequence: "" +  ref seq . get name (  )  )  ;   }  boolean mismatches reference = false ;  for  (  final  allele allele : vc . get alleles (  )  )   {  if  ( allele . is reference (  )  )   {  final byte[] ref = ref seq . get bases (  )  ;  final  string ref string =  string util . bytes to string ( ref vc . get start (  )   -  1 vc . get end (  )   -  vc . get start (  )   +  1 )  ;  if  (  ! ref string . equals ignore case ( allele . get base string (  )  )  )   {  if  ( vc . is biallelic (  )  && vc . issnp (  )  && ref string . equals ignore case ( vc . get alternate allele ( 0 )  . get base string (  )  )  )   {  if  ( recover   swapped   ref   alt )   {  total tracked as swap ref alt +  +  ;  add and track (  liftover utils . swap ref alt ( vc tags   to   reverse tags   to   drop )  source )  ;  return ;   }  else  {  total tracked as swap ref alt +  +  ;   }   }  mismatches reference = true ;   }  break ;   }   }  if  ( mismatches reference )   {  rejects . add ( new  variant context builder ( source )  . filter ( filter   mismatching   ref   allele )  . attribute ( attempted   locus  string . format ( ""%s:%d - %d"" vc . get contig (  )  vc . get start (  )  vc . get end (  )  )  )  . make (  )  )  ;  failed allele check +  +  ;  track lifted variant contig ( rejects by contig source . get contig (  )  )  ;   }  else  {  add and track ( vc source )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MakeSitesOnlyVcf.java, make sites only vcf,public   (  )  {  create   index = true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MakeSitesOnlyVcf.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  final vcf file reader reader = new vcf file reader ( input false )  ;  final vcf header input vcf header = new vcf header 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MakeSitesOnlyVcf.java,main,public static void   ( final  string[] args )  {  new  make sites only vcf (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MakeSitesOnlyVcf.java,subset to samples with original annotations,private static  variant context   ( final  variant context ctx final  set <  string >  samples )  {  final  variant context builder builder = new  variant context builder ( ctx )  ;  final  genotypes context new genotypes = ctx . get genotypes (  )  . subset to samples ( samples )  ;  builder . alleles ( ctx . get alleles (  )  )  ;  return builder . genotypes ( new genotypes )  . make (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\MendelianViolationMetrics.java,calculate derived fields,@ override public void   (  )  {  total   mendelian   violations = num   diploid   denovo  +  num   homvar   homvar   het  +  num   homref   homvar   hom +  num   hom   het   hom +  num   haploid   denovo +  num   haploid   other +  num   other ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\MendelianViolationMetrics.java,get extension,"public static  string   (  )  {  return ""mendelian   violation   metrics"" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\MendelianViolationsByFamily.java, mendelian violations by family,public   (  )  {  super ( s  -  >  new  array list <  >  (  )  true )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MergeVcfs.java, merge vcfs,public   (  )  {  this . create   index = true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MergeVcfs.java,do work,@ override protected int   (  )  {  final  progress logger progress = new  progress logger ( log 10000 )  ;  final  list <  string >  sample list = new  array list <  string >  (  )  ;  input = io util . unroll files ( input io util . vcf   extensions )  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MergeVcfs.java,main,public static void   ( final  string[] argv )  {  new  merge vcfs (  )  . instance main with exit ( argv )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\MendelianViolationDetector.java, mendelian violation,  ( final  string desc )  {  this . description = desc ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\MendelianViolationDetector.java, mendelian violation detector,  ( final  set <  string >  skip   chroms final  set <  string >  male   chroms final  set <  string >  female   chroms final double min   het   fraction final int min   gq final int min   dp final  list <  mendelian violation metrics >  trios final  list <  interval >  par intervals final  progress logger logger )  {  skip   chroms = skip   chroms ;  male   chroms = male   chroms ;  female   chroms = female   chroms ;  min   het   fraction = min   het   fraction ;  min   gq = min   gq ;  min   dp = min   dp ;  this . trios = trios ;  this . par intervals = par intervals ;  this . logger = logger ;  family to violations = new  mendelian violations by family (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\MendelianViolationDetector.java, result,  ( final  collection <  mendelian violation metrics >  metrics final  mendelian violations by family violations )  {  this . metrics = metrics ;  this . violations = violations ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\MendelianViolationDetector.java,accumulate,@ override public void   ( final  variant context ctx )  {  logger . record ( ctx . get contig (  )  ctx . get start (  )  )  ;  final  string variant chrom = ctx . get contig (  )  ;  final int variant pos = ctx . get start (  )  ;  if  ( ctx . is filter
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\MendelianViolationDetector.java,get description,public  string   (  )  {  return description ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\MendelianViolationDetector.java,is in pseudo autosomal region,private boolean   ( final  string chr final int pos )  {  for  (  final  interval par : par intervals )   {  if  ( par . get contig (  )  . equals ( chr )  && pos  >  =  par . get start (  )  && pos  <  =  par . get end (  )  )  return true ;   }  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\MendelianViolationDetector.java,is mendelian violation,private boolean   ( final  genotype p1 final  genotype p2 final  genotype off )  {  final  allele off allele1 = off . get allele ( 0 )  ;  final  allele off allele2 = off . get allele ( 1 )  ;  if  ( p1 . get alleles (  )  . contains ( off allele1 )  && p2 . get alleles (  )  . contains ( off allele2 )  )  return false ;  if  ( p2 . get alleles (  )  . contains ( off allele1 )  && p1 . get alleles (  )  . contains ( off allele2 )  )  return false ;  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\MendelianViolationDetector.java,is variant,private boolean   ( final  genotype .  .  .  gts )  {  for  (  final  genotype gt : gts )   {  if  ( gt . is called (  )  &&  ! gt . is hom ref (  )  )  return true ;   }  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\MendelianViolationDetector.java,merge,public static  mendelian violation detector .  result   ( final  collection <  mendelian violation detector .  result >  results )  {  final  collection <  collection <  mendelian violation metrics >  >  metric collections = new  array list <  >  (  )  ;  final  collection <  mendelian violations by family >  violation collections = new  array list <  >  (  )  ;  for  (  final  mendelian violation detector .  result result : results )   {  metric collections . add ( result . metrics (  )  )  ;  violation collections . add ( result . violations (  )  )  ;   }  return new  mendelian violation detector .  result ( merge metrics ( metric collections )  merge violations ( violation collections )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\MendelianViolationDetector.java,merge metrics,"private static  collection <  mendelian violation metrics >    ( final  collection <  collection <  mendelian violation metrics >  >  results to reduce )  {  final  collection <  mendelian violation metrics >  all metrics = new  array list <  >  (  )  ;  results to reduce . for each ( all metrics::add all )  ;  final  map <  string  list <  mendelian violation metrics >  >  sample to metrics map = all metrics . stream (  )  . collect (  collectors . grouping by ( m  -  >   string . format ( ""%s|%s|%s|%s"" m . family   id m . father m . mother m . offspring )  )  )  ;  return sample to metrics map . values (  )  . stream (  )  . map ( a  -  >   (  mendelian violation metrics ) new  mendelian violation metrics (  )  . merge ( a )  )  . collect (  collectors .  <  mendelian violation metrics  list <  mendelian violation metrics >  > to collection (  array list <  mendelian violation metrics > ::new )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\MendelianViolationDetector.java,merge violations,private static  mendelian violations by family   ( final  collection <  mendelian violations by family >  results to reduce )  {  final  mendelian violations by family master family violations map = new  mendelian violations by family (  )  ;  for  (  final  map <  string  collection <  variant context >  >  child family violations map : results to reduce )   {  for  (  final  string child family : child family violations map . key set (  )  )   {  master family violations map . get ( child family )  . add all ( child family violations map . get ( child family )  )  ;   }   }  return master family violations map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\MendelianViolationDetector.java,metrics,public  collection <  mendelian violation metrics >    (  )  {  return metrics ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\MendelianViolationDetector.java,result,@ override public  result   (  )  {  return new  result ( trios family to violations )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\MendelianViolations\MendelianViolationDetector.java,violations, mendelian violations by family   (  )  {  return violations ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\PairedVariantSubContextIterator.java, paired variant sub context iterator,public   ( final  iterator <  variant context >  left iterator final  string left sample final  iterator <  variant context >  right iterator final  string right sample final sam sequence dictionary dict )  {  this . left iterator = new  peekable iterator <  >  ( left iterator )  ;  this . left sample = left sample ;  this . right iterator = new  peekable iterator <  >  ( right iterator )  ;  this . right sample = right sample ;  this . comparator = new  variant context comparator ( dict )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\PairedVariantSubContextIterator.java, vcf tuple,  ( final  variant context left variant context final  optional <  variant context >  right variant context )  {  this (  optional . of ( left variant context )  right variant context )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\PairedVariantSubContextIterator.java,has next,@ override public boolean   (  )  {  return this . left iterator . has next (  )  || this . right iterator . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\PairedVariantSubContextIterator.java,next,"@ override public  vcf tuple   (  )  {  if  (  ! has next (  )  )  throw new  illegal state exception ( ""next (  )  called while has next (  )  is false . "" )  ;  final  optional <  variant context >  left variant context = this . left iterator . has next"
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\PairedVariantSubContextIterator.java,remove,@ override public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantAccumulatorExecutor.java, multi exception,public   ( final  list <  throwable >  children exceptions )  {  this . children exceptions = children exceptions ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantAccumulatorExecutor.java, multi threaded chunk based,public   ( final int num threads final  variant iterator producer vc iterator producer final  variant processor .  accumulator generator < a r >  accumulator generator )  {  this . executor =  executors . new fixed thread pool ( num threads )  ;  this . vc iterators =  iterators . atomic iterator of ( vc iterator producer . iterators (  )  )  ;  this . num threads = num threads ;  this . accumulator generator = accumulator generator ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantAccumulatorExecutor.java, worker,  ( final  variant processor .  accumulator processor )  {  this . processor = processor ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantAccumulatorExecutor.java,accumulators,public synchronized  collection < a >    (  )  {  return  collections . unmodifiable collection ( accumulators )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantAccumulatorExecutor.java,await completion,"@ override public void   (  )  throws  interrupted exception  {  if  (  ! started )   {  throw new  illegal state exception ( "" this method can be called only after the executor has been started . "" )  ;   }  else  {  executor . await termination (  long "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantAccumulatorExecutor.java,get message,"@ override public  string   (  )  {  return "" children threads encountered exceptions:\n""  +   joiner . on ( ""\n\t"" )  . join (  fluent iterable . from ( children exceptions )  . transform ( throwable  -  >  throwable . get message (  )  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantAccumulatorExecutor.java,run,@ override public void   (  )  {  try  {   optional <  closeable iterator <  variant context >  >  reader maybe ;  while  (  ( reader maybe = vc iterators . next (  )  )  . is present (  )  )   {  final  closeable iterator <  variant context >  reader = r
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantAccumulatorExecutor.java,start,@ override public synchronized void   (  )  {  started = true ;  for  ( int i = 0 ;  i  <  num threads ;  i +  +  )   {  final a accumulator = accumulator generator . build (  )  ;  accumulators . add ( accumulator )  ;  executor . submit ( new  worker ( 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\util\PredicateFilterDecoratingClosableIterator.java, predicate filter decorating closable iterator,"public   ( final  closeable iterator < t >  underlying iterator final  collection <  predicate < t >  >  predicates )  {   preconditions . check argument (  ! predicates . is empty (  )  ""predicates must not be empty"" )  ;   iterator < t >  nested predicate iterator = underlying iterator ;  for  (  final  predicate < t >  predicate : predicates )   {  nested predicate iterator =  iterators . filter ( nested predicate iterator predicate )  ;   }  filtered iterator = nested predicate iterator ;  this . underlying iterator = underlying iterator ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\util\PredicateFilterDecoratingClosableIterator.java,close,@ override public void   (  )  {  underlying iterator . close (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\util\PredicateFilterDecoratingClosableIterator.java,has next,@ override public boolean   (  )  {  return filtered iterator . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\util\PredicateFilterDecoratingClosableIterator.java,next,@ override public t   (  )  {  return filtered iterator . next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\util\PredicateFilterDecoratingClosableIterator.java,remove,@ override public void   (  )  {  underlying iterator . remove (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantIteratorProducer.java, non unique variant predicate,  ( final  vcf file segment source segment )  {  this . source segment = source segment ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantIteratorProducer.java, threadsafe,"  ( final  vcf file segment generator segmenter final  list <  file >  vcfs final  interval list intervals )  {  if  ( intervals  !  =  null )   {  final  list <  interval >  uniques = intervals . uniqued ( false )  . get intervals (  )  ;  this . intervals of interest detector = new  overlap detector <  >  ( 0 0 )  ;  intervals of interest detector . add all ( uniques uniques )  ;   }  else  {  intervals of interest detector = null ;   }  final  vcf file segment generator interesting segment segmenter = intervals of interest detector  =  =  null  ?  segmenter :  vcf file segment generator . excluding non overlaps ( segmenter intervals of interest detector )  ;  segments = new  array list <  >  (  )  ;  for  (  final  file vcf : vcfs )   {  for  (  final  vcf file segment segment : interesting segment segmenter . for vcf ( vcf )  )   {  segments . add ( segment )  ;   }   }  for  (  final  vcf file segment segment : segments )   {  final  interval segment interval = segment . corresponding interval (  )  ;  final  overlap detector <  vcf file segment >  vcf specific detector = multi segment detector per file . get ( segment . vcf (  )  )  ;  if  ( vcf specific detector . get overlaps ( segment interval )  . is empty (  )  )   {  vcf specific detector . add lhs ( segment new  interval ( segment . contig (  )  segment . start (  )  segment . stop (  )  )  )  ;   }  else  {  throw new  illegal argument exception (  string . format ( "" provided segmenting strategy produced overlapping intervals ;  %s overlaps with: %s"" segment  joiner . on ( ""  "" )  . join ( vcf specific detector . get overlaps ( segment interval )  )  )  )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantIteratorProducer.java,apply,@ override public boolean   ( final  variant context vc )  {  final boolean include =  ! intervals of interest detector . get overlaps ( new  interval ( vc . get contig (  )  vc . get start (  )  vc . get end (  )  )  )  . is empty (  )  ;  if  (  ! inclu
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantIteratorProducer.java,by hundred megabase chunks,public static  variant iterator producer   ( final  list <  file >  vcfs )  {  return new  threadsafe (  vcf file segment generator . by whole contig subdividing with width ( one   hundred   million )  vcfs null )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantIteratorProducer.java,by hundred megabase chunks with on the fly filtering by interval,public static  variant iterator producer   ( final  list <  file >  vcfs final  interval list interval list )  {  return new  threadsafe (  vcf file segment generator . by whole contig subdividing with width ( one   hundred   million )  vcfs interval list )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantIteratorProducer.java,close,@ override public void   (  )  {  final  iterator < vcf file reader >  i = all readers . iterator (  )  ;  while  ( i . has next (  )  )   {  i . next (  )  . close (  )  ;  i . remove (  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantIteratorProducer.java,initial value,@ override protected  collection util .  defaulting map <  file vcf file reader >    (  )  {  return new  collection util .  defaulting map <  >  ( file  -  >   {  final vcf file reader reader = new vcf file reader ( file )  ;  log . debug (  string . for
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantIteratorProducer.java,iterator for segment,private  closeable iterator <  variant context >    ( final  vcf file segment segment )  {  final  closeable iterator <  variant context >  query = local vcf file readers . get (  )  . get ( segment . vcf (  )  )  . query ( segment . contig (  )  segment . start (  )  segment . stop (  )  )  ;  final  collection <  predicate <  variant context >  >  filters = new  array list <  >  (  )  ;  if  ( intervals of interest detector  !  =  null )   {  filters . add ( new  overlaps predicate (  )  )  ;   }  filters . add ( new  non unique variant predicate ( segment )  )  ;  return new  predicate filter decorating closable iterator <  >  ( query filters )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantIteratorProducer.java,iterators,@ override public  iterable <  closeable iterator <  variant context >  >    (  )  {  return  fluent iterable . from ( segments )  . transform ( this::iterator for segment )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\RenameSampleInVcf.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  final vcf file reader in = new vcf file reader ( input )  ;  final vcf header header = in . get file header (  )  ;  if  (
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\RenameSampleInVcf.java,main,public static void   ( final  string[] args )  {  new  rename sample in vcf (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantProcessor.java, builder,  ( final  accumulator generator < a r >  accumulator generator )  {  this . accumulator generator = accumulator generator ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VariantProcessor.java, variant processor,  ( final  result merger < result >  merger final  variant accumulator executor < accumulator result >  executor )  {  this . merger = merger ;  this . executor = executor ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegment.java, sequence sized chunk,private   ( final sam sequence record sequence final  file vcf )  {  this . sequence = sequence ;  this . vcf = vcf ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegment.java,contig,@ override public  string   (  )  {  return sequence . get sequence name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegment.java,corresponding interval,public  interval   (  )  {  return new  interval ( contig (  )  start (  )  stop (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegment.java,of whole sequence,static  vcf file segment   ( final sam sequence record sequence final  file vcf )  {  return new  sequence sized chunk ( sequence vcf )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegment.java,start,@ override public int   (  )  {  return 1 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegment.java,stop,@ override public int   (  )  {  return sequence . get sequence length (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegment.java,to string,"@ override public  string   (  )  {  return vcf (  )  . get absolute path (  )   +  ""::""  +  sequence . get sequence name (  )  +  "":1 - "" +  sequence . get sequence length (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegment.java,vcf,@ override public  file   (  )  {  return vcf ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegmentGenerator.java, vcf file segment subdivider,private   ( final  vcf file segment basis )  {  this . basis = basis ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegmentGenerator.java, width limiting decorator,private   ( final  vcf file segment generator underlying strategy final long maximum width )  {  this . underlying strategy = underlying strategy ;  this . width = maximum width  -  1 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegmentGenerator.java,apply,@ override public  iterable <  ?  extends  vcf file segment >    ( final  vcf file segment vcf file segment )  {  return new  vcf file segment subdivider ( vcf file segment )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegmentGenerator.java,by whole contig subdividing with width,public static  vcf file segment generator   ( final long segment width )  {  return  width limiting decorator . wrapping (  by whole contig . get instance (  )  segment width )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegmentGenerator.java,contig,@ override public  string   (  )  {  return basis . contig (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegmentGenerator.java,excluding non overlaps,"public static  < t >  vcf file segment generator   ( final  vcf file segment generator strategy final  overlap detector < t >  overlaps )  {  return new  vcf file segment generator (  )  {  @ override public  iterable <  vcf file segment >  for vcf (  final  file vcf )  {  return  fluent iterable . from ( strategy . for vcf ( vcf )  )  . filter ( new  predicate <  vcf file segment >  (  )  {  @ override public boolean apply (  final  vcf file segment segment )  {  final boolean keep =  ! overlaps . get overlaps ( new  interval ( segment . contig (  )  segment . start (  )  segment . stop (  )  )  )  . is empty (  )  ;  if  (  ! keep )   {  log . debug (  string . format ( "" ignoring segment because it does not overlap with detector  %s::%s:%s - %s"" segment . vcf (  )  . get name (  )  segment . contig (  )  segment . start (  )  segment . stop (  )  )  )  ;   }  return keep ;   }   }   )  ;   }   }   ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegmentGenerator.java,for vcf,@ override public  iterable <  vcf file segment >    ( final  file vcf )  {  return  fluent iterable . from ( underlying strategy . for vcf ( vcf )  )  . transform and concat ( new  function <  vcf file segment  iterable <  ?  extends  vcf file segment > 
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegmentGenerator.java,get instance,public static  by whole contig   (  )  {  return singleton ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegmentGenerator.java,has next,@ override public boolean   (  )  {  return next start  <  =  basis . stop (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegmentGenerator.java,iterator,@ override public  iterator <  vcf file segment >    (  )  {  return new  iterator <  vcf file segment >  (  )  {  int next start = basis . start (  )  ;  @ override public boolean has next (  )  {  return next start  <  =  basis . stop (  )  ;   }  @ ove
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegmentGenerator.java,next,@ override public  vcf file segment   (  )  {  final int start = next start ;  final  vcf file segment ret = new  vcf file segment (  )  {  @ override public int start (  )  {  return start ;   }  @ override public int stop (  )  {  return  ints . checked
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegmentGenerator.java,read sequences,private static  list < sam sequence record >    ( final  file vcf )  {  final vcf file reader reader = new vcf file reader ( vcf )  ;  final vcf header header = reader . get file header (  )  ;  final sam sequence dictionary dict = header . get sequence dictionary (  )  ;  reader . close (  )  ;  return dict . get sequences (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegmentGenerator.java,remove,@ override public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegmentGenerator.java,start,@ override public int   (  )  {  return start ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegmentGenerator.java,stop,@ override public int   (  )  {  return  ints . checked cast (  math . min ( start  +  width basis . stop (  )  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegmentGenerator.java,vcf,@ override public  file   (  )  {  return basis . vcf (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\processor\VcfFileSegmentGenerator.java,wrapping,public static  width limiting decorator   ( final  vcf file segment generator basis final long maximum width )  {  return new  width limiting decorator ( basis maximum width )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\SortVcf.java, sort vcf,public   (  )  {  this . create   index = true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\SortVcf.java,collect file readers and headers,"private void   ( final  list <  string >  sample list sam sequence dictionary sam sequence dictionary )  {  for  (  final  file input : input )   {  final vcf file reader in = new vcf file reader ( input false )  ;  final vcf header header = in . get file header (  )  ;  final sam sequence dictionary dict = in . get file header (  )  . get sequence dictionary (  )  ;  if  ( dict  =  =  null || dict . is empty (  )  )   {  if  ( null  =  =  sam sequence dictionary )   {  throw new  illegal argument exception ( "" sequence dictionary was missing or empty for the vcf: ""  +  input . get absolute path (  )   +  ""  please add a sequence dictionary to this vcf or specify sequence   dictionary . "" )  ;   }  header . set sequence dictionary ( sam sequence dictionary )  ;   }  else  {  if  ( null  =  =  sam sequence dictionary )   {  sam sequence dictionary = dict ;   }  else  {  try  {  sam sequence dictionary . assert same dictionary ( dict )  ;   }  catch  (  final  assertion error e )   {  throw new  illegal argument exception ( e )  ;   }   }   }  if  ( sample list . is empty (  )  )   {  sample list . add all ( header . get sample names in order (  )  )  ;   }  else  {  if  (  ! sample list . equals ( header . get sample names in order (  )  )  )   {  throw new  illegal argument exception ( "" input file ""  +  input . get absolute path (  )   +  "" has sample names that don't match the other files . "" )  ;   }   }  input readers . add ( in )  ;  input headers . add ( header )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\SortVcf.java,do work,@ override protected int   (  )  {  final  list <  string >  sample list = new  array list <  string >  (  )  ;  for  (  final  file input : input )  io util . assert file is readable ( input )  ;  if  ( sequence   dictionary  !  =  null )  io util . asse
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\SortVcf.java,main,public static void   ( final  string[] args )  {  new  sort vcf (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\SortVcf.java,sort inputs,"private  sorting collection <  variant context >    ( final  list < vcf file reader >  readers final vcf header output header )  {  final  progress logger read progress = new  progress logger ( log 25000 ""read"" ""records"" )  ;  final  sorting collection <  variant context >  sorter =  sorting collection . new instance (  variant context . class new vcf record codec ( output header validation   stringency  !  =   validation stringency . strict )  output header . getvcf record comparator (  )  max   records   in   ram tmp   dir )  ;  int reader count = 1 ;  for  (  final vcf file reader reader : readers )   {  log . info ( "" reading entries from input file ""  +  reader count )  ;  for  (  final  variant context variant context : reader )   {  sorter . add ( variant context )  ;  read progress . record ( variant context . get contig (  )  variant context . get start (  )  )  ;   }  reader . close (  )  ;  reader count +  +  ;   }  return sorter ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\SortVcf.java,write sorted output,"private void   ( final vcf header output header final  sorting collection <  variant context >  sorted output )  {  final  progress logger write progress = new  progress logger ( log 25000 ""wrote"" ""records"" )  ;  final  enum set <  options >  options = create   index  ?   enum set . of (  options . index   on   the   fly )  :  enum set . none of (  options . class )  ;  final  variant context writer out = new  variant context writer builder (  )  . set reference dictionary ( output header . get sequence dictionary (  )  )  . set options ( options )  . set output file ( output )  . build (  )  ;  out . write header ( output header )  ;  for  (  final  variant context variant context : sorted output )   {  out . add ( variant context )  ;  write progress . record ( variant context . get contig (  )  variant context . get start (  )  )  ;   }  out . close (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\VcfFormatConverter.java, vcf format converter,public   (  )  {  this . create   index = true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\VcfFormatConverter.java,do work,@ override protected int   (  )  {  final  progress logger progress = new  progress logger ( log 10000 )  ;  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  final vcf file reader reader = new vcf file reade
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\VcfFormatConverter.java,main,public static void   ( final  string[] argv )  {  new  vcf format converter (  )  . instance main with exit ( argv )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\UpdateVcfSequenceDictionary.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is readable ( sequence   dictionary )  ;  io util . assert file is writable ( output )  ;  final sam sequence dictionary sam sequence dictionary = sa
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\UpdateVcfSequenceDictionary.java,main,public static void   ( final  string[] args )  {  new  update vcf sequence dictionary (  )  . instance main with exit ( args )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\SplitVcfs.java, split vcfs,public   (  )  {  this . create   index = true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\SplitVcfs.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  final  progress logger progress = new  progress logger ( log 10000 )  ;  final vcf file reader file reader = new vcf file reader ( input )  ;  final vcf header file header
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\SplitVcfs.java,main,public static void   ( final  string[] argv )  {  new  split vcfs (  )  . instance main with exit ( argv )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\VcfUtils.java,is variant file,static public boolean   ( final  file file )  {  final  string name = file . get name (  )  ;  return name . ends with ( io util . vcf   file   extension )  || name . ends with ( io util . compressed   vcf   file   extension )  || name . ends with ( io util . bcf   file   extension )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\VcfToIntervalList.java,do work,@ override protected int   (  )  {  io util . assert file is readable ( input )  ;  io util . assert file is writable ( output )  ;  final  interval list interval list = vcf file reader . from vcf ( input include   filtered )  ;  interval list . uniqued (
C:\Users\User\Desktop\Thesis\picard\src\main\java\picard\vcf\VcfToIntervalList.java,main,public static void   ( final  string[] argv )  {  new  vcf to interval list (  )  . instance main with exit ( argv )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\CollectSequencingArtifactMetricsTest.java,are metrics equal,private boolean   ( final  file expected base final  file actual base final  string extension )  {  return  metrics file . are metrics equal ( new  file ( expected base  +  extension )  new  file ( actual base  +  extension )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\CollectSequencingArtifactMetricsTest.java,assert all files equal,"private void   ( final  file expected base final  file actual base )  {   assert . assert true ( are metrics equal ( expected base actual base  sequencing artifact metrics . pre   adapter   summary   ext )  "" pre -  adapter summary files differ . "" )  ;   assert . assert true ( are metrics equal ( expected base actual base  sequencing artifact metrics . pre   adapter   details   ext )  "" pre -  adapter details files differ . "" )  ;   assert . assert true ( are metrics equal ( expected base actual base  sequencing artifact metrics . bait   bias   summary   ext )  "" bait -  bias summary files differ . "" )  ;   assert . assert true ( are metrics equal ( expected base actual base  sequencing artifact metrics . bait   bias   details   ext )  "" bait - bias details files differ . "" )  ;   assert . assert true ( are metrics equal ( expected base actual base  sequencing artifact metrics . error   summary   ext )  "" error - summary files differ . "" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\CollectSequencingArtifactMetricsTest.java,get command line program name,@ override public  string   (  )  {  return  collect sequencing artifact metrics . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\ConvertSequencingArtifactToOxoGTest.java,are metrics equal,private static  < t extends  metric base > boolean   (  metrics file < t  ?  >  metric file1  metrics file < t  ?  >  metric file2 final  string[] columns to compare )  throws  no such field exception  {  if  ( metric file1 . get metrics (  )  . size (  )   !  =  metric file2 . get metrics (  )  . size (  )  )  return false ;  if  ( metric file1 . get metrics (  )  . is empty (  )  )  return true ;  t first metric1 = metric file1 . get metrics (  )  . get ( 0 )  ;  for  (  final  string column : columns to compare )   {  if  (  ! metric file1 . get metrics column labels (  )  . contains ( column )  )  return false ;  if  (  ! metric file2 . get metrics column labels (  )  . contains ( column )  )  return false ;  final  field f = first metric1 . get class (  )  . get field ( column )  ;   list <  string >  metric1 values = metric file1 . get metrics (  )  . stream (  )  . map ( m  -  >   {  try  {  return f . get ( m )  . to string (  )  ;   }  catch  (   illegal access exception e )   {  e . print stack trace (  )  ;   }  return null ;   }   )  . collect (  collectors . to list (  )  )  ;   list <  string >  metric2 values = metric file2 . get metrics (  )  . stream (  )  . map ( m  -  >   {  try  {  return f . get ( m )  . to string (  )  ;   }  catch  (   illegal access exception e )   {  e . print stack trace (  )  ;   }  return null ;   }   )  . collect (  collectors . to list (  )  )  ;  if  (  ! metric1 values . equals ( metric2 values )  )  return false ;   }  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\CollectSequencingArtifactMetricsTest.java,run analysis,"private void   ( final  string test case final  string .  .  .  extra args )  throws io exception  {  final  file actual = new  file ( global temp output dir test case )  ;  final  file expected = new  file ( test   cases test case )  ;  final  map <  string  string >  args = new  hash map <  string  string >  (  )  ;  args . put ( ""input"" test   sam . get absolute path (  )  )  ;  args . put ( ""output"" actual . get absolute path (  )  )  ;  args . put ( ""reference   sequence"" reference . get absolute path (  )  )  ;  args . put ( ""minimum   insert   size"" ""30"" )  ;  args . put ( ""maximum   insert   size"" ""30"" )  ;  args . put ( ""context   size"" ""0"" )  ;  for  (  final  string extra arg : extra args )   {  final  string[] kv = extra arg . split ( "" = "" )  ;  args . put ( kv[0] kv[1] )  ;   }  run picard command line ( args )  ;  assert all files equal ( expected actual )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\CollectSequencingArtifactMetricsTest.java,set up,"@ before test public void   (  )  throws io exception  {  global temp output dir = io util . create temp dir ( ""artifact metrics . "" "" . tmp"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\CollectSequencingArtifactMetricsTest.java,tear down,@ after test public void   (  )  throws io exception  {  io util . delete directory tree ( global temp output dir )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\CollectSequencingArtifactMetricsTest.java,test context,"@ test public void   (  )  throws io exception  {  run analysis ( ""with   context"" ""context   size = 1"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\CollectSequencingArtifactMetricsTest.java,test db snp,"@ test public void   (  )  throws io exception  {  run analysis ( ""with   dbsnp"" ""db   snp = ""  +  db   snp )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\CollectSequencingArtifactMetricsTest.java,test interval list,"@ test public void   (  )  throws io exception  {  run analysis ( ""with   intervals"" ""intervals = ""  +  intervals )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\CollectSequencingArtifactMetricsTest.java,test larger context,"@ test public void   (  )  throws io exception  {  run analysis ( ""with   larger   context"" ""context   size = 2"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\CollectSequencingArtifactMetricsTest.java,test no bq cutoff,"@ test public void   (  )  throws io exception  {  run analysis ( ""no   bq   cutoff"" ""minimum   quality   score = 0"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\CollectSequencingArtifactMetricsTest.java,test no mq cutoff,"@ test public void   (  )  throws io exception  {  run analysis ( ""no   mq   cutoff"" ""minimum   mapping   quality = 0"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\CollectSequencingArtifactMetricsTest.java,test unmapped mate,"@ test public void   (  )  throws io exception  {  run analysis ( ""unmapped   mate"" ""minimum   insert   size = 0"" ""maximum   insert   size = 0"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\ConvertSequencingArtifactToOxoGTest.java,test equivalence,"@ test public void   (  )  throws io exception   no such field exception  {  final  file input = sam   file ;  final  file output file oxog =  file . create temp file ( ""test"" "" . oxo   g   metrics"" test   data   dir )  ;  output file oxog . delete on exi"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\AbstractWgsMetricsCollectorTest.java,test for collector without data,@ test public void   (  )  {  long[] template qual histogram = new long[127] ;  long[] template histogram array = new long[11] ;   collect wgs metrics collect wgs metrics = new  collect wgs metrics (  )  ;   abstract wgs metrics collector collector = new 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\AbstractWgsMetricsCollectorTest.java,test for exception with negative coverage,@ test ( expected exceptions =  illegal argument exception . class )  public void   (  )  {   collect wgs metrics collect wgs metrics = new  collect wgs metrics (  )  ;  new  abstract wgs metrics collector ( collect wgs metrics  - 10 create interval list 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\AbstractWgsMetricsCollectorTest.java,test for ref basen,"@ test public void   (  )  {  byte[] ref basis =  { 'a' 'c' 'c' 't' 'a' 'n' 'g' 't' 'n' 'n' }  ;   reference sequence ref = new  reference sequence ( ""test"" 0 ref basis )  ;   collect wgs metrics collect wgs metrics = new  collect wgs metrics (  )  ;   ab"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\AbstractWgsMetricsCollectorTest.java,test for set counter,@ test public void   (  )  {   collect wgs metrics collect wgs metrics = new  collect wgs metrics (  )  ;   abstract wgs metrics collector collector = new  abstract wgs metrics collector ( collect wgs metrics 10 create interval list (  )  )  {  @ override
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\AbstractWgsMetricsCollectorTest.java,test for stop,@ test public void   (  )  {   collect wgs metrics collect wgs metrics = new  collect wgs metrics (  )  ;  collect wgs metrics . stop   after = 10 ;   abstract wgs metrics collector collector = new  abstract wgs metrics collector ( collect wgs metrics 10 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\TransitionTest.java,all transitions,@ data provider public  iterator <  object[] >    (  )  {  return  stream . of (  transition . values (  )  )  . map ( t  -  >  new  object[] { t }  )  . iterator (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\TransitionTest.java,bad bases,@ data provider public  object[][]   (  )  {  return new  object[][] {  {  character . min   value }   {  transition .  base . a . base  -  1 }   { 'z' }   {  character . max   value }  }  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\TransitionTest.java,test identity after two complement,"@ test ( data provider = ""all transitions"" )  public void   ( final  transition transition )  {   assert . assert equals ( transition . complement (  )  . complement (  )  transition )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\TransitionTest.java,test invalid call,"@ test ( data provider = ""bad bases"" expected exceptions =  illegal argument exception . class )  public void   ( final char wrong base )  {   transition . transition of ( 'a' wrong base )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\TransitionTest.java,test invalid ref,"@ test ( data provider = ""bad bases"" expected exceptions =  illegal argument exception . class )  public void   ( final char wrong base )  {   transition . transition of ( wrong base 'a' )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\artifacts\TransitionTest.java,test transition of self,"@ test ( data provider = ""all transitions"" )  public void   ( final  transition transition )  {  final  transition of self =  transition . transition of ( transition . ref (  )  transition . call (  )  )  ;   assert . assert equals ( of self transition ) "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectGcBiasMetricsTest.java,build,"public  file   ( final  list < sam record set builder >  set builder final  file unsorted sam final sam file header header )  throws io exception  {  final  file sorted sam =  vcf test utils . create temporary indexed file ( "" collect gc bias"" "" . bam"" )  ;  final sam file writer writer = new sam file writer factory (  )  . set create index ( true )  . makebam writer ( header false unsorted sam )  ;  for  (  final sam record set builder sub set builder : set builder )   {  for  (  final sam record record : sub set builder )   {  writer . add alignment ( record )  ;   }   }  writer . close (  )  ;  final  sort sam sorter = new  sort sam (  )  ;  final  string[] args = new  string[] { ""input = ""  +  unsorted sam . get absolute path (  )  ""output = ""  +  sorted sam . get absolute path (  )  ""sort   order = coordinate"" }  ;  sorter . instance main ( args )  ;  return sorted sam ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectGcBiasMetricsTest.java,get command line program name,public  string   (  )  {  return  collect gc bias metrics . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectGcBiasMetricsTest.java,run checking noseq test,"@ test public void   (  )  throws io exception  {  final  file input = new  file ( ""testdata / picard / metrics / chrm   no   seq . sam"" )  ;  final  file summary outfile =  file . create temp file ( ""test"" "" . gc   bias . summary   metrics"" )  ;  final  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectGcBiasMetricsTest.java,run gc bias,"public void   ( final  file input final  string reference file final  file summary outfile final  file details outfile final boolean non dups )  throws io exception  {  final  file pdf =  file . create temp file ( ""test"" "" . pdf"" )  ;  pdf . delete on exit (  )  ;  final int window size = 100 ;  final double min gen fraction = 1 . 0e - 5 ;  final boolean bi sulfite seq = false ;  final boolean assume sorted = false ;  final  string[] args = new  string[] { ""input = ""  +  input . get absolute path (  )  ""output = ""  +  details outfile . get absolute path (  )  ""reference   sequence = ""  +  reference file ""summary   output = ""  +  summary outfile . get absolute path (  )  ""chart   output = ""  +  pdf . get absolute path (  )  ""scan   window   size = ""  +  window size ""minimum   genome   fraction = ""  +  min gen fraction ""is   bisulfite   sequenced = ""  +  bi sulfite seq ""level = all   reads"" ""level = sample"" ""level = read   group"" ""assume   sorted = ""  +  assume sorted ""also   ignore   duplicates = ""  +  non dups }  ;  run picard command line ( args )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectGcBiasMetricsTest.java,run gc bias multi level test,"@ test public void   (  )  throws io exception  {  final  file outfile =  file . create temp file ( ""test"" "" . gc   bias . summary   metrics"" )  ;  final  file details outfile =  file . create temp file ( ""test"" "" . gc   bias . detail   metrics"" )  ;  out"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectGcBiasMetricsTest.java,run non dups comparison test,"@ test public void   (  )  throws io exception  {  final  file input file with duplicates = new  file ( ""testdata / picard / metrics / chrm reads . sam"" )  ;  final  file details outfile =  file . create temp file ( ""test"" "" . gc   bias   detail   metrics"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectGcBiasMetricsTest.java,run windows comparison test,"@ test public void   (  )  throws io exception  {  final  file outfile =  file . create temp file ( ""test"" "" . gc   bias   summary   metrics"" )  ;  final  file all chr out file =  file . create temp file ( ""test all chr"" "" . gc   bias   summary   metrics"""
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectGcBiasMetricsTest.java,setup builder,"@ before test void   (  )  throws io exception  {  temp sam file chrm   o =  vcf test utils . create temporary indexed file ( "" collect gc bias"" "" . bam"" )  ;  temp sam file all chr =  vcf test utils . create temporary indexed file ( "" collect gc bias"" "" "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectGcBiasMetricsTest.java,setup test,"public void   ( final int id final  string read group id final sam read group record read group record final  string sample final  string library final sam file header header final sam record set builder set builder )  throws io exception  {  final  string separator = "":"" ;  final int contig1 = 0 ;  final int contig2 = 1 ;  read group record . set sample ( sample )  ;  read group record . set platform ( platform )  ;  read group record . set library ( library )  ;  read group record . set platform unit ( read group id )  ;  header . add read group ( read group record )  ;  set builder . set read group ( read group record )  ;  set builder . set use nm flag ( true )  ;  set builder . set header ( header )  ;  final int max = 800 ;  final int min = 1 ;  final  random rg = new  random ( 5 )  ;  for  ( int i = 0 ;  i  <  num   reads ;  i +  +  )   {  final int start = rg . next int ( max )   +  min ;  final  string new read name = read   name  +  separator  +  id +  separator +  i ;  if  ( i  !  =  num   reads  -  1 )   {  set builder . add pair ( new read name contig1 start  +  id start  +  id  +  length )  ;   }  else  {  set builder . add pair ( new read name contig2 start  +  id start  +  id  +  length )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectGcBiasMetricsTest.java,setup test,"public void   ( final int id final  string read group id final sam read group record read group record final  string sample final  string library final sam file header header final sam record set builder set builder )  throws io exception  {  final  string separator = "":"" ;  final int contig1 = 0 ;  final int contig2 = 1 ;  final int contig3 = 2 ;  read group record . set sample ( sample )  ;  read group record . set platform ( platform )  ;  read group record . set library ( library )  ;  read group record . set platform unit ( read group id )  ;  set builder . set read group ( read group record )  ;  set builder . set use nm flag ( true )  ;  set builder . set header ( header )  ;  final int max = 800 ;  final int min = 1 ;  final  random rg = new  random ( 5 )  ;  for  ( int i = 0 ;  i  <  num   reads ;  i +  +  )   {  final int start = rg . next int ( max )   +  min ;  final  string new read name = read   name  +  separator  +  id +  separator +  i ;  if  ( i  <  =  num   reads  /  3 )   {  set builder . add pair ( new read name contig1 start  +  id start  +  id  +  length )  ;   }  else if  ( i  <   ( num   reads  -   ( num   reads  /  3 )  )  )   {  set builder . add pair ( new read name contig2 start  +  id start  +  id  +  length )  ;   }  else  {  set builder . add pair ( new read name contig3 start  +  id start  +  id  +  length )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectInsertSizeMetricsTest.java,get command line program name,public  string   (  )  {  return  collect insert size metrics . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectInsertSizeMetricsTest.java,test,"@ test public void   (  )  throws io exception  {  final  file input = new  file ( test   data   dir ""insert   size   metrics   test . sam"" )  ;  final  file outfile =  file . create temp file ( ""test"" "" . insert   size   metrics"" )  ;  final  file pdf = "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectInsertSizeMetricsTest.java,test histogram width is set properly,"@ test public void   (  )  throws io exception  {  final  file input = new  file ( test   data   dir ""insert   size   metrics   test . sam"" )  ;  final  file outfile =  file . create temp file ( ""test"" "" . insert   size   metrics"" )  ;  final  file pdf = "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectInsertSizeMetricsTest.java,test multiple orientations for histogram,"@ test public void   (  )  throws io exception  {  final  file output = new  file ( ""testdata / picard / analysis / directed /  collect insert size metrics"" ""multiple   orientation . sam . insert   size   metrics"" )  ;  final  file pdf =  file . create te"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectInsertSizeMetricsTest.java,test wdith of metrics,"@ test public void   (  )  throws io exception  {  final  file test sam file =  file . create temp file ( "" collect insert size metrics"" "" . bam"" test   data   dir )  ;  test sam file . delete on exit (  )  ;  final sam record set builder set builder = ne"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectAlignmentSummaryMetricsTest.java,get command line program name,public  string   (  )  {  return  collect alignment summary metrics . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectAlignmentSummaryMetricsTest.java,test,"@ test public void   (  )  throws io exception  {  final  file input = new  file ( test   data   dir ""summary   alignment   stats   test . sam"" )  ;  final  file reference = new  file ( test   data   dir ""summary   alignment   stats   test . fasta"" )  ;  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectAlignmentSummaryMetricsTest.java,test bisulfite,"@ test public void   (  )  throws io exception  {  final  file input = new  file ( test   data   dir ""summary   alignment   bisulfite   test . sam"" )  ;  final  file reference = new  file ( test   data   dir ""summary   alignment   stats   test . fasta"" ) "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectAlignmentSummaryMetricsTest.java,test bisulfite but not,"@ test public void   (  )  throws io exception  {  final  file input = new  file ( test   data   dir ""summary   alignment   bisulfite   test . sam"" )  ;  final  file reference = new  file ( test   data   dir ""summary   alignment   stats   test . fasta"" ) "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectAlignmentSummaryMetricsTest.java,test chimeras,"@ test public void   (  )  throws io exception  {  final  file input = new  file ( test   data   dir ""summary   alignment   stats   test   chimeras . sam"" )  ;  final  file reference = new  file ( test   data   dir ""summary   alignment   stats   test . fa"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectAlignmentSummaryMetricsTest.java,test multiple levels of metrics,"@ test public void   (  )  throws io exception  {  final  file input = new  file ( test   data   dir ""summary   alignment   stats   test   multiple . sam"" )  ;  final  file outfile =  file . create temp file ( ""alignment metrics"" "" . txt"" )  ;  outfile . "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectAlignmentSummaryMetricsTest.java,test no reference,"@ test public void   (  )  throws io exception  {  final  file input = new  file ( test   data   dir ""summary   alignment   stats   test . sam"" )  ;  final  file outfile =  file . create temp file ( ""alignment metrics"" "" . txt"" )  ;  outfile . delete on e"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectAlignmentSummaryMetricsTest.java,test zero length reads,"@ test public void   (  )  throws io exception  {  final  file input = new  file ( test   data   dir ""summary   alignment   stats   test2 . sam"" )  ;  final  file outfile =  file . create temp file ( ""alignment metrics"" "" . txt"" )  ;  outfile . delete on "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectJumpingLibraryMetricsTest.java,test collect jumping library metrics,"@ test public void   (  )  throws io exception  {  final  file outfile =  file . create temp file ( "" collect jumping library metrics test"" "" . txt"" )  ;  outfile . delete on exit (  )  ;  final  string[] args = new  string[] { ""input = ""  +  sam   file ."
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectQualityYieldMetricsTest.java,get command line program name,public  string   (  )  {  return  collect quality yield metrics . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectQualityYieldMetricsTest.java,test,"@ test public void   (  )  throws io exception  {  final  file input = new  file ( test   data   dir ""insert   size   metrics   test . sam"" )  ;  final  file outfile =  file . create temp file ( ""test"" "" . quality   yield   metrics"" )  ;  outfile . delete"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectOxoGMetricsTest.java,get collect oxog metrics,private static  collect oxog metrics   ( final int minimum insert size final int maximum insert size final int context size final  hash set <  string >  context )  {  final  collect oxog metrics collect oxog metrics = new  collect oxog metrics (  )  ;  collect oxog metrics . minimum   insert   size = minimum insert size ;  collect oxog metrics . maximum   insert   size = maximum insert size ;  collect oxog metrics . context   size = context size ;  collect oxog metrics . contexts = context ;  return collect oxog metrics ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectOxoGMetricsTest.java,right options,"@ data provider ( name = "" right options"" )  public static  object[][]   (  )  {  final  hash set <  string >  right context1 = new  hash set <  >  (  )  ;  right context1 . add ( ""acc"" )  ;  final  hash set <  string >  right context2 = new  hash set <  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectOxoGMetricsTest.java,test collect oxog metrics,"@ test public void   (  )  throws io exception  {  final  file output file =  file . create temp file ( ""test"" "" . oxo   g   metrics"" test   data   dir )  ;  output file . delete on exit (  )  ;  final  string[] args = new  string[] { ""input = ""  +  sam  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectOxoGMetricsTest.java,test collect oxog metrics long context,"@ test public void   (  )  throws io exception  {  final  file output file =  file . create temp file ( ""test"" "" . oxo   g   metrics"" test   data   dir )  ;  output file . delete on exit (  )  ;  final  string[] args = new  string[] { ""input = ""  +  sam  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectOxoGMetricsTest.java,test collect oxog metrics short context,"@ test public void   (  )  throws io exception  {  final  file output file =  file . create temp file ( ""test"" "" . oxo   g   metrics"" test   data   dir )  ;  output file . delete on exit (  )  ;  final  string[] args = new  string[] { ""input = ""  +  sam  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectOxoGMetricsTest.java,test negative custom command line validation,"@ test ( data provider = "" wrong options"" )  public void   ( final int minimum insert size final int maximum insert size final int context size final  hash set <  string >  context final  string expected message )  throws  exception  {  final  collect oxo"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectOxoGMetricsTest.java,test positive custom command line validation,"@ test ( data provider = "" right options"" )  public void   ( final int minimum insert size final int maximum insert size final int context size final  hash set <  string >  context )  throws  exception  {  final  collect oxog metrics collect oxog metrics "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectOxoGMetricsTest.java,wrong options,"@ data provider ( name = "" wrong options"" )  public static  object[][]   (  )  {  final  hash set <  string >  wrong context1 = new  hash set <  >  (  )  ;  wrong context1 . add ( ""aac"" )  ;  final  hash set <  string >  wrong context2 = new  hash set <  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectRnaSeqMetricsTest.java,get command line program name,public  string   (  )  {  return  collect rna seq metrics . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectRnaSeqMetricsTest.java,get ref flat file,"public  file   (  string sequence )  throws  exception  {  final  string[] ref flat fields = new  string[ ref flat columns . values (  )  . length] ;  ref flat fields[ ref flat columns . gene   name . ordinal (  ) ] = ""my gene"" ;  ref flat fields[ ref flat columns . transcript   name . ordinal (  ) ] = ""my transcript"" ;  ref flat fields[ ref flat columns . chromosome . ordinal (  ) ] = sequence ;  ref flat fields[ ref flat columns . strand . ordinal (  ) ] = "" + "" ;  ref flat fields[ ref flat columns . tx   start . ordinal (  ) ] = ""49"" ;  ref flat fields[ ref flat columns . tx   end . ordinal (  ) ] = ""500"" ;  ref flat fields[ ref flat columns . cds   start . ordinal (  ) ] = ""74"" ;  ref flat fields[ ref flat columns . cds   end . ordinal (  ) ] = ""400"" ;  ref flat fields[ ref flat columns . exon   count . ordinal (  ) ] = ""2"" ;  ref flat fields[ ref flat columns . exon   starts . ordinal (  ) ] = ""49 249"" ;  ref flat fields[ ref flat columns . exon   ends . ordinal (  ) ] = ""200 500"" ;  final  file ref flat file =  file . create temp file ( ""tmp . "" "" . ref flat"" )  ;  ref flat file . delete on exit (  )  ;  final  print stream ref flat stream = new  print stream ( ref flat file )  ;  ref flat stream . println (  string util . join ( ""\t"" ref flat fields )  )  ;  ref flat stream . close (  )  ;  return ref flat file ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectRnaSeqMetricsTest.java,r rna intervals files,"@ data provider ( name = "" "" )  public static  object[][] r rna intervals files (  )  throws io exception  {  return new  object[][] {  { null }   {  file . create temp file ( ""tmp . r rna . "" "" . interval   list"" )  }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectRnaSeqMetricsTest.java,test basic,"@ test public void   (  )  throws  exception  {  final  string sequence = ""chr1"" ;  final  string ignored sequence = ""chrm"" ;  final sam record set builder builder = new sam record set builder ( true sam file header .  sort order . coordinate )  ;  builde"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectRnaSeqMetricsTest.java,test multi level,"@ test public void   (  )  throws  exception  {  final  string sequence = ""chr1"" ;  final  string ignored sequence = ""chrm"" ;  final sam record set builder builder = new sam record set builder ( true sam file header .  sort order . coordinate false )  ;  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectRnaSeqMetricsTest.java,test no intevals no frag percentage,"@ test ( data provider = ""r rna intervals files"" )  public void   ( final  file r rna intervals file )  throws  exception  {  final sam record set builder builder = new sam record set builder ( true sam file header .  sort order . coordinate )  ;  if  ( r"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectRnaSeqMetricsTest.java,test transcription strand metrics,"@ test public void   (  )  throws  exception  {  final  string sequence = ""chr1"" ;  final  string ignored sequence = ""chrm"" ;  final sam record set builder builder = new sam record set builder ( true sam file header .  sort order . coordinate )  ;  builde"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectMultipleMetricsTest.java,get command line program name,public  string   (  )  {  return  collect multiple metrics . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectMultipleMetricsTest.java,run gc test,"public void   ( final  file input )  throws io exception  {  final  file outfile =  file . create temp file ( ""test"" """" )  ;  final  string reference file = ""testdata / picard / quality / chrm . reference . fasta"" ;  outfile . delete on exit (  )  ;  final  string[] args = new  string[] { ""input = ""  +  input . get absolute path (  )  ""output = ""  +  outfile . get absolute path (  )  ""reference   sequence = ""  +  reference file ""metric   accumulation   level = ""  +   metric accumulation level . all   reads . name (  )  ""program = null"" ""program = ""  +   collect multiple metrics .  program .  collect alignment summary metrics . name (  )  ""program = ""  +   collect multiple metrics .  program .  collect insert size metrics . name (  )  ""program = ""  +   collect multiple metrics .  program .  collect gc bias metrics . name (  )  }  ;   assert . assert equals ( run picard command line ( args )  0 )  ;  final  metrics file <  gc bias summary metrics  comparable <  ?  >  >  output = new  metrics file <  gc bias summary metrics  comparable <  ?  >  >  (  )  ;  output . read ( new  file reader ( outfile  +  "" . gc   bias . summary   metrics"" )  )  ;  for  (  final  gc bias summary metrics metrics : output . get metrics (  )  )   {  if  ( metrics . accumulation   level . equals ( accumulation   level   all   reads )  )   {   assert . assert equals ( metrics . total   clusters 300 )  ;   assert . assert equals ( metrics . aligned   reads 600 )  ;   assert . assert equals ( metrics . at   dropout 7 . 234062 )  ;   assert . assert equals ( metrics . gc   dropout 4 . 086217 )  ;   assert . assert equals ( metrics . gc   nc   0   19 0 . 0 )  ;   assert . assert equals ( metrics . gc   nc   20   39 1 . 06826 )  ;   assert . assert equals ( metrics . gc   nc   40   59 0 . 987036 )  ;   assert . assert equals ( metrics . gc   nc   60   79 0 . 0 )  ;   assert . assert equals ( metrics . gc   nc   80   100 0 . 0 )  ;   }  else  {   assert . fail ( "" unexpected metric: ""  +  metrics )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectMultipleMetricsTest.java,setup,"void   ( final int num reads final  string read name final int id final  string read group id final sam read group record read group record final  string sample final  string library final sam file header header final sam record set builder set builder )  throws io exception  {  final  string separator = "":"" ;  read group record . set sample ( sample )  ;  read group record . set platform ( platform )  ;  read group record . set library ( library )  ;  read group record . set platform unit ( read group id )  ;  header . add read group ( read group record )  ;  set builder . set read group ( read group record )  ;  set builder . set use nm flag ( true )  ;  set builder . set header ( header )  ;  final int max = 15000 ;  final int min = 1 ;  final  random rg = new  random ( 5 )  ;  for  ( int i = 0 ;  i  <  num reads ;  i +  +  )   {  final int start = rg . next int ( max )   +  min ;  final  string new read name = read name  +  separator  +  id +  separator +  i ;  set builder . add pair ( new read name 0 start  +  id start  +  id  +  99 )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectMultipleMetricsTest.java,setup builder,"@ before test void   (  )  throws io exception  {  final int num reads = 100 ;  final  string flow cell barcode = ""testbarcode"" ;  temp sam file =  file . create temp file ( "" collect gc bias"" "" . bam"" test   dir )  ;  final  file temp sam index = new  fi"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectMultipleMetricsTest.java,test alignment summary via multiple metrics,"@ test public void   (  )  throws io exception  {  final  file input = new  file ( test   data   dir ""summary   alignment   stats   test . sam"" )  ;  final  file reference = new  file ( test   data   dir ""summary   alignment   stats   test . fasta"" )  ;  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectMultipleMetricsTest.java,test gc bias metrics,@ test public void   (  )  throws io exception  {  run gc test ( temp sam file )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectMultipleMetricsTest.java,test insert size,"@ test public void   (  )  throws io exception  {  final  file input = new  file ( test   data   dir ""insert   size   metrics   test . sam"" )  ;  final  file outfile =  file . create temp file ( ""test"" """" )  ;  final  file reference = new  file ( test   d"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTest.java,get command line program name,public  string   (  )  {  return  collect wgs metrics . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTest.java,setup builder,"@ before test void   (  )  throws io exception  {  final  string read name = ""testbarcode"" ;  temp sam file =  vcf test utils . create temporary indexed file ( "" collect wgs metrics"" "" . bam"" )  ;  final  file temp sam file unsorted =  file . create temp "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTest.java,test exclusions,"@ test ( data provider = ""wgs algorithm"" )  public void   ( final  string use fast algorithm )  throws io exception  {  final  file reference = new  file ( ""testdata / picard / sam / merger . fasta"" )  ;  final  file temp sam file =  vcf test utils . crea"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTest.java,test giant deletion,"@ test ( data provider = ""wgs algorithm"" )  public void   ( final  string use fast algorithm )  throws io exception  {  final  file reference = new  file ( ""testdata / picard / quality / chrm . reference . fasta"" )  ;  final  file test sam file =  vcf tes"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTest.java,test large intervals,"@ test ( data provider = ""wgs algorithm"" )  public void   ( final  string use fast algorithm )  throws io exception  {  final  file input = new  file ( test   dir ""for metrics . sam"" )  ;  final  file outfile =  file . create temp file ( ""test"" "" . wgs   "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTest.java,test metrics fromwgs,"@ test ( data provider = ""wgs data provider"" )  public void   ( final  file input final  file outfile final  string reference file final  string use fast algorithm )  throws io exception  {  outfile . delete on exit (  )  ;  final int sample size = 1000 ;"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTest.java,test poor quality bases,"@ test ( data provider = ""wgs algorithm"" )  public void   ( final  string use fast algorithm )  throws io exception  {  final  file reference = new  file ( ""testdata / picard / quality / chrm . reference . fasta"" )  ;  final  file test sam file =  vcf tes"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTest.java,wgs algorithm,"@ data provider ( name = "" "" )  public  object[][] wgs algorithm (  )  {  return new  object[][] {  { ""false"" }   { ""true"" }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTest.java,wgs data provider,"@ data provider ( name = "" "" )  public  object[][] wgs data provider (  )  {  final  string reference file = ""testdata / picard / quality / chrm . reference . fasta"" ;  return new  object[][] {  { temp sam file outfile reference file ""false"" }   { temp sa"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTestUtils.java,create interval list,static  interval list   (  )  {  return new  interval list ( new sam file header (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTestUtils.java,create read ends iterator,static  abstract locus iterator   (  string example sam )  {  final  list <  sam record filter >  filters = new  array list <  >  (  )  ;  final  counting filter dupe filter = new  counting duplicate filter (  )  ;  final  counting filter mapq filter = new  counting mapq filter ( 0 )  ;  filters . add ( new  secondary alignment filter (  )  )  ;  filters . add ( mapq filter )  ;  filters . add ( dupe filter )  ;   sam reader sam reader = create sam reader ( example sam )  ;   abstract locus iterator iterator = new  edge read iterator ( sam reader )  ;  iterator . set sam filters ( filters )  ;  iterator . set mapping quality score cutoff ( 0 )  ;  iterator . set include non pf reads ( false )  ;  return iterator ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTestUtils.java,create reference sequence file,"static  reference sequence file   (  string reference string )  {  final sam sequence record record = new sam sequence record ( ""ref"" reference string . length (  )  )  ;  final sam sequence dictionary dictionary = new sam sequence dictionary (  )  ;  dictionary . add sequence ( record )  ;  return new  reference sequence file (  )  {  boolean done = false ;  @ override public sam sequence dictionary get sequence dictionary (  )  {  return dictionary ;   }  @ override public  reference sequence next sequence (  )  {  if  (  ! done )   {  done = true ;  return get sequence ( record . get sequence name (  )  )  ;   }  return null ;   }  @ override public void reset (  )  {  done = false ;   }  @ override public boolean is indexed (  )  {  return false ;   }  @ override public  reference sequence get sequence (   string contig )  {  if  ( contig . equals ( record . get sequence name (  )  )  )   {  return new  reference sequence ( record . get sequence name (  )  0 reference string . get bytes (  )  )  ;   }  else  {  return null ;   }   }  @ override public  reference sequence get subsequence at (   string contig  long start  long stop )  {  return null ;   }  @ override public  string to string (  )  {  return null ;   }  @ override public void close (  )  throws io exception  {   }   }   ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTestUtils.java,create sam reader,static  sam reader   (  string sam example )  {   byte array input stream input stream = new  byte array input stream ( sam example . get bytes (  )  )  ;  return  sam reader factory . make default (  )  . open (  sam input resource . of ( input stream )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTestUtils.java,create testsam,"private static void   (  string test sam name )  throws io exception  {  final  file test dir = new  file ( ""testdata / picard / analysis / directed /  collect hs metrics / "" )  ;  final  file reference = new  file ( ""testdata / picard / quality / chrm . reference . fasta"" )  ;  final  string read group id = "" test read group"" ;  final  string sample = "" test sample"" ;  final  string platform = "" illumina"" ;  final  string library = "" test library"" ;  final int num reads = 1 ;  final int read length = 10 ;   file sam file =  file . create temp file ( test sam name "" . bam"" test dir )  ;  final sam record set builder set builder = create testsam builder ( reference read group id sample platform library )  ;  set builder . set read length ( read length )  ;   int stream . range ( 0 num reads )  . for each ( i  -  >  set builder . add pair ( "" mediocre baseq""  +  i 0 1 200 false false read length  +  ""m"" read length  +  ""m"" false true 40 )  )  ;  final sam file writer writer = new sam file writer factory (  )  . set create index ( true )  . makebam writer ( set builder . get header (  )  false sam file )  ;  set builder . for each ( writer::add alignment )  ;  writer . close (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTestUtils.java,create testsam builder,protected static sam record set builder   ( final  file reference final  string read group id final  string sample final  string platform final  string library )  {  final sam file header header = new sam file header (  )  ;  try  {  header . set sequence dictionary ( sam sequence dictionary extractor . extract dictionary ( reference . to path (  )  )  )  ;  header . set sort order ( sam file header .  sort order . unsorted )  ;   }  catch  (  final sam exception e )   {  e . print stack trace (  )  ;   }  final sam read group record read group record = new sam read group record ( read group id )  ;  read group record . set sample ( sample )  ;  read group record . set platform ( platform )  ;  read group record . set library ( library )  ;  read group record . set platform unit ( read group id )  ;  header . add read group ( read group record )  ;  final sam record set builder set builder = new sam record set builder ( true sam file header .  sort order . coordinate true 100 )  ;  set builder . set read group ( read group record )  ;  set builder . set use nm flag ( true )  ;  set builder . set header ( header )  ;  return  ( set builder )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTestUtils.java,get reference sequence file walker,"static  reference sequence file walker   (  )  {   string reference string = "" > ref\nacctacgttcaatattcttc"" ;  return get reference sequence file walker ( reference string )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTestUtils.java,get sequence,@ override public  reference sequence   (  string contig )  {  if  ( contig . equals ( record . get sequence name (  )  )  )   {  return new  reference sequence ( record . get sequence name (  )  0 reference string . get bytes (  )  )  ;   }  else  {  ret
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTestUtils.java,get sequence dictionary,@ override public sam sequence dictionary   (  )  {  return dictionary ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTestUtils.java,get subsequence at,@ override public  reference sequence   (  string contig long start long stop )  {  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTestUtils.java,is indexed,@ override public boolean   (  )  {  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTestUtils.java,main,"public static void   (  string[] args )  {  try  {  create testsam ( "" test sam"" )  ;   }  catch  (  io exception e )   {   ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTestUtils.java,next sequence,@ override public  reference sequence   (  )  {  if  (  ! done )   {  done = true ;  return get sequence ( record . get sequence name (  )  )  ;   }  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTestUtils.java,reset,@ override public void   (  )  {  done = false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsTestUtils.java,to string,@ override public  string   (  )  {  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsWithNonZeroCoverageTest.java,get command line program name,public  string   (  )  {  return  collect wgs metrics with non zero coverage . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsWithNonZeroCoverageTest.java,test no coverage,"@ test public void   (  )  throws io exception  {  final  file reference = new  file ( ""testdata / picard / quality / chrm . reference . fasta"" )  ;  final  file test sam file =  file . create temp file ( "" collect wgs metrics"" "" . bam"" test   dir )  ;  t"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsWithNonZeroCoverageTest.java,test poor quality bases,"@ test public void   (  )  throws io exception  {  final  file reference = new  file ( ""testdata / picard / quality / chrm . reference . fasta"" )  ;  final  file test sam file =  file . create temp file ( "" collect wgs metrics"" "" . bam"" test   dir )  ;  t"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsWithNonZeroCoverageTest.java,test with intervals,"@ test public void   (  )  throws io exception  {  final  file input = new  file ( test   dir ""for metrics . sam"" )  ;  final  file outfile =  file . create temp file ( ""test"" "" . wgs   metrics"" )  ;  final  file pdffile =  file . create temp file ( ""test"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CollectWgsMetricsWithNonZeroCoverageTest.java,test without intervals,"@ test public void   (  )  throws io exception  {  final  file input = new  file ( test   dir ""for metrics . sam"" )  ;  final  file outfile =  file . create temp file ( ""test"" "" . wgs   metrics"" )  ;  final  file pdffile =  file . create temp file ( ""test"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\directed\CollectHsMetricsTest.java,get command line program name,@ override public  string   (  )  {  return  collect hs metrics . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\directed\CollectHsMetricsTest.java,run collect hs metrics test,"@ test ( data provider = ""collect hs metrics data provider"" )  public void   ( final  string input final  string target intervals final int minimum mapping quality final int minimum base quality final boolean clip overlapping reads final int total reads f"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\directed\CollectHsMetricsTest.java,targeted interval data provider,"@ data provider ( name = ""collect hs metrics data provider"" )  public  object[][]   (  )  {  final  string reference file = test   dir  +  "" / chrm . fasta"" ;  final  string intervals = test   dir  +  "" / chrm . interval   list"" ;  final  string two small"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\directed\CollectHsMetricsTest.java,test coverage histogram,"@ test public void   (  )  throws io exception  {  final  string input = test   dir  +  "" / single - short - read . sam"" ;  final  string target intervals = test   dir  +  "" / two - small . interval   list"" ;  final int minimum mapping quality = 20 ;  fin"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\FastWgsMetricsCollectorTest.java,generate record,private sam record   (  string name )  {  sam record record = new sam record ( new sam file header (  )  )  ;  record . set read name ( name )  ;  record . set base qualities ( high qualities )  ;  record . set read bases ( ref bases )  ;  return record ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\FastWgsMetricsCollectorTest.java,set up,"@ before test public void   (  )  {   string reference string = "" > chrm\nacctacgttcaatattcttcacctacgttcaatattcttcacctacgttcaatattcttcacctacgttcaatattcttcacctacgttcaatattcttc"" ;  ref = new  reference sequence ( ""chrm"" 0 reference string . get bytes (  )  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\FastWgsMetricsCollectorTest.java,test add info for capping,@ test public void   (  )  {   collect wgs metrics collect wgs metrics = new  collect wgs metrics (  )  ;   fast wgs metrics collector collector = new  fast wgs metrics collector ( collect wgs metrics 1 create interval list (  )  )  ;   abstract locus inf
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\FastWgsMetricsCollectorTest.java,test add info for overlap,@ test public void   (  )  {   collect wgs metrics collect wgs metrics = new  collect wgs metrics (  )  ;   fast wgs metrics collector collector = new  fast wgs metrics collector ( collect wgs metrics 100 create interval list (  )  )  ;   abstract locus i
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\FastWgsMetricsCollectorTest.java,test add info for quality,@ test public void   (  )  throws  exception  {   collect wgs metrics collect wgs metrics = new  collect wgs metrics (  )  ;   fast wgs metrics collector collector = new  fast wgs metrics collector ( collect wgs metrics 100 create interval list (  )  )  ;
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\FastWgsMetricsCollectorTest.java,test add info without overlap,@ test public void   (  )  {   collect wgs metrics collect wgs metrics = new  collect wgs metrics (  )  ;   fast wgs metrics collector collector = new  fast wgs metrics collector ( collect wgs metrics 100 create interval list (  )  )  ;   abstract locus i
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\FastWgsMetricsCollectorTest.java,test for base quality het sens,@ test public void   (  )  {   collect wgs metrics collect wgs metrics = new  collect wgs metrics (  )  ;  collect wgs metrics . include   bq   histogram = true ;   fast wgs metrics collector collector = new  fast wgs metrics collector ( collect wgs metri
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\FastWgsMetricsCollectorTest.java,test for collector without data,@ test public void   (  )  {  long[] template qual histogram = new long[127] ;  long[] template histogram array = new long[11] ;   collect wgs metrics collect wgs metrics = new  collect wgs metrics (  )  ;   fast wgs metrics collector collector = new  fas
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\FastWgsMetricsCollectorTest.java,test for complicated cigar,@ test public void   (  )  {   collect wgs metrics collect wgs metrics = new  collect wgs metrics (  )  ;   fast wgs metrics collector collector = new  fast wgs metrics collector ( collect wgs metrics 100 create interval list (  )  )  ;   abstract locus i
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\FastWgsMetricsCollectorTest.java,test for excluded for quality histogram array,@ test public void   (  )  {   collect wgs metrics collect wgs metrics = new  collect wgs metrics (  )  ;  collect wgs metrics . include   bq   histogram = true ;   fast wgs metrics collector collector = new  fast wgs metrics collector ( collect wgs metri
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\FastWgsMetricsCollectorTest.java,test for histogram array,@ test public void   (  )  {   collect wgs metrics collect wgs metrics = new  collect wgs metrics (  )  ;   fast wgs metrics collector collector = new  fast wgs metrics collector ( collect wgs metrics 10 create interval list (  )  )  ;  long[] template hi
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\directed\CollectTargetedMetricsTest.java,get command line program name,@ override public  string   (  )  {  return  collect targeted pcr metrics . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MergeableMetricBaseTest.java, test can merge,@ test public void   (  )  {  final  test mergeable metric instance1 = new  test mergeable metric (  )  ;  instance1 . unboxed int = 1 ;  final  test derived mergable metric instance2 = new  test derived mergable metric (  )  ;  instance2 . unboxed int = 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MergeableMetricBaseTest.java, test merging derived class,@ test public void   (  )  {  final  test mergeable metric instance1 = new  test mergeable metric (  )  ;  final  test derived mergable metric instance2 = new  test derived mergable metric (  )  ;  instance1 . merge ( instance2 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MergeableMetricBaseTest.java, test merging super class,@ test ( expected exceptions =  illegal argument exception . class )  public void   (  )  {  final  test mergeable metric instance1 = new  test mergeable metric (  )  ;  final  test derived mergable metric instance2 = new  test derived mergable metric (  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MergeableMetricBaseTest.java,test illegal class,@ test ( expected exceptions =  illegal state exception . class )  public void   (  )  {  final  test mergeable metric illegal illegal1 = new  test mergeable metric illegal (  )   illegal2 = new  test mergeable metric illegal (  )  ;  illegal1 . merge ( i
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\directed\CollectTargetedMetricsTest.java,run collect targeted metrics test,"@ test ( data provider = ""targeted interval data provider"" )  public void   ( final  file input final  file outfile final  file per target outfile final  string reference file final  string target intervals final int sample size )  throws io exception  { "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MergeableMetricBaseTest.java,test merging,@ test public void   (  )  {  final  test mergeable metric metric1 = new  test mergeable metric (  )   metric2 = new  test mergeable metric (  )  ;  metric1 . merge ( metric2 )  ;   assert . assert equals ( metric1 . boxed int  (  integer ) 2 )  ;   asser
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MergeableMetricBaseTest.java,test merginga null,"@ test public void   (  )  {  final  test mergeable metric metric1 = new  test mergeable metric (  )   metric2 = new  test mergeable metric (  )  ;  metric1 . must be equal string = ""goodbye"" ;  metric2 . must be equal string = null ;   assert . assert tr"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MergeableMetricBaseTest.java,test merging unequal boolean,@ test ( expected exceptions =  illegal state exception . class )  public void   (  )  {  final  test mergeable metric metric1 = new  test mergeable metric (  )   metric2 = new  test mergeable metric (  )  ;  metric1 . must be equal unboxed boolean = true
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MergeableMetricBaseTest.java,test merging unequal double,@ test ( expected exceptions =  illegal state exception . class )  public void   (  )  {  final  test mergeable metric metric1 = new  test mergeable metric (  )   metric2 = new  test mergeable metric (  )  ;  metric1 . must be equal double = 1d ;   assert
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\directed\CollectTargetedMetricsTest.java,setup builder,"@ before test void   (  )  throws io exception  {  final  string read name = ""testbarcode"" ;  temp sam file =  vcf test utils . create temporary indexed file ( "" collect targeted metrics"" "" . bam"" )  ;  final  file temp sam file unsorted =  vcf test utils"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MergeableMetricBaseTest.java,test merging unequal string,"@ test ( expected exceptions =  illegal state exception . class )  public void   (  )  {  final  test mergeable metric metric1 = new  test mergeable metric (  )   metric2 = new  test mergeable metric (  )  ;  metric1 . must be equal string = ""goodbye"" ;  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\directed\CollectTargetedMetricsTest.java,targeted interval data provider,"@ data provider ( name = "" "" )  public  object[][] targeted interval data provider (  )  {  return new  object[][] {  { temp sam file outfile per target outfile reference file single intervals 1000 }   { temp sam file outfile per target outfile reference "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MergeableMetricBaseTest.java,test merging with restricted members,@ test public void   (  )  {  final  test mergeable metric with restricted members metric1 = new  test mergeable metric with restricted members (  )   metric2 = new  test mergeable metric with restricted members (  )  ;  metric1 . merge ( metric2 )  ;   a
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\directed\CollectTargetedMetricsTest.java,test coverage get total overflow,"@ test public void   (  )  {  final  interval interval = new  interval ( ""chr1"" 1 2 )  ;  final  target metrics collector .  coverage coverage = new  target metrics collector .  coverage ( interval 0 )  ;  for  ( int offset = 0 ;  offset  <  =  interval ."
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MergeableMetricBaseTest.java,test merging with restricted members using base class,@ test public void   (  )  {  final  mergeable metric base metric1 = new  test mergeable metric with restricted members (  )   metric2 = new  test mergeable metric with restricted members (  )  ;  metric1 . merge ( metric2 )  ;   assert . assert equals ( 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\directed\CollectTargetedMetricsTest.java,test raw bq distribution with soft clips,"@ test (  )  public void   (  )  throws io exception  {  final  string input = test   data   dir  +  ""chrm reads with clips . sam"" ;  final  file out file =  file . create temp file ( ""test"" "" .  targeted metrics    coverage"" )  ;  out file . delete on ex"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CounterManagerTest.java,set up,@ before test public void   (  )  {  second test counter manager = new  counter manager ( array length read length )  ;  second test counter manager . set offset ( offset )  ;  second counter = second test counter manager . new counter (  )  ;  test count
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CounterManagerTest.java,test counter inc,"@ test public void   (  )  {   assert . assert equals ( 2 test counter . get ( offset )  "" test method increment:"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CounterManagerTest.java,test for check increment,@ test public void   (  )  {   counter manager test counter manager = new  counter manager ( array length read length )  ;  test counter manager . set offset ( 0 )  ;   counter manager .  counter counter = test counter manager . new counter (  )  ;  for  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CounterManagerTest.java,test for clean counter after,"@ test public void   (  )  {  test counter manager . check out of bounds ( 88 )  ;   assert . assert equals ( 0 test counter . get ( 88 )  "" the value of the array with index 0 must be 1 after clean:"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CounterManagerTest.java,test for clear counter,"@ test public void   (  )  {  test counter manager . clear (  )  ;   assert . assert equals ( 0 test counter . get ( offset )  "" the value of the array with index 0 must be 0 after clear manager:"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CounterManagerTest.java,test for correct counter after rebase,"@ test public void   (  )  {  second test counter manager . check out of bounds ( 11 )  ;   assert . assert equals ( 1 second counter . get ( 11 )  "" the value of the array with index 0 must be 1 after rebase:"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CounterManagerTest.java,test for correct offset after rebase,"@ test public void   (  )  {  second test counter manager . check out of bounds ( 11 )  ;   assert . assert equals ( 11 second test counter manager . get offset (  )  "" after rebase offset must be new int"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CounterManagerTest.java,test for out of bound counter,"@ test public void   (  )  {  second test counter manager . check out of bounds ( 44 )  ;   assert . assert equals ( 44 second test counter manager . get offset (  )  "" new offset after clear must be 44:"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CounterManagerTest.java,test for wrong index in get,@ test ( expected exceptions =  index out of bounds exception . class )  public void   (  )  {  test counter . get ( 40 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\CounterManagerTest.java,test for wrong index in inc,@ test ( expected exceptions =  index out of bounds exception . class )  public void   (  )  {  test counter . increment ( 40 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\replicates\CollectIndependentReplicatesMetricTest.java,convert sam to bam,"private static  file   ( final  string sam )  throws io exception  {  final  merge sam files msf = new  merge sam files (  )  ;  final  file bam = new  file ( bam out dir sam . replace all ( ""sam$"" ""bam"" )  )  ;  final int return code = msf . instance main ( new  string[] { ""input = ""  +   ( new  file ( testdir sam )  . get absolute path (  )  )  ""create   index = true"" ""output = ""  +  bam . get absolute path (  )  }  )  ;   assert . assert equals ( return code 0 )  ;  return bam ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\replicates\CollectIndependentReplicatesMetricTest.java,prepare bams,@ before test public void   (  )  throws io exception  {  sams . key set (  )  . stream (  )  . for each ( key  -  >   {  try  {  bams . put ( key convert sam to bam ( sams . get ( key )  )  )  ;  bams . get ( key )  . delete on exit (  )  ;   }  catch  (
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\replicates\CollectIndependentReplicatesMetricTest.java,simple test,"@ test ( data provider = "" s"" )  public void simple test ( final  string vcf final  string bam final  map <  string  object >  field value map )  throws io exception   no such field exception   illegal access exception  {  final  collect independent repli"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\replicates\CollectIndependentReplicatesMetricTest.java,simple tests data,"@ data provider ( name = ""simple tests"" )  public  iterator <  object[] >    (  )  {  final  list <  object[] >  tests = new  array list <  >  ( 3 )  ;   {  final  map <  string  object >  map = new  linked hash map <  >  (  )  ;  map . put ( ""n sites"" 3 "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\replicates\CollectIndependentReplicatesMetricTest.java,tear down,@ after test public void   (  )  {   test util . recursive delete ( bam out dir )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MultiLevelCollectorTest.java, record count multi level collector,public   ( final  set <  metric accumulation level >  accumulation levels final  list < sam read group record >  sam rg records )  {  setup ( accumulation levels sam rg records )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MultiLevelCollectorTest.java, record count per unit collector,"public   ( final  string sample final  string library final  string read group )  {  metric = new  total number metric (  )  ;  metric . sample = sample ;  metric . library = library ;  metric . read   group = read group ;  units to metrics . put ( none or str ( sample )   +  ""   ""  +  none or str ( library )  +  ""   "" +  none or str ( read group )  metric )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MultiLevelCollectorTest.java, test arg,public   ( final sam record sam record final  reference sequence ref seq )  {  this . sam record = sam record ;  this . ref seq = ref seq ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MultiLevelCollectorTest.java,accept record,@ override public void   ( final  test arg args )  {  num processed +  = 1 ;  metric . tally +  = 1 ;  if  ( metric . sample  !  =  null )   {   assert . assert equals ( metric . sample args . sam record . get read group (  )  . get sample (  )  )  ;   } 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MultiLevelCollectorTest.java,add metrics to file,@ override public void   ( final  metrics file <  total number metric  integer >  total number metric integer metrics file )  {  total number metric integer metrics file . add metric ( metric )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MultiLevelCollectorTest.java,finish,@ override public void   (  )  {  metric . finished = true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MultiLevelCollectorTest.java,get num processed,public int   (  )  {  return num processed ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MultiLevelCollectorTest.java,get units to metrics,public  map <  string  total number metric >    (  )  {  return units to metrics ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MultiLevelCollectorTest.java,make arg,@ override protected  test arg   ( final sam record sam rec final  reference sequence ref seq )  {  return new  test arg ( sam rec ref seq )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MultiLevelCollectorTest.java,make child collector,@ override protected  per unit metric collector <  total number metric  integer  test arg >    ( final  string sample final  string library final  string read group )  {  return new  record count per unit collector ( sample library read group )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MultiLevelCollectorTest.java,multilevel collector test,"@ test ( data provider = ""varied accumulation levels"" )  public void   ( final  set <  metric accumulation level >  accumulation levels )  {  final  sam reader in =  sam reader factory . make default (  )  . open ( testfile )  ;  final  record count multi"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MultiLevelCollectorTest.java,none or str,"public  string   ( final  string str )  {  final  string out ;  if  ( str  =  =  null )   {  out = """" ;   }  else  {  out = str ;   }  return out ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\MultiLevelCollectorTest.java,varied accumulation levels,"@ data provider ( name = "" "" )  public  object[][] varied accumulation levels (  )  {  return new  object[][] {  { make set (  metric accumulation level . all   reads )  }   { make set (  metric accumulation level . all   reads  metric accumulation level "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\WgsMetricsTest.java,build interval list,"private  interval list   ( final int start final int end )  {  final sam file header header = new sam file header (  )  ;  header . add sequence ( new sam sequence record ( ""contig"" 100000000 )  )  ;  final  interval list intervals = new  interval list ( header )  ;  if  ( 0  <  start )  intervals . add ( new  interval ( ""contig"" start end )  )  ;  return intervals ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\WgsMetricsTest.java,empty depth histogram,private  histogram <  integer >    (  )  {  return new  histogram <  >  (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\WgsMetricsTest.java,empty metrics,private  collect wgs metrics .  wgs metrics   (  )  {  return new  collect wgs metrics .  wgs metrics ( build interval list (  - 1  - 1 )  empty depth histogram (  )  empty depth histogram (  )  0 0 0 0 0 0 0 1000000 null  - 1 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\WgsMetricsTest.java,single depth histogram,private  histogram <  integer >    ( final int depth final int count )  {  final  histogram <  integer >  histogram = new  histogram <  >  (  )  ;  histogram . increment ( depth count )  ;  return histogram ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\WgsMetricsTest.java,single depth metrics,private  collect wgs metrics .  wgs metrics   ( final int depth final int count scale final int start )  {  final int count = 100000 * count scale ;  final int total excluded =  ( 10  +  20  +  30 +  40 +  50 +  60 )  * count scale ;  return new  collect wgs metrics .  wgs metrics ( build interval list ( start start )  single depth histogram ( depth count )  single depth histogram ( depth count )  10d * count scale  /  count 20d * count scale  /  count 30d * count scale  /  count 40d * count scale  /  count 50d * count scale  /  count 60d * count scale  /  count total excluded  /   ( double )  ( count  +  total excluded )  1000000 null  - 1 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\WgsMetricsTest.java,test merge overlapping intervals,@ test ( expected exceptions =  {  picard exception . class }  )  public void   (  )  {  single depth metrics ( 1 1 1 )  . merge ( single depth metrics ( 1 1 1 )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\WgsMetricsTest.java,test wgs metrics merge,"@ test ( data provider = ""  data provider"" )  public void test wgs metrics merge ( final  collect wgs metrics .  wgs metrics left final  collect wgs metrics .  wgs metrics right final  collect wgs metrics .  wgs metrics expected )  {  left . merge ( right"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\WgsMetricsTest.java,test wgs metrics merge data provider,"@ data provider ( name = "" "" )  public  object[][] test wgs metrics merge data provider (  )  {  return new  object[][] {  { empty metrics (  )  empty metrics (  )  empty metrics (  )  }   { empty metrics (  )  single depth metrics ( 1 1 1 )  single depth"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\WgsMetricsTest.java,two site depth histogram,private  histogram <  integer >    ( final int depth1 final int count1 final int depth2 final int count2 )  {  final  histogram <  integer >  histogram = new  histogram <  >  (  )  ;  if  ( 0  <  depth1 )  histogram . increment ( depth1 count1 )  ;  if  ( 0  <  depth2 )  histogram . increment ( depth2 count2 )  ;  return histogram ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\WgsMetricsTest.java,two site depth metrics,private  collect wgs metrics .  wgs metrics   ( final int depth1 final int count scale1 final int depth2 final int count scale2 final int start )  {  final int count1 = 100000 * count scale1 ;  final int count2 = 100000 * count scale2 ;  final int count = count1  +  count2 ;  final int count scale = count scale1  +  count scale2 ;  final int total excluded =  ( 10  +  20  +  30 +  40 +  50 +  60 )  * count scale ;  return new  collect wgs metrics .  wgs metrics ( build interval list ( start start  +  1 )  two site depth histogram ( depth1 count1 depth2 count2 )  two site depth histogram ( depth1 count1 depth2 count2 )  10d * count scale  /  count 20d * count scale  /  count 30d * count scale  /  count 40d * count scale  /  count 50d * count scale  /  count 60d * count scale  /  count total excluded  /   ( double )  ( count  +  total excluded )  100000 null  - 1 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\TheoreticalSensitivityTest.java,het sens data provider,"@ data provider ( name = "" "" )  public  object[][] het sens data provider (  )  {  final  file wgs metrics file = new  file ( test   dir ""test    solexa - 332667 . wgs   metrics"" )  ;  final  file targeted metrics file = new  file ( test   dir ""test   251"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\TheoreticalSensitivityTest.java,test central limit theorem,@ test public void   (  )  throws  exception  {  final double[] weights =  { 1 . 0 1 . 0 1 . 0 }  ;  final  theoretical sensitivity .  roulette wheel wheel = new  theoretical sensitivity .  roulette wheel ( weights )  ;  final int sample size = 1000 ;  fi
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\TheoreticalSensitivityTest.java,test deterministic quality and depth,@ test public void   (  )  throws  exception  {  final double log odds threshold = 0 . 0 ;  final double tolerance = 0 . 001 ;  final int sample size = 1 ;  for  ( int q = 5 ;  q  <  10 ;  q +  +  )   {  for  ( int n = 5 ;  n  <  10 ;  n +  +  )   {  fina
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\TheoreticalSensitivityTest.java,test het alt depth distribution,@ test public void   (  )  throws  exception  {  final int n = 6 ;  final double p = 0 . 5 ;  final  list <  array list <  double >  >  distribution =  theoretical sensitivity . het alt depth distribution ( n )  ;  for  ( int n = 0 ;  n  <  n  -  1 ;  n +
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\TheoreticalSensitivityTest.java,test het sens distributions,@ test public void   (  )  throws  exception  {  final double tolerance = 0 . 02 ;  final double expected result =  . 9617 ;  final int max depth = 500 ;  final double[] depth distribution = new double[max depth  +  1] ;  final double[] quality distributi
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\TheoreticalSensitivityTest.java,test het sens targeted,"@ test ( data provider = ""het sens data provider"" )  public void   ( final double expected final  file metrics file )  throws  exception  {  final double tolerance = 0 . 000   000   01 ;  final  metrics file  metrics = new  metrics file (  )  ;   metrics "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\TheoreticalSensitivityTest.java,test proportions above thresholds,@ test public void   (  )  throws  exception  {  final  list <  array list <  integer >  >  sums = new  array list <  array list <  integer >  >  (  )  ;  sums . add ( new  array list <  integer >  (  arrays . as list ( 0 0 0 )  )  )  ;  sums . add ( new 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\TheoreticalSensitivityTest.java,test roulette wheel,@ test public void   (  )  throws  exception  {  final double[] deterministic weights =  { 0 . 0 1 . 0 0 . 0 }  ;  final  theoretical sensitivity .  roulette wheel deterministic wheel = new  theoretical sensitivity .  roulette wheel ( deterministic weight
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\cmdline\CommandLineProgramStartupErrorLogTest.java,do work,@ override public int   (  )  {  return 0 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\cmdline\CommandLineProgramStartupErrorLogTest.java,test no startup error log,@ test public void   (  )  {   byte array output stream stderr stream = new  byte array output stream (  )  ;   print stream new stderr = new  print stream ( stderr stream )  ;   print stream old stderr =  system . err ;   system . set err ( new stderr ) 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\cmdline\CommandLineProgramStartupErrorLogTest.java,test no startup output log,@ test public void   (  )  {   byte array output stream stdout stream = new  byte array output stream (  )  ;   print stream new stdout = new  print stream ( stdout stream )  ;   print stream old stdout =  system . out ;   system . set out ( new stdout ) 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\WgsMetricsProcessorImplTest.java,set up,@ before test public void   (  )  {  progress = new  progress logger (  log . get instance (  wgs metrics processor impl . class )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\WgsMetricsProcessorImplTest.java,test for exit after,@ test public void   (  )  {   abstract locus iterator iterator = create read ends iterator ( example sam one read )  ;   collect wgs metrics collect wgs metrics = new  collect wgs metrics (  )  ;  collect wgs metrics . stop   after = 16 ;   abstract wgs 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\WgsMetricsProcessorImplTest.java,test for filtered bases,@ test public void   (  )  {   abstract locus iterator iterator = create read ends iterator ( example sam one read )  ;   collect wgs metrics collect wgs metrics = new  collect wgs metrics (  )  ;   fast wgs metrics collector collector = new  fast wgs met
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\analysis\WgsMetricsProcessorImplTest.java,test for process file,@ test public void   (  )  {   abstract locus iterator iterator = create read ends iterator ( example sam one read )  ;   collect wgs metrics collect wgs metrics = new  collect wgs metrics (  )  ;   fast wgs metrics collector collector = new  fast wgs met
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\cmdline\PicardCommandLineTest.java, test picard public,"@ test public void   (  )  {   picard command line picard command line = new  picard command line (  )  ;  picard command line . instance main ( new  string[] { """" }  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\cmdline\PicardCommandLineTest.java,test launch all command line programs with barclay parser,"@ test public void   (  )  {   picard command line . process all command line programs (  collections . singleton list ( ""picard"" )   (   class <  command line program >  clazz   command line program properties cl properties )   -  >   {  if  ( null  !  ="
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\cmdline\PicardCommandLineTest.java,test print usage,"@ test public void   (  )  {   assert . assert equals ( new  picard command line (  )  . instance main ( new  string[] { "" - h"" }  )  1 )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\cmdline\PicardCommandLineTest.java,test process command line programs,"@ test public void   (  )  {  final  list <  class <  command line program >  >  allcl ps = new  array list <  >  (  )  ;   picard command line . process all command line programs (  collections . singleton list ( ""picard"" )   (   class <  command line pr"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CheckFingerprintTest.java,bad data,"@ data provider ( name = "" "" )  public  object[][] bad data (  )  {  return new  object[][] {  { test   input   vcf   empty test   output test   genotypes   vcf1 subsetted   haplotype   database   for   testing }   { test   input   vcf   no   file test   "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CheckFingerprintTest.java,get command line program name,@ override public  string   (  )  {  return  check fingerprint . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CheckFingerprintTest.java,mk temp,@ before class private void   (  )  {  if  (  ! temp folder . exists (  )  )   {  temp folder . mkdir (  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CheckFingerprintTest.java,rm temp,@ after class private void   (  )  {  io util . delete directory tree ( temp folder )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CheckFingerprintTest.java,sams to fingerprint,"@ data provider ( name = "" "" )   object[][] sams to fingerprint (  )  {  return new  object[][] {  { na12891   r1   sam na12891   fp }   { na12892   r1   sam na12891   fp }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CheckFingerprintTest.java,setup,"@ before class public void   (  )  throws io exception  {  na12891   named   na12892   vcf =  vcf test utils . create temporary indexed vcf from input ( new  file ( test   data   dir ""na12891   named   na12892 . vcf"" )  ""fingerprint"" )  ;  na12892   1   v"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CheckFingerprintTest.java,test bad data,"@ test ( data provider = ""bad data"" expected exceptions =  {  malformed feature file . class sam exception . class }  )  public void   ( final  string input vcf final  string output loc final  string genotypes file final  file haplotype file )  {   string"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CheckFingerprintTest.java,test base output,"@ test public void   (  )  {   string[] args = new  string[] { ""i = ""  +  test   input   vcf1 ""o = ""  +  test   output ""g = ""  +  test   genotypes   vcf1 ""h = ""  +  subsetted   haplotype   database   for   testing }  ;   assert . assert equals ( run picar"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CheckFingerprintTest.java,test check fingerprint no rg,"@ test ( data provider = ""sams to fingerprint"" )  void   (  file file  file genotypes )  throws io exception  {  tester ( true file genotypes )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CheckFingerprintTest.java,test check fingerprint sam,"@ test ( data provider = ""sams to fingerprint"" )  void   (  file file  file genotypes )  throws io exception  {  tester ( false file genotypes )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CheckFingerprintTest.java,test check fingerprint vcf,"@ test ( data provider = ""vcfs to fingerprint"" )  void   (  file file  file genotypes )  throws io exception  {  tester ( false file genotypes )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CheckFingerprintTest.java,test identify contaminant,"@ test public void   (  )  {  final  file mixture = new  file ( test   data   dir ""na128791   in   na12892 . 25   pct . sam"" )  ;  final  file contaminant = new  file ( test   data   dir ""na12891 . over . fingerprints . r2 . sam"" )  ;  final  file contami"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CheckFingerprintTest.java,test summary and detail outputs,"@ test public void   (  )  {   string[] args = new  string[] { ""i = ""  +  test   input   vcf1 ""s = ""  +  test   data   dir  +  "" / temp checkfp dir / summary"" ""d = ""  +  test   data   dir  +  "" / temp checkfp dir / detail"" ""g = ""  +  test   genotypes   vc"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CheckFingerprintTest.java,tester,"private  file   ( boolean ignorerg  file file  file genotypes )  throws io exception  {  final  list <  string >  args = new  array list <  >  (  )  ;  final  file output summary =  file . create temp file ( ""fingerprint"" ""summary   metrics"" )  ;  output summary . delete on exit (  )  ;  final  file output detail =  file . create temp file ( ""fingerprint"" ""detail   metrics"" )  ;  output summary . delete on exit (  )  ;  args . add ( ""input = ""  +  file . get absolute path (  )  )  ;  args . add ( ""g = ""  +  genotypes . get absolute path (  )  )  ;  if  ( ignorerg )  args . add ( ""ignore   rg = true"" )  ;  args . add ( ""h = ""  +  haplotype   map . get absolute path (  )  )  ;  args . add ( ""summary   output = ""  +  output summary . get absolute path (  )  )  ;  args . add ( ""detail   output = ""  +  output detail . get absolute path (  )  )  ;   assert . assert equals ( run picard command line ( args )  0 )  ;   assert . assert true ( output summary . exists (  )  "" expected output file ""  +  output summary . get absolute path (  )   +  "" to exist . "" )  ;   assert . assert true ( output detail . exists (  )  "" expected output file ""  +  output detail . get absolute path (  )   +  "" to exist . "" )  ;  return output summary ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CheckFingerprintTest.java,vcfs to fingerprint,"@ data provider ( name = "" "" )   object[][] vcfs to fingerprint (  )  {  return new  object[][] {  { na12891   named   na12892   vcf na12892   fp }   { na12892   1   vcf na12892   fp }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fastq\BamToBfqTest.java,inputs,"@ data provider ( name = "" "" )  public static  object[][] inputs (  )  throws io exception  {  return new  object[][] {  { input   bam false ""bam   to   bfq   test"" }   { input   bam true ""bam   to   bfq   paired   test"" }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fastq\BamToBfqTest.java,test bam to bfq,"@ test ( data provider = ""inputs"" )  public void   ( final  file input final boolean is paired run final  string output file prefix )  throws io exception  {  final  file analysis dir = io util . create temp dir ( "" bam to bfq test"" "" . dir"" )  ;  try  { "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\FingerprintCheckerTest.java,p loh data,"@ data provider ( name = ""p loh"" )  public  iterator <  object[] >    (  )  {  final  list <  object[] >  list of doubles = new  array list <  >  (  )  ;  for  ( int i = 1 ;  i  <  20 ;  i +  +  )   {  list of doubles . add ( new  object[] { i  /  40d }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\FingerprintCheckerTest.java,queryable data,"@ data provider ( name = "" "" )  public  iterator <  object[] >  queryable data (  )  throws io exception  {   list <  object[] >  tests = new  array list <  >  (  )  ;  tests . add ( new  object[] { new  file ( test   data   dir ""na12891 . fp . vcf"" )  fa"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\FingerprintCheckerTest.java,setup,@ before class public void   (  )  {  hb . add snp ( snp )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\FingerprintCheckerTest.java,test check fingerprints fail,"@ test ( data provider = ""check fingerprints sam data provider fail"" expected exceptions =  picard exception . class )  public void   ( final  file sam file1 final  file sam file2 final boolean expected match )  {  final  string[] args =  { ""expect   all "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\FingerprintCheckerTest.java,test check fingerprints sam,"@ test ( data provider = ""check fingerprints sam data provider"" )  public void   ( final  file sam file1 final  file sam file2 final boolean expected match final boolean silent )  {  final  string[] args =  { ""expect   all   groups   to   match = true"" ""l"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\FingerprintCheckerTest.java,test check fingerprints sam data provider,"@ data provider ( name = ""check fingerprints sam data provider"" )  public  object[][]   (  )  {  final  file na12891   r1 = new  file ( test   data   dir ""na12891 . over . fingerprints . r1 . sam"" )  ;  final  file na12891   r2 = new  file ( test   data  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\FingerprintCheckerTest.java,test check fingerprints sam data provider fail,"@ data provider ( name = ""check fingerprints sam data provider fail"" )  public  object[][]   (  )  {  final  file na12891   r1 = new  file ( test   data   dir ""na12891 . over . fingerprints . r1 . sam"" )  ;  final  file na12892   r1 = new  file ( test   d"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\FingerprintCheckerTest.java,test check fingerprints vcf,"@ test ( data provider = ""check fingerprints vcf data provider"" )  public void   ( final  file vcf file final  file genotypes file final  string observed sample alias final  string expected sample alias final double ll expected sample final double ll rand"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\FingerprintCheckerTest.java,test check fingerprints vcf data provider,"@ data provider ( name = ""check fingerprints vcf data provider"" )  public  object[][]   (  )  {  return new  object[][] {  { new  file ( test   data   dir ""na12891 . vcf"" )  new  file ( test   data   dir ""na12891 . fp . vcf"" )  ""na12891"" ""na12891""  - 0 . "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\FingerprintCheckerTest.java,test fingerprint vcf,"@ test ( data provider = ""check fingerprints vcf data provider"" )  public void   ( final  file vcf file final  file genotypes file final  string observed sample alias final  string expected sample alias final double ll expected sample final double ll rand"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\FingerprintCheckerTest.java,test match results,"@ test ( data provider = ""p loh"" )  public void   ( final double p loh )  {  final  fingerprint fp observed = new  fingerprint ( ""test"" null ""noop"" )  ;  final  fingerprint fp expected = new  fingerprint ( ""test"" null ""noop"" )  ;  final  haplotype probabi"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\FingerprintCheckerTest.java,test queryable,"@ test ( data provider = ""queryable data"" )  public void   ( final  file vcf boolean expected queryable )  {  try  ( vcf file reader reader = new vcf file reader ( vcf false )  )  {   assert . assert equals ( reader . is queryable (  )  expected queryable"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\FingerprintCheckerTest.java,test random sublist,@ test public void   (  )  throws  exception  {  final  list <  integer >  list = new  array list <  >  (  )  ;  list . add ( 1 )  ;  list . add ( 2 )  ;  list . add ( 3 )  ;   assert . assert equals ( list  fingerprint checker . random sublist ( list 3 )
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\FingerprintCheckerTest.java,test terminate on bad file,@ test ( expected exceptions =  picard exception . class )  public void   (  )  {  final  fingerprint checker fp checker = new  fingerprint checker ( subsetted   haplotype   database   for   testing )  ;  final  file bad sam = new  file ( test   data   di
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\FingerprintCheckerTest.java,test write fingerprint,"@ test public void   (  )  throws io exception  {  final  file haplotype   db = new  file ( test   data   dir ""haplotype map   small . vcf"" )  ;  final  file vcf input = new  file ( test   data   dir ""test sample   small . vcf"" )  ;  final  file fasta = n"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,bam filesl bs,"@ data provider ( name = "" "" )  public  object[][] bam filesl bs (  )  {  return new  object[][] {  { na12891   r1 na12891   r2 0 }   { na12891   r1 na12892   r1 0 }   { na12892   r2 na12891   r2 0 }   { na12892   r2 na12891   r1 0 }   { na12891   r1 na12"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,bam filesr gs,"@ data provider ( name = "" "" )  public  object[][] bam filesr gs (  )  {  return new  object[][] {  { na12891   r1 na12891   r2 false 0  ( na12891   r1   r gs  +  na12891   r2   r gs )  *  ( na12891   r1   r gs  +  na12891   r2   r gs )  }   { na12891   r"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,bam filess ms,"@ data provider ( name = "" "" )  public  object[][] bam filess ms (  )  {  return new  object[][] {  { na12891   r1 na12891   r2 0 1 }   { na12891   r1 na12892   r1 0 2 }   { na12892   r2 na12891   r2 0 2 }   { na12892   r2 na12891   named   na12892   r1 0"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,bam files sources,"@ data provider ( name = "" "" )  public  object[][] bam files sources (  )  {  return new  object[][] {  { na12891   r1 na12891   r2 0 }   { na12892   r1 na12892   r2 0 }   { na12891   r1 na12892   r1 0 }   { na12892   r2 na12891   r2 0 }   { na12892   r2 "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,can write to dev null,"@ test public void   (  )  throws io exception  {   file f = new  file ( "" / dev / null"" )  ;   assert . assert true ( f . can read (  )  )  ;  final  output stream stream = new  file output stream ( f )  ;  final  buffered writer writer = new  buffered w"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,check files data,"@ data provider ( name = "" "" )  public  iterator <  object[] >  check files data (  )  {   list <  object[] >  tests = new  array list <  >  (  )  ;  tests . add ( new  object[] {  arrays . as list ( na12891   1   vcf na12892   1   vcf na12891   g   vcf n"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,check paths data,"@ data provider ( name = "" "" )  public  iterator <  object[] >  check paths data (  )  throws io exception  {   list <  object[] >  tests = new  array list <  >  (  )  ;  final  file fofn =  file . create temp file ( ""crosscheck"" "" . fofn"" test   data   d"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,check sample map failures data,"@ test ( data provider = "" "" expected exceptions =  illegal argument exception . class )  public void check sample map failures data ( final  file input sample map final  file second input sample map )  throws io exception  {   file metrics =  file . crea"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,check samples crosscheck all data,"@ data provider ( name = "" "" )  public  iterator <  object[] >  check samples crosscheck all data (  )  {   list <  object[] >  tests = new  array list <  >  (  )  ;  tests . add ( new  object[] {  arrays . as list ( na12891   1   vcf na12892   1   vcf ) "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,check samples crosscheck all with mapping data,"@ data provider public  iterator <  object[] >    (  )  {   list <  object[] >  tests = new  array list <  >  (  )  ;   file na12892   to   na12891 = new  file ( test   data   dir ""na12892   to   na12891 . txt"" )  ;   file  not there   to   na12892 = new "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,check samples data,"@ data provider ( name = "" "" )  public  iterator <  object[] >  check samples data (  )  {   list <  object[] >  tests = new  array list <  >  (  )  ;  tests . add ( new  object[] {  arrays . as list ( na12891   1   vcf na12892   1   vcf )   arrays . as l"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,do test,private void   ( final  string[] args final  file metrics final int expected ret val final int expectedn metrics final  crosscheck metric .  data type expected type final boolean expect all match )  throws io exception  {  final  crosscheck fingerprints cross checker = new  crosscheck fingerprints (  )  ;   assert . assert equals ( cross checker . instance main ( args )  expected ret val )  ;  final  metrics file <  crosscheck metric  comparable <  ?  >  >  metrics output = new  metrics file <  >  (  )  ;  metrics output . read ( new  file reader ( metrics )  )  ;   assert . assert false ( metrics output . get metrics (  )  . stream (  )  . any match ( m  -  >  m . data   type  !  =  expected type )  )  ;   assert . assert false ( metrics output . get metrics (  )  . stream (  )  . any match ( m  -  >  m . lod   score   normal   tumor  =  =  null )  )  ;   assert . assert false ( metrics output . get metrics (  )  . stream (  )  . any match ( m  -  >  m . lod   score  =  =  null )  )  ;   assert . assert false ( metrics output . get metrics (  )  . stream (  )  . any match ( m  -  >  m . lod   score   tumor   normal  =  =  null )  )  ;  if  ( expect all match )   {   assert . assert true ( metrics output . get metrics (  )  . stream (  )  . all match ( m  -  >  m . result  =  =   crosscheck metric .  fingerprint result . inconclusive || m . result . is match (  )   =  =  m . left   sample . equals ( m . right   sample )  )  )  ;   }  else if  ( expected ret val  =  =  0 )   {   assert . assert true ( metrics output . get metrics (  )  . stream (  )  . all match ( m  -  >  m . result  =  =   crosscheck metric .  fingerprint result . inconclusive || m . result . is expected (  )  )  )  ;   }  else  {   assert . assert true ( metrics output . get metrics (  )  . stream (  )  . any match ( m  -  >   ! m . result . is expected (  )  )  )  ;   }   assert . assert equals ( metrics output . get metrics (  )  . size (  )  expectedn metrics )  ;  if  (  ! metrics output . get metrics (  )  . is empty (  )  && expected type  !  =   crosscheck metric .  data type . readgroup )   {   assert . assert true ( metrics output . get metrics (  )  . stream (  )  . any match ( m  -  >  m . result  !  =   crosscheck metric .  fingerprint result . inconclusive )  )  ;   }  for  (  final  string field name : lookup map . get ( expected type )  )   {  try  {  final  field field =  crosscheck metric . class . get field ( field name )  ;   assert . assert true ( metrics output . get metrics (  )  . stream (  )  . all match ( m  -  >   {  try  {  return field . get ( m )   !  =   fingerprint id details . multiple values string && field . get ( m )   !  =  null ;   }  catch  (   illegal access exception e )   {  e . print stack trace (  )  ;  return false ;   }   }   )  )  ;   }  catch  (   no such field exception e )   {  e . print stack trace (  )  ;  assert false ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,setup,@ before class public void   (  )  throws io exception  {  na12891   r1 =  sam test utils . create indexed bam ( na12891   r1   sam na12891   r1   sam )  ;  na12891   r2 =  sam test utils . create indexed bam ( na12891   r2   sam na12891   r2   sam )  ;  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,test check files,"@ test ( data provider = ""check files data"" )  public void   ( final  list <  file >  files final int expected ret val final int number of samples boolean  expect all match )  throws io exception  {   file metrics =  file . create temp file ( "" fingerprin"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,test check paths,"@ test ( data provider = ""check paths data"" )  public void   ( final  list <  string >  paths final  string haploype map final int expected ret val final int number of samples boolean  expect all match )  throws io exception  {   file metrics =  file . cr"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckReadGroupFingerprintsTest.java,bam filesl bs,"@ data provider ( name = "" "" )  public  object[][] bam filesl bs (  )  {  return new  object[][] {  { na12891   r1 na12891   r2 0 true }   { na12891   r1 na12892   r1 0 false }   { na12892   r2 na12891   r2 0 false }   { na12892   r2 na12891   r1 0 false "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,test check samples,"@ test ( data provider = ""check samples data"" )  public void   ( final  list <  file >  files1 final  list <  file >  files2 final int expected ret val final int number of samples boolean  expect all match )  throws io exception  {   file metrics =  file "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckReadGroupFingerprintsTest.java,bam filesr gs,"@ data provider ( name = "" "" )  public  object[][] bam filesr gs (  )  {  return new  object[][] {  { na12891   r1 na12891   r2 false 0 na12891   r1   r gs  +  na12891   r2   r gs }   { na12891   r1 na12892   r1 false 0 na12891   r1   r gs  +  na12892   r"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckReadGroupFingerprintsTest.java,bam filess ms,"@ data provider ( name = "" "" )  public  object[][] bam filess ms (  )  {  return new  object[][] {  { na12891   r1 na12891   r2 0 1 true }   { na12891   r1 na12892   r1 0 2 false }   { na12892   r2 na12891   r2 0 2 false }   { na12892   r2 na12891   named"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,test cross checkl bs,"@ test ( data provider = ""bam filesl bs"" )  public void   ( final  file file1 final  file file2 final int expected ret val )  throws io exception  {   file metrics =  file . create temp file ( "" fingerprinting"" ""na1291 . lb . crosscheck   metrics"" )  ;  m"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckReadGroupFingerprintsTest.java,bam files sources,"@ data provider ( name = "" "" )  public  object[][] bam files sources (  )  {  return new  object[][] {  { na12891   r1 na12891   r2 0 }   { na12892   r1 na12892   r2 0 }   { na12891   r1 na12892   r1 0 }   { na12892   r2 na12891   r2 0 }   { na12892   r2 "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckReadGroupFingerprintsTest.java,can write to dev null,"@ test public void   (  )  throws io exception  {   file f = new  file ( "" / dev / null"" )  ;   assert . assert true ( f . can read (  )  )  ;  final  output stream stream = new  file output stream ( f )  ;  final  buffered writer writer = new  buffered w"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,test cross checkl bs with clustering,"@ test public void   (  )  throws io exception  {   file metrics =  file . create temp file ( "" fingerprinting"" ""na1291 . lb . crosscheck   metrics"" )  ;  metrics . delete on exit (  )  ;   {  final  string[] args = new  string[] { ""input = ""  +  na12891 "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckReadGroupFingerprintsTest.java,do matrix test,"private void   ( final  string[] args final  file metrics final int expected ret val final int expectedn metrics final boolean expect all match )  throws io exception  {  final  crosscheck read group fingerprints cross checker = new  crosscheck read group fingerprints (  )  ;   assert . assert equals ( cross checker . instance main ( args )  expected ret val )  ;   assert . assert true ( metrics . can read (  )  )  ;  try  (  stream <  string >  lines =  files . lines ( metrics . to path (  )   charset . default charset (  )  )  )  {  long num of lines = lines . count (  )   -  1 ;   assert . assert equals ( num of lines expectedn metrics )  ;   }  if  ( expect all match )   {  try  (  stream <  string >  lines =  files . lines ( metrics . to path (  )   charset . default charset (  )  )  )  {  lines . skip ( 1 )  . for each ( s  -  >   {  final  list <  string >  strings =  arrays . as list ( s . split ( ""\t"" )  )  ;  strings . sub list ( 1 strings . size (  )  )  . for each ( str  -  >   assert . assert true (  double . parse double ( str )   >  0d ""expected positive value  found: ""  +  str )  )  ;   }   )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,test cross checkr gs,"@ test ( data provider = ""bam filesr gs"" )  public void   ( final  file file1 final  file file2 final boolean expect all match final int expected ret val final int expectedn metrics )  throws io exception  {   file metrics =  file . create temp file ( "" f"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,test cross checks ms,"@ test ( data provider = ""bam filess ms"" )  public void   ( final  file file1 final  file file2 final int expected ret val final int number of samples )  throws io exception  {   file metrics =  file . create temp file ( "" fingerprinting"" ""na1291 . sm . c"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,test cross check sources,"@ test ( data provider = ""bam files sources"" )  public void   ( final  file file1 final  file file2 final int expected ret val )  throws io exception  {   file metrics =  file . create temp file ( "" fingerprinting"" ""na1291 .  sources . crosscheck   metric"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckReadGroupFingerprintsTest.java,do test,private void   ( final  string[] args final  file metrics final int expected ret val final int expectedn metrics final  crosscheck metric .  data type expected type final boolean expect all match )  throws io exception   no such field exception  {  final  crosscheck read group fingerprints cross checker = new  crosscheck read group fingerprints (  )  ;   assert . assert equals ( cross checker . instance main ( args )  expected ret val )  ;  final  metrics file <  crosscheck metric  comparable <  ?  >  >  metrics output = new  metrics file <  >  (  )  ;  metrics output . read ( new  file reader ( metrics )  )  ;   assert . assert true ( metrics output . get metrics (  )  . stream (  )  . all match ( m  -  >  m . data   type  =  =  expected type )  )  ;   assert . assert true ( metrics output . get metrics (  )  . stream (  )  . all match ( m  -  >  m . lod   score   normal   tumor  !  =  null )  )  ;   assert . assert true ( metrics output . get metrics (  )  . stream (  )  . all match ( m  -  >  m . lod   score  !  =  null )  )  ;   assert . assert true ( metrics output . get metrics (  )  . stream (  )  . all match ( m  -  >  m . lod   score   tumor   normal  !  =  null )  )  ;  if  ( expect all match )   {   assert . assert true ( metrics output . get metrics (  )  . stream (  )  . all match ( m  -  >  m . result  =  =   crosscheck metric .  fingerprint result . inconclusive || m . result . is match (  )   =  =  m . left   sample . equals ( m . right   sample )  )  )  ;   }  else if  ( expected ret val  =  =  0 )   {   assert . assert true ( metrics output . get metrics (  )  . stream (  )  . all match ( m  -  >  m . result  =  =   crosscheck metric .  fingerprint result . inconclusive || m . result . is expected (  )  )  )  ;   }  else  {   assert . assert true ( metrics output . get metrics (  )  . stream (  )  . any match ( m  -  >   ! m . result . is expected (  )  )  )  ;   }   assert . assert equals ( metrics output . get metrics (  )  . size (  )  expectedn metrics )  ;  if  (  ! metrics output . get metrics (  )  . is empty (  )  && expected type  !  =   crosscheck metric .  data type . readgroup )   {   assert . assert true ( metrics output . get metrics (  )  . stream (  )  . any match ( m  -  >  m . result  !  =   crosscheck metric .  fingerprint result . inconclusive )  )  ;   }  for  (  final  string field name : lookup map . get ( expected type )  )   {  final  field field =  crosscheck metric . class . get field ( field name )  ;   assert . assert true ( metrics output . get metrics (  )  . stream (  )  . all match ( m  -  >   {  try  {  return field . get ( m )   !  =  multiple values string && field . get ( m )   !  =  null ;   }  catch  (   illegal access exception e )   {  e . print stack trace (  )  ;  return false ;   }   }   )  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckReadGroupFingerprintsTest.java,new parameters data,"@ data provider ( name = "" "" )  public  object[][] new parameters data (  )  {  return new  object[][] {  { ""crosscheck   by = ""  +   crosscheck metric .  data type . library }   { ""crosscheck   by = ""  +   crosscheck metric .  data type . sample }   { ""c"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,test second input check all,"@ test ( data provider = ""check samples crosscheck all data"" )  public void   ( final  list <  file >  files1 final  list <  file >  files2 final int expected ret val final int number of samples1 final int number of samples2 boolean  expect all match )  t"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckReadGroupFingerprintsTest.java,setup,@ before class public void   (  )  throws io exception  {  na12891   r1 =  sam test utils . create indexed bam ( na12891   r1   sam na12891   r1   sam )  ;  na12891   r2 =  sam test utils . create indexed bam ( na12891   r2   sam na12891   r2   sam )  ;  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckFingerprintsTest.java,test second input check all with mapping,"@ test ( data provider = ""check samples crosscheck all with mapping data"" )  public void   ( final  list <  file >  files1 final  list <  file >  files2 final  file input sample map final  file second input sample map final int expected ret val final int "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckReadGroupFingerprintsTest.java,test cannot use new parameters,"@ test ( data provider = ""new parameters data"" )  public void   ( final  string extra parameter )  {  final  file file1 = na12891   r1 ;  final  file file2 = na12892   r1 ;  final  string[] args = new  string[] { ""input = ""  +  file1 . get absolute path ("
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckReadGroupFingerprintsTest.java,test cross checkl bs,"@ test ( data provider = ""bam filesl bs"" )  public void   ( final  file file1 final  file file2 final int expected ret val final boolean expect all match )  throws io exception  {   file metrics =  file . create temp file ( "" fingerprinting"" ""na1291 . lb "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckReadGroupFingerprintsTest.java,test cross checkr gs,"@ test ( data provider = ""bam filesr gs"" )  public void   ( final  file file1 final  file file2 final boolean expect all match final int expected ret val final int expectedn metrics )  throws io exception   no such field exception  {   file metrics =  fil"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\CrosscheckReadGroupFingerprintsTest.java,test cross checks ms,"@ test ( data provider = ""bam filess ms"" )  public void   ( final  file file1 final  file file2 final int expected ret val final int number of samples final boolean expected all match )  throws io exception  {   file metrics =  file . create temp file ( """
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\ClusterCrosscheckMetricsTest.java,get command line program name,@ override public  string   (  )  {  return  cluster crosscheck metrics . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\ClusterCrosscheckMetricsTest.java,test simple cluster,"@ test public void   (  )  throws io exception  {   file metrics =  file . create temp file ( "" fingerprinting"" ""na1291   and   na12892 . rg . crosscheck   metrics"" )  ;  metrics . delete on exit (  )  ;  final  string[] args = new  string[] { ""input = "" "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,basedir doesnt exist test,"@ test ( expected exceptions = sam exception . class )  public void   (  )  {  final  string[] args = make checker args ( new  file ( ""a   made   up   file / in   some   weird   location"" )  1 ""76t76t"" new  illumina data type[] {  illumina data type .  po"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,create single locs file,"private void   (  )  {  try  {  final  file single locs file = new  file ( intensity dir  abstract illumina position file reader . s   locs   file )  ;  final  file writer writer = new  file writer ( single locs file )  ;  writer . write ( "" this is a test string . "" )  ;  writer . close (  )  ;   }  catch  (  final io exception e )   {  e . print stack trace (  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,different sized bcl test,@ test public void   (  )  {  final int lane = 5 ;  final  list <  integer >  tiles = make list ( 1 2 3 4 )  ;  final int[] cycles =  illumina file util test . cycle range ( 1 50 )  ;  final  illumina data type[] data types = new  illumina data type[] {  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,get command line program name,public  string   (  )  {  return  check illumina directory . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,make checker args,"public  string[]   ( final  file basecall dir final int lane final  string read structure final  illumina data type[] data types final  list <  integer >  filter tiles final boolean make fake files final boolean create sym links )  {  final  string[] data type args = new  string[data types . length  +  filter tiles . size (  )   +  5] ;  data type args[0] = ""b = ""  +  basecall dir ;  data type args[1] =  standard option definitions . lane   short   name  +  "" = ""  +  lane ;  data type args[2] = ""rs = ""  +  read structure ;  data type args[3] = ""f = ""  +  make fake files ;  data type args[4] = ""x = ""  +  create sym links ;  for  ( int i = 0 ;  i  <  data types . length ;  i +  +  )   {  data type args[i  +  5] = ""dt = ""  +  data types[i] ;   }  if  (  ! filter tiles . is empty (  )  )   {  final int start = data types . length  +  5 ;  for  ( int i = start ;  i  <  data type args . length ;  i +  +  )   {  data type args[i] = ""t = ""  +  filter tiles . get ( i  -  start )  ;   }   }  return data type args ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,make files,public void   ( final  supported illumina format[] formats final int lane final  list <  integer >  tiles final int[] cycles )  {  for  (  final  illumina file util .  supported illumina format format : formats )   {   illumina file util test . make files ( format intensity dir lane tiles cycles )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,make map,"public static  map <  integer  list <  integer >  >    ( final  list <  integer >  lanes final  list <  list <  integer >  >  tiles )  {  final  map <  integer  list <  integer >  >  map = new  hash map <  >  (  )  ;  if  ( lanes . size (  )   !  =  tiles . size (  )  )   {  throw new  illegal argument exception ( "" number of lanes  ( ""  +  lanes  +  "" )  does not equal number of tiles ! "" )  ;   }  for  ( int i = 0 ;  i  <  lanes . size (  )  ;  i +  +  )   {  map . put ( lanes . get ( i )  tiles . get ( i )  )  ;   }  return map ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,negative test data,"@ data provider ( name = "" "" )  public  object[][] negative test data (  )  {  return new  object[][] {  { new  supported illumina format[] {  bcl  filter }  new  illumina data type[] {  base calls  illumina data type .  quality scores  illumina data type"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,negative tests,"@ test ( data provider = ""negative test data"" )  public void   ( final  illumina file util .  supported illumina format[] formats final  illumina data type[] data types final  list <  string >  files to delete final  list <  string >  files to empty final"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,no symlink locs test,@ test public void   (  )  {  symlink test ( false )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,positive test data,"@ data provider ( name = "" "" )  public  object[][] positive test data (  )  {  return new  object[][] {  { new  supported illumina format[] {  bcl  locs  pos  filter }  new  illumina data type[] {  base calls  illumina data type .  quality scores  illumin"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,positive tests,"@ test ( data provider = ""positive test data"" )  public void   ( final  illumina file util .  supported illumina format[] formats final  illumina data type[] data types final int lane final  list <  integer >  tiles final int[] cycles final  string read s"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,set up,"@ before method private void   (  )  throws  exception  {  illumina dir = io util . create temp dir ( ""ift   test"" "" illumina dir"" )  ;  interop dir = new  file ( illumina dir "" inter op"" )  ;  if  (  ! interop dir . exists (  )  &&  ! interop dir . mkdir"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,symlink locs test,@ test public void   (  )  {  symlink test ( true )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,symlink test,"public void   (  boolean create symlinks )  {  final  list <  integer >  tile list = make list ( 1101 1102 1103 2101 2102 2103 )  ;  final int lane = 5 ;  make files ( new  supported illumina format[] {  bcl }  lane tile list  illumina file util test . cycle range ( 1 50 )  )  ;   string[] args = make checker args ( basecall dir lane ""50t"" new  illumina data type[] {  position }  new  array list <  >  (  )  false create symlinks )  ;  write tile metrics out file ( make map ( make list ( lane )  make list ( tile list )  )  )  ;  create single locs file (  )  ;  if  ( create symlinks )   {  final  file intensity lane dir = new  file ( intensity dir  illumina file util . long lane str ( lane )  )  ;  intensity lane dir . mkdirs (  )  ;   }   assert . assert equals ( run picard command line ( args )  0 )  ;  args = make checker args ( basecall dir lane ""50t"" new  illumina data type[] {  illumina data type .  position }  new  array list <  >  (  )  false true )  ;   assert . assert equals ( run picard command line ( args )  0 )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,tear down,@ after method private void   (  )  {  io util . delete directory tree ( data dir )  ;  io util . delete directory tree ( basecall dir )  ;  io util . delete directory tree ( intensity dir )  ;  io util . delete directory tree ( illumina dir )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,write file of size,public void   ( final  file file final int size )  {  try  {  final  buffered writer writer = new  buffered writer ( new  file writer ( file )  )  ;  for  ( int i = 0 ;  i  <  size ;  i +  +  )   {  final int to write =  math . min ( 1000 size )  ;  final char[] write buffer = new char[to write] ;  for  ( int j = 0 ;  j  <  write buffer . length ;  j +  +  )   {  write buffer[j] =  ( char )  (  math . random (  )  * 150 )  ;   }  writer . write ( write buffer )  ;   }  writer . flush (  )  ;  writer . close (  )  ;   }  catch  (  final  exception exc )   {  throw new  runtime exception ( exc )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CheckIlluminaDirectoryTest.java,write tile metrics out file,"public  file   ( final  file interop dir final byte version number final byte record size final  map <  integer  list <  integer >  >  lanes to tiles )  {  final  file tile metrics out = new  file ( interop dir "" tile metrics out . bin"" )  ;  if  (  ! tile metrics out . exists (  )  )   {  try  {  if  (  ! tile metrics out . create new file (  )  )   {  throw new  picard exception ( "" could not create tile metrics out file ( ""  +  tile metrics out . get absolute path (  )   +  "" ) "" )  ;   }   }  catch  (  final io exception e )   {  throw new  picard exception ( ""io exception creating tile metrics out file  ( ""  +  tile metrics out  +  "" )  for writing ! "" e )  ;   }   }  int total entries = 0 ;  for  (  final  map .  entry <  integer  list <  integer >  >  l2t : lanes to tiles . entry set (  )  )   {  total entries +  = l2t . get value (  )  . size (  )  ;   }  final  mapped byte buffer buf ;  try  {  final  random access file raf = new  random access file ( tile metrics out ""rw"" )  ;  final  file channel channel = raf . get channel (  )  ;  buf = channel . map (  file channel .  map mode . read   write 0 2  +  10 * total entries )  ;  buf . order (  byte order . little   endian )  ;  buf . put ( version number )  ;  buf . put ( record size )  ;  for  (  final int lane : lanes to tiles . key set (  )  )   {  for  (  final int tile : lanes to tiles . get ( lane )  )   {  buf . put short (  ( short ) lane )  ;  buf . put short (  ( short ) tile )  ;  buf . put short (  ( short ) 0 )  ;  buf . put float ( 0f )  ;   }   }  buf . force (  )  ;   closer util . close ( channel )  ;   closer util . close ( raf )  ;   }  catch  (  final io exception e )   {  throw new  picard exception ( ""io exception writing tile metrics out file  ( ""  +  tile metrics out  +  "" ) "" e )  ;   }  return tile metrics out ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\HaplotypeMapTest.java,haplotype map for writing,"@ data provider ( name = "" "" )  public  object[][] haplotype map for writing (  )  {  sam file header header = new sam file header (  )  ;  header . set sort order ( sam file header .  sort order . coordinate )  ;  sam sequence dictionary sd = new sam seq"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\HaplotypeMapTest.java,haplotype map reader data,"@ data provider ( name = "" "" )  public  object[][] haplotype map reader data (  )  {  return new  object[][] {  { test   map }   { test   vcf   map }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\HaplotypeMapTest.java,test equivalence hapd bandvcf,@ test public void   (  )  {  final  haplotype map map hapdb = new  haplotype map ( test   map )  ;  final  haplotype map mapvcf = new  haplotype map ( test   vcf   map )  ;  for  (  final  haplotype block haplotype block : map hapdb . get haplotypes (  )
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\HaplotypeMapTest.java,test haplotype map reader,"@ test ( data provider = ""haplotype map reader data"" )  public void   ( final  file file )  {  final  haplotype map map = new  haplotype map ( file )  ;   assert . assert equals ( map . get haplotypes (  )  . size (  )  23 "" wrong number of haplotypes ret"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\HaplotypeMapTest.java,test haplotype map write to vcf,"@ test ( data provider = ""haplotype map for writing"" )  public void   ( final  haplotype map haplotype map )  throws  exception  {  final  file temp =  file . create temp file ( ""haplotype map"" "" . vcf"" )  ;  temp . delete on exit (  )  ;  haplotype map ."
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\HaplotypeMapTest.java,test haplotype map writer,"@ test ( data provider = ""haplotype map for writing"" )  public void   ( final  haplotype map haplotype map )  throws  exception  {   file temp =  file . create temp file ( ""haplotype map"" ""txt"" )  ;  temp . delete on exit (  )  ;  haplotype map . write to"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\HaplotypeProbabilitiesTest.java,data test haplotype probabilities from contaminator sequence add to probs,"@ data provider ( name = "" "" )  public  object[][] data test haplotype probabilities from contaminator sequence add to probs (  )  {  return new  object[][] {  { new  haplotype probabilities from contaminator sequence ( hb1  . 1 )  snp1 0 0 }   { new  hap"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\HaplotypeProbabilitiesTest.java,data test haplotype probabilities from sequence add to probs,"@ data provider ( name = "" "" )  public  object[][] data test haplotype probabilities from sequence add to probs (  )  {  return new  object[][] {  { new  haplotype probabilities from sequence ( hb1 )  snp1 new byte[] {  }  7 }   { new  haplotype probabili"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\HaplotypeProbabilitiesTest.java,data testp evidence given prior fromg ls,"@ data provider ( name = "" "" )  public  object[][] data testp evidence given prior fromg ls (  )  {  return new  object[][] { new  object[] { new  haplotype probabilities from genotype likelihoods ( hb1 )   collections . singleton list ( snp1 )   collecti"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\HaplotypeProbabilitiesTest.java,initialize haplotype block,"@ before test public static void   (  )  {  snp1 = new  snp ( ""snp1"" ""test"" 1  ( byte ) 'a'  ( byte ) 't' 0 . 25  collections .  <  string > empty list (  )  )  ;  snp2 = new  snp ( ""snp2"" ""test"" 2  ( byte ) 'a'  ( byte ) 'g' 0 . 5  collections .  <  stri"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\HaplotypeProbabilitiesTest.java,test haplotype probabilities from contaminator sequence add to probs,"@ test ( data provider = ""data test haplotype probabilities from contaminator sequence add to probs"" )  public void   ( final  haplotype probabilities from contaminator sequence hp final  snp snp final int n alt final int n total )  throws  exception  {  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\HaplotypeProbabilitiesTest.java,test haplotype probabilities from sequence add to probs,"@ test ( data provider = ""data test haplotype probabilities from sequence add to probs"" )  public void   ( final  haplotype probabilities from sequence hp final  snp snp final byte[] bases final int qual )  throws  exception  {  for  (  final byte base : "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\HaplotypeProbabilitiesTest.java,testp evidence given prior fromg ls,"@ test ( data provider = ""data testp evidence given prior fromg ls"" )  public void   ( final  haplotype probabilities from genotype likelihoods hp final  list <  snp >  snps final  list <  boolean >  swaps final  list < double[] >  g ls )  throws  excepti"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\HaplotypeProbabilityOfNormalGivenTumorTest.java,test get likelihoods,"@ test ( data provider = ""  data"" )  public void test get likelihoods ( final double p loh final double[] tumor likelihood final double[] normal likelihood )  throws  exception  {  final  haplotype probabilities hp = new  haplotype probabilities from geno"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\fingerprint\HaplotypeProbabilityOfNormalGivenTumorTest.java,test get likelihoods data,"@ data provider ( name = "" "" )  public  iterator <  object[] >  test get likelihoods data (  )  {  final  list <  object[] >  test data = new  array list <  >  (  )  ;  test data . add ( new  object[] { 0 . 0 new double[] { 1 0 0 }  new double[] { 1 0 0 }"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,get command line program name,public  string   (  )  {  return  extract illumina barcodes . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,get quality test data,"@ data provider ( name = ""quality barcode data"" )  public  object[][]   (  )  {  return new  object[][] {  { 16 0 1 0 "" barcode has good quality  1 match"" }   { 25 0 0 0 "" barcode has quality failures  no matches"" }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,run it,private  metrics file <  extract illumina barcodes .  barcode metric  integer >    ( final  list <  string >  args final  file metrics file )  throws  exception  {   assert . assert equals ( run picard command line ( args )  0 )  ;  final  metrics file <  extract illumina barcodes .  barcode metric  integer >  retval = new  metrics file <  >  (  )  ;  retval . read ( new  file reader ( metrics file )  )  ;  return retval ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,set up,"@ before test private void   (  )  throws  exception  {  basecalls dir =  file . create temp file ( ""eib . "" "" . tmp"" )  ;   assert . assert true ( basecalls dir . delete (  )  )  ;   assert . assert true ( basecalls dir . mkdir (  )  )  ;  io util . copy"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,tear down,@ after test private void   (  )  {  io util . delete directory tree ( basecalls dir )  ;  io util . delete directory tree ( dual )  ;  io util . delete directory tree ( qual )  ;  io util . delete directory tree ( no symlink )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,test barcode matching,"@ test public void   (  )  throws  exception  {  final int lane = 1 ;  final int barcode position = 26 ;  final  metrics file <  extract illumina barcodes .  barcode metric  integer >  metrics file = run it ( lane ""25t8b25t"" )  ;   extract illumina barcod"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,test cbcl dual barcodes,"@ test public void   (  )  throws  exception  {  final  file metrics file =  file . create temp file ( ""cbcl . "" "" . metrics"" )  ;  metrics file . delete on exit (  )  ;  final  string[] args = new  string[] { ""basecalls   dir = ""  +  cbcl . get absolute "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,test dual barcodes,"@ test public void   (  )  throws  exception  {  final  file metrics file =  file . create temp file ( ""dual . "" "" . metrics"" )  ;  metrics file . delete on exit (  )  ;  final  string[] args = new  string[] { ""basecalls   dir = ""  +  dual . get absolute "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,test no locs symlink,"@ test public void   (  )  throws  exception  {  final  file metrics file =  file . create temp file ( ""dual . "" "" . metrics"" )  ;  metrics file . delete on exit (  )  ;  final  string[] args = new  string[] { ""basecalls   dir = ""  +  no symlink . get abs"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,test non writable output file,"@ test public void   (  )  throws  exception  {  final  file existing file = new  file ( basecalls dir ""s   1   1101   barcode . txt . gz"" )  ;  try  {  existing file . set read only (  )  ;  final  string read structure = ""25t8b25t"" ;  final int lane = 1"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,test paired end with barcode and molecular indicies,"@ test public void   (  )  throws  exception  {  final  metrics file <  extract illumina barcodes .  barcode metric  integer >  metrics file = run it ( 1 ""4m21t8b21t4m"" )  ;   assert . assert equals ( metrics file . get metrics (  )  . get ( 0 )  . perfec"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,test paired end with barcode on first end,"@ test public void   (  )  throws  exception  {  final  metrics file <  extract illumina barcodes .  barcode metric  integer >  metrics file = run it ( 1 ""25t8b25t"" )  ;   assert . assert equals ( metrics file . get metrics (  )  . get ( 0 )  . perfect   "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,test paired end with barcode on second end,"@ test public void   (  )  throws  exception  {  final  metrics file <  extract illumina barcodes .  barcode metric  integer >  metrics file = run it ( 1 ""25t25t8b"" )  ;   assert . assert equals ( metrics file . get metrics (  )  . get ( 12 )  . perfect  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,test parsing,private void   ( final  illumina data provider factory factory final  read structure read structure final  extract illumina barcodes .  barcode metric metricacagtg final int barcode position )  {  int num reads = 0 ;  final  base illumina data provider data provider = factory . make data provider (  )  ;  while  ( data provider . has next (  )  )   {  final  cluster data cluster = data provider . next (  )  ;  if  ( metricacagtg . barcode . equals ( cluster . get matched barcode (  )  )  )   {   +  + num reads ;   }   assert . assert equals ( cluster . get read ( read structure . templates . get indices (  ) [0] )  . get qualities (  )  . length barcode position  -  1 )  ;   assert . assert equals ( cluster . get read ( read structure . templates . get indices (  ) [0] )  . get bases (  )  . length barcode position  -  1 )  ;   }   assert . assert equals ( num reads metricacagtg . reads )  ;  data provider . close (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,test quality barcodes,"@ test ( data provider = ""quality barcode data"" )  public void   ( final int quality final int max mismatches final int perfect matches final int one mismatch final  string test name )  throws  exception  {  final  file metrics file =  file . create temp "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,test single end with barcode at end,"@ test public void   (  )  throws  exception  {  final  metrics file <  extract illumina barcodes .  barcode metric  integer >  metrics file = run it ( 1 ""25t8b"" )  ;   assert . assert equals ( metrics file . get metrics (  )  . get ( 0 )  . perfect   mat"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,test single end with barcode at end and molecular indicies,"@ test public void   (  )  throws  exception  {  final  metrics file <  extract illumina barcodes .  barcode metric  integer >  metrics file = run it ( 1 ""4m21t8b"" )  ;   assert . assert equals ( metrics file . get metrics (  )  . get ( 0 )  . perfect   m"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,test single end with barcode at start,"@ test public void   (  )  throws  exception  {  final  metrics file <  extract illumina barcodes .  barcode metric  integer >  metrics file = run it ( 1 ""8b25t"" )  ;   assert . assert equals ( metrics file . get metrics (  )  . get ( 11 )  . perfect   ma"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ExtractIlluminaBarcodesTest.java,test single end with barcode at start and molecular indicies,"@ test public void   (  )  throws  exception  {  final  metrics file <  extract illumina barcodes .  barcode metric  integer >  metrics file = run it ( 1 ""8b4m21t"" )  ;   assert . assert equals ( metrics file . get metrics (  )  . get ( 11 )  . perfect   "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToFastqTest.java,compare fastqs,private void   (  file test data dir  file output sam  string filename )  {   file f1 = new  file ( output sam . get parent file (  )  filename )  ;   file f2 = new  file ( test data dir filename )  ;   fastq reader reader1 = new  fastq reader ( f1 )  ;   list <  fastq record >  reads = new  array list <  >  (  )  ;   fastq reader reader2 = new  fastq reader ( f2 )  ;  for  (   fastq record record : reader1 )   {  reads . add ( record )  ;   }  for  (   fastq record record : reader2 )   {   assert . assert true ( reads . contains ( record )  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToFastqTest.java,convert params file,"private void   (  string library params file int concatn column fields  file test data dir  file output dir  file library params  list <  file >  output prefixes )  throws  file not found exception  {  try  (  line reader reader = new  buffered line reader ( new  file input stream ( new  file ( test data dir library params file )  )  )  )  {  final  print writer writer = new  print writer ( library params )  ;  final  string header = reader . read line (  )  ;  writer . println ( header  +  ""\toutput   prefix"" )  ;  while  ( true )   {  final  string line = reader . read line (  )  ;  if  ( line  =  =  null )   {  break ;   }  final  string[] fields = line . split ( ""\t"" )  ;  final  file output prefix = new  file ( output dir  string util . join ( """"  arrays . copy of range ( fields 0 concatn column fields )  )  )  ;  output prefixes . add ( output prefix )  ;  writer . println ( line  +  ""\t""  +  output prefix )  ;   }  writer . close (  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToFastqTest.java,get command line program name,public  string   (  )  {  return  illumina basecalls to fastq . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToFastqTest.java,run standard test,"private void   ( final int lane final  string job name final  string library params file final int concatn column fields final  string read structure string final  file base calls dir final  file test data dir )  throws  exception  {  final  file output dir =  file . create temp file ( job name "" . dir"" )  ;  try  {  output dir . delete (  )  ;  output dir . mkdir (  )  ;  output dir . delete on exit (  )  ;  final  file library params = new  file ( output dir library params file )  ;  library params . delete on exit (  )  ;  final  list <  file >  output prefixes = new  array list <  file >  (  )  ;  convert params file ( library params file concatn column fields test data dir output dir library params output prefixes )  ;  run picard command line ( new  string[] { ""basecalls   dir = ""  +  base calls dir ""lane = ""  +  lane ""run   barcode =  hi mom"" ""read   structure = ""  +  read structure string ""multiplex   params = ""  +  library params ""machine   name = machine1"" ""flowcell   barcode = abcdeacxx"" ""max   reads   in   ram   per   tile = 100"" }  )  ;  final  read structure read structure = new  read structure ( read structure string )  ;  for  (  final  file output sam : output prefixes )   {  for  ( int i = 1 ;  i  <  =  read structure . templates . length (  )  ;   +  + i )   {  final  string filename = output sam . get name (  )   +  "" . ""  +  i +  "" . fastq"" ;  io util . assert files equal ( new  file ( output sam . get parent file (  )  filename )  new  file ( test data dir filename )  )  ;   }  for  ( int i = 1 ;  i  <  =  read structure . sample barcodes . length (  )  ;   +  + i )   {  final  string filename = output sam . get name (  )   +  "" . barcode   ""  +  i +  "" . fastq"" ;  io util . assert files equal ( new  file ( output sam . get parent file (  )  filename )  new  file ( test data dir filename )  )  ;   }  for  ( int i = 1 ;  i  <  =  read structure . molecular barcode . length (  )  ;   +  + i )   {  final  string filename = output sam . get name (  )   +  "" . index   ""  +  i +  "" . fastq"" ;  io util . assert files equal ( new  file ( output sam . get parent file (  )  filename )  new  file ( test data dir filename )  )  ;   }   }   }  finally  {   test util . recursive delete ( output dir )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToFastqTest.java,test cbcl convert,"@ test public void   (  )  throws  exception  {  run standard test ( 1 ""dual barcode . "" ""barcode   double . params"" 2 ""151t8b8b151t"" test   data   dir   with   cbcls dual   cbcl   test   data   dir )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToFastqTest.java,test de multiplexed,"@ test public void   (  )  throws  exception  {  run standard test ( 1 ""multiplexed barcode . "" ""mp   barcode . params"" 1 ""25t8b25t"" basecalls   dir test   data   dir )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToFastqTest.java,test de multiplexed with index,"@ test public void   (  )  throws  exception  {  run standard test ( 1 ""multiplexed barcode with index . "" ""mp   barcode . params"" 1 ""25t8b4m21t"" basecalls   dir test   data   dir   with   4m )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToFastqTest.java,test de multiplexed withtwo indexes,"@ test public void   (  )  throws  exception  {  run standard test ( 1 ""multiplexed barcode with two indexes . "" ""mp   barcode . params"" 1 ""25t8b4m4m17t"" basecalls   dir test   data   dir   with   4m4m )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToFastqTest.java,test dual barcodes,"@ test public void   (  )  throws  exception  {  run standard test ( 1 ""dual barcode . "" ""barcode   double . params"" 2 ""25t8b8b25t"" dual   basecalls   dir dual   test   data   dir )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToFastqTest.java,test hiseqx single locs,"@ test public void   (  )  throws  exception  {  run standard test ( 1 ""hiseqx single locs . "" ""barcode   double . params"" 2 ""25t8b8b25t"" test   data   hiseqx   single   locs hiseqx   test   data   dir )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToFastqTest.java,test multiplex with illumina read name headers,"@ test public void   (  )  throws  exception  {  final  file output dir =  file . create temp file ( ""test multiplexrh . "" "" . dir"" )  ;  try  {  output dir . delete (  )  ;  output dir . mkdir (  )  ;  output dir . delete on exit (  )  ;  final  string f"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToFastqTest.java,test non barcoded,"@ test public void   (  )  throws  exception  {  final  string suffix = "" . 1 . fastq"" ;  final  file output fastq1 =  file . create temp file ( ""non barcoded . "" suffix )  ;  output fastq1 . delete on exit (  )  ;  final  string output prefix = output fa"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CollectIlluminaBasecallingMetricsTest.java,run it,"private  metrics file <  illumina basecalling metrics  integer >    ( final int lane final  string read structure final  file basecalls dir final  file barcodes dir final boolean is indexed )  throws  exception  {  final  file metrics file =  file . create temp file ( ""cibm . "" "" . metrics"" )  ;  metrics file . delete on exit (  )  ;   array list <  string >  args list = new  array list <  string >  (  )  ;  args list . add ( ""basecalls   dir = ""  +  basecalls dir . get path (  )  )  ;  if  ( null  !  =  barcodes dir )  args list . add ( ""barcodes   dir = ""  +  barcodes dir . get path (  )  )  ;  args list . add ( ""lane = ""  +  lane )  ;  args list . add ( ""output = ""  +  metrics file . get path (  )  )  ;  if  ( read structure  !  =  null )  args list . add ( ""read   structure = ""  +  read structure )  ;  if  ( is indexed )  args list . add ( ""input = ""  +  new  file ( basecalls dir . get path (  )  ""barcode data . ""  +  lane )  . get path (  )  )  ;  final  string[] args = new  string[args list . size (  ) ] ;  args list . to array ( args )  ;   assert . assert equals ( new  collect illumina basecalling metrics (  )  . instance main ( args )  0 )  ;  final  metrics file <  illumina basecalling metrics  integer >  retval = new  metrics file <  illumina basecalling metrics  integer >  (  )  ;  retval . read ( new  file reader ( metrics file )  )  ;  return retval ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CollectIlluminaBasecallingMetricsTest.java,set up,"@ before test private void   (  )  throws  exception  {  root test dir =  file . create temp file ( ""cibm . "" "" . tmp"" )  ;   assert . assert true ( root test dir . delete (  )  )  ;   assert . assert true ( root test dir . mkdir (  )  )  ;  for  (  final"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CollectIlluminaBasecallingMetricsTest.java,tear down,@ after test private void   (  )  {  io util . delete directory tree ( root test dir )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CollectIlluminaBasecallingMetricsTest.java,test indexed run lane,"@ test ( data provider = ""  data provider"" )  public void test indexed run lane1 ( final boolean use barcodes dir )  throws  exception  {  final  file barcodes dir =  ( use barcodes dir )   ?  new  file ( root test dir "" / 25t8b25t / barcodes   dir"" )  : "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CollectIlluminaBasecallingMetricsTest.java,test indexed run lane data provider,"@ data provider ( name = "" "" )  public  object[][] test indexed run lane1 data provider (  )  {  return new  object[][] {  { true }   { false }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CollectIlluminaBasecallingMetricsTest.java,test non indexed run lane,"@ test public void   (  )  throws  exception  {  final  metrics file <  illumina basecalling metrics  integer >  metrics file = run it ( 1 ""125t125t"" new  file ( root test dir ""125t125t /  data /  intensities /  base calls"" )  null false )  ;  final  illu"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\CollectIlluminaBasecallingMetricsTest.java,test novaseq indexed run,"@ test public void   (  )  throws  exception  {  final  metrics file <  illumina basecalling metrics  integer >  metrics file = run it ( 1 ""151t8b8b151t"" new  file ( ""testdata / picard / illumina / 151t8b8b151t   cbcl /  data /  intensities /  base calls"""
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,get command line program name,public  string   (  )  {  return  illumina basecalls to sam . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,run standard test,"private void   ( final int lane final  string job name final  string library params file final int concatn column fields final  string read structure final  file base calls dir final  file test data dir final  integer tile )  throws  exception  {  final  path output dir =  files . create temp directory ( job name )  ;  try  {  final  string tile prefix =  ( tile  !  =  null )   ?  tile  +  "" . "" : """" ;  final  file library params = new  file ( output dir . to file (  )  library params file )  ;  library params . delete on exit (  )  ;  final  list <  file >  sam files = new  array list <  file >  (  )  ;  final  line reader reader = new  buffered line reader ( new  file input stream ( new  file ( test data dir library params file )  )  )  ;  final  print writer writer = new  print writer ( library params )  ;  final  string header = reader . read line (  )  ;  writer . println ( header  +  ""\toutput"" )  ;  while  ( true )   {  final  string line = reader . read line (  )  ;  if  ( line  =  =  null )   {  break ;   }  final  string[] fields = line . split ( ""\t"" )  ;  final  file output sam = new  file ( output dir . to file (  )   string util . join ( """"  arrays . copy of range ( fields 0 concatn column fields )  )   +  "" . sam"" )  ;  output sam . delete on exit (  )  ;  sam files . add ( new  file ( output sam . get parent file (  )  tile prefix  +  output sam . get name (  )  )  )  ;  writer . println ( line  +  ""\t""  +  output sam )  ;   }  writer . close (  )  ;  reader . close (  )  ;   list <  string >  args = new  array list <  >  (  )  ;  args . add ( ""basecalls   dir = ""  +  base calls dir )  ;  args . add ( ""lane = ""  +  lane )  ;  args . add ( ""run   barcode =  hi mom"" )  ;  args . add ( ""read   structure = ""  +  read structure )  ;  args . add ( ""library   params = ""  +  library params )  ;  if  ( tile  !  =  null )   {  args . add ( ""process   single   tile = ""  +  tile )  ;   }   assert . assert equals ( run picard command line ( args )  0 )  ;  for  (  final  file output sam : sam files )   {  io util . assert files equal ( output sam new  file ( test data dir output sam . get name (  )  )  )  ;   }   }  finally  {   test util . recursive delete ( output dir . to file (  )  )  ;   files . delete ( output dir )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test cbcl convert,"@ test public void   (  )  throws  exception  {  run standard test ( 1 ""cbcl convert . "" ""barcode   double . params"" 2 ""151t8b8b151t"" test   data   dir   with   cbcls dual   cbcl   test   data   dir )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test cbcl convert single tile,"@ test public void   (  )  throws  exception  {  run standard test ( 1 ""cbcl convert . "" ""barcode   double . params"" 2 ""151t8b8b151t"" test   data   dir   with   cbcls dual   cbcl   test   data   dir 1102 )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test corrupt data return code,"@ test ( groups =  { ""broken"" }  )  public void   (  )  throws  exception  {  boolean exception thrown = false ;  try  {  run standard test ( 9 ""dual barcode . "" ""negative   test . params"" 2 ""30t8b8b"" basecalls   dir test   data   dir )  ;   }  catch  (  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test dual barcodes,"@ test public void   (  )  throws  exception  {  run standard test ( 1 ""dual barcode . "" ""barcode   double . params"" 2 ""25t8b8b25t"" dual   basecalls   dir dual   test   data   dir )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test dual barcodes single tile,"@ test public void   (  )  throws  exception  {  run standard test ( 1 ""dual barcode . "" ""barcode   double . params"" 2 ""25t8b8b25t"" dual   basecalls   dir dual   test   data   dir 1101 )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test hiseqx single locs,"@ test public void   (  )  throws  exception  {  run standard test ( 1 ""hiseqx single locs . "" ""barcode   double . params"" 2 ""25t8b8b25t"" test   data   hiseqx   single   locs hiseqx   test   data   dir )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test multiplexed,"@ test public void   (  )  throws  exception  {  run standard test ( 1 ""multiplexed barcode . "" ""barcode . params"" 1 ""25t8b25t"" basecalls   dir test   data   dir )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test multiplexed withmm index,"@ test public void   (  )  throws  exception  {  run standard test ( 1 ""multiplexed barcode2 . "" ""barcode . params"" 1 ""25t8b4m4m17t"" basecalls   dir test   data   dir   with   4m4m   index )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test multiplexed withm index,"@ test public void   (  )  throws  exception  {  run standard test ( 1 ""multiplexed barcode . "" ""barcode . params"" 1 ""25t8b4m21t"" basecalls   dir test   data   dir   with   4m   index )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test multiplexed with alternate barcode name,"@ test public void   (  )  throws  exception  {  run standard test ( 1 ""single barcode alt name . "" ""multiplexed   positive   rgtags . params"" 1 ""25t8b25t"" basecalls   dir test   data   dir )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test non barcoded,"@ test public void   (  )  throws  exception  {  final  file output bam =  file . create temp file ( ""non barcoded . "" "" . sam"" )  ;  output bam . delete on exit (  )  ;  final int lane = 1 ;   assert . assert equals ( run picard command line ( new  strin"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test non barcoded tile subset,"@ test public void   (  )  throws  exception  {  final  file output bam =  file . create temp file ( ""non barcoded . "" "" . sam"" )  ;  output bam . delete on exit (  )  ;  final int lane = 1 ;   assert . assert equals ( run picard command line ( new  strin"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test non barcoded with dual moleclar index,"@ test public void   (  )  throws  exception  {  final  file output bam =  file . create temp file ( ""non barcoded with dualmi . "" "" . sam"" )  ;  output bam . delete on exit (  )  ;  final int lane = 1 ;   assert . assert equals ( run picard command line "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test non barcoded with molecular index,"@ test public void   (  )  throws  exception  {  final  file output bam =  file . create temp file ( ""non barcoded withmi . "" "" . sam"" )  ;  output bam . delete on exit (  )  ;  final int lane = 1 ;   assert . assert equals ( run picard command line ( new"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test non barcoded with tag per molecular index dual,"@ test public void   (  )  throws  exception  {  final  file output bam =  file . create temp file ( ""non barcoded with dualmi . "" "" . sam"" )  ;  output bam . delete on exit (  )  ;  final int lane = 1 ;   assert . assert equals ( run picard command line "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test non barcoded with tag per molecular index dual four molecular indexes,"@ test public void   (  )  throws  exception  {  final  file output bam =  file . create temp file ( ""non barcoded with dualmi . "" "" . sam"" )  ;  output bam . delete on exit (  )  ;  final int lane = 1 ;   assert . assert equals ( run picard command line "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test non barcoded with tag per molecular index dual too few tags,"@ test public void   (  )  throws  exception  {  final  file output bam =  file . create temp file ( ""non barcoded with dualmi . "" "" . sam"" )  ;  output bam . delete on exit (  )  ;  final int lane = 1 ;   assert . assert equals ( run picard command line "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test non barcoded with tag per molecular index dual too many tags,"@ test public void   (  )  throws  exception  {  final  file output bam =  file . create temp file ( ""non barcoded with dualmi . "" "" . sam"" )  ;  output bam . delete on exit (  )  ;  final int lane = 1 ;   assert . assert equals ( run picard command line "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test non barcoded with tag per molecular index isn ull,"@ test public void   (  )  throws  exception  {  final  file output bam =  file . create temp file ( ""non barcoded withmi . "" "" . sam"" )  ;  output bam . delete on exit (  )  ;  final int lane = 1 ;   assert . assert equals ( run picard command line ( new"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamTest.java,test tile number comparator,"@ test public void   (  )  {   assert . assert true (  illumina basecalls converter . tile   number   comparator . compare ( 100 10 )   <  0 """" )  ;   assert . assert true (  illumina basecalls converter . tile   number   comparator . compare ( 20 200 )  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamAdapterClippingTest.java,get command line program name,public  string   (  )  {  return  illumina basecalls to sam . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamAdapterClippingTest.java,get illumina basecalls to sam test data,"@ data provider ( name = ""data"" )  private  object[][]   (  )  {  return new  object[][] {  { ""1"" ""125t125t"" null null 32 }   { ""2"" ""125t125t"" null null 108 }   { ""1"" ""125t125t"" ""acgtacgtacgtacgt"" ""acgtacgtacgtacgt"" 0 }   { ""2"" ""125t125t"" ""acgtacgtacgtacg"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaBasecallsToSamAdapterClippingTest.java,test basic,"@ test ( data provider = ""data"" )  public void   ( final  string lane final  string read structure final  string five primer adapter final  string three primer adapter final int expected num clipped records )  throws  exception  {  final  file sam file = "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaLaneMetricsCollectorTest.java,build output file,"private static  file   ( final  file directory final  string prefix final  string extension )  {  return new  file ( directory  string . format ( ""%s . %s"" prefix extension )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaLaneMetricsCollectorTest.java,test collect illumina lane metrics,"@ test ( data provider = "" "" )  public void test collect illumina lane metrics ( final  string test run final  read structure read structure final boolean is nova seq )  throws  exception  {  for  (  final boolean use read structure :  arrays . as list ( "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaLaneMetricsCollectorTest.java,test collect illumina lane metrics data provider,"@ data provider ( name = ""test collect illumina lane metrics"" )  public  object[][]   (  )  {  return new  object[][] {  { ""a7le0"" new  read structure ( ""25t8b8b25t"" )  false }   { ""c2mfaacxx"" new  read structure ( ""95t101t"" )  false }   { ""h7batadxx"" new"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaLaneMetricsCollectorTest.java,test lane metrics data provider,"@ data provider ( name = ""test lane metrics"" )  public  object[][]   (  )  {  return new  object[][] {  { ""130321   sl - mak   0035   fc000000000 - a306b"" }   { ""130318   sl - hbb   0226   bfcc1wymacxx"" }   { ""130401   sl - hac   0022   bh07pbadxx"" }  }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaLaneMetricsCollectorTest.java,test missing phasing values silent,"@ test public void   (  )  throws io exception  {  final  read structure read structure = new  read structure ( ""151t8b8b151t"" )  ;  for  (  final boolean use read structure :  arrays . as list ( true false )  )   {  final  file run directory = test   mis"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaLaneMetricsCollectorTest.java,test missing phasing values strict,"@ test ( expected exceptions =  picard exception . class )  public void   (  )  {  final  read structure read structure = new  read structure ( ""151t8b8b151t"" )  ;  for  (  final boolean use read structure :  arrays . as list ( true false )  )   {  final "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\IlluminaLaneMetricsCollectorTest.java,test write lane metrics,"@ test ( data provider = ""test lane metrics"" )  public void   ( final  string test run )  throws  exception  {  for  (  final boolean use read structure :  arrays . as list ( true false )  )   {  final  collect illumina lane metrics clp = new  collect ill"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java, bases and quals,public   ( final byte[] bases final byte[] quals final  integer mask start )  {  this . bases = bases ;  this . quals = quals ;  this . masked quals = quals masked from ( mask start )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,bases to string,"public  string   (  )  {  final  string builder sb = new  string builder ( bases . length )  ;  for  (  final byte base : bases )   {  switch  ( base )   {  case a: sb . append ( ""a "" )  ;  break ;  case c: sb . append ( ""c "" )  ;  break ;  case g: sb . append ( ""g "" )  ;  break ;  case t: sb . append ( ""t "" )  ;  break ;  case p: sb . append ( "" .  "" )  ;  break ;  default : throw new  runtime exception ( ""this should not happen !   bad byte in bases ! "" )  ;   }   }  return sb . to string (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,box arr,public static  integer[]   ( final int[] ints )  {  final  integer[] box arr = new  integer[ints . length] ;  for  ( int i = 0 ;  i  <  box arr . length ;  i +  +  )   {  box arr[i] = ints[i] ;   }  return box arr ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,compare cluster to bcl data,"public void   ( final  cluster data cluster final  bcl data bcl data final int cluster num final int count num )  {  final byte[][] bases = bcl data . get bases (  )  ;  final byte[][] qualities = bcl data . get qualities (  )  ;   assert . assert equals ( bases . length cluster . get num reads (  )  "" at cluster num ""  +  cluster num )  ;   assert . assert equals ( qualities . length cluster . get num reads (  )  "" at cluster num ""  +  cluster num )  ;  final  string builder base builder = new  string builder (  )  ;  final  string builder qual builder = new  string builder (  )  ;  final  string builder barcode = new  string builder (  )  ;  base builder . append ( ""new byte[] { "" )  ;  for  ( int i = 0 ;  i  <  bases . length ;  i +  +  )   {  final byte[] sub base = bases[i] ;  final byte[] sub qual = qualities[i] ;  for  ( int j = 0 ;  j  <  sub base . length ;  j +  +  )   {  if  (  ( char ) sub base[j]  =  =  ' . ' )   {  base builder . append ( 'p' )  ;   }  else  {  base builder . append (  ( char ) sub base[j] )  ;   }  base builder . append ( "" "" )  ;  qual builder . append ( sub qual[j] )  ;  qual builder . append ( "" "" )  ;  if  ( i  =  =  1 )   {  if  (  ( char ) sub base[j]  =  =  ' . ' )   {  barcode . append ( 'p' )  ;   }  else  {  barcode . append (  ( char ) sub base[j] )  ;   }   }   }   }  base builder . delete char at ( base builder . length (  )   -  1 )  ;  qual builder . delete char at ( qual builder . length (  )   -  1 )  ;  base builder . append ( "" }  \n new byte[] { "" )  ;  base builder . append ( qual builder . to string (  )  )  ;  base builder . append ( "" }  \n \"""" )  ;  base builder . append ( barcode . to string (  )  )  ;  base builder . append ( ""\"""" )  ;  for  ( int i = 0 ;  i  <  cluster . get num reads (  )  ;  i +  +  )   {  if  (  !  arrays . equals ( bases[i] cluster . get read ( i )  . get bases (  )  )  )   {   system . out . println ( cluster . get lane (  )   +  "" : ""  +  cluster . get tile (  )  +  "" : "" +  cluster num )  ;   system . out . println ( base builder . to string (  )  )  ;   }   assert . assert equals ( bases[i] cluster . get read ( i )  . get bases (  )  ""  bases differ for read ""  +  i  +  "" at cluster num "" +  cluster num +  "" at cluster count "" +  count num )  ;   assert . assert equals ( qualities[i] cluster . get read ( i )  . get qualities (  )  ""  qualities differ for read ""  +  i  +  "" at cluster num "" +  cluster num +  "" at cluster count "" +  count num )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,copy bcls,"public static void   ( final  file src lane dir final  file dst dir )  {  final  file[] list files = src lane dir . list files (  )  ;  for  (  final  file dir : list files )   {  if  ( dir . is directory (  )  )   {   file cycle dir = null ;  for  (  final  file file : dir . list files (  )  )   {  if  ( file . get name (  )  . ends with ( "" . bcl"" )  )   {  if  ( cycle dir  =  =  null )   {  cycle dir = new  file ( dst dir dir . get name (  )  )  ;  if  (  ! cycle dir . mkdir (  )  )   {  throw new  runtime exception ( "" couldn't make directory  ( ""  +  cycle dir . get absolute path (  )   +  "" ) "" )  ;   }   }  io util . copy file ( file new  file ( cycle dir file . get name (  )  )  )  ;   }   }   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,delete bcl files,"public static void   ( final  file lane directory final  string read structure )  {  final  read structure rs = new  read structure ( read structure )  ;  int index = 1 ;  for  (  final  read descriptor rd : rs . descriptors )   {  if  ( rd . type  =  =   read type . s )   {  for  ( int i = index ;  i  <  index  +  rd . length ;  i +  +  )   {  final  file cycle dir = new  file ( lane directory ""c""  +  i  +  "" . 1"" )  ;  final  file[] cycle files = cycle dir . list files (  )  ;  for  (  final  file to delete : cycle files )   {  if  (  ! to delete . delete (  )  )   {  throw new  runtime exception ( "" couldn't delete file ""  +  to delete . get absolute path (  )  )  ;   }   }   }   }  index +  = rd . length ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,eamss data nog series,"@ data provider ( name = "" "" )  public  object[][] eamss data no10g series (  )  {  return new  object[][] {  { new  bases and quals ( new byte[] { g g g g g g g g g }  new byte[] { 13 7 35 32 31 33 31 26 29 }  null )  }   { new  bases and quals ( new byt"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,eamss parsing test nog series,"@ test ( data provider = ""eamss data no10g series"" )  public void   ( final  bases and quals bq )  {  test eamss ( bq )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,eamss parsing test withg series,"@ test ( data provider = ""eamss data withg series"" )  public void   ( final  bases and quals bq )  {  test eamss ( bq )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,eamss test dat,"@ data provider ( name = ""eamss data withg series"" )  public  object[][]   (  )  {  return new  object[][] {  { new  bases and quals ( new byte[] { a c g g t g g g g g g g g g a c t }  new byte[] { 7 8 33 7 12 33 16 17 2 2 32 35 35 35 2 15 9 }  5 )  }   {"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,full bcl parser test,"@ test ( data provider = ""tile maps"" )  public void   ( final int[] tiles final int size final int seek after final int new tile index final int ordered tile index )  {  full bcl parser test impl ( test   data   dir read   structure tiles size seek after "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BinTdUtil.java,cluster data,public static  map <  integer  cluster data >    ( final int lane final  list <  integer >  tiles final  string read structure final  illumina data type .  .  .  data types )  {  final  list <  integer >  sorted tiles = new  array list <  integer >  ( tiles )  ;   collections . sort ( sorted tiles )  ;  final  map <  integer  cluster data >  data = new  hash map <  integer  cluster data >  (  )  ;  int offset = 0 ;  for  (  final int tile : sorted tiles )   {  final  string key = lt str ( lane tile )  ;  final  list <  cluster data >  cds = gold data . get ( key )  ;  final  list <  integer >  read nos = gold indices . get ( key )  ;  final int size = gold sizes . get ( key )  ;  for  ( int i = 0 ;  i  <  cds . size (  )  ;  i +  +  )   {  data . put ( offset  +  read nos . get ( i )  selective copy cd ( cds . get ( i )  read structure data types )  )  ;   }  offset +  = size ;   }  return data ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BinTdUtil.java,copy intensities,private static  four channel intensity data   ( final  four channel intensity data to copy final int start final int length )  {  final  four channel intensity data fcid = new  four channel intensity data ( length )  ;   system . arraycopy ( to copy . geta (  )  start fcid . geta (  )  0 length )  ;   system . arraycopy ( to copy . getc (  )  start fcid . getc (  )  0 length )  ;   system . arraycopy ( to copy . getg (  )  start fcid . getg (  )  0 length )  ;   system . arraycopy ( to copy . gett (  )  start fcid . gett (  )  0 length )  ;  return fcid ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BinTdUtil.java,copy read data,public static  read data[]   ( final  read structure rs final  illumina data type[] dts final  cluster data to copy )  {  boolean do bases = false ;  boolean do quals = false ;  for  (  final  illumina data type dt : dts )   {  switch  ( dt )   {  case  base calls: do bases = true ;  break ;  case  quality scores: do quals = true ;  break ;   }   }  if  (  ! do bases &&  ! do quals )  return null ;  final  read data rd to copy = to copy . get read ( 0 )  ;  final  read data[] rds = new  read data[rs . non skips . length (  ) ] ;  int index = 0 ;  int base index = 0 ;  for  ( int i = 0 ;  i  <  rs . descriptors . size (  )  ;  i +  +  )   {  final  read descriptor read desc = rs . descriptors . get ( i )  ;  if  ( read desc . type  !  =   read type . s )   {  final  read data cur read = new  read data ( read desc . type )  ;  if  ( do bases )   {  final byte[] bases =  arrays . copy of range ( rd to copy . get bases (  )  base index base index  +  read desc . length )  ;  cur read . set bases ( bases )  ;   }  if  ( do quals )   {  final byte[] quals =  arrays . copy of range ( rd to copy . get qualities (  )  base index base index  +  read desc . length )  ;  cur read . set qualities ( quals )  ;   }  rds[index +  + ] = cur read ;   }  base index +  = read desc . length ;   }  return rds ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BinTdUtil.java,lt str,"public static final  string   ( final int lane final int tile )  {  return ""s   ""  +  lane  +  ""   "" +  tile ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BinTdUtil.java,make cd,public static  cluster data   ( final int lane final int tile final int x coord final int y coord final boolean pf final byte[] bases final byte[] qualities final  string matched barcode )  {  final  read data rd = new  read data (  )  ;  rd . set bases (  arrays . copy of ( bases bases . length )  )  ;  rd . set qualities (  arrays . copy of ( qualities bases . length )  )  ;  rd . set read type (  read type . t )  ;  final  cluster data cd = new  cluster data ( rd )  ;  cd . set lane ( lane )  ;  cd . set tile ( tile )  ;  cd . setx ( x coord )  ;  cd . sety ( y coord )  ;  cd . set pf ( pf )  ;  cd . set matched barcode ( matched barcode )  ;  return cd ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BinTdUtil.java,selective copy cd,public static  cluster data   ( final  cluster data to copy final  string read structure final  illumina data type .  .  .  data types )  {  final  read structure rs = new  read structure ( read structure )  ;  final  read data[] rd = copy read data ( rs data types to copy )  ;  final  cluster data cd = new  cluster data ( rd )  ;  cd . set tile ( to copy . get tile (  )  )  ;  cd . set lane ( to copy . get lane (  )  )  ;  for  (  final  illumina data type idt : data types )   {  switch  ( idt )   {  case  position: cd . setx ( to copy . getx (  )  )  ;  cd . sety ( to copy . gety (  )  )  ;  break ;  case pf: cd . set pf ( to copy . is pf (  )  )  ;  break ;  case  barcodes: cd . set matched barcode ( to copy . get matched barcode (  )  )  ;  break ;  default : break ;   }   }  return cd ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,full bcl parser test impl,"public void   ( final  file dir final  string read structure final int[] tiles final int size final int seek after final int new tile index final int ordered tile index final boolean multi tile )  {  final  read structure rs = new  read structure ( read structure )  ;  final  output mapping output mapping = new  output mapping ( rs )  ;  final  illumina file util util = new  illumina file util ( dir . get parent file (  )  lane )  ;  final  per tile per cycle file util bcl file util =  (  per tile per cycle file util ) util . get util (  illumina file util .  supported illumina format .  bcl )  ;  final  multi tile bcl file util multi tile bcl file util =  (  multi tile bcl file util ) util . get util (  illumina file util .  supported illumina format .  multi tile bcl )  ;  final  list <  integer >  tile integers = new  array list <  integer >  (  )  ;  for  (  final int tile : tiles )   {  tile integers . add ( tile )  ;   }  final  bcl parser bcl parser ;  if  ( multi tile )   {  final  file bci = new  file ( multi   tile   data   dir ""s   ""  +  lane  +  "" . bci"" )  ;  bcl parser = new  multi tile bcl parser ( dir lane multi tile bcl file util . get files ( tile integers output mapping . get output cycles (  )  )  output mapping true new  bcl quality evaluation strategy (  bcl quality evaluation strategy . illumina   alleged   minimum   quality )  new  tile index ( bci )  )  ;   }  else  {  bcl parser = new  bcl parser ( dir lane bcl file util . get files ( tile integers output mapping . get output cycles (  )  )  output mapping new  bcl quality evaluation strategy (  bcl quality evaluation strategy . illumina   alleged   minimum   quality )  )  ;   }  final  map <  integer  cluster data >  test data =  bin td util . cluster data ( lane  arrays . as list ( box arr ( tiles )  )  read structure data   types )  ;  int count = 0 ;  int read num = 0 ;  while  ( bcl parser . has next (  )  )   {  final  bcl data bcl data = bcl parser . next (  )  ;  if  ( test data . contains key ( read num )  )   {  compare cluster to bcl data ( test data . get ( read num )  bcl data read num count )  ;   }  if  ( count  =  =  seek after )   {  bcl parser . seek to tile ( tiles[new tile index] )  ;  read num =  ( ordered tile index * tile   sizes )  ;   }  else  {  read num +  +  ;   }  count +  +  ;   }   assert . assert equals ( count size )  ;  bcl parser . close (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,full bcl parser testw bad deleted skips,"@ test ( data provider = ""tile maps"" expected exceptions =  runtime exception . class )  public void   ( final int[] tiles final int size final int seek after final int new tile index final int ordered tile index )  {  full bcl parser testw deleted skips "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,full bcl parser testw deleted skips,"@ test ( data provider = ""tile maps"" )  public void   ( final int[] tiles final int size final int seek after final int new tile index final int ordered tile index )  {  full bcl parser testw deleted skips impl ( tiles size seek after new tile index order"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,full bcl parser testw deleted skips impl,"public void   ( final int[] tiles final int size final int seek after final int new tile index final int ordered tile index final  string read structure )  {  final  file basecall dir = io util . create temp dir ( ""bcl parser test"" "" base calls"" )  ;   exception exc = null ;  try  {  final  file l001 = new  file ( basecall dir ""l001"" )  ;  if  (  ! l001 . mkdir (  )  )   {  throw new  runtime exception ( "" couldn't make lane dir ""  +  l001 . get absolute path (  )  )  ;   }  copy bcls ( test   data   dir l001 )  ;  delete bcl files ( l001 read structure )  ;  full bcl parser test impl ( l001 read   structure   wskips tiles size seek after new tile index ordered tile index false )  ;   }  catch  (  final  exception thr exc )   {  exc = thr exc ;   }  finally  {  io util . delete directory tree ( basecall dir )  ;   }  if  ( exc  !  =  null )   {  if  ( exc . get class (  )   =  =   picard exception . class )   {  throw new  picard exception ( exc . get message (  )  )  ;   }  throw new  runtime exception ( exc )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,full bcl parser testw partially deleted skips,"@ test ( data provider = ""tile maps"" )  public void   ( final int[] tiles final int size final int seek after final int new tile index final int ordered tile index )  {  full bcl parser testw deleted skips impl ( tiles size seek after new tile index order"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,full bcl parser testw skips,"@ test ( data provider = ""tile maps"" )  public void   ( final int[] tiles final int size final int seek after final int new tile index final int ordered tile index )  {  full bcl parser test impl ( test   data   dir read   structure   wskips tiles size se"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,fullmt bcl parser test,public void   ( final int[] tiles final int size final int seek after final int new tile index final int ordered tile index )  {  full bcl parser test impl ( multi   tile   data   dir read   structure tiles size seek after new tile index ordered tile index true )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,get multi tile maps,"@ data provider ( name = ""multi tile maps"" )  public  object[][]   (  )  {  return new  object[][] {  { new int[] { 11101 11102 11103 }  341292  - 1  - 1  - 1 }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,get tile maps,"@ data provider ( name = ""tile maps"" )  public  object[][]   (  )  {  return new  object[][] {  { new int[] { 1101 1201 2101 }  180  - 1  - 1  - 1 }   { new int[] { 1101 2101 1201 }  180  - 1  - 1  - 1 }   { new int[] { 2101 1201 }  120  - 1  - 1  - 1 }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,quals masked from,private byte[]   ( final  integer mask start )  {  final byte[] masked quals =  arrays . copy of ( quals quals . length )  ;  if  ( mask start  !  =  null )   {  for  ( int i = mask start ;  i  <  masked quals . length ;  i +  +  )   {  masked quals[i] =  bcl parser . masking   quality ;   }   }  return masked quals ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,quals to string,"public  string   ( final byte[] quals to convert )  {  final  string builder sb = new  string builder ( bases . length )  ;  for  (  final byte qual : quals to convert )   {  sb . append (  string . value of (  ( int ) qual )  )  ;  sb . append ( "" "" )  ;   }  return sb . to string (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,test eamss,public void   ( final  bases and quals bq )  {  final byte[] bases =  arrays . copy of ( bq . bases bq . bases . length )  ;  final byte[] quals =  arrays . copy of ( bq . quals bq . quals . length )  ;   bcl parser . run eamss for read in place ( bases quals )  ;   assert . assert equals ( bases bq . bases )  ;   assert . assert equals ( quals bq . masked quals )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\BclParserTest.java,to string,"public  string   (  )  {  return "" bases and quals (  ""  +  bases to string (  )   +  ""  "" +  quals to string ( quals )  +  ""  "" +  quals to string ( masked quals )  +  "" ) "" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\CycleIlluminaFileMapTest.java,construct path string,"private static  string   ( int lane int cycle )  {  return test   data   dir  +  "" / ""  +  lane to dir ( lane )  +  "" / c"" +  cycle +  "" . 1"" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\CycleIlluminaFileMapTest.java,iterator test data,"@ data provider ( name = "" "" )  public  object[][] iterator test data (  )  {  return new  object[][] { new  object[] { test   data   dir 1 1101 "" . bcl"" make list ( new  file ( test   data   dir  +  "" / c1 . 1"" ""s   1   1101 . bcl"" )  new  file ( test   "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\CycleIlluminaFileMapTest.java,lane to dir,"private static  string   ( int lane )  {   string out str =  string . value of ( lane )  ;  while  ( out str . length (  )   <  3 )   {  out str = ""0""  +  out str ;   }  return ""l""  +  out str ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\fakers\BclFileFakerTest.java,test file length matches header length,"@ test public void   (  )  throws  exception  {  final  file fake file =  file . create temp file ( "" bcl file faker test"" "" . bcl"" )  ;  fake file . delete on exit (  )  ;  new  bcl file faker (  )  . fake file ( fake file 100000 )  ;  final  bcl reader "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\fakers\BclFileFakerTest.java,testgz file is actuallyg zipped,"@ test public void   (  )  throws  exception  {  final  file fake file =  file . create temp file ( "" bcl file faker test"" "" . bcl . gz"" )  ;  fake file . delete on exit (  )  ;  new  bcl file faker (  )  . fake file ( fake file 100000 )  ;  new  bcl read"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\FilterParserTest.java,all tiles to values,public static final  boolean[]   (  integer[] tiles )  {   boolean[][] values = new  boolean[tiles . length][] ;  for  ( int i = 0 ;  i  <  tiles . length ;  i +  +  )   {  values[i] = tile to value ( tiles[i] )  ;   }  return array flatten ( values )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\FilterParserTest.java,array flatten,public static final  < t > t[]   ( final t[][] arrays )  {  int total = 0 ;  for  (  t[] arr : arrays )   {  total +  = arr . length ;   }  int result index = 0 ;  final t[] result =  ( t[] )  array . new instance ( arrays[0][0] . get class (  )  total )  ;  for  ( int i = 0 ;  i  <  arrays . length ;  i +  +  )   {   system . arraycopy ( arrays[i] 0 result result index arrays[i] . length )  ;  result index +  = arrays[i] . length ;   }  return result ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\FilterParserTest.java,array to list,public static final  list <  integer >    ( final  integer[] array )  {  final  list <  integer >  list = new  array list <  integer >  (  )  ;  for  (  int item : array )   {  list . add ( item )  ;   }  return list ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\FilterParserTest.java,failing verify tiles,"@ data provider ( name = "" "" )  public  object[][] failing verify tiles (  )  {  return new  object[][] {  { new  integer[] { 1 }  new  integer[] { 2 }  }   { new  integer[] { 2 }  new  integer[] { 1 }  }   { new  integer[] { 4 }  new  integer[] { 5 }  } "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\FilterParserTest.java,passing parser test,"@ test ( data provider = ""passing tiles"" )  public void   (  integer[] tiles )  {  final  illumina file util f util = new  illumina file util (  base calls dir 1 )  ;  final  boolean[] values = all tiles to values ( tiles )  ;  final  list <  integer >  t"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\FilterParserTest.java,passing seeking parser test,"@ test ( data provider = ""seek to tile"" )  public void   ( int skip before int tile to skip to  integer[] tiles  boolean[][] expected values )  {  final  illumina file util f util = new  illumina file util (  base calls dir 1 )  ;  final  boolean[] values"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\FilterParserTest.java,passing tiles,"@ data provider ( name = "" "" )  public  object[][] passing tiles (  )  {  return new  object[][] {  { new  integer[] { 1 }  }   { new  integer[] { 2 }  }   { new  integer[] { 4 }  }   { new  integer[] { 1 4 }  }   { new  integer[] { 2 3 }  }   { new  inte"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\FilterParserTest.java,seek to tile,"@ data provider ( name = "" "" )  public  object[][] seek to tile (  )  {  return new  object[][] {  { 0 2 new  integer[] { 2 }  new  boolean[][] { s   1   0002   filter }  }   { 4 4 new  integer[] { 1 4 }  new  boolean[][] { new  boolean[] { f f t f }  s  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\FilterParserTest.java,tile to value,"public static final  boolean[]   ( int tile )  {  switch  ( tile )   {  case 1: return s   1   0001   filter ;  case 2: return s   1   0002   filter ;  case 3: return s   1   0003   filter ;  case 4: return s   1   0004   filter ;   }  throw new  runtime exception ( "" you shouldn't reach this statement ! "" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\FilterParserTest.java,verify data test,"@ test ( data provider = ""failing verify tiles"" expected exceptions =  picard exception . class )  public void   ( final  integer[] init tiles final  integer[] verify tiles )  {  final  illumina file util f util = new  illumina file util (  base calls dir"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaDataProviderFactoryTest.java, test factory,public   ( final  file basecall directory final int lane final  read structure read structure final  illumina data type .  .  .  data types )  {  super ( basecall directory lane read structure new  bcl quality evaluation strategy (  bcl quality evaluation strategy . illumina   alleged   minimum   quality )  data types )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaDataProviderTest.java,bad data,"@ data provider ( name = "" "" )  public  object[][] bad data (  )  {  return new  object[][] {  { "" bad  lane ( 5 ) "" 5 60 make list ( 1101 1201 2101 )  new  illumina data type[] {  illumina data type .  barcodes }  ""25t8b25t"" binary   td   location }   { "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaDataProviderTest.java,barcode parsing test,"@ test public void   (  )  {  run barcode parsing test ( new  illumina data provider factory ( binary   td   location 1 new  read structure ( ""25t8b25t"" )  bcl quality evaluation strategy  illumina data type .  base calls  illumina data type .  barcodes )"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaDataProviderTest.java,binary data,"@ data provider ( name = "" "" )  public  object[][] binary data (  )  {  return new  object[][] {  { "" bustard  parsing  test ( 25t8b25t )  w /  clocs"" 1 180 make list ( 1101 1201 2101 )  new  illumina data type[] {  illumina data type .  barcodes }  ""25t8"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaDataProviderTest.java,compare bases and quals,private void   ( final  read data rd1 final  read data rd2 final  string test name )  {   assert . assert equals ( rd1 . get bases (  )  rd2 . get bases (  )  test name )  ;   assert . assert equals ( rd1 . get qualities (  )  rd2 . get qualities (  )  test name )  ;   assert . assert equals ( rd1 . get read type (  )  rd2 . get read type (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaDataProviderTest.java,compare positional data,private void   ( final  cluster data cd1 final  cluster data cd2 final  string test name )  {   assert . assert equals ( cd1 . get lane (  )  cd2 . get lane (  )  test name )  ;   assert . assert equals ( cd1 . get tile (  )  cd2 . get tile (  )  test name )  ;   assert . assert equals ( cd1 . getx (  )  cd2 . getx (  )  test name )  ;   assert . assert equals ( cd1 . gety (  )  cd2 . gety (  )  test name )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaDataProviderTest.java,compare read data,private void   ( final  cluster data cd1 final  cluster data cd2 final  string test name )  {  compare positional data ( cd1 cd2 test name )  ;   assert . assert equals ( cd1 . get num reads (  )  cd2 . get num reads (  )  )  ;  for  ( int i = 0 ;  i  <  cd1 . get num reads (  )  ;  i +  +  )   {  compare bases and quals ( cd1 . get read ( i )  cd2 . get read ( i )  test name )  ;   }   assert . assert equals ( cd1 . get matched barcode (  )  cd2 . get matched barcode (  )  test name )  ;   assert . assert equals ( cd1 . is pf (  )  . boolean value (  )  cd2 . is pf (  )  . boolean value (  )  test name )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaDataProviderTest.java,get data types,private  illumina data type[]   ( final  illumina data type[] extra data types )  {  final  illumina data type[] dts ;  if  ( extra data types  =  =  null )   {  dts = default   data   types ;   }  else  {  dts =  arrays . copy of ( default   data   types default   data   types . length  +  extra data types . length )  ;   system . arraycopy ( extra data types 0 dts default   data   types . length extra data types . length )  ;   }  return dts ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaDataProviderTest.java,run barcode parsing test,public void   ( final  illumina data provider factory factory )  {  int total = 0 ;  final  base illumina data provider data provider = factory . make data provider (  )  ;  while  ( data provider . has next (  )  )   {  final  cluster data cluster = data provider . next (  )  ;  final  string matched barcode = cluster . get matched barcode (  )  ;  if  ( matched barcode  !  =  null )   {   assert . assert equals ( matched barcode new  string ( cluster . get read ( 1 )  . get bases (  )  )  )  ;   }  if  ( total  >  10 )   {  break ;   }  total +  +  ;   }  data provider . close (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaDataProviderTest.java,run test,"private void   ( final  string test name final int size final  map <  integer  cluster data >  read no to cluster data final int seek after first read final int seek test data read offset final  base illumina data provider data provider )  throws  exception  {  int count = 0 ;  int read num = 0 ;  while  ( data provider . has next (  )  )   {  final  cluster data cluster = data provider . next (  )  ;  if  ( read no to cluster data . contains key ( read num )  )   {  compare read data ( cluster read no to cluster data . get ( read num )  test name  +  "" cluster num ""  +  read num )  ;   }  if  ( seek after first read  !  =  0 && count  =  =  0 )   {  data provider . seek to tile ( seek after first read )  ;  read num +  = seek test data read offset ;   }  read num +  +  ;  count +  +  ;   }   assert . assert equals ( count size test name )  ;  data provider . close (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaDataProviderTest.java,test illumina data provider bcl method,"@ test ( data provider = ""binary data"" )  public void   ( final  string test name final int lane final int size final  list <  integer >  tiles final  illumina data type[] extra data types final  string illumina config str final int seek after first read "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaDataProviderTest.java,test illumina data provider missing datas,"@ test ( data provider = ""bad data"" expected exceptions =  {  picard exception . class  illegal argument exception . class }  )  public void   ( final  string test name final int lane final int size final  list <  integer >  tiles final  illumina data typ"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTilePerCycleParserTest.java, mock cycled illumina data,public   (  )  {  this . values = new  array list <  string >  (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTilePerCycleParserTest.java, mock per tile cycle parser,public   ( final  file directory final int lane final  cycle illumina file map tiles to cycle files final  output mapping output mapping )  {  super ( directory lane tiles to cycle files output mapping )  ;  expected output lengths = output mapping . get output read lengths (  )  ;  this . initialize (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTilePerCycleParserTest.java,add value,public void   ( final  string value )  {  values . add ( value )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTilePerCycleParserTest.java,basic iteration test,@ test public void   (  )  {  final  list <  string >  expected values = get file names ( default   tiles )  ;  final  per tile cycle parser <  mock cycled illumina data >  parser = make parser (  )  ;  int index = 0 ;  while  ( parser . has next (  )  ) 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTilePerCycleParserTest.java,compare values,"private int   ( final  list <  string >  parser values final  list <  string >  expected values int index )  {  for  (  final  string parser value : parser values )   {   assert . assert true ( index  <  expected values . size (  )  )  ;   assert . assert equals ( parser value expected values . get ( index )  "" with index ""  +  index )  ;   +  + index ;   }  return index ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTilePerCycleParserTest.java,get file names,public  list <  string >    ( final  list <  integer >  tiles )  {  final  list <  string >  file names = new  array list <  string >  (  )  ;  for  (  final  integer tile : tiles )   {  for  ( int i = 1 ;  i  <  =  max   cycle ;  i +  +  )   {  file names . add ( str   del ( tile i )  )  ;   }   }  return file names ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTilePerCycleParserTest.java,get illumina file maps,public  cycle illumina file map   ( final  list <  integer >  tiles final int[] cycles )  {  final  cycle illumina file map cycle file map = new  cycle illumina file map (  )  ;  for  (  final int cycle : cycles )   {  final  illumina file map file map = new  illumina file map (  )  ;  for  (  final  integer tile : tiles )   {  file map . put ( tile new  file ( str   del ( tile cycle )  )  )  ;   }  cycle file map . put ( cycle file map )  ;   }  return cycle file map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTilePerCycleParserTest.java,get values,public  list <  string >    (  )  {  return values ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTilePerCycleParserTest.java,has next,@ override public boolean   (  )  {  return current cycle  <  max   cycle ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTilePerCycleParserTest.java,initialize,@ override public void   (  )  {  seek to tile ( current tile )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTilePerCycleParserTest.java,make cycle file parser,@ override protected  cycle files parser <  mock cycled illumina data >    ( final  list <  file >  files )  {  return new  cycle files parser <  mock cycled illumina data >  (  )  {  int current cycle = 0 ;  @ override public void close (  )  {   }  @ ov
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTilePerCycleParserTest.java,make parser,"public  per tile cycle parser <  mock cycled illumina data >    (  )  {  final  cycle illumina file map file map = get illumina file maps ( default   tiles cycles )  ;  return new  mock per tile cycle parser ( new  file ( "" fake file"" )  1 file map output   mapping )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTilePerCycleParserTest.java,next,@ override public  mock cycled illumina data   (  )  {  final  mock cycled illumina data ild = new  mock cycled illumina data (  )  ;  if  (  ! has next (  )  )   {  throw new  no such element exception (  )  ;   }  ild . add value ( str   del ( files . g
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTilePerCycleParserTest.java,seeking iteration test,"@ test ( data provider = ""seeking tests"" )  public void   ( final  integer seek pos1 final  integer new tile1 final  integer seek pos2 final  integer new tile2 )  {  final  list <  string >  expected values = get file names ( default   tiles )  ;  final  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTilePerCycleParserTest.java,seeking tests,"@ data provider ( name = "" "" )  public  object[][] seeking tests (  )  {  return new  object[][] {  { 1 3 null null }   { 22 1 null null }   { 38 2 null null }   { 75 4 null null }   { 1 3 70 1 }   { 1 3 45 2 }   { 12 2 59 4 }   { 45 3 70 3 }   { 14 1 5 2"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTilePerCycleParserTest.java,str   del,"public static  string   ( final  object .  .  .  objects )  {   string out = objects[0] . to string (  )  ;  for  ( int i = 1 ;  i  <  objects . length ;  i +  +  )   {  out +  = ""   ""  +  objects[i] ;   }  return out ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTilePerCycleParserTest.java,supported types,public  set <  illumina data type >    (  )  {  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTileParserTest.java, dummy dt,public   ( final  integer value )  {  this . value = value ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTileParserTest.java, mock per tile parser,public   ( final  illumina file map tiles to files )  {  super ( tiles to files )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTileParserTest.java,basic iteration test,"@ test public void   (  )  {  final  illumina file map fm = new  illumina file map (  )  ;  fm . put ( 1 new  file ( ""s   1   1"" )  )  ;  fm . put ( 2 new  file ( ""s   1   2"" )  )  ;  fm . put ( 3 new  file ( ""s   1   3"" )  )  ;  fm . put ( 4 new  file ( "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTileParserTest.java,fail verify test missing tile,@ test ( expected exceptions =  picard exception . class )  public void   (  )  {  final  per tile parser <  dummy dt >  ddts = new  mock per tile parser ( file   map )  ;  ddts . verify data ( make list ( 1 2 4 5 )  null )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTileParserTest.java,fail verify test too many tiles,@ test ( expected exceptions =  picard exception . class )  public void   (  )  {  final  per tile parser <  dummy dt >  ddts = new  mock per tile parser ( file   map )  ;  ddts . verify data ( make list ( 1 2 3 4 5 6 )  null )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTileParserTest.java,has next,@ override public boolean   (  )  {  return values . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTileParserTest.java,make tile iterator,@ override protected  closeable iterator <  dummy dt >    ( final  file file )  {  return new  closeable iterator <  dummy dt >  (  )  {  private final  iterator <  integer >  values = file   to   value . get ( file . get name (  )  )  . iterator (  )  ; 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTileParserTest.java,missing tile test,"@ test ( expected exceptions =  picard exception . class data provider = ""missing tiles"" )  public void   ( final  integer missing tile )  {  final  per tile parser <  dummy dt >  ddts = new  mock per tile parser ( file   map )  ;  ddts . seek to tile ( m"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTileParserTest.java,missing tiles,"@ data provider ( name = "" "" )  public  object[][] missing tiles (  )  {  return new  object[][] {  {  - 1 }   { 10 }   {  integer . max   value }   {  integer . min   value }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTileParserTest.java,next,@ override public  dummy dt   (  )  {  return new  dummy dt ( values . next (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTileParserTest.java,pass verify test,@ test public void   (  )  {  final  per tile parser <  dummy dt >  ddts = new  mock per tile parser ( file   map )  ;  ddts . verify data ( make list ( 1 2 3 4 5 )  null )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTileParserTest.java,remove,@ override public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTileParserTest.java,seek to tile test,"@ test ( data provider = ""seeking tests"" )  public void   (  integer first seek pos  integer first tile  integer second seek pos  integer second tile )  {  final  per tile parser <  dummy dt >  ddts = new  mock per tile parser ( file   map )  ;  for  ( in"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTileParserTest.java,seeking tests,"@ data provider ( name = "" "" )  public  object[][] seeking tests (  )  {  return new  object[][] {  { 1 4 null null }   { 15 1 null null }   { 25 3 null null }   { 24 5 null null }   { 1 3 10 1 }   { 1 3 15 2 }   { 12 2 15 4 }   { 6 3 12 5 }   { 14 5 25 2"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PerTileParserTest.java,supported types,@ override public  set <  illumina data type >    (  )  {  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\AbstractIlluminaPositionFileReaderTest.java, mock position file reader,"public   ( final int lane final int tile final float[] x coords final float[] y coords )  {  super ( new  file ( ""s   ""  +  lane  +  ""   "" +  tile +  ""   pos . txt . gz"" )  )  ;  this . x coords = x coords ;  this . y coords = y coords ;  current cluster = 0 ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\AbstractIlluminaPositionFileReaderTest.java,has next,@ override public boolean   (  )  {  return current cluster  <  x coords . length ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\AbstractIlluminaPositionFileReaderTest.java,invalid file names,"@ data provider ( name = "" "" )  public  object[][] invalid file names (  )  {  return new  object[][] {  { ""whatever . locs"" }   { ""whatever . clocs"" }   { ""whatever . pos"" }   { ""s   1 . clocs"" }   { ""s      2 . clocs"" }   { ""s   1   4 .  notclocs"" }   {"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\AbstractIlluminaPositionFileReaderTest.java,invalid file names test,"@ test ( expected exceptions =  picard exception . class data provider = ""invalid file names"" )  public void   ( final  string file name )  {  final int lane = 3 ;  final int tile = 4 ;  final  abstract illumina position file reader reader = new  mock pos"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\AbstractIlluminaPositionFileReaderTest.java,invalid positions,"@ data provider ( name = "" "" )  public  object[][] invalid positions (  )  {  return new  object[][] {  { new float[] { 0f 5f  - 11f }  new float[] { 1f 12f 13f }  }   { new float[] {  - 15 . 05f }  new float[] { 19801f }  }   { new float[] { 10 . 05f 3f "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\AbstractIlluminaPositionFileReaderTest.java,invalid reader test,"@ test ( expected exceptions =  illegal argument exception . class data provider = ""invalid positions"" )  public void   ( float[] x coords float[] y coords )  {  final int lane = 3 ;  final int tile = 4 ;  final  abstract illumina position file reader rea"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\AbstractIlluminaPositionFileReaderTest.java,iterator remove test,"@ test ( expected exceptions =  unsupported operation exception . class )  public void   (  )  {  final  abstract illumina position file reader reader = new  mock position file reader ( ""s   1   1   pos . txt"" 0 0 null null )  ;  reader . remove (  )  ;  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\AbstractIlluminaPositionFileReaderTest.java,make exception msg,"@ override protected  string   (  )  {  return "" abstract  illumina position file reader test current cluster = ""  +  current cluster ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\AbstractIlluminaPositionFileReaderTest.java,unsafe next info,@ override protected  position info   (  )  {   position info pi = new  position info ( x coords[current cluster] y coords[current cluster] get lane (  )  get tile (  )  )  ;   +  + current cluster ;  return pi ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\AbstractIlluminaPositionFileReaderTest.java,valid reader test,@ test public void   (  )  {  final int lane = 2 ;  final int tile = 8 ;  final  abstract illumina position file reader reader = new  mock position file reader ( lane tile x   coords y   coords )  ;  int index = 0 ;  while  ( reader . has next (  )  )   {
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PosParserTest.java, test result,public   ( final int lane final int tile final float x pos final float y pos final int x qseq coord final int yq seq coord )  {  this . lane = lane ;  this . tile = tile ;  this . x pos = x pos ;  this . y pos = y pos ;  this . xq seq coord = x qseq coord ;  this . yq seq coord = yq seq coord ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PosParserTest.java,compare results,"public static void   ( final  test result tr final  positional data pd final int index )  {   assert . assert equals ( tr . xq seq coord pd . getx coordinate (  )  ""  at index ""  +  index )  ;   assert . assert equals ( tr . yq seq coord pd . gety coordinate (  )  ""  at index ""  +  index )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PosParserTest.java,make test results,public static  list <  test result >    ( final int lane final int tile final float[] xy pos final int[] xy qseq )  {  final  array list <  test result >  results = new  array list <  test result >  (  )  ;  for  ( int i = 0 ;  i  <  xy pos . length ;  i +  = 2 )   {  results . add ( new  test result ( lane tile xy pos[i] xy pos[i  +  1] xy qseq[i] xy qseq[i  +  1] )  )  ;   }  return results ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PosParserTest.java,multi tile data,"@ data provider ( name = "" "" )  public  object[][] multi tile data (  )  {  return new  object[][] {  { make list ( 1 2 3 )  null make list ( s   1   1   pos s   1   2   pos s   1   3   pos )  }   { make list ( 1 2 3 )  1 make list ( s   1   1   pos s   1"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PosParserTest.java,multi tile data test,"@ test ( data provider = ""multi tile data"" )  public void   ( final  list <  integer >  tiles final  integer starting tile index final  list <  file >  files )  {  final  illumina file map fm = new  illumina file map (  )  ;  for  ( int i = 0 ;  i  <  til"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PosParserTest.java,single tile data,"@ data provider ( name = "" "" )  public  object[][] single tile data (  )  {  return new  object[][] {  { 1 1 s   1   1   pos }   { 1 null s   1   1   pos }   { 3202 3202 s   9   3202   pos }   { 3202 null s   9   3202   pos }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\PosParserTest.java,single tile data test,"@ test ( data provider = ""single tile data"" )  public void   ( final int tile final  integer starting tile final  file file )  {  final  illumina file map fm = new  illumina file map (  )  ;  fm . put ( tile file )  ;  final  pos parser parser =  ( starti"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,assert defaults,"public void   ( final  illumina file util file util final  integer lane final  list <  supported illumina format >  formats to test )  {  if  ( lane  =  =  null )   {   assert . assert equals ( file util . get lane (  )  default   lane )  ;   }  else  {   assert . assert equals ( new  integer ( file util . get lane (  )  )  lane )  ;   }   assert . assert equals ( file util . get util (  supported illumina format .  barcode )  . get tiles (  )  default   tiles )  ;   assert . assert equals ( file util . get util (  supported illumina format .  bcl )  . get tiles (  )  default   tiles )  ;   assert . assert equals ( file util . get util (  supported illumina format .  pos )  . get tiles (  )  default   tiles )  ;   assert . assert equals ( file util . get util (  supported illumina format .  locs )  . get tiles (  )  default   tiles )  ;   assert . assert equals ( file util . get util (  supported illumina format .  clocs )  . get tiles (  )  default   tiles )  ;   assert . assert equals ( file util . get util (  supported illumina format .  filter )  . get tiles (  )  default   tiles )  ;  final  set <  integer >  detected cycles =  (  (  per tile per cycle file util ) file util . get util (  supported illumina format .  bcl )  )  . get detected cycles (  )  ;   assert . assert equals ( detected cycles . size (  )  default   cycles . length )  ;  int i = 0 ;  for  (  final  integer cycle : detected cycles )   {   assert . assert equals ( cycle . int value (  )  default   cycles[i +  + ] "" elements differ at index ""  +  i )  ;   }   assert . assert equals ( file util . get actual tiles ( formats to test )  default   tiles )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,cycle range,public static int[]   ( final int end )  {  return cycle range ( 1 end )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,delete relative files,public final void   ( final  list <  string >  relative files to delete )  {  delete relative files ( intensity dir relative files to delete )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,empty relative files,"public static void   ( final  file base file final  list <  string >  relative files to delete )  {  for  (  final  string relative file : relative files to delete )   {  final  file actual file = new  file ( base file relative file )  ;  if  (  ! actual file . exists (  )  )   {  throw new  runtime exception ( "" trying to empty a non - existent file""  +  actual file . get absolute path (  )  )  ;   }  if  ( actual file . is directory (  )  )   {  throw new  runtime exception ( "" trying to empty a directory ( ""  +  actual file . get absolute path (  )   +  "" ) "" )  ;   }  else  {  if  (  ! actual file . delete (  )  )   {  throw new  runtime exception ( "" couldn't remove previous file when emptying ( ""  +  actual file . get absolute path (  )   +  "" ) "" )  ;   }  else  {  try  {  if  (  ! actual file . create new file (  )  )   {  throw new  runtime exception ( "" couldn't create empty file: ""  +  actual file . get absolute path (  )   +  "" ) "" )  ;   }   }  catch  (  final io exception ioe )   {  throw new  runtime exception ( ioe )  ;   }   }   }  if  (  ! actual file . exists (  )  )   {  throw new  picard exception ( "" file should exist: ""  +  actual file )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,invalid lane forlt regex,"@ test ( data provider = ""invalid lanes"" expected exceptions =  picard exception . class )  public void   ( final int lane )  {   parameterized file util . make lane tile regex ( "" . test"" lane )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,invalid lanes,"@ data provider ( name = "" "" )  public  object[][] invalid lanes (  )  {  return new  object[][] {  {  - 1000 }   {  - 10 }   {  - 1 }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,lane dir,"private static  string   ( final int lane )  {   string ldir =  string . value of ( lane )  ;  while  ( ldir . length (  )   <  3 )   {  ldir = ""0""  +  ldir ;   }  return ""l""  +  ldir ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,long tile,"private static  string   ( final int tile final boolean make long )  {  if  ( make long )   {   string lt =  string . value of ( tile )  ;  while  ( lt . length (  )   <  4 )   {  lt = ""0""  +  lt ;   }  return lt ;   }  else  {  return  string . value of ( tile )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,make cycle file list,"private static  list <  string >    ( final  file dir final  string ext final int lane final int[] cycles final boolean long fmt final int .  .  .  tiles )  {  final  list <  string >  files = new  array list <  string >  (  )  ;  final  file lane dir = new  file ( dir lane dir ( lane )  )  ;  for  (  final int cycle : cycles )   {  final  file cycle dir = new  file ( lane dir ""c""  +  cycle  +  "" . 1"" )  ;  for  (  final  integer tile : tiles )   {  files . add ( cycle dir  +  "" / s   ""  +  lane +  ""   "" +  long tile ( tile long fmt )  +  ext )  ;   }   }  return files ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,make files,"public static void   ( final  supported illumina format format final  file intensity dir final int lane final  list <  integer >  tiles final int[] cycles final  string compression )  {   string lane dir =  string . value of ( lane )  ;  while  ( lane dir . length (  )   <  3 )   {  lane dir = ""0""  +  lane dir ;   }  lane dir = ""l""  +  lane dir ;  final  file basecall dir = new  file ( intensity dir "" base calls"" )  ;  final  file basecall lane dir = new  file ( basecall dir lane dir )  ;  final  file intensity lane dir = new  file ( intensity dir lane dir )  ;  switch  ( format )   {  case  barcode: make per tile files ( basecall dir lane tiles maybe add ext ( ""   barcode . txt"" compression )  true )  ;  break ;  case  pos: make per tile files ( intensity dir lane tiles maybe add ext ( ""   pos . txt"" compression )  false )  ;  break ;  case  locs: make per tile files ( intensity lane dir lane tiles maybe add ext ( "" . locs"" null )  false )  ;  break ;  case  clocs: make per tile files ( intensity lane dir lane tiles maybe add ext ( "" . clocs"" null )  false )  ;  break ;  case  filter: make per tile files ( basecall lane dir lane tiles maybe add ext ( "" . filter"" null )  true )  ;  break ;  case  bcl: make per tile per cycle files ( basecall lane dir lane tiles cycles "" . bcl"" )  ;  break ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,make per tile file,"public  file   ( final  file parent dir final int lane final int tile final  string extension final  string compression final boolean long format )  {  return new  file ( parent dir ""s   ""  +  lane  +  ""   "" +  long tile ( tile long format )  +  extension +   ( compression  !  =  null  ?  compression : """" )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,make per tile files,"private static void   ( final  file parent dir final int lane final  list <  integer >  tiles final  string ext final boolean long name )  {  if  (  ! parent dir . exists (  )  )   {  if  (  ! parent dir . mkdir (  )  )   {  throw new  runtime exception ( "" couldn't create directory ""  +  parent dir . get absolute path (  )  )  ;   }   }  for  (  final  integer tile : tiles )   {  write non empty file ( new  file ( parent dir ""s   ""  +  lane  +  ""   "" +  long tile ( tile long name )  +  ext )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,make per tile per cycle file path,"public  file   ( final  file parent dir final int lane final int tile final int cycle final  string extension )  {  return new  file ( parent dir ""c""  +  cycle  +  "" . 1 / s   "" +  lane +  ""   "" +  tile +  extension )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,make per tile per cycle files,"private static void   ( final  file parent dir final int lane final  list <  integer >  tiles final int[] cycles final  string ext )  {  if  (  ! parent dir . exists (  )  )   {  if  (  ! parent dir . mkdir (  )  )   {  throw new  runtime exception ( "" couldn't create directory ""  +  parent dir . get absolute path (  )  )  ;   }   }  for  (  final int cycle : cycles )   {  final  file cycle dir = new  file ( parent dir ""c""  +  cycle  +  "" . 1"" )  ;  if  (  ! cycle dir . exists (  )  )   {  if  (  ! cycle dir . mkdir (  )  )   {  throw new  runtime exception ( "" couldn't create directory ""  +  cycle dir . get absolute path (  )  )  ;   }   }  for  (  final  integer tile : tiles )   {  write non empty file ( new  file ( cycle dir ""s   ""  +  lane  +  ""   "" +  tile +  ext )  )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,maybe add ext,private static  string   ( final  string file ext final  string compression ext )  {  if  ( compression ext  !  =  null )   {  return file ext  +  compression ext ;   }  else  {  return file ext ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,missing cycle data ranges,"@ data provider ( name = "" "" )  public  object[][] missing cycle data ranges (  )  {  return new  object[][] {  { make list ( new  range ( 10 15 )  )  }   { make list ( new  range ( 9 12 )  new  range ( 14 15 )  )  }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,missing tile formats,"@ data provider ( name = "" "" )  public  object[][] missing tile formats (  )  {  return new  object[][] {  { 1 make list (  supported illumina format .  bcl  supported illumina format .  barcode )  make list (  supported illumina format .  bcl  supported "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,missing tile test,"@ test ( data provider = ""missing tile formats"" )  public void   ( final int lane final  list <  supported illumina format >  formats final  list <  supported illumina format >  formats to get tiles final  list <  string >  relative files to delete final "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,not matching regex test,"@ test ( data provider = ""valid lanes invalid regexes"" )  public void   ( final int lane final  string lt example )  {  regex matches (  parameterized file util . make lane tile regex ( "" . test"" lane )  lt example false )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,pass new util test,@ test public void   (  )  {  for  (  final  supported illumina format format :  supported illumina format . values (  )  )   {  make files ( format intensity dir default   lane default   tiles default   cycles )  ;  make files ( format intensity dir defa
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,passing verify test,@ test public void   (  )  {  for  (  final  supported illumina format format :  supported illumina format . values (  )  )   {  make files ( format intensity dir default   lane default   tiles default   cycles )  ;  make files ( format intensity dir defa
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,per tile file utils,"@ data provider ( name = ""per tile file formats"" )  public  object[][]   (  )  {  return new  object[][] {  {  supported illumina format .  locs null false lane dir ( default   lane )  }   {  supported illumina format .  clocs null false lane dir ( defaul"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,per tile file utils test,"@ test ( data provider = ""per tile file formats"" )  public void   ( final  supported illumina format format final  string compression final boolean long format final  string parent dir )  {  make files ( format intensity dir default   lane default   tiles"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,per tile per cycle file formats,"@ data provider ( name = "" "" )  public  object[][] per tile per cycle file formats (  )  {  return new  object[][] {  {  supported illumina format .  bcl "" base calls / ""  +  lane dir ( default   lane )  default   cycles false false }   {  supported illum"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,per tile per cycle file utils missing cycle test,"@ test ( expected exceptions =  picard exception . class data provider = ""missing cycle data ranges"" )  public void   ( final  list <  range >  cycle ranges to make )  {  final  supported illumina format format =  supported illumina format .  bcl ;  for  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,per tile per cycle file utils test,"@ test ( data provider = ""per tile per cycle file formats"" )  public void   ( final  supported illumina format format final  string parent dir final int[] cycles final boolean create early skipped cycles final boolean create late skipped cycles )  {  if  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,regex matches,public void   ( final  string regex final  string to match final boolean expected result )  {  final  pattern pt =  pattern . compile ( regex )  ;  final  matcher ma = pt . matcher ( to match )  ;   assert . assert equals ( ma . matches (  )  expected result )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,regex tests,"@ test ( data provider = ""valid lanes"" )  public void   ( final int lane final  string lt example )  {  regex matches (  parameterized file util . make lane tile regex ( "" . test"" lane )  lt example )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,set up,"@ before method private void   (  )  throws  exception  {  intensity dir = io util . create temp dir ( ""ift   test"" "" intensities"" )  ;  basecall dir = new  file ( intensity dir "" base calls"" )  ;  if  (  ! basecall dir . mkdir (  )  )   {  throw new  run"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,tear down,@ after method private void   (  )  {  io util . delete directory tree ( intensity dir )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,test default per tile per cycle util,public void   ( final  per tile per cycle file util pcfu final  file parent dir final int[] cycles )  {  final  cycle illumina file map cfm = pcfu . get files ( cycles )  ;  final  cycle illumina file map cfmw tiles = pcfu . get files ( default   tiles cycles )  ;  final  cycle illumina file map cfm no cycles ;  if  (  arrays . equals ( cycles default   cycles )  )   {  cfm no cycles = pcfu . get files (  )  ;   }  else  {  cfm no cycles = null ;   }   assert . assert equals ( cfm . size (  )  cycles . length )  ;  for  (  final int cycle : cycles )   {  final  illumina file map t file iter = cfm . get ( cycle )  ;  final  illumina file map t file iter2 = cfmw tiles . get ( cycle )  ;  final  illumina file map t file iter3 ;  if  ( cfm no cycles  !  =  null )   {  t file iter3 = cfm no cycles . get ( cycle )  ;   }  else  {  t file iter3 = null ;   }  for  (  final  integer tile : default   tiles )   {  final  file tc file = t file iter . get ( tile )  ;  final  file tc file2 = t file iter2 . get ( tile )  ;   assert . assert equals ( tc file . get absolute path (  )  tc file2 . get absolute path (  )  )  ;  if  ( t file iter3  !  =  null )   {  final  file tf file3 = t file iter3 . get ( tile )  ;   assert . assert equals ( tc file . get absolute path (  )  tf file3 . get absolute path (  )  )  ;   }   assert . assert equals ( tc file make per tile per cycle file path ( parent dir default   lane tile cycle pcfu . extension )  )  ;   assert . assert true ( tc file . exists (  )  )  ;   assert . assert true ( tc file . length (  )   >  0 )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,test default per tile util,public void   ( final  per tile file util ptfu final  string compression final boolean long format final  file parent dir )  {  final  illumina file map fm = ptfu . get files (  )  ;  final  illumina file map fmw tiles = ptfu . get files ( default   tiles )  ;   assert . assert equals ( fm . size (  )  default   tiles . size (  )  )  ;  for  (  final  integer tile : default   tiles )   {  final  file t file = fm . get ( tile )  ;  final  file t file2 = fmw tiles . get ( tile )  ;   assert . assert equals ( t file . get absolute path (  )  t file2 . get absolute path (  )  )  ;   assert . assert equals ( t file make per tile file ( parent dir default   lane tile ptfu . extension compression long format )  )  ;   assert . assert true ( t file . exists (  )  )  ;   assert . assert true ( t file . length (  )   >  0 )  ;   }  final  list <  integer >  tiles = new  array list <  integer >  ( default   tile   test   subset )  ;  final  illumina file map subset map = ptfu . get files ( default   tile   test   subset )  ;  for  (  final  integer tile : subset map . key set (  )  )   {  tiles . remove ( tile )  ;   assert . assert true ( default   tile   test   subset . contains ( tile )  )  ;  final  file t file = subset map . get ( tile )  ;   assert . assert equals ( t file make per tile file ( parent dir default   lane tile ptfu . extension compression long format )  )  ;   assert . assert true ( t file . exists (  )  )  ;   assert . assert true ( t file . length (  )   >  0 )  ;   }   assert . assert true ( tiles . is empty (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,test has cbcls,"@ test ( data provider = ""  data provider"" )  public void test has cbcls ( final int lane final boolean create cbcl dir final boolean create cbcl final boolean expected result )  throws io exception  {  final  file basecalls dir = io util . create temp di"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,test has cbcls data provider,"@ data provider ( name = "" "" )  public  object[][] test has cbcls data provider (  )  {  return new  object[][] {  { 1 true true true }   { 1 true false false }   { 1 false false false }   {  - 1 false false false }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,test subset default per tile per cycle util,public void   ( final  per tile per cycle file util pcfu final  file parent dir final int[] cycles )  {  final  list <  integer >  tiles = new  array list <  integer >  ( default   tile   test   subset )  ;  final  cycle illumina file map subset map = pcfu . get files ( default   tile   test   subset cycles )  ;  final  cycle illumina file map cfm no cycles ;  if  (  arrays . equals ( cycles default   cycles )  )   {  cfm no cycles = pcfu . get files ( default   tile   test   subset )  ;   }  else  {  cfm no cycles = null ;   }  for  (  final int cycle : cycles )   {  final  illumina file map t file iter = subset map . get ( cycle )  ;  final  illumina file map t file iter2 ;  if  ( cfm no cycles  !  =  null )   {  t file iter2 = cfm no cycles . get ( cycle )  ;   }  else  {  t file iter2 = null ;   }  for  (  final  integer tile : subset map . get ( cycle )  . key set (  )  )   {   assert . assert true ( default   tile   test   subset . contains ( tile )  )  ;  tiles . remove ( tile )  ;  final  file tc file = t file iter . get ( tile )  ;  if  ( t file iter2  !  =  null )   {   assert . assert equals ( tc file t file iter2 . get ( tile )  )  ;   }   assert . assert equals ( tc file make per tile per cycle file path ( parent dir default   lane tile cycle pcfu . extension )  )  ;   assert . assert true ( tc file . exists (  )  )  ;   assert . assert true ( tc file . length (  )   >  0 )  ;   }   }   assert . assert true ( tiles . is empty (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,valid lanes,"@ data provider ( name = "" "" )  public  object[][] valid lanes (  )  {  return new  object[][] {  { 0 ""s   0   1111 . test"" }   { 1 ""s   1   23 . test"" }   { 10 ""s   10   1 . test"" }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,valid lanes invalid regexes,"@ data provider ( name = "" "" )  public  object[][] valid lanes invalid regexes (  )  {  return new  object[][] {  { 0 ""s    - 0   111"" }   { 1 ""s   1   a3"" }   { 10 ""s    - 100   1"" }   { 20 ""s   21   1"" }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\IlluminaFileUtilTest.java,write non empty file,"private static void   ( final  file file )  {  try  {  final  output stream output stream = new  data output stream ( new  file output stream ( file )  )  ;  final int expected length = 10 ;  output stream . write ( expected length )  ;  for  ( int i =  - 3 ;  i  <  expected length ;  i +  +  )  output stream . write ( 0x0 )  ;  output stream . close (  )  ;   }  catch  (  final io exception e )   {  throw new  runtime exception ( "" exception trying to create non - empty file ! "" e )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\BclReaderTest.java,call,@ override public  void   (  )  throws  exception  {  final  bcl reader reader = new  bcl reader ( even   i  ?  qual   1failing   bcl   file : qual   0failing   bcl   file bcl quality evaluation strategy false )  ;   assert . assert equals ( reader . num 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\BclReaderTest.java,failing file test,"@ test ( expected exceptions =  picard exception . class data provider = ""failing files"" )  public void   ( final  file failing file )  {  final  bcl quality evaluation strategy bcl quality evaluation strategy = new  bcl quality evaluation strategy (  bcl"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\BclReaderTest.java,failing files,"@ data provider ( name = "" "" )  public  object[][] failing files (  )  {  return new  object[][] {  { qual   0failing   bcl   file }   { qual   1failing   bcl   file }   { new  file (  test data dir "" some none existent file . bcl"" )  }   { file   too   l"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\BclReaderTest.java,low quality and failing test,@ test ( expected exceptions =  picard exception . class )  public void   (  )  throws  execution exception   interrupted exception  {  final  bcl quality evaluation strategy bcl quality evaluation strategy = new  bcl quality evaluation strategy (  bcl qu
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\BclReaderTest.java,low quality but passing test,@ test public void   (  )  throws  execution exception   interrupted exception  {  final  bcl quality evaluation strategy bcl quality evaluation strategy = new  bcl quality evaluation strategy ( 1 )  ;  final  collection <  callable <  void >  >  callable
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\BclReaderTest.java,quals as bytes,public byte[]   (  )  {  final byte[] byte vals = new byte[expected quals . length] ;  for  ( int i = 0 ;  i  <  byte vals . length ;  i +  +  )   {  byte vals[i] =  ( byte ) expected quals[i] ;   }  return byte vals ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\BclReaderTest.java,read valid file,@ test public void   (  )  {  final  bcl quality evaluation strategy bcl quality evaluation strategy = new  bcl quality evaluation strategy (  bcl quality evaluation strategy . illumina   alleged   minimum   quality )  ;  final  bcl reader reader = new  b
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\CbclReaderTest.java,test empty tile,"@ test public void   (  )  {  final  map <  integer  file >  filters = new  hash map <  >  (  )  ;  filters . put ( 1101 tile   1101   filter )  ;  final  locs file reader locs file reader = new  locs file reader ( new  file ( ""testdata / picard / illumin"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\CbclReaderTest.java,test missing tile,@ test ( expected exceptions =  picard exception . class )  public void   (  )  {  final  map <  integer  file >  filters = new  hash map <  >  (  )  ;  filters . put ( 1101 tile   1101   filter )  ;  final  locs file reader locs file reader = new  locs f
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\CbclReaderTest.java,test read valid file,"@ test public void   (  )  {  final  map <  integer  file >  filters = new  hash map <  >  (  )  ;  filters . put ( 1101 tile   1101   filter )  ;  final  locs file reader locs file reader = new  locs file reader ( new  file ( ""testdata / picard / illumin"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\ClocsFileReaderTest.java,multi bin mixed empty bin test,@ test public void   (  )  {  final  clocs file reader clocs reader = new  clocs file reader ( mbcf   w   empty   bins   throughout )  ;  int td index = 0 ;  int next index = multi   bin   indices[td index] ;  for  ( int i = 0 ;  i  <  multi   bin   expec
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\ClocsFileReaderTest.java,multi bin passing clocs files,"@ data provider ( name = "" "" )  public  object[][] multi bin passing clocs files (  )  {  return new  object[][] {  { multi   bin   passing   clocs   file 0 2102 }   { mbcf   w   empty   bins   at   start 2 2103 }   { mbcf   w   empty   bins   at   end 0 "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\ClocsFileReaderTest.java,multi bin test,"@ test ( data provider = ""multi bin passing clocs files"" )  public void   ( final  file multi bin passing clocs file final int bin shift final int tile )  {  final  clocs file reader clocs reader = new  clocs file reader ( multi bin passing clocs file )  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\ClocsFileReaderTest.java,multi row file test,@ test public void   (  )  {  final  clocs file reader clocs reader = new  clocs file reader ( mbcf   multi   row   file )  ;  int td index = 0 ;  int next index = multi   row   indices[td index] ;  for  ( int i = 1 ;  i  <  =  39891 ;  i +  +  )   {   as
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\ClocsFileReaderTest.java,single bin test,@ test public void   (  )  {  final  clocs file reader clocs reader = new  clocs file reader ( passing   clocs   file )  ;  for  ( int i = 0 ;  i  <   pos file reader test .  passing pos float coord . length ;  i +  +  )   {   assert . assert true ( clocs
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\FilterFileReaderTest.java,failing files for picard exception,"@ data provider ( name = "" "" )  public  object[][] failing files for picard exception (  )  {  return new  object[][] {  { ""pf   failing1 . filter"" }   { ""pf   failing2 . filter"" }   { ""pf   too large . filter"" }   { ""pf   too short . filter"" }   { ""pf   "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\FilterFileReaderTest.java,failing files forsam exception,"@ data provider ( name = "" "" )  public  object[][] failing files forsam exception (  )  {  return new  object[][] {  { ""pf   non existent file . filter"" }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\FilterFileReaderTest.java,read faked file,"@ test void   (  )  throws  exception  {  final  file fake file =  file . create temp file ( "" filter file faker test"" "" . filter"" )  ;  fake file . delete on exit (  )  ;  new  filter file faker (  )  . fake file ( fake file 100 )  ;  final  filter file "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\FilterFileReaderTest.java,read invalid values for picard exception,"@ test ( data provider = ""failing files for picard exception"" expected exceptions =  picard exception . class )  public void   ( final  string failing file )  {  final  filter file reader reader = new  filter file reader ( new  file ( test   data   dir fa"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\FilterFileReaderTest.java,read invalid values forsam exception,"@ test ( data provider = ""failing files forsam exception"" expected exceptions = sam exception . class )  public void   ( final  string failing file )  {  final  filter file reader reader = new  filter file reader ( new  file ( test   data   dir failing fi"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\FilterFileReaderTest.java,read past end,@ test ( expected exceptions =  no such element exception . class )  public void   (  )  {  final  filter file reader reader = new  filter file reader ( passing   filter   file )  ;  for  ( int i = 0 ;  i  <  reader . num clusters ;  i +  +  )   {  reader
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\FilterFileReaderTest.java,read valid file,@ test public void   (  )  {  final  filter file reader reader = new  filter file reader ( passing   filter   file )  ;   assert . assert equals ( reader . num clusters expected pfs . length )  ;  for  ( int i = 0 ;  i  <  reader . num clusters ;  i +  + 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\LocsFileReaderTest.java,invalid files,"@ data provider ( name = "" "" )  public  object[][] invalid files (  )  {  return new  object[][] {  { ""s   1   7 . locs"" }   { ""s   1   8 . locs"" }   { ""s   1   9 . locs"" }   { ""s   1   10 . locs"" }   { ""s   f2af . locs"" }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\LocsFileReaderTest.java,invalid files test,"@ test ( expected exceptions =  picard exception . class data provider = ""invalid files"" )  public void   ( final  string file name )  {  final  locs file reader reader = new  locs file reader ( new  file (  test dir file name )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\LocsFileReaderTest.java,passing file test,@ test public void   (  )  {  final  locs file reader reader = new  locs file reader (  locs file )  ;  int td index = 0 ;  int next index =  indices[td index] ;  for  ( int i = 0 ;  i  <   num values ;  i +  +  )   {   assert . assert true ( reader . has
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ReadStructureTest.java,invalid read structures,"@ data provider ( name = "" "" )  public  object[][] invalid read structures (  )  {  return new  object[][] {  { """" new  array list <  read descriptor >  (  )  }   { ""0t"" make list ( rd ( 0 t )  )  }   { "" - 1t"" make list ( rd (  - 1 t )  )  }   { ""0s"" mak"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ReadStructureTest.java,invalid read structures from list,"@ data provider ( name = "" "" )  public  object[][] invalid read structures from list (  )  {  int num tests = 0 ;  for  (  final  object[] args : invalid read structures (  )  )   {  if  ( args[1]  !  =  null )   +  + num tests ;   }  final  object[][] ou"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ReadStructureTest.java,rd,public  read descriptor   ( final int length final  read type rt )  {  return new  read descriptor ( length rt )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ReadStructureTest.java,substructure to read structure data,"@ data provider ( name = ""substructures to read structure data"" )  public  object[][]   (  )  {  return new  object[][] {  { new  read structure ( ""10t10t"" )  . templates ""10t10t"" }   { new  read structure ( ""10t4m10t"" )  . templates ""10t10t"" }   { new  r"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ReadStructureTest.java,substructure to read structure negative data,"@ data provider ( name = "" "" )  public  object[][] substructure to read structure negative data (  )  {  return new  object[][] {  { new  read structure ( ""10t"" )  . sample barcodes }   { new  read structure ( ""10m"" )  . sample barcodes }   { new  read st"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ReadStructureTest.java,test invalid read structure from list,"@ test ( data provider = ""invalid read structures from list"" expected exceptions =  illegal argument exception . class )  public void   ( final  string rs string final  list <  read descriptor >  descriptors )  {  final  read structure read structure = ne"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ReadStructureTest.java,test invalid read structure from string,"@ test ( data provider = ""invalid read structures"" expected exceptions =  illegal argument exception . class )  public void   ( final  string rs string final  list <  read descriptor >  descriptors )  {  final  read structure read structure = new  read st"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ReadStructureTest.java,test read structure,"private void   ( final  read structure read structure final  string structure string final  list <  read descriptor >  descriptors final int num templates final int num barcodes final int num skips final int num molecular indexes )  {   assert . assert equals ( read structure . to string (  )  structure string )  ;  int total cycles = 0 ;  int t index = 0 ;  int b index = 0 ;  int s index = 0 ;  int m index = 0 ;  for  ( int i = 0 ;  i  <  descriptors . size (  )  ;  i +  +  )   {   assert . assert equals ( read structure . descriptors . get ( i )  descriptors . get ( i )  )  ;  switch  ( read structure . descriptors . get ( i )  . type )   {  case t:  assert . assert equals ( i read structure . templates . get indices (  ) [t index +  + ] )  ;  break ;  case b:  assert . assert equals ( i read structure . sample barcodes . get indices (  ) [b index +  + ] )  ;  break ;  case s:  assert . assert equals ( i read structure . skips . get indices (  ) [s index +  + ] )  ;  break ;  case m:  assert . assert equals ( i read structure . molecular barcode . get indices (  ) [m index +  + ] )  ;  break ;  default :  assert . fail ( "" unrecognized read type: ""  +  read structure . descriptors . get ( i )  . type )  ;   }  total cycles +  = read structure . descriptors . get ( i )  . length ;   }   assert . assert equals ( read structure . total cycles total cycles )  ;   assert . assert equals ( read structure . sample barcodes . length (  )  num barcodes )  ;   assert . assert equals ( read structure . templates . length (  )  num templates )  ;   assert . assert equals ( read structure . molecular barcode . length (  )  num molecular indexes )  ;   assert . assert equals ( read structure . skips . length (  )  num skips )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ReadStructureTest.java,test substructure to read structure,"@ test ( data provider = ""substructure to read structure negative data"" expected exceptions =  illegal argument exception . class )  public void   ( final  read structure .  substructure substructure )  {  substructure . to read structure (  )  . to strin"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ReadStructureTest.java,test valid structures from list,"@ test ( data provider = ""valid read structures"" )  public void   ( final  string rs string final  list <  read descriptor >  descriptors final int num templates final int num barcodes final int num skips final int num molecular indexes )  {  final  read "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ReadStructureTest.java,test valid structures from string,"@ test ( data provider = ""valid read structures"" )  public void   ( final  string rs string final  list <  read descriptor >  descriptors final int num templates final int num barcodes final int num skips final int num molecular indexes )  {  final  read "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\ReadStructureTest.java,valid read structures,"@ data provider ( name = "" "" )  public  object[][] valid read structures (  )  {  return new  object[][] {  { ""2t"" make list ( rd ( 2 t )  )  1 0 0 0 }   { ""1234b"" make list ( rd ( 1234 b )  )  0 1 0 0 }   {  integer . max   value  +  ""s"" make list ( rd ("
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\TileMetricsUtilTest.java,create test dirs,"private  path   ( int num cycle metrics files boolean base metrics file )  throws io exception  {   path base dir =  files . create temp directory ( "" tile metrics util test"" )  ;   path base op dir =  files . create directory ( base dir . resolve (  tile metrics util . interop   subdirectory   name )  )  ;   int stream . range ( 1 num cycle metrics files  +  1 )  . for each ( i  -  >   {  try  {   path cycle dir =  files . create directory ( base op dir . resolve ( ""c""  +  i  +  "" . 1"" )  )  ;  if  ( i  =  =  num cycle metrics files )   {   files . create file ( cycle dir . resolve (  tile metrics util . tile   metrics   out   file   name )  )  ;   }   }  catch  (  io exception e )   {  e . print stack trace (  )  ;   }   }   )  ;  if  ( base metrics file )   {   files . create file ( base op dir . resolve (  tile metrics util . tile   metrics   out   file   name )  )  ;   }  return base dir ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\TileMetricsUtilTest.java,test find tile metrics,@ test public void   (  )  throws io exception  {   path base dir = create test dirs ( 0 true )  ;   file tile metrics file =  tile metrics util . render tile metrics file from basecalling directory ( base dir . to file (  )  0 false )  ;   assert . asser
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\TileMetricsUtilTest.java,test find tile metrics nova seq in base inter op,@ test public void   (  )  throws io exception  {   path base dir = create test dirs ( 1 true )  ;   file tile metrics file =  tile metrics util . render tile metrics file from basecalling directory ( base dir . to file (  )  1 true )  ;   assert . assert
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\TileMetricsUtilTest.java,test find tile metrics nova seq in cycle dirs,@ test public void   (  )  throws io exception  {   path base dir = create test dirs ( 2 false )  ;   file tile metrics file =  tile metrics util . render tile metrics file from basecalling directory ( base dir . to file (  )  2 true )  ;   assert . asser
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\TileMetricsUtilTest.java,test missing tile metrics,@ test ( expected exceptions =  illegal state exception . class )  public void   (  )  throws io exception  {   path base dir = create test dirs ( 0 false )  ;   tile metrics util . render tile metrics file from basecalling directory ( base dir . to file 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\PosFileReaderTest.java,compare position info,"public static void   ( final  abstract illumina position file reader .  position info pi final float x pos final float y pos final int xq seq coord final int yq seq coord final int lane final int tile final int index )  {   assert . assert equals ( pi . x pos x pos "" differs at index: ""  +  index )  ;   assert . assert equals ( pi . y pos y pos "" differs at index: ""  +  index )  ;   assert . assert equals ( pi . x qseq coord xq seq coord "" differs at index: ""  +  index )  ;   assert . assert equals ( pi . y qseq coord yq seq coord "" differs at index: ""  +  index )  ;   assert . assert equals ( pi . lane lane "" differs at index: ""  +  index )  ;   assert . assert equals ( pi . tile tile "" differs at index: ""  +  index )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\PosFileReaderTest.java,failing data pos file test,"@ test ( data provider = ""invalid data files"" expected exceptions =  picard exception . class )  public void   ( final  file file )  {  final  pos file reader pfr = new  pos file reader ( file )  ;  try  {  while  ( pfr . has next (  )  )   {  pfr . next "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\PosFileReaderTest.java,failing name pos file test,@ test ( expected exceptions =  picard exception . class )  public void   (  )  {  final  pos file reader pfr = new  pos file reader (  invalid name pos file )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\PosFileReaderTest.java,invalid data files,"@ data provider ( name = "" "" )  public  object[][] invalid data files (  )  {  return new  object[][] {  { new  file (  test dir ""s   1   1101   pos . txt"" )  }   { new  file (  test dir ""s   1   1102   pos . txt"" )  }   { new  file (  test dir ""s   1   1"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\PosFileReaderTest.java,valid pos file test,@ test public void   (  )  {  final  pos file reader pfr = new  pos file reader (  passing pos file )  ;  for  ( int i = 0 ;  i  <   passing pos float coord . length ;  i +  +  )   {   assert . assert true ( pfr . has next (  )  )  ;  final  abstract illu
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\PosFileReaderTest.java,zero length file test,"@ test public void   (  )  {  final  pos file reader pfr = new  pos file reader ( new  file (  test dir ""s   1   1104   pos . txt"" )  )  ;   assert . assert false ( pfr . has next (  )  )  ;  pfr . close (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java, file test def,public   ( final int header size final  binary file iterator < t >  bb iter )  {  this . header size = header size ;  this . bb iter = bb iter ;  this . num elements = file as bytes ( header size  file length  -  1 )  . length  /  bb iter . get element size (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java, no header test iter,public   ( final  buffer buf )  {  this . buf = buf ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java,file as byte buffer,public  byte buffer   ( final int header size )  {  final byte[] bytes = file as bytes ( header size  file length  -  1 )  ;  final  byte buffer bb =  byte buffer . allocate ( bytes . length )  ;  bb . put ( bytes )  ;  bb . position ( 0 )  ;  bb . order (  byte order . little   endian )  ;  return bb ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java,file as bytes,public byte[]   ( final int start final int end )  {  final int[] b ints =  { 0x31 0x22 0x41 0x01 0x45 0x6e 0x64 0x4f 0x66 0x48 0x65 0x61 0x64 0x65 0x72 0x42 0x6f 0x64 0x79 0x50 0x61 0x72 0x74 0x6f 0x66 0x54 0x68 0x65 0x46 0x69 0x6c 0x65 0x37 0x37 0x0a 0x45 0x6e 0x64 0x43 0x6f 0x6d 0x6d 0x75 0x6e 0x69 0x63 0x61 0x74 0x69 0x6f 0x6e }  ;  final int total = end  -  start  +  1 ;  final byte[] bytes = new byte[total] ;  for  ( int i = 0 ;  i  <  total ;  i +  +  )   {  bytes[i] =  ( byte ) b ints[start  +  i] ;   }  return bytes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java,get test iterator,@ override public  iterator <  float >    ( final  byte buffer byte buffer )  {  return new  no header test iter <  float >  ( byte buffer )  {  @ override public  float next (  )  {  return byte buffer . get float (  )  ;   }   }   ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java,has next,public boolean   (  )  {  return buf . has remaining (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java,header as byte buffer,public  byte buffer   ( final int header size )  {  final byte[] bytes = file as bytes ( 0 header size  -  1 )  ;  final  byte buffer bb =  byte buffer . allocate ( bytes . length )  ;  bb . put ( bytes )  ;  bb . position ( 0 )  ;  bb . order (  byte order . little   endian )  ;  return bb ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java,invalid file size tests,"@ test ( expected exceptions =  picard exception . class data provider = ""invalid file sizes"" )  public void   ( final int header size final int expected elements )  {  final  binary file iterator <  integer >  bb iter = m map backed iterator factory . ge"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java,invalid file sizes,"@ data provider ( name = "" "" )  public  object[][] invalid file sizes (  )  {  return new  object[][] {  { 1 12 }   { 3 11 }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java,negative header test,@ test ( expected exceptions =  picard exception . class )  public void   (  )  {  final  binary file iterator <  integer >  bb iter = m map backed iterator factory . get integer iterator (  - 1  bin file )  ;  bb iter . get header bytes (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java,next,@ override public  float   (  )  {  return byte buffer . get float (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java,only header test,@ test public void   (  )  {  final  binary file iterator <  integer >  bb iter = m map backed iterator factory . get integer iterator (  ( int )  bin file . length (  )   bin file )  ;   assert . assert equals ( bb iter . get header bytes (  )  header as
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java,remove,public void   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java,test,public void   (  )  {  final  byte buffer test buffer = file as byte buffer ( header size )  ;  if  ( header size  >  0 )   {  final  byte buffer header buffer = header as byte buffer ( header size )  ;  test header bytes ( header buffer bb iter . get header bytes (  )  )  ;   }  bb iter . assert total elements equal ( num elements )  ;  final  iterator < t >  test iter = get test iterator ( test buffer )  ;  while  ( has next ( test iter bb iter )  )   {   assert . assert equals ( test iter . next (  )  bb iter . next (  )  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java,test header bytes,"public void   ( final  byte buffer bb1 final  byte buffer bb2 )  {   assert . assert true ( bb1 . equals ( bb2 )  "" header bytes are not equal !  ""  +  bb1 . to string (  )   +  ""  !  =  "" +  bb2 . to string (  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java,test valid configurations,"@ test ( data provider = ""valid test defs"" )  public void   ( final  file test def ftd )  {  ftd . test (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java,too large header test,@ test ( expected exceptions =  picard exception . class )  public void   (  )  {  final  binary file iterator <  integer >  bb iter = m map backed iterator factory . get integer iterator (  file length  +  10  bin file )  ;  bb iter . get header bytes ( 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\illumina\parser\readers\MMapBackedIteratorFactoryTest.java,valid test defs,"@ data provider ( name = "" "" )  public  object[][] valid test defs (  )  {  return new  object[][] {  { new  file test def <  integer >  ( 15 m map backed iterator factory . get integer iterator ( 15  bin file )  )  {  @ override public  iterator <  integ"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\IntelInflaterDeflaterLoadTest.java,check intel supported,"private void   ( final  string component name )  {  if  (  !  system utils . is   os   linux &&  !  system utils . is   os   mac )   {  throw new  skip exception ( component name  +  "" is not available on this platform"" )  ;   }  if  (  system utils . os   arch  !  =  null &&  system utils . os   arch . equals ( ""ppc64le"" )  )   {  throw new  skip exception ( component name  +  "" is not available for this architecture"" )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\IntelInflaterDeflaterLoadTest.java,test intel deflater is available,"@ test public void   (  )  {  check intel supported ( "" intel deflater"" )  ;   assert . assert true ( new  intel deflater (  )  . load ( null )  "" intel shared library was not loaded .   this could be due to a configuration error  or your system might not"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\IntelInflaterDeflaterLoadTest.java,test intel inflater is available,"@ test public void   (  )  {  check intel supported ( "" intel inflater"" )  ;   assert . assert true ( new  intel inflater (  )  . load ( null )  "" intel shared library was not loaded .   this could be due to a configuration error  or your system might not"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\reference\NonNFastaSizeTest.java,no intervals,"@ test public void   (  )  throws io exception  {  final  file input = new  file ( reference )  ;  final  file outfile =  file . create temp file ( ""non ncount"" "" . txt"" )  ;  outfile . delete on exit (  )  ;  final  string[] args = new  string[] { ""input"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\reference\NonNFastaSizeTest.java,with intervals,"@ test public void   (  )  throws io exception  {  final  file input = new  file ( reference )  ;  final  file outfile =  file . create temp file ( ""non ncount"" "" . txt"" )  ;  final  file intervals = new  file ( ""testdata / picard / reference / test . int"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\pedigree\PedFileTest.java,test from sex map,"@ test ( data provider = ""  data provider"" )  public void test from sex map ( final  collection <  string >  females final  collection <  string >  males )  throws  exception  {  final  map <  string  sex >  data = new  hash map <  string  sex >  (  )  ; "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\pedigree\PedFileTest.java,test from sex map data provider,"@ data provider (  )  public  object[][]   (  )  {  return new  object[][] { new  object[] {  arrays . as list (  )   arrays . as list (  )  }  new  object[] {  arrays . as list ( ""female1"" ""female2"" ""female3"" )   arrays . as list ( ""male1"" ""male2"" ""male3"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\metrics\CollectRrbsMetricsTest.java,chrm reads,"@ test public void   (  )  throws  exception  {  final  metrics file <  rrbs summary metrics  ?  >  metrics file = get summary file ( chr   m   sam chr   m   reference root test dir  +  "" / read   test"" new  array list <  string >  (  )  )  ;  final  rrbs"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\metrics\CollectRrbsMetricsTest.java,get summary file,"private  metrics file <  rrbs summary metrics  ?  >    ( final  string input final  string reference final  string prefix final  list <  string >  sequences )  throws  exception  {  final  list <  string >  arg list = new  array list <  string >  (  )  ;  arg list . add ( ""input = ""  +  input )  ;  arg list . add ( ""metrics   file   prefix = ""  +  prefix )  ;  arg list . add ( ""reference = ""  +  reference )  ;  for  (  final  string sequence : sequences )   {  arg list . add ( ""sequence   names = ""  +  sequence )  ;   }  final  string[] args = new  string[arg list . size (  ) ] ;  arg list . to array ( args )  ;   assert . assert equals ( new  collect rrbs metrics (  )  . instance main ( args )  0 )  ;  final  metrics file <  rrbs summary metrics  ?  >  ret val = new  metrics file <  rrbs summary metrics  integer >  (  )  ;  ret val . read ( new  file reader ( prefix  +  "" . rrbs   summary   metrics"" )  )  ;  return ret val ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\metrics\CollectRrbsMetricsTest.java,set up,"@ before test private void   (  )  throws  exception  {  root test dir =  file . create temp file ( ""crmt . "" "" . tmp"" )  ;   assert . assert true ( root test dir . delete (  )  )  ;   assert . assert true ( root test dir . mkdir (  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\metrics\CollectRrbsMetricsTest.java,tear down,@ after test private void   (  )  {  io util . delete directory tree ( root test dir )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CleanSamTest.java,get command line program name,public  string   (  )  {  return  clean sam . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CleanSamTest.java,test clean sam,"@ test ( data provider = ""  data provider"" )  public void test clean sam ( final  string sam file final  string expected cigar )  throws io exception  {  final  file cleaned file =  file . create temp file ( sam file  +  "" . "" "" . sam"" )  ;  cleaned file "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CleanSamTest.java,test clean sam data provider,"@ data provider ( name = "" "" )  public  object[][] test clean sam data provider (  )  {  return new  object[][] {  { ""simple   fits . sam"" ""100m"" }   { ""simple   overhang . sam"" ""99m1s"" }   { ""fits   with   deletion . sam"" ""91m2d9m"" }   { ""overhang   with"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CleanSamTest.java,test clean sam tester,"@ test ( data provider = ""  data provider"" )  public void test clean sam tester ( final  string original cigar final  string expected cigar final int default chromosome length final int align start )  throws io exception  {  final  clean sam tester clean "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CleanSamTest.java,test clean sam tester data provider,"@ data provider ( name = "" "" )  public  object[][] test clean sam tester data provider (  )  {  return new  object[][] {  { ""100m"" ""100m"" 101 2 }   { ""100m"" ""99m1s"" 101 3 }   { ""91m2d9m"" ""91m2d9m"" 102 1 }   { ""91m2d9m"" ""91m2d8m1s"" 101 1 }   { ""99m1i"" ""99m"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,get command line program name,public  string   (  )  {  return  comparesa ms . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,test bigger sequence dictionaries,"@ test public void   (  )  {  test helper ( ""bigger   seq   dict . sam"" ""bigger   seq   dict . sam"" 2 0 0 0 0 0 0 true )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,test group with same coordinate,"@ test public void   (  )  {  test helper ( ""group   same   coord . sam"" ""group   same   coord   diff   order . sam"" 3 0 0 0 0 1 2 false )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,test group with same coordinate and no match in other,"@ test public void   (  )  {  test helper ( ""group   same   coord . sam"" ""diff   coords . sam"" 0 5 0 0 0 0 0 false )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,test group with same coordinate same position,"@ test public void   (  )  {  test helper ( ""genomic   sorted   same   position . sam"" ""genomic   sorted   same   position . sam"" 2 0 0 0 0 0 0 true )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,test has non primary,"@ test public void   (  )  {  test helper ( ""genomic   sorted . sam"" ""has   non   primary . sam"" 2 0 0 0 0 0 0 true )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,test helper,private void   ( final  string f1 final  string f2 final int expected match final int expected differ final int expected unmapped both final int expected unmapped left final int expected unmapped right final int expected missing left final int expected missing right final boolean are equal )  {  final  string[] sam files =  { new  file ( test   files   dir f1 )  . get absolute path (  )  new  file ( test   files   dir f2 )  . get absolute path (  )  }  ;   comparesa ms comparesa ms = new  comparesa ms (  )  ;  comparesa ms . instance main ( sam files )  ;   assert . assert equals ( comparesa ms . are equal (  )  are equal )  ;   assert . assert equals ( comparesa ms . get mappings match (  )  expected match )  ;   assert . assert equals ( comparesa ms . get mappings differ (  )  expected differ )  ;   assert . assert equals ( comparesa ms . get unmapped both (  )  expected unmapped both )  ;   assert . assert equals ( comparesa ms . get unmapped left (  )  expected unmapped left )  ;   assert . assert equals ( comparesa ms . get unmapped right (  )  expected unmapped right )  ;   assert . assert equals ( comparesa ms . get missing left (  )  expected missing left )  ;   assert . assert equals ( comparesa ms . get missing right (  )  expected missing right )  ;  final  string[] sam files reversed =  { new  file ( test   files   dir f2 )  . get absolute path (  )  new  file ( test   files   dir f1 )  . get absolute path (  )  }  ;  comparesa ms = new  comparesa ms (  )  ;  comparesa ms . instance main ( sam files reversed )  ;   assert . assert equals ( comparesa ms . are equal (  )  are equal )  ;   assert . assert equals ( comparesa ms . get mappings match (  )  expected match )  ;   assert . assert equals ( comparesa ms . get mappings differ (  )  expected differ )  ;   assert . assert equals ( comparesa ms . get unmapped both (  )  expected unmapped both )  ;   assert . assert equals ( comparesa ms . get unmapped left (  )  expected unmapped right )  ;   assert . assert equals ( comparesa ms . get unmapped right (  )  expected unmapped left )  ;   assert . assert equals ( comparesa ms . get missing left (  )  expected missing right )  ;   assert . assert equals ( comparesa ms . get missing right (  )  expected missing left )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,test identical,"@ test public void   (  )  {  test helper ( ""genomic   sorted . sam"" ""genomic   sorted . sam"" 2 0 0 0 0 0 0 true )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,test more on one side,"@ test public void   (  )  {  test helper ( ""genomic   sorted   5 . sam"" ""genomic   sorted   5   plus . sam"" 3 2 0 0 0 3 0 false )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,test sequence dictionaries different,"@ test public void   (  )  {  test helper ( ""genomic   sorted . sam"" ""chr21 . sam"" 0 0 0 0 0 0 0 false )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,test sequence dictionaries different,"@ test public void   (  )  {  test helper ( ""genomic   sorted . sam"" ""bigger   seq   dict . sam"" 0 0 0 0 0 0 0 false )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,test sorts different,"@ test public void   (  )  {  test helper ( ""genomic   sorted . sam"" ""unsorted . sam"" 0 0 0 0 0 0 0 false )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,test unmapped,"@ test public void   (  )  {  test helper ( ""genomic   sorted . sam"" ""unmapped   first . sam"" 1 0 0 0 1 0 0 false )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,test unmapped,"@ test public void   (  )  {  test helper ( ""genomic   sorted . sam"" ""unmapped   second . sam"" 1 0 0 0 1 0 0 false )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,test unmapped,"@ test public void   (  )  {  test helper ( ""unmapped   first . sam"" ""unmapped   second . sam"" 0 0 0 1 1 0 0 false )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,test unmapped,"@ test public void   (  )  {  test helper ( ""unmapped   first . sam"" ""unmapped   first . sam"" 1 0 1 0 0 0 0 true )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,test unsorted,"@ test public void   (  )  {  test helper ( ""unsorted . sam"" ""unsorted . sam"" 2 0 0 0 0 0 0 true )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CompareSAMsTest.java,test unsorted,"@ test public void   (  )  {  test helper ( ""unsorted . sam"" ""unsorted2 . sam"" 0 1 0 0 0 0 1 false )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\AbstractAlignmentMergerTest.java,tes overlapped read clipping with non overlapped reads,"@ test public void   (  )  {  final sam record set builder set = new sam record set builder (  )  ;  set . set read length ( 110 )  ;  final  list < sam record >  recs = set . add pair ( ""q1"" 0 100 200 false false ""110m"" ""110m"" false true 30 )  ;  final s"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\AbstractAlignmentMergerTest.java,test basic overlapped read clipping,"@ test public void   (  )  {  final sam record set builder set = new sam record set builder (  )  ;  set . set read length ( 110 )  ;  final  list < sam record >  recs = set . add pair ( ""q1"" 0 100 90 false false ""110m"" ""110m"" false true 30 )  ;  final sa"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\AbstractAlignmentMergerTest.java,test overlapped read clipping with existing soft clipping,"@ test public void   (  )  {  final sam record set builder set = new sam record set builder (  )  ;  set . set read length ( 120 )  ;  final  list < sam record >  recs = set . add pair ( ""q1"" 0 100 95 false false ""110m10s"" ""15s105m"" false true 30 )  ;  fi"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\AbstractAlignmentMergerTest.java,test overlapped read clipping with existing soft clipping and hard clipping,"@ test public void   (  )  {  final sam record set builder set = new sam record set builder (  )  ;  set . set read length ( 120 )  ;  final  list < sam record >  recs = set . add pair ( ""q1"" 0 100 95 false false ""110m10s5h"" ""5h15s105m"" false true 30 )  ;"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\AddCommentsToBamTest.java,get command line program name,public  string   (  )  {  return  add comments to bam . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\AddCommentsToBamTest.java,run it,"private void   ( final  file input file final  file output file final  string[] comment list )  {  final  list <  string >  args = new  array list <  string >  (  arrays . as list ( ""input = ""  +  input file . get absolute path (  )  ""output = ""  +  output file . get absolute path (  )  )  )  ;  for  (  final  string comment : comment list )   {  args . add ( ""comment = ""  +  comment )  ;   }  run picard command line ( args )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\AddCommentsToBamTest.java,test add comments to bam,"@ test public void   (  )  throws  exception  {  final  file output file =  file . create temp file ( ""add comments to bam test . ""  bam file io utils . bam   file   extension )  ;  output file . delete on exit (  )  ;  run it ( input   file output file c"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\AddCommentsToBamTest.java,test using newlines,"@ test ( expected exceptions =  illegal argument exception . class )  public void   (  )  throws  exception  {  final  file output file =  file . create temp file ( ""add comments to bam test . mew line""  bam file io utils . bam   file   extension )  ;  ou"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\AddCommentsToBamTest.java,test using sam,"@ test ( expected exceptions =  picard exception . class )  public void   (  )  throws  exception  {  final  file output file =  file . create temp file ( ""add comments to bam test . sam file""  bam file io utils . bam   file   extension )  ;  output file "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\DownsampleSamTest.java, valid arguments test provider,"@ data provider ( name = "" "" )  public  object[][]  valid arguments test provider (  )  {  final  list <  object[] >  objects = new  array list <  >  (  )  ;  for  (  final  strategy strategy :  strategy . values (  )  )  for  (  final  integer seed : new"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\DownsampleSamTest.java,get command line program name,@ override public  string   (  )  {  return  downsample sam . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\DownsampleSamTest.java,setup builder,"@ before test void   (  )  throws io exception  {  final int num reads = 10000 ;  final  string flow cell barcode = ""testbarcode"" ;  final  string separator = "":"" ;  final int lane = 1 ;  final int tile = 2203 ;  final  random rg = new  random ( 31 )  ;  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\DownsampleSamTest.java,tear down,@ after test private void   (  )  {  io util . delete directory tree ( temp dir )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\DownsampleSamTest.java,test downsample strategies,"@ test ( data provider = "" valid arguments test provider"" )  public void   ( final double fraction final  strategy strategy final  integer seed )  throws io exception  {  test downsample worker ( temp sam file fraction strategy . name (  )  seed )  ;   } "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\DownsampleSamTest.java,test downsample worker,"private void   ( final  file sam file final double fraction final  string strategy final  integer seed )  throws io exception  {  final  file downsampled =  file . create temp file ( "" downsample sam"" "" . bam"" temp dir )  ;  final  string[] args = new  string[] { ""input = ""  +  sam file . get absolute path (  )  ""output = ""  +  downsampled . get absolute path (  )  ""probability = ""  +  fraction ""strategy = ""  +  strategy ""random   seed = ""  +   (  ( seed  =  =  null )   ?  ""null"" : seed . to string (  )  )  ""create   index = true"" }  ;   assert . assert equals ( run picard command line ( args )  0 )  ;  final  validate sam file validate sam file = new  validate sam file (  )  ;  validate sam file . input = downsampled ;   assert . assert equals ( validate sam file . do work (  )  0 )  ;  if  ( seed  !  =  null )   {   testng util . assert greater than (  sam test util . count sam total record ( downsampled )  fraction *  . 8 *  sam test util . count sam total record ( sam file )  )  ;   testng util . assert less than (  sam test util . count sam total record ( downsampled )  fraction * 1 . 2 *  sam test util . count sam total record ( sam file )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CreateSequenceDictionaryTest.java,get command line program name,public  string   (  )  {  return  create sequence dictionary . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CreateSequenceDictionaryTest.java,test basic,"@ test public void   (  )  throws  exception  {  final  file output dict =  file . create temp file ( "" create sequence dictionary test . "" "" . dict"" )  ;  output dict . delete (  )  ;  output dict . delete on exit (  )  ;  final  string[] argv =  { ""refe"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CreateSequenceDictionaryTest.java,test default output file,"@ test public void   (  )  throws  exception  {  final  file expected dict = new  file ( test   data   dir  +  "" / sam"" ""basic . dict"" )  ;  expected dict . delete on exit (  )  ;   assert . assert false ( expected dict . exists (  )  )  ;  final  string["
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CreateSequenceDictionaryTest.java,test for equivalence,"@ test public void   (  )  throws  exception  {  final  file output dict =  file . create temp file ( "" create sequence dictionary test . "" "" . dict"" )  ;  output dict . delete (  )  ;  final  string[] argv =  { ""reference = ""  +  equivalence   test   fas"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\CreateSequenceDictionaryTest.java,test non unique sequence name,"@ test ( expected exceptions =  picard exception . class )  public void   (  )  throws  exception  {  final  file output dict =  file . create temp file ( "" create sequence dictionary test . "" "" . dict"" )  ;  output dict . delete on exit (  )  ;  final  s"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\DuplicationMetricsTest.java,empty metrics,"private  duplication metrics   (  )  {  final  duplication metrics metric = new  duplication metrics (  )  ;  metric . library = ""library"" ;  metric . unpaired   reads   examined = 0 ;  metric . read   pairs   examined = 0 ;  metric . secondary   or   supplementary   rds = 0 ;  metric . unmapped   reads = 0 ;  metric . unpaired   read   duplicates = 0 ;  metric . read   pair   duplicates = 0 ;  metric . read   pair   optical   duplicates = 0 ;  metric . calculate derived fields (  )  ;  return metric ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\DuplicationMetricsTest.java,infinite loop from github   ,@ test ( time out = 1000 )  public void   (  )  {   duplication metrics . estimate library size ( 357087883 357087881 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\DuplicationMetricsTest.java,non empty metrics,"private  duplication metrics   ( final int scale )  {  final  duplication metrics metric = new  duplication metrics (  )  ;  metric . library = ""library"" ;  metric . unpaired   reads   examined = 1000 * scale ;  metric . read   pairs   examined = 1000 * scale ;  metric . secondary   or   supplementary   rds = scale ;  metric . unmapped   reads = 10 * scale ;  metric . unpaired   read   duplicates = 100 * scale ;  metric . read   pair   duplicates = 110 * scale ;  metric . read   pair   optical   duplicates = 10 * scale ;  metric . calculate derived fields (  )  ;  return metric ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\DuplicationMetricsTest.java,test merge,"@ test ( data provider = ""  data provider"" )  public void test merge ( final  duplication metrics left final  duplication metrics right final  duplication metrics expected )  {  left . merge ( right )  ;  left . calculate derived fields (  )  ;   assert ."
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\DuplicationMetricsTest.java,test merge data provider,"@ data provider ( name = "" "" )  public  object[][] test merge data provider (  )  {  return new  object[][] {  { empty metrics (  )  empty metrics (  )  empty metrics (  )  }   { empty metrics (  )  non empty metrics ( 1 )  non empty metrics ( 1 )  }   { "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FixMateInformationTest.java,get command line program name,public  string   (  )  {  return  fix mate information . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FixMateInformationTest.java,ignore missing mate exception test,@ test ( expected exceptions = sam exception . class )  public void   (  )  throws io exception  {  missing mate test helper ( false )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FixMateInformationTest.java,ignore missing mate test,@ test public void   (  )  throws io exception  {   assert . assert equals ( missing mate test helper ( true )  0 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FixMateInformationTest.java,missing mate test helper,"public int   ( final boolean ignore missing mates )  throws io exception  {  final  file in sam file = new  file ( test   data   dir missing   mate   test )  ;  final  file out sam file =  file . create temp file ( ""out missing mate test"" ""sam"" )  ;  out sam file . delete on exit (  )  ;  final  string[] args = new  string[] { ""input = ""  +  in sam file . get absolute path (  )  ""output = ""  +  out sam file . get absolute path (  )  ""ignore   missing   mates = ""  +  ignore missing mates }  ;  return new  fix mate information (  )  . instance main ( args )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\GatherBamFilesTest.java,get command line program name,public  string   (  )  {  return  gather bam files . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\GatherBamFilesTest.java,sanity check the gathering,"@ test public void   (  )  throws  exception  {  final  file output file =  file . create temp file ( ""gather bam files test . sam file . ""  bam file io utils . bam   file   extension )  ;  output file . delete on exit (  )  ;  final  list <  string >  ar"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\GatherBamFilesTest.java,test the gathering,"@ test public void   (  )  throws  exception  {  final  file output file =  file . create temp file ( ""gather bam files test . sam file . ""  bam file io utils . bam   file   extension )  ;  output file . delete on exit (  )  ;  final  list <  string >  ar"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FilterSamReadsTest.java,bad argument combinationsdata,"@ data provider ( name = "" "" )  public  object[][] bad argument combinationsdata (  )  {  return new  object[][] {  {  filter sam reads .  filter . include javascript ""read   list   file"" }   {  filter sam reads .  filter . exclude aligned ""read   list   "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FilterSamReadsTest.java,data test debug option,"@ data provider ( name = "" "" )  public  object[][] data test debug option (  )  {  return new  object[][] {  { null false }   { true true }   { false false }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FilterSamReadsTest.java,data test js filter,"@ data provider ( name = "" "" )  public  object[][] data test js filter (  )  {  return new  object[][] {  { test   dir  +  ""aligned . sam"" test   dir  +  "" filter sam reads / filter odd starts . js"" 3 }   { test   dir  +  ""aligned . sam"" test   dir  +  "" "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FilterSamReadsTest.java,data test paired interval filter,"@ data provider ( name = "" "" )  public  object[][] data test paired interval filter (  )  {  return new  object[][] {  { test   dir  +  "" filter sam reads / filter1 . interval   list"" 4 }   { test   dir  +  "" filter sam reads / filter2 . interval   list"" "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FilterSamReadsTest.java,data test read filter,"@ data provider ( name = "" "" )  public  object[][] data test read filter (  )  {   list <  string >  reads =  arrays . as list ( ""mapped   pair   chr1"" ""prove   one   of   pair"" ""one   of   pair"" )  ;  return new  object[][] {  {  filter sam reads .  filt"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FilterSamReadsTest.java,data test tag filter,"@ data provider ( name = "" "" )  public  object[][] data test tag filter (  )  {  return new  object[][] {  { ""testdata / picard / sam / aligned . sam"" ""rg"" ""0"" true 8 }   { ""testdata / picard / sam / aligned . sam"" ""rg"" ""0"" false 0 }   { ""testdata / picar"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FilterSamReadsTest.java,get command line program name,@ override public  string   (  )  {  return  filter sam reads . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FilterSamReadsTest.java,get read count,private long   (  filter sam reads filter test )  throws  exception  {  final  sam reader sam reader =  sam reader factory . make default (  )  . open ( filter test . output )  ;  long count =  stream support . stream ( sam reader . spliterator (  )  false )  . count (  )  ;  sam reader . close (  )  ;  return count ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FilterSamReadsTest.java,set up,"@ before test public void   (  )  throws io exception  {  builder . set read length ( read   length )  ;  builder . add pair ( ""mapped   pair   chr1"" 0 1 151 )  ;  builder . add pair ( ""mapped   pair   chr2"" 1 1 151 )  ;  builder . add pair ( ""prove   one"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FilterSamReadsTest.java,setup program,private  filter sam reads   ( final  file input file final  file input sam final  filter sam reads .  filter filter )  throws  exception  {  return setup program ( input file input sam filter null )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FilterSamReadsTest.java,test bad argument combinations,"@ test ( data provider = ""bad argument combinationsdata"" )  public void   ( final  filter sam reads .  filter filter final  string file argument )  throws io exception  {  final  file dummy file =  file . create temp file ( test   dir ""dummy"" )  ;  dummy "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FilterSamReadsTest.java,test debug option,"@ test ( data provider = ""data test debug option"" )  public void   (  boolean write debug reads boolean is debug file expected )  throws  exception  {  final  file input sam = new  file ( ""testdata / picard / sam / aligned . sam"" )  ;  final  file javascr"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FilterSamReadsTest.java,test java script filters,"@ test ( data provider = ""data test js filter"" )  public void   ( final  string sam filename final  string javascript filename final int expect number )  throws  exception  {  final  file input sam = new  file ( sam filename )  ;  final  file javascript f"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FilterSamReadsTest.java,test paired interval filter,"@ test ( data provider = ""data test paired interval filter"" )  public void   ( final  string interval filename final int expect number )  throws  exception  {  final  file input sam =  vcf test utils . create temporary indexed file ( ""test sam"" "" . bam"" )"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FilterSamReadsTest.java,test read filters,"@ test ( data provider = ""data test read filter"" )  public void   ( final  filter sam reads .  filter filter type final  list <  string >  read list final int expect number )  throws  exception  {  final  file input sam =  file . create temp file ( ""test "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FilterSamReadsTest.java,test tag filter,"@ test ( data provider = ""data test tag filter"" )  public void   ( final  string sam filename final  string tag final  string tag value final boolean include reads final int expect number )  throws  exception  {  final  file input sam = new  file ( sam fi"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,bad format files,"@ data provider ( name = "" "" )  public  object[][] bad format files (  )  {  return new  object[][] {  { ""bad - format / bad - qual - header . txt"" }   { ""bad - format / bad - seq - header . txt"" }   { ""bad - format / extra - line . txt"" }   { ""bad - form"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,bad pair names,"@ data provider ( name = "" "" )  public  object[][] bad pair names (  )  {  return new  object[][] {  { """" """" }   { ""aa / 1"" ""bb / 2"" }   { ""aa"" ""bb"" }   { ""aa / 1"" ""aa"" }   { ""aa"" ""aa / 2"" }   { ""aa / 1"" ""aa / 1"" }   { ""aa / 2"" ""aa / 2"" }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,bad paired files,"@ data provider ( name = "" "" )  public  object[][] bad paired files (  )  {  return new  object[][] {  { ""ok - paired / pair1 . txt"" ""bad - paired / pair2 - one - more - record . txt"" }   { ""bad - paired / pair1 - one - more - record . txt"" ""ok - paired /"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,bad version files,"@ data provider ( name = "" "" )  public  object[][] bad version files (  )  {  return new  object[][] {  { ""fastq - sanger / sanger   full   range   as   sanger - 63 . fastq""  fastq quality format .  illumina }   { ""fastq - solexa / s   1   sequence . txt"""
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,before class,"@ before class public static void   (  )  throws io exception  {  final  file dummy file = new temp file ( ""dummy"" )  ;  freader1 = new  fastq reader ( dummy file )  ;  freader2 = new  fastq reader ( dummy file )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,convert file,"private  file   ( final  string fastq filename1 final  string fastq filename2 final  fastq quality format version final boolean permissive format final boolean use sequential fastqs )  throws io exception  {  final  file fastq1 = new  file ( test   data   dir fastq filename1 )  ;  final  file fastq2 =  ( fastq filename2  !  =  null )   ?  new  file ( test   data   dir fastq filename2 )  : null ;  final  file sam file = new temp sam file ( fastq1 . get name (  )  )  ;  final  list <  string >  args = new  array list <  string >  (  )  ;  args . add ( ""fastq = ""  +  fastq1 . get absolute path (  )  )  ;  args . add ( ""output = ""  +  sam file . get absolute path (  )  )  ;  args . add ( ""quality   format = ""  +  version )  ;  args . add ( ""read   group   name = rg"" )  ;  args . add ( ""sample   name = s1"" )  ;  if  ( fastq filename2  !  =  null )  args . add ( ""fastq2 = ""  +  fastq2 . get absolute path (  )  )  ;  if  ( permissive format )  args . add ( ""allow   and   ignore   empty   lines = true"" )  ;  if  ( use sequential fastqs )  args . add ( ""use   sequential   fastqs = true"" )  ;   assert . assert equals ( run picard command line ( args )  0 )  ;  return sam file ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,convert file and verify record count,private void   ( final int expected count final  string fastq filename1 final  string fastq filename2 final  fastq quality format version final boolean permissive format final boolean use sequential fastqs )  throws io exception  {  final  file sam file = convert file ( fastq filename1 fastq filename2 version permissive format use sequential fastqs )  ;  final  sam reader sam reader =  sam reader factory . make default (  )  . open ( sam file )  ;  final sam record iterator iterator = sam reader . iterator (  )  ;  int actual count = 0 ;  while  ( iterator . has next (  )  )   {  iterator . next (  )  ;  actual count +  +  ;   }  sam reader . close (  )  ;   assert . assert equals ( actual count expected count )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,get command line program name,public  string   (  )  {  return  fastq to sam . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,new temp file,"private static  file   ( final  string filename )  throws io exception  {  final  file file =  file . create temp file ( filename "" . tmp"" )  ;  file . delete on exit (  )  ;  return file ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,new temp sam file,"private static  file   ( final  string filename )  throws io exception  {  final  file file =  file . create temp file ( filename "" . sam"" )  ;  file . delete on exit (  )  ;  return file ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,ok pair names,"@ data provider ( name = "" "" )  public  object[][] ok pair names (  )  {  return new  object[][] {  { ""aa / 1"" ""aa / 2"" }   { ""aa"" ""aa"" }   { ""aa / bb"" ""aa / bb"" }   { ""aa / bb / "" ""aa / bb / "" }   { ""aa / bb / 1"" ""aa / bb / 2"" }   { ""aa / bb / cc / dd / "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,ok paired files,"@ data provider ( name = "" "" )  public  object[][] ok paired files (  )  {  return new  object[][] {  { ""ok - paired / pair1 . txt"" ""ok - paired / pair2 . txt""  fastq quality format .  standard }   { ""fastq - illumina / s   1   1   sequence . txt"" ""fastq "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,ok version files,"@ data provider ( name = "" "" )  public  object[][] ok version files (  )  {  return new  object[][] {  { ""fastq - sanger / 5k - v1 -  rhodobacter   lw1 . sam . fastq""  fastq quality format .  standard }   { ""fastq - sanger / 5k - 30bb2aaxx . 3 . aligned ."
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,permissive format files,"@ data provider ( name = "" "" )  public  object[][] permissive format files (  )  {  return new  object[][] {  { ""permissive - format / pair1 . txt"" ""permissive - format / pair2 . txt""  fastq quality format .  standard }   { ""permissive - format / s   1   "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,read pair name bad,"@ test ( data provider = ""bad pair names"" expected exceptions =  picard exception . class )  public void   ( final  string name1 final  string name2 )  throws io exception  {  fastq to sam . get base name ( name1 name2 freader1 freader2 )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,read pair name ok,"@ test ( data provider = ""ok pair names"" )  public void   ( final  string name1 final  string name2 )  throws io exception  {  fastq to sam . get base name ( name1 name2 freader1 freader2 )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,test bad file,"@ test ( data provider = ""bad format files"" expected exceptions = sam exception . class )  public void   ( final  string filename )  throws io exception  {  convert file ( filename null  fastq quality format .  standard )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,test fastq version bad,"@ test ( data provider = ""bad version files"" expected exceptions = sam exception . class )  public void   ( final  string fastq version filename final  fastq quality format version )  throws io exception  {  convert file ( fastq version filename version )"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,test fastq version ok,"@ test ( data provider = ""ok version files"" )  public void   ( final  string fastq version filename final  fastq quality format version )  throws io exception  {  convert file ( fastq version filename version )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,test paired bad,"@ test ( data provider = ""bad paired files"" expected exceptions =  picard exception . class )  public void   ( final  string filename1 final  string filename2 )  throws io exception  {  convert file ( filename1 filename2  fastq quality format .  standard "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,test paired ok,"@ test ( data provider = ""ok paired files"" )  public void   ( final  string filename1 final  string filename2 final  fastq quality format version )  throws io exception  {  convert file ( filename1 filename2 version )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,test permissive fail,"@ test ( data provider = ""permissive format files"" expected exceptions = sam exception . class )  public void   ( final  string filename1 final  string filename2 final  fastq quality format version )  throws io exception  {  convert file ( filename1 filen"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,test permissive ok,"@ test ( data provider = ""permissive format files"" )  public void   ( final  string filename1 final  string filename2 final  fastq quality format version )  throws io exception  {  convert file ( filename1 filename2 version true )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\FastqToSamTest.java,test sequential files,"@ test public void   (  )  throws io exception  {  final  string single end = ""sequential - files / single   end   r1   001 . fastq"" ;  final  string paired end1 = ""sequential - files / paired   end   r1   001 . fastq"" ;  final  string paired end2 = ""sequ"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\AsIsMarkDuplicatesTester.java,test same unclipped prime opposite strand,"@ test ( data provider = ""  data"" )  public void test same unclipped5 prime opposite strand ( final  file input )  {  final  abstract mark duplicates command line program tester tester = new  by sum of baseq and in original ordermd tester (  )  ;  final  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\AsIsMarkDuplicatesTester.java,test same unclipped prime opposite strand data,"@ data provider public  object[][]   (  )  {  final  file test   dir = new  file ( ""testdata / picard / sam /  mark duplicates"" )  ;  return new  object[][] { new  object[] { new  file ( test   dir ""same unclipped5prime endv1 . sam"" )  }  new  object[] { "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\BySumOfBaseQAndInOriginalOrderMDTester.java, by sum of baseq and in original ordermd tester,public   (  )  {  super (  duplicate scoring strategy .  scoring strategy . sum   of   base   qualities sam file header .  sort order . unsorted false )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\BySumOfBaseQAndInOriginalOrderMDTester.java,get program,@ override protected  command line program   (  )  {  return new  mark duplicates (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\ElcHashBasedDuplicatesFinderTest.java,fill histogram data provider,"@ data provider ( name = "" "" )  public  object[][] fill histogram data provider (  )  {  return new  object[][] {  { duplicates finder new  histogram <  >  (  )  new  histogram <  >  (  )  generate paired read sequence ( false )  generate paired read sequ"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\ElcHashBasedDuplicatesFinderTest.java,search duplicates data provider,"@ data provider ( name = "" "" )  public  object[][] search duplicates data provider (  )  {  return new  object[][] {  { duplicates finder new  histogram <  >  (  )  new  histogram <  >  (  )  generate paired read sequences ( 1 false )  1 0 0 }   { duplica"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\ElcHashBasedDuplicatesFinderTest.java,test fill histogram,"@ test ( data provider = ""fill histogram data provider"" )  public void   (  elc duplicates finder duplicates finder  histogram <  integer >  duplication histo  histogram <  integer >  optical histo  paired read sequence prs  array list <  paired read sequ"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\ElcHashBasedDuplicatesFinderTest.java,test search duplicates,"@ test ( data provider = ""search duplicates data provider"" )  public void   (  elc duplicates finder duplicates finder  histogram <  integer >  duplication histo  histogram <  integer >  optical histo  array list <  paired read sequence >  dupes int dup h"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\AbstractMarkDuplicatesCommandLineProgramTester.java, abstract mark duplicates command line program tester,public   (  )  {  this ( sam record set builder . default   duplicate   scoring   strategy )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\AbstractMarkDuplicatesCommandLineProgramTester.java,get command line program name,@ override public  string   (  )  {  return get program (  )  . get class (  )  . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTagRepresentativeReadIndexTester.java, mark duplicates tag representative read index tester,"public   (  )  {  add arg ( ""tagging   policy =  all"" )  ;  add arg ( ""tag   duplicate   set   members = true"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTagRepresentativeReadIndexTester.java,get program,@ override protected  command line program   (  )  {  return new  mark duplicates (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTagRepresentativeReadIndexTester.java,test,@ override public void   (  )  {  try  {  update expected duplication metrics (  )  ;  int output records = 0 ;  int index in file = 0 ;  final  sam reader reader =  sam reader factory . make default (  )  . open ( get output (  )  )  ;  for  (  final sam
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\EstimateLibraryComplexityTest.java,create data test default min group count,"@ data provider ( name = ""test default min group count"" )  public  object[][]   (  )  {  return new  object[][] {  { ""dupes . sam"" 0 0 }   { ""big   dupes . sam"" 8 497 }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\EstimateLibraryComplexityTest.java,create data test max diff rate,"@ data provider ( name = ""test max diff rate"" )  public  object[][]   (  )  {  return new  object[][] {  { ""dupes . sam"" 0 2 }   { ""big   dupes . sam"" 8 500 }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\EstimateLibraryComplexityTest.java,create data test simple duplicate,"@ data provider ( name = ""test simple duplicate"" )  public  object[][]   (  )  {  return new  object[][] {  { ""dupes . sam"" 2 2 }   { ""big   dupes . sam"" 12 500 }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\EstimateLibraryComplexityTest.java,create data test simple duplicate with max read length,"@ data provider ( name = ""test simple duplicate with max read length"" )  public  object[][]   (  )  {  return new  object[][] {  { ""dupes . sam"" 2 2 }   { ""big   dupes . sam"" 512 500 }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\EstimateLibraryComplexityTest.java,create data test simple duplicates with secondary and supplementary records,"@ data provider ( name = ""test simple duplicates with secondary and supplementary records"" )  public  object[][]   (  )  {  return new  object[][] {  { ""dupes   with   sos . sam"" 2 2 }   { ""big   dupes   with   sos . sam"" 12 500 }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\EstimateLibraryComplexityTest.java,examine metrics file,private void   ( final  file output final int num duplicates final int num read pairs examined )  {  final  list <  duplication metrics >  metrics list =  metrics file . read beans ( output )  ;   assert . assert equals ( metrics list . size (  )  1 )  ;  final  duplication metrics metrics = metrics list . get ( 0 )  ;   assert . assert equals ( metrics . read   pair   duplicates * 2  +  metrics . unpaired   read   duplicates num duplicates )  ;   assert . assert equals ( metrics . read   pairs   examined num read pairs examined )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\EstimateLibraryComplexityTest.java,get command line program name,public  string   (  )  {  return  estimate library complexity . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\EstimateLibraryComplexityTest.java,test default min group count,"@ test ( data provider = "" "" )  public void test default min group count ( final  string test name final int num duplicates final int num read pairs examined )  throws io exception  {  final  file input = new  file ( test   data   dir test name )  ;  fina"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\EstimateLibraryComplexityTest.java,test max diff rate,"@ test ( data provider = "" "" )  public void test max diff rate ( final  string test name final int num duplicates final int num read pairs examined )  throws io exception  {  final  file input = new  file ( test   data   dir test name )  ;  final  file ou"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\EstimateLibraryComplexityTest.java,test simple duplicate,"@ test ( data provider = "" "" )  public void test simple duplicate ( final  string test name final int num duplicates final int num read pairs examined )  throws io exception  {  final  file input = new  file ( test   data   dir test name )  ;  final  file"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\EstimateLibraryComplexityTest.java,test simple duplicate with max read length,"@ test ( data provider = "" "" )  public void test simple duplicate with max read length ( final  string test name final int num duplicates final int num read pairs examined )  throws io exception  {  final  file input = new  file ( test   data   dir test n"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\EstimateLibraryComplexityTest.java,test simple duplicates with secondary and supplementary records,"@ test ( data provider = "" "" )  public void test simple duplicates with secondary and supplementary records ( final  string test name final int num duplicates final int num read pairs examined )  throws io exception  {  final  file input = new  file ( tes"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTagRepresentativeReadIndexTest.java,get tester,protected  mark duplicates tag representative read index tester   (  )  {  return new  mark duplicates tag representative read index tester (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTagRepresentativeReadIndexTest.java,test multi representative read tags,@ test public void   (  )  {  final  mark duplicates tag representative read index tester tester = get tester (  )  ;  tester . get sam record set builder (  )  . set read length ( 45 )  ;  tester . test representative reads = true ;  tester . set expecte
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTagRepresentativeReadIndexTest.java,test representative read tag,@ test public void   (  )  {  final  mark duplicates tag representative read index tester tester = get tester (  )  ;  tester . get sam record set builder (  )  . set read length ( 45 )  ;  tester . test representative reads = true ;  tester . set expecte
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarTest.java,get tester,protected  abstract mark duplicates command line program tester   (  )  {  return new  mark duplicates with mate cigar tester (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarTest.java,test scoring strategy for mate reference length comparison,"@ test public void   (  )  {  final  abstract mark duplicates command line program tester tester = get tester (  )  ;  tester . add mate pair ( ""ready"" 1 1 105 false false true true ""50m"" ""5i45m"" false true false false false default   base   quality )  ; "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarTest.java,test scoring strategy for read name comparison,@ test public void   (  )  {  final  abstract mark duplicates command line program tester tester = get tester (  )  ;  tester . add mapped fragment ( 0 1 false default   base   quality )  ;  tester . add mapped fragment ( 0 1 true default   base   quality
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarTest.java,test two fragments large soft clip,@ test ( expected exceptions =  picard exception . class )  public void   (  )  {  final  abstract mark duplicates command line program tester tester = get tester (  )  ;  tester . get sam record set builder (  )  . set read length ( 100 )  ;  tester . ad
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarTest.java,test two fragments large soft clip with minimum distance failure,"@ test ( expected exceptions =  picard exception . class )  public void   (  )  {  final  abstract mark duplicates command line program tester tester = get tester (  )  ;  tester . add arg ( ""minimum   distance = 989"" )  ;  tester . get sam record set bui"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarTest.java,test two fragments large soft clip with minimum distanceok,"@ test public void   (  )  {  final  abstract mark duplicates command line program tester tester = get tester (  )  ;  tester . add arg ( ""minimum   distance = 990"" )  ;  tester . get sam record set builder (  )  . set read length ( 100 )  ;  tester . add"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarTest.java,test two mapped pairs with soft clipping first of pair only,"@ test public void   (  )  {  final  abstract mark duplicates command line program tester tester = get tester (  )  ;  tester . get sam record set builder (  )  . set read length ( 76 )  ;  tester . add mapped pair ( 0 12 46 false false ""6s42m28s"" ""3s73m"""
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTest.java, expected pn and vn,private   ( final  string expected pn final  string expected vn )  {  this . expected pn = expected pn ;  this . expected vn = expected vn ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTest.java,add mapped fragment,"public void   ( final int reference sequence index final int alignment start final boolean is duplicate final  string cigar final int default quality score )  {  final  abstract mark duplicates command line program tester tester = get tester (  )  ;  tester . add mate pair ( ""runid:1:1:15993:13361"" 2 41212324 41212310 false false false false ""33s35m"" ""19s49m"" true true false false false default   base   quality )  ;  tester . add mate pair ( ""runid:2:2:15993:13362"" 2 41212324 41212310 false false true true ""33s35m"" ""19s49m"" true true false false false default   base   quality )  ;  final  string barcode tag = ""bc"" ;  for  (  final sam record record : new  iterable adapter < sam record >  ( tester . get record iterator (  )  )  )   {  record . set attribute ( barcode tag "" barcode1"" )  ;   }  tester . add arg ( ""barcode   tag = ""  +  barcode tag )  ;  tester . run test (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTest.java,get tester,protected  abstract mark duplicates command line program tester   (  )  {  return new  mark duplicates tester (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTest.java,pg record chaining test,"@ test ( data provider = "" "" )  public void pg record chaining test ( final boolean suppress pg final  map <  string  list <  expected pn and vn >  >  expected pn vn by read name )  {  final  file output dir = io util . create temp dir ( test   base   nam"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTest.java,pg record chaining test data provider,"@ data provider ( name = ""pg record chaining test"" )  public  object[][]   (  )  {  final  map <  string  list <  expected pn and vn >  >  with pg map = new  hash map <  string  list <  expected pn and vn >  >  (  )  ;  with pg map . put ( ""1aaxx . 1 . 1"""
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTest.java,set up,"@ before class public void   (  )  {  test   base   name = "" mark duplicates"" ;  test   data   dir = new  file ( ""testdata / picard / sam /  mark duplicates"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTest.java,test optical duplicate detection,"@ test ( data provider = ""  data provider"" )  public void test optical duplicate detection ( final  file sam final long expected num optical duplicates )  {  final  file output dir = io util . create temp dir ( test   base   name  +  "" . "" "" . tmp"" )  ;  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTest.java,test optical duplicate detection data provider,"@ data provider ( name = "" "" )  public  object[][] test optical duplicate detection data provider (  )  {  return new  object[][] {  { new  file ( test   data   dir ""optical   dupes . sam"" )  1l }   { new  file ( test   data   dir ""optical   dupes   casav"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTest.java,test two mapped pairs with soft clipping first of pair only,"@ test public void   (  )  {  final  abstract mark duplicates command line program tester tester = get tester (  )  ;  tester . get sam record set builder (  )  . set read length ( 76 )  ;  tester . add mapped pair ( 0 12 46 false false ""6s42m28s"" ""3s73m"""
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTest.java,test with barcode complex,"@ test public void   (  )  {  final  abstract mark duplicates command line program tester tester = get tester (  )  ;  tester . get sam record set builder (  )  . set read length ( 68 )  ;  final  string read name one = ""runid:1:1:15993:13361"" ;  final  s"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTest.java,test with barcode duplicate,"@ test public void   (  )  {  final  abstract mark duplicates command line program tester tester = get tester (  )  ;  tester . get sam record set builder (  )  . set read length ( 68 )  ;  tester . add mate pair ( ""runid:1:1:15993:13361"" 2 41212324 41212"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTest.java,test with barcode fragment duplicate,"@ test public void   (  )  {  final  abstract mark duplicates command line program tester tester = get tester (  )  ;  tester . add mapped fragment ( 2 41212324 false ""50m"" default   base   quality )  ;  tester . add mapped fragment ( 2 41212324 true ""50m"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTest.java,test with individual read barcodes,"@ test public void   (  )  {  final  abstract mark duplicates command line program tester tester = get tester (  )  ;  tester . get sam record set builder (  )  . set read length ( 68 )  ;  final  string read name one = ""runid:1:1:15993:13361"" ;  final  s"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTester.java, mark duplicates tester,public   (  )  {  super (  duplicate scoring strategy .  scoring strategy . total   mapped   reference   length )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesTester.java,get program,@ override protected  command line program   (  )  {  return new  mark duplicates (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarTester.java, mark duplicates with mate cigar tester,"public   (  )  {  super (  scoring strategy . total   mapped   reference   length )  ;  add arg ( ""max   records   in   ram = 1000"" )  ;  add arg ( ""block   size = 250"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicatesWithMateCigarTester.java,get program,@ override protected  command line program   (  )  {  return new  mark duplicates with mate cigar (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicateWithMissingReadOneBarcodeTest.java,get argument name,"@ override protected  string   (  )  {  return ""read   two   barcode   tag"" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicateWithMissingReadOneBarcodeTest.java,get tag value,"@ override protected  string   (  )  {  return ""rx"" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicateWithMissingReadTwoBarcodeTest.java,get argument name,"@ override protected  string   (  )  {  return ""read   two   barcode   tag"" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicateWithMissingReadTwoBarcodeTest.java,get tag value,"@ override protected  string   (  )  {  return ""rx"" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicateWithMissingSampleBarcodeTest.java,get argument name,"@ override protected  string   (  )  {  return ""barcode   tag"" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\MarkDuplicateWithMissingSampleBarcodeTest.java,get tag value,"@ override protected  string   (  )  {  return ""bc"" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\QuerySortedMarkDuplicatesTester.java, query sorted mark duplicates tester,public   (  )  {  super (  duplicate scoring strategy .  scoring strategy . total   mapped   reference   length sam file header .  sort order . queryname )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\QuerySortedMarkDuplicatesTester.java,get program,@ override protected  command line program   (  )  {  return new  mark duplicates (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\SimpleMarkDuplicatesWithMateCigarTest.java,get tester,protected  abstract mark duplicates command line program tester   (  )  {  return new  simple mark duplicates with mate cigar tester (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\SimpleMarkDuplicatesWithMateCigarTest.java,test two mapped pairs with soft clipping first of pair only no mate cigar,@ test ( expected exceptions = sam exception . class )  @ override public void   (  )  {  super . test two mapped pairs with soft clipping first of pair only no mate cigar (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\SimpleMarkDuplicatesWithMateCigarTester.java, simple mark duplicates with mate cigar tester,"public   (  )  {  super (  duplicate scoring strategy .  scoring strategy . total   mapped   reference   length )  ;  add arg ( ""max   records   in   ram = 1000"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\SimpleMarkDuplicatesWithMateCigarTester.java,get program,@ override protected  command line program   (  )  {  return new  simple mark duplicates with mate cigar (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\ElcIdenticalBasesDuplicatesFinderTest.java,change read content,private void   ( byte[] read )  {  for  ( int i = min   identical   bases ;  i  <  =  min   identical   bases  +  read . length * max   diff   rate ;  i +  +  )   {  read[i] +  = 1 ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\ElcIdenticalBasesDuplicatesFinderTest.java,fill histogram data provider,"@ data provider ( name = "" "" )  public  object[][] fill histogram data provider (  )  {  return new  object[][] {  { duplicates finder new  histogram <  >  (  )  new  histogram <  >  (  )  generate paired read sequence ( false )  generate paired read sequ"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\ElcIdenticalBasesDuplicatesFinderTest.java,generate paired read sequence,protected  paired read sequence   ( boolean is optical duplicates )  {   paired read sequence prs = new  paired read sequence (  )  ;  prs . read1 = new byte[100] ;  prs . read2 = new byte[100] ;  if  ( is optical duplicates )   {  short read group = 1 ;  short tile =  short . max   value ;  prs . set read group ( read group )  ;  prs . set tile ( tile )  ;  prs . setx ( 127 )  ;  prs . sety ( 255 )  ;   }  return prs ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\ElcIdenticalBasesDuplicatesFinderTest.java,generate paired read sequences,protected  array list <  paired read sequence >    ( int seqs size boolean is optical duplicates )  {   array list <  paired read sequence >  seq = new  array list <  >  ( seqs size )  ;  for  ( int i = 0 ;  i  <  seqs size ;  i +  +  )   {  seq . add ( generate paired read sequence ( is optical duplicates )  )  ;   }  return seq ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\ElcIdenticalBasesDuplicatesFinderTest.java,generate seqs with no dup,protected  array list <  paired read sequence >    ( int seqs size boolean is optical duplicates )  {   array list <  paired read sequence >  seq = generate paired read sequences ( seqs size is optical duplicates )  ;   paired read sequence prs = seq . get ( seq . size (  )   -  1 )  ;  change read content ( prs . read1 )  ;  change read content ( prs . read2 )  ;  return seq ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\ElcIdenticalBasesDuplicatesFinderTest.java,search duplicates data provider,"@ data provider ( name = "" "" )  public  object[][] search duplicates data provider (  )  {  return new  object[][] {  { duplicates finder new  histogram <  >  (  )  new  histogram <  >  (  )  generate paired read sequences ( 1 false )  1 0 0 }   { duplica"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\ElcIdenticalBasesDuplicatesFinderTest.java,test fill histogram,"@ test ( data provider = ""fill histogram data provider"" )  public void   (  elc duplicates finder duplicates finder  histogram <  integer >  duplication histo  histogram <  integer >  optical histo  paired read sequence prs  array list <  paired read sequ"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\ElcIdenticalBasesDuplicatesFinderTest.java,test search duplicates,"@ test ( data provider = ""search duplicates data provider"" )  public void   (  elc duplicates finder duplicates finder  histogram <  integer >  duplication histo  histogram <  integer >  optical histo  array list <  paired read sequence >  dupes int dup h"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\util\OpticalDuplicateFinderTest.java,assert equals,"void   ( final boolean[] actual final boolean[] expected )  {  if  (  !  arrays . equals ( actual expected )  )   {  throw new  assertion error ( ""expected: ""  +   arrays . to string ( expected )   +  "" but was: "" +   arrays . to string ( actual )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\util\OpticalDuplicateFinderTest.java,count true,int   ( final boolean[] bs )  {  int count = 0 ;  for  (  final boolean b : bs )  if  ( b )   +  + count ;  return count ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\util\OpticalDuplicateFinderTest.java,get read group,@ override public short   (  )  {  return 1 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\util\OpticalDuplicateFinderTest.java,loc,private  physical location   ( final int tile final int x final int y )  {  final  physical location l = new  physical location int (  )  {  @ override public short get read group (  )  {  return 1 ;   }   }   ;  l . set tile (  ( short ) tile )  ;  l . setx ( x )  ;  l . sety ( y )  ;  return l ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\util\OpticalDuplicateFinderTest.java,test default regex,"@ test public void   (  )  {  final  string read name1 = ""000000000 - zzzzz:1:1105:17981:23325"" ;  final  string read name2 = ""000000000 - zzzzz:1:1109:22981:17995"" ;  final int[] tokens = new int[3] ;   assert . assert equals (  read name parser . get la"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\util\OpticalDuplicateFinderTest.java,test keeper,@ test public void   (  )  {  final  log log =  log . get instance (  optical duplicate finder test . class )  ;  final  optical duplicate finder finder = new  optical duplicate finder (  optical duplicate finder . default   read   name   regex 100 log ) 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\util\OpticalDuplicateFinderTest.java,test keeper at end within clique of all optical duplicates,@ test public void   (  )  {  final  log log =  log . get instance (  optical duplicate finder test . class )  ;  final  optical duplicate finder finder = new  optical duplicate finder (  optical duplicate finder . default   read   name   regex 15 log )  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\util\OpticalDuplicateFinderTest.java,test keeper not in list,@ test public void   (  )  {  final  log log =  log . get instance (  optical duplicate finder test . class )  ;  final  optical duplicate finder finder = new  optical duplicate finder (  optical duplicate finder . default   read   name   regex 100 log ) 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\util\OpticalDuplicateFinderTest.java,test max set size,@ test public void   (  )  {  final  log log =  log . get instance (  optical duplicate finder test . class )  ;   list <  physical location >  locs =  arrays . as list ( loc ( 7 1500 1500 )  loc ( 7 1501 1501 )  loc ( 7 1490 1502 )  )  ;  final  optical 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\util\OpticalDuplicateFinderTest.java,test very long read names,"@ test public void   (  )  {  final  string read name1 = ""m01234:123:000000000 - zzzzz:1:1105:17981:23325"" ;  final  string read name2 = ""m01234:123:000000000 - zzzzz:1:1109:22981:17995"" ;  final int[] tokens = new int[3] ;   assert . assert equals (  rea"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigarTester.java, umi aware mark duplicates with mate cigar tester,"  ( final boolean allow missing umis )  {  add arg ( ""umi   metrics   file = ""  +  umi metrics file )  ;  if  ( allow missing umis )   {  add arg ( ""allow   missing   umis = ""  +  true )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigarTester.java,add mate pair with umi,"public void   ( final  string read name final int reference sequence index1 final int reference sequence index2 final int alignment start1 final int alignment start2 final boolean record1 unmapped final boolean record2 unmapped final boolean is duplicate1 final boolean is duplicate2 final  string cigar1 final  string cigar2 final boolean strand1 final boolean strand2 final boolean first only final boolean record1 non primary final boolean record2 non primary final int default quality final  string umi final  string assignedumi )  {  final  list < sam record >  sam record list = sam record set builder . add pair ( read name reference sequence index1 reference sequence index2 alignment start1 alignment start2 record1 unmapped record2 unmapped cigar1 cigar2 strand1 strand2 record1 non primary record2 non primary default quality )  ;  final sam record record1 = sam record list . get ( 0 )  ;  final sam record record2 = sam record list . get ( 1 )  ;  if  ( this . no mate cigars )   {  record1 . set attribute ( ""mc"" null )  ;  record2 . set attribute ( ""mc"" null )  ;   }  if  ( first only )   {  sam record set builder . get records (  )  . remove ( record2 )  ;   }  final  string key1 = sam record to duplicates flags key ( record1 )  ;   assert . assert false ( this . duplicate flags . contains key ( key1 )  )  ;  this . duplicate flags . put ( key1 is duplicate1 )  ;  final  string key2 = sam record to duplicates flags key ( record2 )  ;   assert . assert false ( this . duplicate flags . contains key ( key2 )  )  ;  this . duplicate flags . put ( key2 is duplicate2 )  ;  if  ( umi  !  =  null )   {  record1 . set attribute ( ""rx"" umi )  ;  record2 . set attribute ( ""rx"" umi )  ;   }  if  ( assignedumi  !  =  null )   {  record1 . set attribute ( expected umi tag assignedumi )  ;  record2 . set attribute ( expected umi tag assignedumi )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigarTester.java,get program,@ override protected  command line program   (  )  {   umi aware mark duplicates with mate cigar uamdwmc = new  umi aware mark duplicates with mate cigar (  )  ;  return uamdwmc ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigarTester.java,set expected assigned umis, umi aware mark duplicates with mate cigar tester   ( final  list <  string >  expected assigned umis )  {  this . expected assigned umis = expected assigned umis ;  return this ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigarTester.java,set expected metrics, umi aware mark duplicates with mate cigar tester   ( final  umi metrics expected metrics )  {  this . expected metrics = expected metrics ;  return this ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigarTester.java,test,@ override public void   (  )  {  final  sam reader reader =  sam reader factory . make default (  )  . open ( get output (  )  )  ;  for  (  final sam record record : reader )   {  if  ( expected assigned umis  !  =  null )   {   assert . assert equals (
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigarTest.java,get tester,protected  umi aware mark duplicates with mate cigar tester   ( final boolean allow missing umis )  {  return new  umi aware mark duplicates with mate cigar tester ( allow missing umis )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigarTest.java,test bad umi sets data provider,"@ data provider ( name = "" "" )  private  object[][] test bad umi sets data provider (  )  {  return new  object[][] {  {  arrays . as list ( new  string[] { ""aaaa"" ""a"" }  )   arrays . as list ( new  string[] { ""aaaa"" ""a"" }  )   arrays . as list ( new  boo"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigarTest.java,test bad umis,"@ test ( data provider = ""test bad umi sets data provider"" expected exceptions =  {  illegal argument exception . class  picard exception . class }  )  public void   (  list <  string >  umis  list <  string >  assigned umi final  list <  boolean >  is du"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigarTest.java,test empty umi data provider,"@ data provider ( name = "" "" )  private  object[][] test empty umi data provider (  )  {  return new  object[][] {  {  arrays . as list ( new  string[] { null null null }  )   arrays . as list ( new  string[] { null null null }  )   arrays . as list ( new"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigarTest.java,test empty umis,"@ test ( data provider = ""test empty umi data provider"" )  public void   (  list <  string >  umis  list <  string >  assigned umi final  list <  boolean >  is duplicate final int edit distance to join )  {   umi aware mark duplicates with mate cigar test"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigarTest.java,test umi,"@ test ( data provider = ""  sets data provider"" )  public void test umi (  list <  string >  umis  list <  string >  assigned umi final  list <  boolean >  is duplicate final int edit distance to join )  {   umi aware mark duplicates with mate cigar teste"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigarTest.java,test umi metrics,"@ test ( data provider = ""  data provider"" )  public void test umi metrics (  list <  string >  umis  list <  string >  assigned umi final  list <  boolean >  is duplicate final int edit distance to join final  umi metrics expected metrics )  {   umi awar"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigarTest.java,test umi metrics data provider,"@ data provider ( name = "" "" )  private  object[][] test umi metrics data provider (  )  {  double effective length4   1 =  -  ( 4 .   /  5 .  )  *  math . log ( 4 .   /  5 .  )   /   math . log ( 4 .  )   -   ( 1 .   /  5 .  )  *  math . log ( 1 .   /  5"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigarTest.java,test umi sets data provider,"@ data provider ( name = "" "" )  private  object[][] test umi sets data provider (  )  {  return new  object[][] {  {  arrays . as list ( new  string[] { ""aaaa"" ""aaaa"" ""atta"" ""aaaa"" ""aaat"" }  )   arrays . as list ( new  string[] { ""aaaa"" ""aaaa"" ""atta"" ""aaa"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigarTest.java,test umi util,"@ test ( data provider = ""  data provider"" )  public void test umi util (  list <  string >  observed  list <  string >  expected )  {  for  ( int i = 0 ;  i  <  observed . size (  )  ;  i +  +  )   {  sam record rec = new sam record ( new sam file header"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\markduplicates\UmiAwareMarkDuplicatesWithMateCigarTest.java,test umi util data provider,"@ data provider ( name = "" "" )  private  object[][] test umi util data provider (  )  {  return new  object[][] {  {  arrays . as list ( new  string[] { ""aaaa"" ""aa - aa"" "" - a - t - a"" ""aaaaa -  - "" "" -  -  - a"" "" -  -  - "" """" }  )   arrays . as list ( ne"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\PipedDataTest.java,test sort sam,"@ test public void   (  )  {   string[] command =  { "" / bin / bash"" "" - c"" ""java  - classpath ""  +  class path  +  ""picard . cmdline .  picard command line "" +  "" view sam "" +  ""i = testdata / picard / sam / test . bam "" +  ""alignment   status =  all "" +"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeSamFilesTest.java,get command line program name,public  string   (  )  {  return  merge sam files . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeSamFilesTest.java,unsorted input sorted output test,"@ test public void   (  )  throws  exception  {  final  file unsorted input test data dir = new  file ( test   data   dir ""unsorted   input"" )  ;  final  file merged output =  file . create temp file ( ""unsorted input sorted output test . ""  bam file io u"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\PositionBasedDownsampleSamTest.java, invalid arguments test provider,"@ data provider ( name = "" "" )  public  object[][]  invalid arguments test provider (  )  {  return new  object[][] {  {  - 1 . 0 }   {  -  . 00001 }   {  - 5 . 0 }   { 1 . 00001 }   { 5 . 0 }   { 50 . 0 }   {  double . max   value }   {  double . positiv"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\PositionBasedDownsampleSamTest.java, test builder,@ test public void   (  )  {  final  validate sam file validate sam file = new  validate sam file (  )  ;  validate sam file . input = temp sam file ;   assert . assert equals ( validate sam file . do work (  )  0 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\PositionBasedDownsampleSamTest.java, test invalid arguments,"@ test ( data provider = "" invalid arguments test provider"" )  public void   ( final double fraction )  throws io exception  {  final  file sam file = temp sam file ;  final  file downsampled =  file . create temp file ( "" positional downsample sam"" "" . b"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\PositionBasedDownsampleSamTest.java, test invalid twice,"@ test ( data provider = ""allow twice data"" )  public void   ( final boolean allow multiple )  throws io exception  {  final  file sam file = temp sam file ;  final  file downsampled =  file . create temp file ( "" positional downsample sam"" "" . bam"" temp "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\PositionBasedDownsampleSamTest.java, valid arguments test provider,"@ data provider ( name = "" "" )  public  object[][]  valid arguments test provider (  )  {  final  list <  object[] >  objects = new  array list <  object[] >  (  )  ;  for  ( double i = 0 . 3 ;  i  <  =  1 ;  i +  =  . 1 )   {  final  object[] array =  { "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\PositionBasedDownsampleSamTest.java,allow twice data,"@ data provider ( name = "" "" )  public  object[][] allow twice data (  )  {  return new  object[][] {  { true }   { false }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\PositionBasedDownsampleSamTest.java,get command line program name,@ override public  string   (  )  {  return  position based downsample sam . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\PositionBasedDownsampleSamTest.java,setup builder,"@ before test void   (  )  throws io exception  {  final int num reads = 10000 ;  final  string flow cell barcode = ""testbarcode"" ;  final int maxx = 10000 ;  final int maxy = 20000 ;  final int minx = 1000 ;  final int miny = 2000 ;  final  string separa"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\PositionBasedDownsampleSamTest.java,tear down,@ after test private void   (  )  {  io util . delete directory tree ( temp dir )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\PositionBasedDownsampleSamTest.java,test downsample single tile,"@ test ( data provider = "" valid arguments test provider"" )  public void   ( final double fraction )  throws io exception  {  test downsample worker ( temp sam file fraction )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\PositionBasedDownsampleSamTest.java,test downsample worker,"public void   ( final  file sam file final double fraction )  throws io exception  {  final  file downsampled =  file . create temp file ( "" positional downsample sam"" "" . bam"" temp dir )  ;  final  string[] args = new  string[] { ""input = ""  +  sam file . get absolute path (  )  ""output = ""  +  downsampled . get absolute path (  )  ""fraction = ""  +  fraction ""create   index = true"" }  ;   assert . assert equals ( run picard command line ( args )  0 )  ;  final  validate sam file validate sam file = new  validate sam file (  )  ;  validate sam file . input = downsampled ;   assert . assert equals ( validate sam file . do work (  )  0 )  ;   testng util . assert greater than (  sam test util . count sam total record ( downsampled )  fraction *  . 8 *  sam test util . count sam total record ( sam file )  )  ;   testng util . assert less than (  sam test util . count sam total record ( downsampled )  fraction * 1 . 2 *  sam test util . count sam total record ( sam file )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java, alignment accumulator,private   ( final boolean seen unaligned final int num alignments final  string primary alignment sequence )  {  this . seen unaligned = seen unaligned ;  this . num alignments = num alignments ;  this . primary alignment sequence = primary alignment sequence ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java, hit spec,  ( final boolean primary final boolean filtered final int mapq )  {  this . primary = primary ;  this . filtered = filtered ;  this . mapq = mapq ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java, most distant strategy alignment spec,private   ( final boolean expected primary final  string sequence final int alignment start )  {  this ( expected primary sequence alignment start 10 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java, multiple alignment spec,  ( final  string cigar final boolean reverse strand final int mapq final boolean one of the best )  {  this . cigar = cigar ;  this . reverse strand = reverse strand ;  this . mapq = mapq ;  this . one of the best = one of the best ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java, unmapped read strategies provider,"@ data provider ( name = "" unmapped read strategies"" )  public  object[][]   (  )  {  return new  object[][] {  {  abstract alignment merger .  unmapping read strategy . do   not   change ""contam . expected . no   change . sam"" }   { null ""contam . expect"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,add alignment for most strategy,"private void   ( final sam file writer writer final sam record unmapped record final  most distant strategy alignment spec spec final boolean reverse )  {  final sam record aligned record = new sam record ( writer . get file header (  )  )  ;  aligned record . set read name ( unmapped record . get read name (  )  )  ;  aligned record . set read bases ( unmapped record . get read bases (  )  )  ;  aligned record . set base qualities ( unmapped record . get base qualities (  )  )  ;  aligned record . set reference name ( spec . sequence )  ;  aligned record . set alignment start ( spec . alignment start )  ;  aligned record . set read negative strand flag ( reverse )  ;  aligned record . set cigar string ( unmapped record . get read bases (  )  . length  +  ""m"" )  ;  aligned record . set mapping quality ( spec . mapq )  ;  aligned record . set read paired flag ( unmapped record . get read paired flag (  )  )  ;  aligned record . set first of pair flag ( unmapped record . get first of pair flag (  )  )  ;  aligned record . set second of pair flag ( unmapped record . get second of pair flag (  )  )  ;  aligned record . set mate unmapped flag ( true )  ;  writer . add alignment ( aligned record )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,add alignments for best fragment mapq strategy,"private void   ( final sam file writer writer final sam record unmapped record final  string sequence final int[] mapqs )  {  boolean reverse = false ;  int alignment start = 1 ;  for  (  final int mapq : mapqs )   {  final sam record aligned record = new sam record ( writer . get file header (  )  )  ;  aligned record . set read name ( unmapped record . get read name (  )  )  ;  aligned record . set read bases ( unmapped record . get read bases (  )  )  ;  aligned record . set base qualities ( unmapped record . get base qualities (  )  )  ;  aligned record . set reference name ( sequence )  ;  aligned record . set alignment start ( alignment start )  ;  alignment start +  = 10 ;  aligned record . set read negative strand flag ( reverse )  ;  reverse =  ! reverse ;  aligned record . set cigar string ( unmapped record . get read bases (  )  . length  +  ""m"" )  ;  aligned record . set mapping quality ( mapq )  ;  aligned record . set read paired flag ( unmapped record . get read paired flag (  )  )  ;  aligned record . set first of pair flag ( unmapped record . get first of pair flag (  )  )  ;  aligned record . set second of pair flag ( unmapped record . get second of pair flag (  )  )  ;  aligned record . set mate unmapped flag ( true )  ;  writer . add alignment ( aligned record )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,assert sam valid,private void   ( final  file sam )  {  new  validate sam tester (  )  . assert sam valid ( sam )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,broken aligned files,"@ data provider ( name = "" "" )   object[][] broken aligned files (  )  {  return new  object[][] { new  object[] { ""special header . aligned . breaks . length . sam"" }  new  object[] { ""special header . aligned . breaks . md5 . sam"" }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,create sam files to be merged,"private  file[]   ( final  multiple alignment spec[] specs )  {  try  {  final  file unmapped sam =  file . create temp file ( ""unmapped . "" "" . sam"" )  ;  unmapped sam . delete on exit (  )  ;  final sam file writer factory factory = new sam file writer factory (  )  ;  final sam file header header = new sam file header (  )  ;  header . set sort order ( sam file header .  sort order . queryname )  ;  final sam record unmapped record = new sam record ( header )  ;  unmapped record . set read name ( ""the read"" )  ;  unmapped record . set read string ( ""acgtacgtacgtacgt"" )  ;  unmapped record . set base quality string ( ""5555555555555555"" )  ;  unmapped record . set read unmapped flag ( true )  ;  final sam file writer unmapped writer = factory . makesam writer ( header false unmapped sam )  ;  unmapped writer . add alignment ( unmapped record )  ;  unmapped writer . close (  )  ;  final  file aligned sam =  file . create temp file ( ""aligned . "" "" . sam"" )  ;  aligned sam . delete on exit (  )  ;  final  string sequence = ""chr1"" ;  header . set sequence dictionary ( sam sequence dictionary extractor . extract dictionary ( sequence dict2 . to path (  )  )  )  ;  final sam file writer aligned writer = factory . makesam writer ( header false aligned sam )  ;  for  (  final  multiple alignment spec spec : specs )   {  final sam record aligned record = new sam record ( header )  ;  aligned record . set read name ( unmapped record . get read name (  )  )  ;  aligned record . set read bases ( unmapped record . get read bases (  )  )  ;  aligned record . set base qualities ( unmapped record . get base qualities (  )  )  ;  aligned record . set reference name ( sequence )  ;  aligned record . set alignment start ( 1 )  ;  aligned record . set read negative strand flag ( spec . reverse strand )  ;  aligned record . set cigar string ( spec . cigar )  ;  aligned record . set mapping quality ( spec . mapq )  ;  if  ( spec . one of the best )   {  aligned record . set attribute ( one   of   the   best   tag 1 )  ;   }  aligned writer . add alignment ( aligned record )  ;   }  aligned writer . close (  )  ;  return new  file[] { unmapped sam aligned sam }  ;   }  catch  (  io exception e )   {  throw new  picard exception ( e . get message (  )  e )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,do merge alignment,"private void   ( final  file unmapped bam final  list <  file >  aligned bams final  list <  file >  read1 aligned bams final  list <  file >  read2 aligned bams final  integer read1 trim final  integer read2 trim final boolean align reads only final boolean clip adapters final boolean is bisulfite sequence final int max ins or dels final  string prog record id final  string prog group version final  string prog group command line final  string prog group name final boolean paired run final  file ref seq final  file output final  sam pair util .  pair orientation expected orientation final  merge bam alignment .  primary alignment strategy primary alignment strategy final  string attributes to retain final  boolean include secondary final  boolean unmap contaminant reads final sam file header .  sort order sort order final  abstract alignment merger .  unmapping read strategy unmapping read strategy )  {  final  list <  string >  tags to rc = new  array list <  >  ( sam record . tags   to   reverse   complement )  ;  final  list <  string >  tags to rev = new  array list <  >  ( sam record . tags   to   reverse )  ;  tags to rc . add ( ""ab"" )  ;  tags to rev . add all (  arrays . as list ( ""aa"" ""ac"" ""as"" ""ai"" ""af"" )  )  ;  final  list <  string >  args = new  array list <  >  (  arrays . as list ( ""unmapped   bam = ""  +  unmapped bam . get absolute path (  )  ""aligned   reads   only = ""  +  align reads only ""clip   adapters = ""  +  clip adapters ""is   bisulfite   sequence = ""  +  is bisulfite sequence ""max   insertions   or   deletions = ""  +  max ins or dels ""add   pg   tag   to   reads = true"" )  )  ;  if  ( aligned bams  !  =  null )   {  for  (  final  file aligned bam : aligned bams )   {  args . add ( ""aligned   bam = ""  +  aligned bam . get absolute path (  )  )  ;   }   }  if  ( read1 aligned bams  !  =  null )   {  for  (  final  file aligned bam : read1 aligned bams )   {  args . add ( ""read1   aligned   bam = ""  +  aligned bam . get absolute path (  )  )  ;   }   }  if  ( read2 aligned bams  !  =  null )   {  for  (  final  file aligned bam : read2 aligned bams )   {  args . add ( ""read2   aligned   bam = ""  +  aligned bam . get absolute path (  )  )  ;   }   }  if  ( read1 trim  !  =  null )   {  args . add ( ""read1   trim = ""  +  read1 trim )  ;   }  if  ( read2 trim  !  =  null )   {  args . add ( ""read2   trim = ""  +  read2 trim )  ;   }  if  ( prog record id  !  =  null )   {  args . add ( ""program   record   id = ""  +  prog record id )  ;   }  if  ( prog group version  !  =  null )   {  args . add ( ""program   group   version = ""  +  prog group version )  ;   }  if  ( prog group command line  !  =  null )   {  args . add ( ""program   group   command   line = ""  +  prog group command line )  ;   }  if  ( prog group name  !  =  null )   {  args . add ( ""program   group   name = ""  +  prog group name )  ;   }  args . add ( ""paired   run = ""  +  paired run )  ;  args . add ( ""reference   sequence = ""  +  ref seq . get absolute path (  )  )  ;  args . add ( ""output = ""  +  output . get absolute path (  )  )  ;  if  ( expected orientation  !  =  null )   {  args . add ( ""expected   orientations = ""  +  expected orientation )  ;   }  if  ( primary alignment strategy  !  =  null )   {  args . add ( ""primary   alignment   strategy = ""  +  primary alignment strategy )  ;   }  if  ( attributes to retain  !  =  null )   {  args . add ( ""attributes   to   retain = ""  +  attributes to retain )  ;   }  for  (  final  string t : tags to rc )   {  args . add ( ""attributes   to   reverse   complement = ""  +  t )  ;   }  for  (  final  string t : tags to rev )   {  args . add ( ""attributes   to   reverse = ""  +  t )  ;   }  if  ( include secondary  !  =  null )   {  args . add ( ""include   secondary   alignments = ""  +  include secondary )  ;   }  if  ( unmap contaminant reads  !  =  null )   {  args . add ( ""unmap   contaminant   reads = ""  +  unmap contaminant reads )  ;   }  if  ( unmapping read strategy  !  =  null )   {  args . add ( ""unmapped   read   strategy = ""  +  unmapping read strategy )  ;   }  if  ( sort order  !  =  null )   {  args . add ( ""sort   order = ""  +  sort order . name (  )  )  ;   }   assert . assert equals ( run picard command line ( args )  0 "" merge did not succeed"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,equals,public boolean   ( final  object o )  {  if  ( this  =  =  o )  return true ;  if  ( o  =  =  null || get class (  )   !  =  o . get class (  )  )  return false ;  final  alignment accumulator that =  (  alignment accumulator ) o ;  if  ( num alignments  !  =  that . num alignments )  return false ;  if  ( seen unaligned  !  =  that . seen unaligned )  return false ;  if  ( primary alignment sequence  !  =  null  ?   ! primary alignment sequence . equals ( that . primary alignment sequence )  : that . primary alignment sequence  !  =  null )  return false ;  return true ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,get command line program name,public  string   (  )  {  return  merge bam alignment . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,get data for merging test,"@ data provider ( name = ""separate trimmed"" )  public  object[][]   (  )  {  return new  object[][] {  { merging unmapped bam  arrays . as list ( first read aligned bam )   arrays . as list ( second read aligned bam )  17 20 ""one file per read"" }   { merg"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,get data for sorting test,"@ data provider ( name = ""data"" )  public  object[][]   (  )  {  return new  object[][] {  { unmapped bam aligned queryname sorted bam true true "" basic test with pre - sorted alignment"" }   { unmapped bam aligned bam false true "" basic test with unsorted"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,hash code,@ override public int   (  )  {  int result =  ( seen unaligned  ?  1 : 0 )  ;  result = 31 * result  +  num alignments ;  result = 31 * result  +   ( primary alignment sequence  !  =  null  ?  primary alignment sequence . hash code (  )  : 0 )  ;  return
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,make read,private sam record   ( final sam file header aligned header final sam record unmapped rec final  hit spec hit spec final int hit index )  {  final sam record rec = new sam record ( aligned header )  ;  rec . set read name ( unmapped rec . get read name (  )  )  ;  rec . set read bases ( unmapped rec . get read bases (  )  )  ;  rec . set base qualities ( unmapped rec . get base qualities (  )  )  ;  rec . set mapping quality ( hit spec . mapq )  ;  if  (  ! hit spec . primary )  rec . set not primary alignment flag ( true )  ;  final  cigar cigar = new  cigar (  )  ;  final int read length = rec . get read length (  )  ;  if  ( hit spec . filtered )   {  cigar . add ( new  cigar element ( read length  -  4  cigar operator . m )  )  ;  cigar . add ( new  cigar element ( 1  cigar operator . i )  )  ;  cigar . add ( new  cigar element ( 1  cigar operator . m )  )  ;  cigar . add ( new  cigar element ( 1  cigar operator . i )  )  ;  cigar . add ( new  cigar element ( 1  cigar operator . m )  )  ;   }  else  {  cigar . add ( new  cigar element ( read length  cigar operator . m )  )  ;   }  rec . set cigar ( cigar )  ;  rec . set reference name ( big sequence name )  ;  rec . set attribute ( sam tag . hi . name (  )  hit index )  ;  rec . set alignment start ( hit index  +  1 )  ;  return rec ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test best fragment mapq strategy,"private void   ( final  string test name final int[] first map qs final int[] second map qs final boolean include secondary final int expected first mapq final int expected second mapq )  throws  exception  {  final  file unmapped sam =  file . create temp file ( ""unmapped . "" "" . sam"" )  ;  unmapped sam . delete on exit (  )  ;  final sam file writer factory factory = new sam file writer factory (  )  ;  final sam file header header = new sam file header (  )  ;  header . set sort order ( sam file header .  sort order . queryname )  ;  final  string read name = ""the read"" ;  final sam record first unmapped read = new sam record ( header )  ;  first unmapped read . set read name ( read name )  ;  first unmapped read . set read string ( ""acgtacgtacgtacgt"" )  ;  first unmapped read . set base quality string ( ""5555555555555555"" )  ;  first unmapped read . set read unmapped flag ( true )  ;  first unmapped read . set mate unmapped flag ( true )  ;  first unmapped read . set read paired flag ( true )  ;  first unmapped read . set first of pair flag ( true )  ;  final sam record second unmapped read = new sam record ( header )  ;  second unmapped read . set read name ( read name )  ;  second unmapped read . set read string ( ""tcgaacgttcgaactg"" )  ;  second unmapped read . set base quality string ( ""6666666666666666"" )  ;  second unmapped read . set read unmapped flag ( true )  ;  second unmapped read . set mate unmapped flag ( true )  ;  second unmapped read . set read paired flag ( true )  ;  second unmapped read . set second of pair flag ( true )  ;  final sam file writer unmapped writer = factory . makesam writer ( header false unmapped sam )  ;  unmapped writer . add alignment ( first unmapped read )  ;  unmapped writer . add alignment ( second unmapped read )  ;  unmapped writer . close (  )  ;  final  file aligned sam =  file . create temp file ( ""aligned . "" "" . sam"" )  ;  aligned sam . delete on exit (  )  ;  final  string sequence = ""chr1"" ;  header . set sequence dictionary ( sam sequence dictionary extractor . extract dictionary ( sequence dict2 . to path (  )  )  )  ;  final sam file writer aligned writer = factory . makesam writer ( header false aligned sam )  ;  add alignments for best fragment mapq strategy ( aligned writer first unmapped read sequence first map qs )  ;  add alignments for best fragment mapq strategy ( aligned writer second unmapped read sequence second map qs )  ;  aligned writer . close (  )  ;  final  file output =  file . create temp file ( ""test best fragment mapq strategy . ""  +  test name "" . sam"" )  ;  output . delete on exit (  )  ;  do merge alignment ( unmapped sam  collections . singleton list ( aligned sam )  null null null null false true false 1 ""0"" ""1 . 0"" ""align ! "" ""my aligner"" true fasta output  sam pair util .  pair orientation . fr  merge bam alignment .  primary alignment strategy .  best end mapq null include secondary null null )  ;  final  sam reader reader =  sam reader factory . make default (  )  . open ( output )  ;  int num first records = 0 ;  int num second records = 0 ;  int first primary mapq =  - 1 ;  int second primary mapq =  - 1 ;  for  (  final sam record rec : reader )   {   assert . assert true ( rec . get read paired flag (  )  )  ;  if  ( rec . get first of pair flag (  )  )   +  + num first records ;  else if  ( rec . get second of pair flag (  )  )   +  + num second records ;  else  assert . fail ( ""unpossible ! "" )  ;  if  (  ! rec . get read unmapped flag (  )  &&  ! rec . get not primary alignment flag (  )  )   {  if  ( rec . get first of pair flag (  )  )   {   assert . assert equals ( first primary mapq  - 1 )  ;  first primary mapq = rec . get mapping quality (  )  ;   }  else  {   assert . assert equals ( second primary mapq  - 1 )  ;  second primary mapq = rec . get mapping quality (  )  ;   }   }  else if  ( rec . get not primary alignment flag (  )  )   {   assert . assert true ( rec . get mate unmapped flag (  )  )  ;   }   }  reader . close (  )  ;   assert . assert equals ( first primary mapq expected first mapq )  ;   assert . assert equals ( second primary mapq expected second mapq )  ;  if  (  ! include secondary )   {   assert . assert equals ( num first records 1 )  ;   assert . assert equals ( num second records 1 )  ;   }  else  {   assert . assert equals ( num first records  math . max ( 1 first map qs . length )  )  ;   assert . assert equals ( num second records  math . max ( 1 second map qs . length )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test best fragment mapq strategy data provider,"@ data provider ( name = ""test best fragment mapq strategy"" )  public  object[][]   (  )  {  return new  object[][] {  { ""single alignment first end"" new int[] { 12 }  new int[0] 12  - 1 }   { ""single alignment second end"" new int[0] new int[] { 12 }   - "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test contamination detection,"@ test ( data provider = "" unmapped read strategies"" )  public void   ( final  abstract alignment merger .  unmapping read strategy strategy final  string basename )  throws io exception  {  final  file unmapped sam = new  file ( test   data   dir ""contam"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test earliest fragment strategy,"@ test ( data provider = ""  data provider"" )  public void test earliest fragment strategy ( final  string test name final  multiple alignment spec[] specs )  throws io exception  {  final  file output =  file . create temp file ( test name "" . sam"" )  ;  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test earliest fragment strategy data provider,"@ data provider ( name = "" "" )  public  object[][] test earliest fragment strategy data provider (  )  {  return new  object[][] {  { ""simple forward"" new  multiple alignment spec[] { new  multiple alignment spec ( ""16m"" false 200 true )  }  }   { ""simple"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test earliest fragment strategy paired,"@ test ( expected exceptions =  unsupported operation exception . class )  public void   (  )  throws  exception  {  final  file output =  file . create temp file ( ""merge test"" "" . sam"" )  ;  output . delete on exit (  )  ;  final  file unmapped sam =  f"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test fragment multi hit with filtering,"@ test ( data provider = ""  test cases"" )  public void test fragment multi hit with filtering ( final  string description final  list <  hit spec >  hit specs final  integer expected primary hit index final int expected num reads final int expected primar"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test fragment multi hit with filtering test cases,"@ data provider ( name = "" "" )  public  object[][] test fragment multi hit with filtering test cases (  )  {  final  array list <  object[] >  ret = new  array list <  object[] >  (  )  ;   list <  hit spec >  hit specs ;  hit specs = new  array list <  h"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test header from mapped breaks,"@ test ( data provider = ""broken aligned files"" expected exceptions =  illegal argument exception . class )  public void   ( final  string filename )  throws io exception  {  final  file unmapped sam = new  file ( test   data   dir ""special header . unmap"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test mapped to multiple strands,"@ test public void   (  )  throws  exception  {  final  file output mapped to multiple stands =  file . create temp file ( ""mapped to multiple strands"" "" . sam"" )  ;  output mapped to multiple stands . delete on exit (  )  ;  do merge alignment ( merging "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test merge header mapped and reference,"@ test public void   (  )  throws io exception  {  final  file unmapped sam = new  file ( test   data   dir ""special header . unmapped . sam"" )  ;  final  file aligned sam = new  file ( test   data   dir ""special header . aligned . sam"" )  ;  final  file "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test merge header mapped and reference with aligned as named stream,"@ test public void   (  )  throws io exception   interrupted exception   no such field exception   illegal access exception  {  final  file unmapped sam = new  file ( test   data   dir ""special header . unmapped . sam"" )  ;  final  file aligned sam = new "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test merge header mapped and reference with unmapped as named stream,"@ test public void   (  )  throws io exception   interrupted exception   no such field exception   illegal access exception  {  final  file unmapped sam = new  file ( test   data   dir ""special header . unmapped . sam"" )  ;  final  file aligned sam = new "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test merger,"@ test public void   (  )  throws  exception  {  final  file output =  file . create temp file ( ""merge test"" "" . sam"" )  ;  output . delete on exit (  )  ;  do merge alignment ( unmapped bam  collections . singleton list ( aligned bam )  null null null n"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test merger from multiple files,"@ test public void   (  )  throws  exception  {  final  file output =  file . create temp file ( ""merge test"" "" . sam"" )  ;  output . delete on exit (  )  ;  do merge alignment ( unmapped bam  arrays . as list ( one half aligned bam other half aligned bam"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test merger with supplemental,"@ test public void   (  )  throws  exception  {  final  file output with supplemental =  file . create temp file ( ""merge with supplemental test"" "" . sam"" )  ;  output with supplemental . delete on exit (  )  ;  do merge alignment ( unmapped bam  collecti"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test merging from separated read trimmed alignments,"@ test ( data provider = ""separate trimmed"" )  public void   ( final  file unmapped final  list <  file >  r1 align final  list <  file >  r2 align final int r1 trim final int r2 trim final  string test name )  throws  exception  {  final  file output =  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test most distant strategy,"public void   ( final  string test name final boolean include secondary final  most distant strategy alignment spec[] first end specs final  most distant strategy alignment spec[] second end specs )  throws  exception  {  final  file unmapped sam =  file . create temp file ( ""unmapped . "" "" . sam"" )  ;  unmapped sam . delete on exit (  )  ;  final sam file writer factory factory = new sam file writer factory (  )  ;  final sam file header header = new sam file header (  )  ;  header . set sort order ( sam file header .  sort order . queryname )  ;  final  string read name = ""the read"" ;  final sam record first unmapped read = new sam record ( header )  ;  first unmapped read . set read name ( read name )  ;  first unmapped read . set read string ( ""acgt"" )  ;  first unmapped read . set base quality string ( ""5555"" )  ;  first unmapped read . set read unmapped flag ( true )  ;  first unmapped read . set mate unmapped flag ( true )  ;  first unmapped read . set read paired flag ( true )  ;  first unmapped read . set first of pair flag ( true )  ;  final sam record second unmapped read = new sam record ( header )  ;  second unmapped read . set read name ( read name )  ;  second unmapped read . set read string ( ""tcga"" )  ;  second unmapped read . set base quality string ( ""6666"" )  ;  second unmapped read . set read unmapped flag ( true )  ;  second unmapped read . set mate unmapped flag ( true )  ;  second unmapped read . set read paired flag ( true )  ;  second unmapped read . set second of pair flag ( true )  ;  final sam file writer unmapped writer = factory . makesam writer ( header false unmapped sam )  ;  unmapped writer . add alignment ( first unmapped read )  ;  unmapped writer . add alignment ( second unmapped read )  ;  unmapped writer . close (  )  ;  final  file aligned sam =  file . create temp file ( ""aligned . "" "" . sam"" )  ;  aligned sam . delete on exit (  )  ;  header . set sequence dictionary (  sam reader factory . make default (  )  . get file header ( sequence dict )  . get sequence dictionary (  )  )  ;  final sam file writer aligned writer = factory . makesam writer ( header false aligned sam )  ;   string expected first primary sequence = null ;  int expected first primary alignment start =  - 1 ;   string expected second primary sequence = null ;  int expected second primary alignment start =  - 1 ;  boolean reverse = false ;  for  (  final  most distant strategy alignment spec spec : first end specs )   {  add alignment for most strategy ( aligned writer first unmapped read spec reverse )  ;  reverse =  ! reverse ;  if  ( spec . expected primary )   {  expected first primary sequence = spec . sequence ;  expected first primary alignment start = spec . alignment start ;   }   }  for  (  final  most distant strategy alignment spec spec : second end specs )   {  add alignment for most strategy ( aligned writer second unmapped read spec reverse )  ;  reverse =  ! reverse ;  if  ( spec . expected primary )   {  expected second primary sequence = spec . sequence ;  expected second primary alignment start = spec . alignment start ;   }   }  aligned writer . close (  )  ;  final  file output =  file . create temp file ( ""test most distant strategy . ""  +  test name "" . sam"" )  ;  output . delete on exit (  )  ;  do merge alignment ( unmapped sam  collections . singleton list ( aligned sam )  null null null null false true false 1 ""0"" ""1 . 0"" ""align ! "" ""my aligner"" true fasta output  sam pair util .  pair orientation . fr  merge bam alignment .  primary alignment strategy .  most distant null include secondary null null )  ;  final  sam reader reader =  sam reader factory . make default (  )  . open ( output )  ;  int num first records = 0 ;  int num second records = 0 ;   string first primary sequence = null ;  int first primary alignment start =  - 1 ;   string second primary sequence = null ;  int second primary alignment start =  - 1 ;  for  (  final sam record rec : reader )   {   assert . assert true ( rec . get read paired flag (  )  )  ;  if  ( rec . get first of pair flag (  )  )   +  + num first records ;  else if  ( rec . get second of pair flag (  )  )   +  + num second records ;  else  assert . fail ( ""unpossible ! "" )  ;  if  (  ! rec . get read unmapped flag (  )  &&  ! rec . get not primary alignment flag (  )  )   {  if  ( rec . get first of pair flag (  )  )   {   assert . assert equals ( first primary alignment start  - 1 )  ;  first primary sequence = rec . get reference name (  )  ;  first primary alignment start = rec . get alignment start (  )  ;   }  else  {   assert . assert equals ( second primary alignment start  - 1 )  ;  second primary sequence = rec . get reference name (  )  ;  second primary alignment start = rec . get alignment start (  )  ;   }   }  else if  ( rec . get not primary alignment flag (  )  )   {   assert . assert true ( rec . get mate unmapped flag (  )  )  ;   }   }   closer util . close ( reader )  ;   assert . assert equals ( first primary sequence expected first primary sequence )  ;   assert . assert equals ( first primary alignment start expected first primary alignment start )  ;   assert . assert equals ( second primary sequence expected second primary sequence )  ;   assert . assert equals ( second primary alignment start expected second primary alignment start )  ;  if  (  ! include secondary )   {   assert . assert equals ( num first records 1 )  ;   assert . assert equals ( num second records 1 )  ;   }  else  {   assert . assert equals ( num first records  math . max ( 1 first end specs . length )  )  ;   assert . assert equals ( num second records  math . max ( 1 second end specs . length )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test most distant strategy data provider,"@ data provider ( name = ""test most distant strategy"" )  public  object[][]   (  )  {  return new  object[][] {  { ""multiple alignments both ends"" new  most distant strategy alignment spec[] { new  most distant strategy alignment spec ( false ""chr1"" 1 20 "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test multi hit,"@ test public void   (  )  throws io exception  {  final  file unmapped sam = new  file ( test   data   dir ""multihit . unmapped . sam"" )  ;  final  file aligned sam = new  file ( test   data   dir ""multihit . aligned . sam"" )  ;  final  file merged =  fi"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test old queryname sort fails,"@ test ( expected exceptions =  {  illegal state exception . class  picard exception . class }  )  public void   (  )  throws io exception  {  final  file merged =  file . create temp file ( ""merged""  bam file io utils . bam   file   extension )  ;  merge"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test paired multi hit with filtering,"@ test ( data provider = ""  test cases"" )  public void test paired multi hit with filtering ( final  string description final  list <  hit spec >  first of pair final  list <  hit spec >  second of pair final  integer expected primary hit index final int "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test paired multi hit with filtering test cases,"@ data provider ( name = "" "" )  public  object[][] test paired multi hit with filtering test cases (  )  {  final  array list <  object[] >  ret = new  array list <  object[] >  (  )  ;   list <  hit spec >  first of pair ;   list <  hit spec >  second of"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test remove nm md and uq on overlapping reads,"@ test public void   (  )  throws io exception  {  final  file output =  file . create temp file ( ""test remove nm md and uq on overlapping reads"" "" . sam"" )  ;  output . delete on exit (  )  ;  do merge alignment ( new  file ( test   data   dir ""removeta"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test short fragment clipping,"@ test public void   (  )  throws  exception  {  final  file output =  file . create temp file ( ""test short fragment clipping"" "" . sam"" )  ;  output . delete on exit (  )  ;  do merge alignment ( new  file ( test   data   dir ""cliptest . unmapped . sam"" "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,test sorting on sam alignment merger,"@ test ( data provider = ""data"" )  public void   ( final  file unmapped final  file aligned final boolean sorted final boolean coordinate sorted final  string test name )  throws io exception  {  final  file target =  file . create temp file ( ""target"" ""b"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\MergeBamAlignmentTest.java,to string,"@ override public  string   (  )  {  return "" alignment accumulator { ""  +  ""seen unaligned = ""  +  seen unaligned  +  ""  num alignments = "" +  num alignments +  ""  primary alignment sequence = '"" +  primary alignment sequence +  '\'' +  ' } ' ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamFileConverterTest.java,convert file,"private void   ( final  file input file final  file file to compare final  string extension )  {  final  sam format converter sam format converter = new  sam format converter (  )  ;  final  list <  file >  sam files = new  array list <  file >  (  )  ;  final  validate sam file validate sam file = new  validate sam file (  )  ;  final  comparesa ms comparesa ms = new  comparesa ms (  )  ;  sam format converter . input = input file ;  try  {  sam format converter . output =  file . create temp file ( "" sam file converter test . ""  +  input file . get name (  )  extension )  ;  sam format converter . output . delete on exit (  )  ;   }  catch  (  final io exception e )   {  e . print stack trace (  )  ;   }  sam format converter . do work (  )  ;  validate sam file . input = sam format converter . output ;  assert equals ( validate sam file . do work (  )  0 )  ;  sam files . add ( sam format converter . output )  ;  sam files . add ( file to compare )  ;  comparesa ms . sam files = sam files ;  comparesa ms . do work (  )  ;  assert true ( comparesa ms . are equal (  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamFileConverterTest.java,testbam tocram,"@ test public void   (  )  {  convert file ( unmapped bam unmapped cram "" . cram"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamFileConverterTest.java,testbam tosam,"@ test public void   (  )  {  convert file ( unmapped bam unmapped sam "" . sam"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamFileConverterTest.java,testcram tobam,"@ test public void   (  )  {  convert file ( unmapped cram unmapped bam "" . bam"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamFileConverterTest.java,testcram tosam,"@ test public void   (  )  {  convert file ( unmapped cram unmapped sam "" . sam"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamFileConverterTest.java,testsam tobam,"@ test public void   (  )  {  convert file ( unmapped sam unmapped bam "" . bam"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamFileConverterTest.java,testsam tocram,"@ test public void   (  )  {  convert file ( unmapped sam unmapped cram "" . cram"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,basic positive tests,"@ test ( data provider = ""positive test data"" )  public void   ( final sam file header .  sort order so final boolean remove duplicates final boolean remove alignment info final boolean restore original qualities final boolean output by read group final  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,get command line program name,public  string   (  )  {  return  revert sam . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,get negative test data,"@ data provider ( name = ""override test data"" )  public  object[][]   (  )  {  return new  object[][] {  { "" new sample"" null }   { null "" new library"" }   { "" new sample"" "" new library"" }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,get postitive test data,"@ data provider ( name = ""positive test data"" )  public  object[][]   (  )  {  return new  object[][] {  { null true true true true null null  collections . empty   list }   { sam file header .  sort order . queryname true true true false "" hey  dad ! "" n"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test assert all read groups mapped failure,"@ test ( expected exceptions =  {  picard exception . class }  )  public void   (  )  {  final sam read group record rg1 = new sam read group record ( ""rg1"" )  ;  final sam read group record rg2 = new sam read group record ( ""rg2"" )  ;  final sam read gro"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test assert all read groups mapped success,"@ test public void   (  )  {  final sam read group record rg1 = new sam read group record ( ""rg1"" )  ;  final sam read group record rg2 = new sam read group record ( ""rg2"" )  ;  final  map <  string  file >  output map = new  hash map <  string  file >  ("
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test command line help,"@ test public void   (  )  throws  exception  {  final  file output dir =  files . create temp directory ( ""picard revert sam test"" )  . to file (  )  ;  output dir . delete on exit (  )  ;  final  string args[] = new  string[1] ;  args[0] = "" -  - help"" "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test file paths with map file,"@ test public void   (  )  {  final  map <  string  file >  output map =  revert sam . create output map ( valid output map null "" . bam""  collections . empty list (  )  )  ;   assert . assert equals ( output map . get ( ""rg1"" )  new  file ( "" / path / to"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test file paths without map file,"@ test public void   (  )  {  final sam read group record rg1 = new sam read group record ( ""rg1"" )  ;  final sam read group record rg2 = new sam read group record ( ""rg2"" )  ;  final  map <  string  file >  output map =  revert sam . create output map ( "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test get default extension,"@ test public void   (  )  {   assert . assert equals (  revert sam . get default extension ( ""this . is . a . sam"" )  "" . sam"" )  ;   assert . assert equals (  revert sam . get default extension ( ""this . is . a . cram"" )  "" . cram"" )  ;   assert . asser"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test is output map header valid,"@ test public void   (  )  {  boolean is valid =  revert sam .  validation util . is output map header valid (  arrays . as list ( ""read   group   id"" ""output"" )  )  ;   assert . assert equals ( is valid true )  ;  is valid =  revert sam .  validation uti"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test mutex output map vs output,"@ test public void   (  )  throws  exception  {  final  file output dir =  files . create temp directory ( ""picard revert sam test"" )  . to file (  )  ;  output dir . delete on exit (  )  ;  final  string args[] = new  string[4] ;  int index = 0 ;  args[i"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test no input,"@ test public void   (  )  throws  exception  {  final  file output dir =  files . create temp directory ( ""picard revert sam test"" )  . to file (  )  ;  output dir . delete on exit (  )  ;  final  string args[] = new  string[0] ;  try  {  final int retur"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test no rg info output by rg,"@ test ( expected exceptions =  picard exception . class )  public void   (  )  {  final  string[] args = new  string[] { ""i = testdata / picard / sam / bam2fastq / paired / bad / missing - rg - info . sam"" ""output   by   readgroup = true"" ""o =  . "" }  ; "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test no rg info sanitize,"@ test public void   (  )  throws  exception  {  final  file output =  file . create temp file ( ""no - rg - reverted"" "" . sam"" )  ;  output . delete on exit (  )  ;  final  string[] args = new  string[] { ""i = testdata / picard / sam / bam2fastq / paired "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test output by read group with output map,"@ test public void   (  )  throws  exception  {  final  file output dir =  files . create temp directory ( ""tmp picard test"" )  . to file (  )  ;  final  file output map file =  files . create temp file ( ""picard revert sam test output map"" "" . txt"" )  . "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test sample library override,"@ test ( data provider = ""override test data"" expected exceptions =  {  picard exception . class }  )  public void   ( final  string sample final  string library )  throws  exception  {  final  file output =  file . create temp file ( ""bad"" "" . sam"" )  ; "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test sanitize and deduplicate records,"@ test public void   (  )  throws  exception  {  final  file input =  file . create temp file ( ""test - input - santize - and - deduplicate - records"" "" . sam"" )  ;  final  file output =  file . create temp file ( ""test - output - santize - and - deduplic"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test single end,"@ test public void   (  )  throws  exception  {  final  file output =  file . create temp file ( ""single   end   reverted"" "" . sam"" )  ;  output . delete on exit (  )  ;  final  string args[] =  { ""input = ""  +  single end sam to revert ""output = ""  +  ou"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test single end sanitize,"@ test public void   (  )  throws  exception  {  final  file output =  file . create temp file ( ""single   end   reverted"" "" . sam"" )  ;  output . delete on exit (  )  ;  final  string args[] =  { ""input = ""  +  single end sam to revert ""output = ""  +  ou"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test validate output params by read group bad header map,@ test public void   (  )  {  final  list <  string >  errors = new  array list <  string >  (  )  ;   revert sam .  validation util . validate output params by read group ( null bad header output map errors )  ;   assert . assert equals ( errors . size (
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test validate output params by read group dir valid,@ test public void   (  )  {  final  list <  string >  errors = new  array list <  string >  (  )  ;   revert sam .  validation util . validate output params by read group ( sam test data null errors )  ;   assert . assert equals ( errors . size (  )  0 )
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test validate output params by read group map valid,@ test public void   (  )  {  final  list <  string >  errors = new  array list <  string >  (  )  ;   revert sam .  validation util . validate output params by read group ( null valid output map errors )  ;   assert . assert equals ( errors . size (  )  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test validate output params by read group missing map,@ test public void   (  )  {  final  list <  string >  errors = new  array list <  string >  (  )  ;   revert sam .  validation util . validate output params by read group ( null non existent output map errors )  ;   assert . assert equals ( errors . size
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test validate output params by read group no map or dir,@ test public void   (  )  {  final  list <  string >  errors = new  array list <  string >  (  )  ;   revert sam .  validation util . validate output params by read group ( null null errors )  ;   assert . assert equals ( errors . size (  )  1 )  ;   ass
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test validate output params not by read group dir,@ test public void   (  )  {  final  list <  string >  errors = new  array list <  string >  (  )  ;   revert sam .  validation util . validate output params not by read group ( sam test data null errors )  ;   assert . assert equals ( errors . size (  ) 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test validate output params not by read group map,@ test public void   (  )  {  final  list <  string >  errors = new  array list <  string >  (  )  ;   revert sam .  validation util . validate output params not by read group ( null valid output map errors )  ;   assert . assert equals ( errors . size ( 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test validate output params not by read group no output,@ test public void   (  )  {  final  list <  string >  errors = new  array list <  string >  (  )  ;   revert sam .  validation util . validate output params not by read group ( null null errors )  ;   assert . assert equals ( errors . size (  )  1 )  ;  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,test validate output params not by read group valid,@ test public void   (  )  {  final  list <  string >  errors = new  array list <  string >  (  )  ;   revert sam .  validation util . validate output params not by read group ( writable path null errors )  ;   assert . assert equals ( errors . size (  ) 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\RevertSamTest.java,verify positive results,"private void   ( final  file output file final  revert sam reverter final boolean remove duplicates final boolean remove alignment info final boolean restore original qualities final boolean output by read group final  string read group id final int num reads expected final  string sample final  string library )  {  output file . delete on exit (  )  ;  final  sam reader reader =  sam reader factory . make default (  )  . reference sequence ( reference fasta )  . open ( output file )  ;  final sam file header header = reader . get file header (  )  ;   assert . assert equals ( header . get sort order (  )  sam file header .  sort order . queryname )  ;   assert . assert equals ( header . get program records (  )  . size (  )  remove alignment info  ?  0 : 1 )  ;  final  list < sam read group record >  read groups = header . get read groups (  )  ;  if  ( output by read group )   {   assert . assert equals ( read groups . size (  )  1 )  ;   assert . assert equals ( read groups . get ( 0 )  . get id (  )  read group id )  ;   }  for  (  final sam read group record rg : header . get read groups (  )  )   {  if  ( sample  !  =  null )   {   assert . assert equals ( rg . get sample (  )  sample )  ;   }  else  {   assert . assert equals ( rg . get sample (  )  "" hi  mom ! "" )  ;   }  if  ( library  !  =  null )   {   assert . assert equals ( rg . get library (  )  library )  ;   }  else  {   assert . assert equals ( rg . get library (  )  ""my - library"" )  ;   }   }  int num reads = 0 ;  for  (  final sam record rec : reader )   {  num reads +  +  ;  if  ( remove duplicates )   {   assert . assert false ( rec . get duplicate read flag (  )  "" duplicates should have been removed: ""  +  rec . get read name (  )  )  ;   }  if  ( remove alignment info )   {   assert . assert true ( rec . get read unmapped flag (  )  "" alignment info should have been removed: ""  +  rec . get read name (  )  )  ;   }  if  ( restore original qualities &&  ! unmapped read . equals ( rec . get read name (  )   +  "" / ""  +   ( rec . get first of pair flag (  )   ?  ""1"" : ""2"" )  )  )   {   assert . assert equals ( rec . get base quality string (  )  reverted qualities )  ;   }  else  {   assert . assert not same ( rec . get base quality string (  )  reverted qualities )  ;   }  for  (  final sam record . sam tag and value attr : rec . get attributes (  )  )   {  if  ( remove alignment info ||  (  ! attr . tag . equals ( ""pg"" )  &&  ! attr . tag . equals ( ""nm"" )  &&  ! attr . tag . equals ( sam tag . mq . to string (  )  )  )  )   {   assert . assert false ( reverter . attribute   to   clear . contains ( attr . tag )  attr . tag  +  "" should have been cleared . "" )  ;   }   }   }   assert . assert equals ( num reads num reads expected )  ;   closer util . close ( reader )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,add,"void   ( final sam record record )  {  if  (  ! record . get read paired flag (  )  )  throw new  picard exception ( "" record ""  +  record . get read name (  )   +  "" is not paired"" )  ;  if  ( record . get first of pair flag (  )  )   {  if  ( mate1  !  =  null )  throw new  picard exception ( "" mate 1 already set for record: ""  +  record . get read name (  )  )  ;  mate1 = record ;   }  else if  ( record . get second of pair flag (  )  )   {  if  ( mate2  !  =  null )  throw new  picard exception ( "" mate 2 already set for record: ""  +  record . get read name (  )  )  ;  mate2 = record ;   }  else throw new  picard exception ( "" neither  first of pair flag or  second of pair flag is set for a paired record"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,bad files,"@ data provider ( name = "" "" )  public  object[][] bad files (  )  {  return new  object[][] {  { ""bad / unpaired - mate . sam"" }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,bad grouped files,"@ data provider ( name = "" "" )  public  object[][] bad grouped files (  )  {  return new  object[][] {  { ""bad / grouped - unpaired - mate . sam"" }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,clipping tests,"@ data provider ( name = "" "" )  public  object[][] clipping tests (  )  {  return new  object[][] {  { null ""aaaaaaaaaa"" ""1111111111"" ""aaaaaaaaaa"" ""1111111111"" ""cccccccccc"" ""2222222222"" ""gggggggggg"" ""2222222222"" "" no clipping test"" }   { ""x"" ""aaaaaaa"" ""11"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,convert file,private void   ( final  string[] args )  {   assert . assert equals ( run picard command line ( args )  0 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,create fastq read header set,protected static  set <  string >    ( final  file file )  {  final  set <  string >  set = new  hash set <  string >  (  )  ;  final  fastq reader freader = new  fastq reader ( file )  ;  while  ( freader . has next (  )  )   {  final  fastq record frec = freader . next (  )  ;  set . add ( frec . get read name (  )  )  ;   }  return set ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,createpu pairs map,protected static  map <  string  map <  string  mate pair >  >    ( final  file sam file )  throws io exception  {  io util . assert file is readable ( sam file )  ;  final  sam reader reader =  sam reader factory . make default (  )  . open ( sam file )  ;  final  map <  string  map <  string  mate pair >  >  map = new  linked hash map <  >  (  )  ;   map <  string  mate pair >  cur file map ;  for  (  final sam record record : reader )   {  final  string platform unit = record . get read group (  )  . get platform unit (  )  ;  cur file map = map . get ( platform unit )  ;  if  ( cur file map  =  =  null )   {  cur file map = new  linked hash map <  >  (  )  ;  map . put ( platform unit cur file map )  ;   }   mate pair mpair = cur file map . get ( record . get read name (  )  )  ;  if  ( mpair  =  =  null )   {  mpair = new  mate pair (  )  ;  cur file map . put ( record . get read name (  )  mpair )  ;   }  mpair . add ( record )  ;   }  reader . close (  )  ;  return map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,create sam mate pairs map,private  map <  string  mate pair >    ( final  file sam file )  throws io exception  {  io util . assert file is readable ( sam file )  ;  final  sam reader reader =  sam reader factory . make default (  )  . open ( sam file )  ;  final  map <  string  mate pair >  map = new  linked hash map <  string  mate pair >  (  )  ;  for  (  final sam record record : reader )   {   mate pair mpair = map . get ( record . get read name (  )  )  ;  if  ( mpair  =  =  null )   {  mpair = new  mate pair (  )  ;  map . put ( record . get read name (  )  mpair )  ;   }  mpair . add ( record )  ;   }  reader . close (  )  ;  return map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,get command line program name,public  string   (  )  {  return  sam to fastq . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,missing rg files,"@ data provider ( name = "" "" )  public  object[][] missing rg files (  )  {  return new  object[][] {  { ""bad / missing - rg - info . sam"" }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,new temp fastq file,"private  file   ( final  string filename )  throws io exception  {  return new temp fastq file ( filename "" . fastq"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,ok files,"@ data provider ( name = "" "" )  public  object[][] ok files (  )  {  return new  object[][] {  { ""ok / sorted - pair . sam"" }   { ""ok / sorted - pair - no - rg . sam"" }   { ""ok / last - pair - mates - flipped . sam"" }   { ""ok / first - mate - bof - last -"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,ok grouped files,"@ data provider ( name = "" "" )  public  object[][] ok grouped files (  )  {  return new  object[][] {  { ""ok / grouped - last - pair - mates - flipped . sam"" new  string[] { ""rg1"" ""rg2"" }  }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,test bad file,"@ test ( data provider = ""bad files"" expected exceptions = sam format exception . class )  public void   ( final  string sam filename )  throws io exception  {  final  file sam file = new  file ( test   data   dir sam filename )  ;  final  file pair1 =  f"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,test bad grouped file,"@ test ( data provider = ""bad grouped files"" expected exceptions = sam format exception . class )  public void   ( final  string sam filename )  throws io exception  {  final  file pair1 file = new temp fastq file ( ""pair1"" )  ;  final  file pair2 file = "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,test bad grouped file output per rg,"@ test ( data provider = ""bad grouped files"" expected exceptions = sam exception . class )  public void   ( final  string sam filename )  throws io exception  {  convert file ( new  string[] { ""input = ""  +  test   data   dir  +  "" / "" +  sam filename ""ou"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,test clipping,"@ test ( data provider = ""clipping tests"" )  public void   ( final  string clipping action final  string bases1   1 final  string quals1   1 final  string bases1   2 final  string quals1   2 final  string bases2   1 final  string quals2   1 final  string "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,test file compression,"@ test ( data provider = ""ok files"" )  public void   ( final  string sam filename )  throws io exception  {  final  file sam file = new  file ( test   data   dir sam filename )  ;  final  file pair1 file = new temp fastq file ( ""pair1"" "" . fastq . gz"" )  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,test missing rg file,"@ test ( data provider = ""missing rg files"" )  public void   ( final  string sam filename )  throws io exception  {  final  file sam file = new  file ( test   data   dir sam filename )  ;  final  file pair1 file = new temp fastq file ( ""pair1"" )  ;  final"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,test missing rg file output per rg,"@ test ( data provider = ""missing rg files"" expected exceptions =  picard exception . class )  public void   ( final  string sam filename )  throws io exception  {  convert file ( new  string[] { ""input = ""  +  test   data   dir  +  "" / "" +  sam filename "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,test ok file,"@ test ( data provider = ""ok files"" )  public void   ( final  string sam filename )  throws io exception  {  final  file sam file = new  file ( test   data   dir sam filename )  ;  final  file pair1 file = new temp fastq file ( ""pair1"" )  ;  final  file p"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,test ok grouped files,"@ test ( data provider = ""ok grouped files"" )  public void   ( final  string sam filename final  string[] group files )  throws io exception  {  final  file sam file = new  file ( test   data   dir sam filename )  ;  final  map <  string  set <  string > "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,test ok interleaved file,"@ test ( data provider = ""ok files"" )  public void   ( final  string sam filename )  throws io exception  {  final  file sam file = new  file ( test   data   dir sam filename )  ;  final  file pair file = new temp fastq file ( ""pair"" )  ;  convert file ( "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,test trimming,"@ test ( data provider = ""trimmed data"" )  public void   ( final  string sam filename final int read1 trim final int read1 max bases final int expected read1 length final int read2 trim final int read2 max bases final int expected read2 length )  throws i"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,trimmed data,"@ data provider ( name = "" "" )  public  object[][] trimmed data (  )  {  return new  object[][] {  { ""ok / sorted - pair . sam"" 6 7 7 5 8 8 }   { ""ok / sorted - pair . sam"" 7 7 6 3 8 8 }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,verify fastq,"private void   ( final  file pair1 file final  file pair2 file final  file sam file )  throws io exception  {  final  set <  string >  output header set1 = create fastq read header set ( pair1 file )  ;  final  set <  string >  output header set2 = create fastq read header set ( pair2 file )  ;   assert . assert equals ( output header set1 . size (  )  output header set2 . size (  )  )  ;  final  map <  string  mate pair >  map = create sam mate pairs map ( sam file )  ;   assert . assert equals ( map . size (  )  output header set2 . size (  )  )  ;  for  (  final  map .  entry <  string  mate pair >  entry : map . entry set (  )  )   {  final  mate pair mpair = entry . get value (  )  ;   assert . assert not null ( mpair . mate1 )  ;   assert . assert not null ( mpair . mate2 )  ;   assert . assert equals ( mpair . mate1 . get read name (  )  mpair . mate2 . get read name (  )  )  ;  final  string read name = mpair . mate1 . get read name (  )  ;   assert . assert true ( output header set1 . contains ( read name  +  "" / 1"" )  )  ;   assert . assert true ( output header set2 . contains ( read name  +  "" / 2"" )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqTest.java,verify file is gz compressed,private void   ( final  file file )  throws io exception  {   file input stream fis = new  file input stream ( file )  ;  final byte[] expected magic number =  {  ( byte ) 0x1f  ( byte ) 0x8b }  ;  byte[] observed magic number = new byte[2] ;  fis . read ( observed magic number 0 2 )  ;  fis . close (  )  ;   assert . assert equals ( observed magic number expected magic number )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SetNmMdAndUqTagsTest.java,fix file,"private void   ( final  file input final  file output final  file reference )  throws io exception  {  final  string[] args =  { ""input = ""  +  input ""output = ""  +  output ""reference   sequence = ""  +  reference }  ;   set nm md and uq tags set nm md and uq tags = new  set nm md and uq tags (  )  ;   assert . assert equals ( set nm md and uq tags . instance main ( args )  0 "" fix did not succeed"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SetNmMdAndUqTagsTest.java,set uq only,"private void   ( final  file input final  file output final  file reference )  throws io exception  {  final  string[] args =  { ""input = ""  +  input ""output = ""  +  output ""reference   sequence = ""  +  reference ""set   only   uq = true"" }  ;   set nm md and uq tags set nm md and uq tags = new  set nm md and uq tags (  )  ;   assert . assert equals ( set nm md and uq tags . instance main ( args )  0 "" fix did not succeed"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SetNmMdAndUqTagsTest.java,sort,"private void   ( final  file input final  file output )  {  final  string[] args =  { ""input = ""  +  input ""output = ""  +  output ""sort   order = coordinate"" }  ;   sort sam sort sam = new  sort sam (  )  ;   assert . assert equals ( sort sam . instance main ( args )  0 "" sort did not succeed"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SetNmMdAndUqTagsTest.java,test valid sort,"@ test ( data provider = ""files to fix"" )  public void   ( final  file input final  file reference )  throws io exception  {  final  file sort output =  file . create temp file ( "" sort"" "" . bam"" )  ;  sort output . delete on exit (  )  ;  final  file fix"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SetNmMdAndUqTagsTest.java,test valid sort data,"@ data provider ( name = ""files to fix"" )   object[][]   (  )  {  return new  object[][] { new  object[] { new  file ( ""testdata / picard / sam / aligned . sam"" )  fasta }  new  object[] { new  file ( ""testdata / picard / sam / aligned   queryname   sorte"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SetNmMdAndUqTagsTest.java,test valid uq sort,"@ test ( data provider = ""files to fix"" )  public void   ( final  file input final  file reference )  throws io exception  {  final  file sort output =  file . create temp file ( "" sort"" "" . bam"" )  ;  sort output . delete on exit (  )  ;  final  file fix"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SetNmMdAndUqTagsTest.java,validate,"private void   ( final  file input final  file output final  file reference )  {  final  string[] args =  { ""input = ""  +  input ""output = ""  +  output ""mode = verbose"" ""reference   sequence = ""  +  reference }  ;   validate sam file validate sam = new  validate sam file (  )  ;   assert . assert equals ( validate sam . instance main ( args )  0 ""validate did not succeed"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SetNmMdAndUqTagsTest.java,validate uq,"private void   ( final  file input final  file reference )  {  final  sam reader reader =  sam reader factory . make default (  )  . reference sequence ( reference )  . open ( input )  ;  final sam record iterator iterator = reader . iterator (  )  ;  while  ( iterator . has next (  )  )   {  sam record rec = iterator . next (  )  ;  if  (  ! rec . get read unmapped flag (  )  )   assert . assert not null ( rec . get attribute ( ""uq"" )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqWithTagsTest.java,argument combinations,"@ test ( data provider = "" data"" )  public void argument combinations ( final  string[] stg arguments final  string[] qtg arguments final  string[] sep arguments final int return code )  throws io exception  {  final  file temp   input =  file . create te"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqWithTagsTest.java,argument combinationsdata,"@ data provider ( name = "" "" )  public  object[][] argument combinationsdata (  )  {  return new  object[][] {  { null null null 1 }   { stg   array null null 0 }   { stg   array new  string[] { ""uy"" }  null 1 }   { stg   array null new  string[] { ""aaaaa"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqWithTagsTest.java,get command line program name,public  string   (  )  {  return  sam to fastq with tags . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqWithTagsTest.java,ok grouped files,"@ data provider ( name = "" "" )  public  object[][] ok grouped files (  )  {  return new  object[][] {  { ""ok / grouped - last - pair - mates - flipped . sam"" new  string[] { ""rg1"" ""rg2"" }  }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqWithTagsTest.java,query non existant tag,"@ data provider ( name = "" "" )  public  object[][] query non existant tag (  )  {  return new  object[][] {  { ""ok / sorted - single . sam"" }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqWithTagsTest.java,test ok grouped files,"@ test ( data provider = ""ok grouped files"" )  public void   ( final  string sam filename final  string[] group files )  throws io exception  {  final  file sam file = new  file ( test   data   dir sam filename )  ;  final  map <  string  set <  string > "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqWithTagsTest.java,test query non existant tag,"@ test ( data provider = ""query non existant tag"" expected exceptions =  picard exception . class )  public void   ( final  string sam filename )  throws io exception  {  final  file temp   input =  file . create temp file ( ""input"" "" . fastq"" )  ;  temp "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqWithTagsTest.java,test tag group fastq,"@ test ( data provider = ""  data"" )  public void test tag group fastq ( final  string[] sequence tags final  string[] quality tags final  string[] sep args final  string bases   1   1 final  string quals   1   1 final  string bases   1   2 final  string q"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SamToFastqWithTagsTest.java,test tag group fastq data,"@ data provider ( name = "" "" )  public  object[][] test tag group fastq data (  )  {  return new  object[][] {  { new  string[] { ""cr"" }  new  string[] { ""cy"" }  null ""aaaaa"" ""11111"" ""ccccc"" ""22222"" null null null null "" one  sequence  tag  group"" }   { n"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SplitSamByLibraryTest.java,basic positive test,"@ test public void   (  )  {   split sam by library splitter = new  split sam by library (  )  ;  splitter . input = new  file ( ""testdata / picard / sam / split   test . sam"" )  ;   assert . assert equals ( splitter . do work (  )  0 ""sam file split shou"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SplitSamByLibraryTest.java,count reads,private int   (  file sam file )  {   sam reader reader =  sam reader factory . make default (  )  . open ( sam file )  ;  int count = 0 ;  for  (  iterator it = reader . iterator (  )  ;  it . has next (  )  ;   )   {  it . next (  )  ;  count +  +  ;   }   closer util . close ( reader )  ;  return count ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SplitSamByLibraryTest.java,test no library specified,"@ test public void   (  )  {   split sam by library splitter = new  split sam by library (  )  ;  splitter . input = new  file ( ""testdata / picard / sam / invalid   coord   sort   order . sam"" )  ;   assert . assert equals ( splitter . do work (  )   spl"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SplitSamByLibraryTest.java,test no unknown file,"@ test public void   (  )  {   split sam by library splitter = new  split sam by library (  )  ;  splitter . input = new  file ( ""testdata / picard / sam / split   test2 . sam"" )  ;   assert . assert equals ( splitter . do work (  )  0 ""sam file split sho"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\CleanSamTester.java, clean sam tester,public   ( final  string expected cigar final int read length final int default chromosome length )  {  super ( read length true default chromosome length )  ;  this . expected cigar = expected cigar ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\CleanSamTester.java,get command line program name,@ override public  string   (  )  {  return  clean sam . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\CleanSamTester.java,test,"protected void   (  )  {  try  {  final  sam file validator validator = new  sam file validator ( new  print writer (  system . out )  8000 )  ;  validator . set ignore warnings ( true )  ;  validator . set verbose ( true 1000 )  ;  validator . set errors to ignore (  arrays . as list ( sam validation error .  type . missing   read   group )  )  ;   sam reader factory factory =  sam reader factory . make default (  )  . validation stringency (  validation stringency . lenient )  ;   sam reader sam reader = factory . open ( get output (  )  )  ;  final sam record iterator iterator = sam reader . iterator (  )  ;  while  ( iterator . has next (  )  )   {  final sam record rec = iterator . next (  )  ;   assert . assert equals ( rec . get cigar string (  )  expected cigar )  ;  if  ( sam utils . has mate cigar ( rec )  )   {   assert . assert equals ( sam utils . get mate cigar string ( rec )  expected cigar )  ;   }   }   closer util . close ( sam reader )  ;  sam reader = factory . open ( get output (  )  )  ;  final boolean validated = validator . validate sam file verbose ( sam reader null )  ;   closer util . close ( sam reader )  ;   assert . assert true ( validated "" validate sam file failed"" )  ;   }  finally  {   test util . recursive delete ( get output dir (  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SplitSamByNumberOfReadsTest.java,compare input with outputs,private void   ( final  sam reader reader1 final  sam reader reader2 final sam record iterator input iterator final int expected first size )  {  int count = 0 ;  for  (  sam record rec : reader1 )   {  sam record input rec = input iterator . next (  )  ;   assert . assert equals ( rec . get read name (  )  input rec . get read name (  )  )  ;  count +  +  ;   }   assert . assert equals ( count expected first size )  ;  for  (  sam record rec : reader2 )   {  sam record input rec = input iterator . next (  )  ;   assert . assert equals ( rec . get read name (  )  input rec . get read name (  )  )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SplitSamByNumberOfReadsTest.java,get command line program name,public  string   (  )  {  return  split sam by number of reads . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SplitSamByNumberOfReadsTest.java,testn files,"@ test public void   (  )  throws io exception  {  final  string tmp dir = io util . get default tmp dir (  )  . get absolute path (  )  ;  final  string[] args = new  string[] { ""input = ""  +  paired   file . get absolute path (  )  ""total   reads   in  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SplitSamByNumberOfReadsTest.java,test no total reads,"@ test public void   (  )  throws io exception  {  final  string tmp dir = io util . get default tmp dir (  )  . get absolute path (  )  ;  final  string[] args = new  string[] { ""input = ""  +  paired   file . get absolute path (  )  ""split   to   n   rea"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SplitSamByNumberOfReadsTest.java,test ok file,"@ test public void   (  )  throws io exception  {  final  string tmp dir = io util . get default tmp dir (  )  . get absolute path (  )  ;  final  string[] args = new  string[] { ""input = ""  +  paired   file . get absolute path (  )  ""total   reads   in  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SplitSamByNumberOfReadsTest.java,test one output,"@ test public void   (  )  throws io exception  {  final  string tmp dir = io util . get default tmp dir (  )  . get absolute path (  )  ;  final  string[] args = new  string[] { ""input = ""  +  paired   file . get absolute path (  )  ""total   reads   in  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SplitSamByNumberOfReadsTest.java,test stream without total reads,"@ test public void   (  )  throws io exception  {  final  string tmp dir = io util . get default tmp dir (  )  . get absolute path (  )  ;  final  string[] args = new  string[] { ""input =  / dev / stdin"" ""split   to   n   reads = 5"" ""output = ""  +  tmp di"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SplitSamByNumberOfReadsTest.java,test three read template,"@ test public void   (  )  throws io exception  {  final  string tmp dir = io util . get default tmp dir (  )  . get absolute path (  )  ;  final  string[] args = new  string[] { ""input = ""  +  three   read   template . get absolute path (  )  ""total   re"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\SplitSamByNumberOfReadsTest.java,test wrong total reads,"@ test public void   (  )  throws io exception  {  final  string tmp dir = io util . get default tmp dir (  )  . get absolute path (  )  ;  final  string[] args = new  string[] { ""input = ""  +  paired   file . get absolute path (  )  ""total   reads   in  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\util\ReadNameParserTests.java,do test get rapid default read name regex split,"private void   ( int num fields )  {  final int[] input fields = new int[3] ;  final int[] expected fields = new int[3] ;   string read name = """" ;  for  ( int i = 0 ;  i  <  num fields ;  i +  +  )   {  if  ( 0  <  i )  read name +  = "":"" ;  read name +  =  integer . to string ( i )  ;   }  input fields[0] = input fields[1] = input fields[2] =  - 1 ;  if  ( num fields  <  3 )   {   assert . assert equals (  read name parser . get last three fields ( read name ':' input fields )   - 1 )  ;   }  else  {   assert . assert equals (  read name parser . get last three fields ( read name ':' input fields )  num fields )  ;  expected fields[0] = expected fields[1] = expected fields[2] =  - 1 ;  if  ( 0  <  num fields )  expected fields[0] = num fields  -  3 ;  if  ( 1  <  num fields )  expected fields[1] = num fields  -  2 ;  if  ( 2  <  num fields )  expected fields[2] = num fields  -  1 ;  for  ( int i = 0 ;  i  <  input fields . length ;  i +  +  )   {   assert . assert equals ( input fields[i] expected fields[i] )  ;   }   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\util\ReadNameParserTests.java,test get rapid default read name regex split,@ test public void   (  )  {  for  ( int i = 1 ;  i  <  10 ;  i +  +  )   {  do test get rapid default read name regex split ( i )  ;   }   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\util\ReadNameParserTests.java,test parse read name data provider,"@ data provider ( name = "" "" )  public  object[][] test parse read name data provider (  )  {  return new  object[][] {  { ""runid:7:1203:2886:82292"" 1203 2886 82292 }   { ""runid:7:1203:2884:16834"" 1203 2884 16834 }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\util\ReadNameParserTests.java,test parse read nameok,"@ test ( data provider = ""test parse read name data provider"" enabled = true )  public void   ( final  string read name final int tile final int x final int y )  {   read name parser parser = new  read name parser (  )  ;   physical location loc = new  ph"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\util\ReadNameParserTests.java,test parse read name overflow,"@ test ( data provider = ""test parse read name data provider"" enabled = true )  public void   ( final  string read name final int tile final int x final int y )  {   read name parser parser = new  read name parser (  )  ;   physical location loc = new  ph"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\util\ReadNameParserTests.java,test rapid parse int,@ test public void   (  )  {  for  ( int i =  - 100 ;  i  <  100 ;  i +  +  )   {   assert . assert equals (  read name parser . rapid parse int (  integer . to string ( i )  )  i )  ;   assert . assert equals (  read name parser . rapid parse int (  inte
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\util\ReadNameParserTests.java,test rapid parse int fails,"@ test public void   (  )  {   list <  string >  values =  collection util . make list ( ""foo"" ""bar"" ""abc123"" "" - foo"" ""f00"" "" - f00"" )  ;  for  (   string s : values )   {  try  {   read name parser . rapid parse int ( s )  ;   assert . fail ( "" should h"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\util\ReadNameParserTests.java,test read name parsing,"@ test ( data provider = "" "" )  public void test read name parsing ( final  string read name regex final  string read name final int tile final int x final int y final boolean add location information succeeds )  {  final  read name parser parser = new  r"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\util\ReadNameParserTests.java,test read name parsing data provider,"@ data provider ( name = ""test read name parsing"" )  public  object[][]   (  )  {  final  string last three fields regex = "" (  ? : . *: )  ?  ( [0 - 9] +  ) [^:]*: ( [0 - 9] +  ) [^:]*: ( [0 - 9] +  ) [^:]*$"" ;  return new  object[][] {  { last three fie"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java, sam file tester,public   ( final int read length final boolean delete on exit )  {  this ( read length delete on exit sam record set builder . default   chromosome   length )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,add arg,public void   ( final  string arg )  {  args . add ( arg )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,add fragment,private void   ( final  string read name final int reference sequence index final int alignment start final boolean record unmapped final boolean is duplicate final  string cigar final  string quality string final int default quality score final boolean is secondary final boolean is supplementary )  {  final sam record record = sam record set builder . add frag ( read name reference sequence index alignment start false record unmapped cigar quality string default quality score is secondary is supplementary )  ;  final  string key = sam record to duplicates flags key ( record )  ;   assert . assert false ( this . duplicate flags . contains key ( key )  )  ;  this . duplicate flags . put ( key is duplicate )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,add mapped fragment,public void   ( final  string read name final int reference sequence index final int alignment start final boolean is duplicate final  string cigar final  string quality string final boolean is secondary final boolean is supplementary final int default quality score )  {  add fragment ( read name reference sequence index alignment start false is duplicate cigar quality string default quality score is secondary is supplementary )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,add mapped pair,public void   ( final int reference sequence index final int alignment start1 final int alignment start2 final boolean is duplicate1 final boolean is duplicate2 final  string cigar1 final  string cigar2 final boolean strand1 final boolean strand2 final boolean first only final int default quality score )  {  add mate pair ( reference sequence index alignment start1 alignment start2 false false is duplicate1 is duplicate2 cigar1 cigar2 strand1 strand2 first only false false default quality score )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,add mate pair,public void   ( final  string read name final int reference sequence index final int alignment start1 final int alignment start2 final boolean record1 unmapped final boolean record2 unmapped final boolean is duplicate1 final boolean is duplicate2 final  string cigar1 final  string cigar2 final boolean strand1 final boolean strand2 final boolean first only final boolean record1 non primary final boolean record2 non primary final int default quality )  {  add mate pair ( read name reference sequence index reference sequence index alignment start1 alignment start2 record1 unmapped record2 unmapped is duplicate1 is duplicate2 cigar1 cigar2 strand1 strand2 first only record1 non primary record2 non primary default quality )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,add record,public void   ( final sam record record )  {  final  string key = sam record to duplicates flags key ( record )  ;   assert . assert false ( this . duplicate flags . contains key ( key )  )  ;  this . duplicate flags . put ( key record . get duplicate read flag (  )  )  ;  this . sam record set builder . add record ( record )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,add unmapped fragment,public void   ( final int reference sequence index final  string quality string )  {  add fragment ( reference sequence index  - 1 true false null quality string  - 1 false )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,add unmapped pair,public void   ( final int reference sequence index final int default quality score )  {  add mate pair ( reference sequence index  - 1  - 1 true true false false null null false false false false false default quality score )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,create input file,"private  file   (  )  {  final  file input = new  file ( output dir ""input . sam"" )  ;  final sam file writer writer = new sam file writer factory (  )  . makesam orbam writer ( sam record set builder . get header (  )  true input )  ;  sam record set builder . get records (  )  . for each ( writer::add alignment )  ;  writer . close (  )  ;  return input ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,get args,public  array list <  string >    (  )  {  return args ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,get delete on exit,public boolean   (  )  {  return delete on exit ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,get input,public  sam reader   (  )  {  return sam record set builder . get sam reader (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,get number of records,public int   (  )  {  return this . sam record set builder . size (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,get output,public  file   (  )  {  return output ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,get output dir,public  file   (  )  {  return output dir ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,get record iterator,public  closeable iterator < sam record >    (  )  {  return this . sam record set builder . iterator (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,get sam record set builder,public sam record set builder   (  )  {  return sam record set builder ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,run test,"public void   (  )  {  final  file input = create input file (  )  ;  output = new  file ( output dir ""output . sam"" )  ;  args . add ( ""input = ""  +  input . get absolute file (  )  )  ;  args . add ( ""output = ""  +  output . get absolute file (  )  )  ;   assert . assert equals ( run picard command line ( args )  0 )  ;  test (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,sam record to duplicates flags key,"protected  string   ( final sam record record )  {  final  string builder name builder = new  string builder (  )  ;  name builder . append ( record . get read name (  )  )  ;  name builder . append ( "" - "" )  ;  if  ( record . get read unmapped flag (  )  )   {  name builder . append ( "" unmapped"" )  ;   }  else  {  name builder . append ( record . get contig (  )  )  . append ( "" - "" )  . append ( record . get alignment start (  )  )  ;   }  name builder . append ( "" - "" )  . append ( record . get read paired flag (  )  )  . append ( "" - "" )  . append ( record . get not primary alignment flag (  )  )  . append ( "" - "" )  ;  if  ( record . get read paired flag (  )  )   {  name builder . append ( record . get first of pair flag (  )  )  . append ( "" - "" )  . append ( record . get second of pair flag (  )  )  ;   }  else  {  name builder . append ( ""false - false"" )  ;   }  return name builder . to string (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,set header,public void   ( final sam file header header )  {  this . sam record set builder . set header ( header )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,set no mate cigars,public void   ( final boolean value )  {  this . no mate cigars = value ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,set output,public void   ( final  file output )  {  this . output = output ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\SamFileTester.java,set output dir,"private void   (  )  {  this . output dir = io util . create temp dir ( this . get class (  )  . get simple name (  )   +  "" . "" "" . tmp"" )  ;  if  ( delete on exit )   {  output dir . delete on exit (  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\ValidateSamTester.java,assert sam valid,"public void   ( final  file sam file )  {  final int validate exit status = run picard command line ( new  string[] { ""i = ""  +  sam file . get absolute path (  )  }  )  ;   assert . assert equals ( validate exit status 0 )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\testers\ValidateSamTester.java,get command line program name,public  string   (  )  {  return  validate sam file . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\ValidateSamFileTest.java,get command line program name,@ override public  string   (  )  {  return  validate sam file . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\ValidateSamFileTest.java,sam files,"@ data provider public  object[][]   (  )  {  return new  object[][] {  { ""nofile""  validate sam file .  return types . failed . value (  )  }   { ""good / sorted - pair . sam""  validate sam file .  return types . successful . value (  )  }   { ""bad / unpa"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\ValidateSamFileTest.java,test,"@ test ( data provider = ""sam files"" )  public void   ( final  string sam file name final int exit status )  {  final int validate exit status = run picard command line ( new  string[] { ""i = ""  +  new  file ( test   data   dir  +  sam file name )  . get "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\TestDataProviders.java,independent test of data provider test,"@ test public void   (  )  throws  exception  {  final  iterator <  object[] >  data =  testng util . get data providers ( ""picard"" )  ;   assert . assert true ( data . has next (  )  "" found no data from test all data providersdata .   something is wrong"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\TestDataProviders.java,test all data providers data,"@ data provider ( name = "" dataproviders that dont test themselves"" )  public  iterator <  object[] >    (  )  throws  exception  {  return  testng util . get data providers ( ""picard"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\TestDataProviders.java,test data providerswithdp,"@ test ( data provider = "" dataproviders that dont test themselves"" )  public void   ( @ no injection final  method method final  class clazz )  throws  illegal access exception   instantiation exception  {   object instance = clazz . new instance (  )  ;"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\AlleleSubsettingUtilsTest.java,make updatep ls andad data,"@ data provider ( name = ""updatep ls andad data"" )  public  object[][]   (  )  {   list <  object[] >  tests = new  array list <  >  (  )  ;  int i = 0 ;  final  variant context vc base = new  variant context builder ( ""test"" ""20"" 10 10 ac )  . make (  ) "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\AlleleSubsettingUtilsTest.java,swap allele data,"@ data provider ( name = "" "" )   iterator <  object[] >  swap allele data (  )  {   list <  object[] >  tests = new  array list <  >  (  )  ;  final  variant context vc base = new  variant context builder ( ""test"" ""20"" 10 10 ac )  . make (  )  ;  final  g"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\AlleleSubsettingUtilsTest.java,test swap alleles,"@ test ( data provider = ""swap allele data"" )  void   ( final  variant context ctx final  allele old allele final  allele new allele final  variant context result final boolean should succeed )  {  try  {  final  variant context new vc =  allele subsettin"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\AlleleSubsettingUtilsTest.java,test updatep ls andad data,"@ test ( data provider = ""updatep ls andad data"" )  public void   ( final  variant context originalvc final  variant context selectedvc final  list <  genotype >  expected genotypes )  {  for  (  final  genotype genotype : originalvc . get genotypes (  ) "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\ViewSamTest.java,get command line program name,@ override public  string   (  )  {  return  view sam . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\ViewSamTest.java,test header version,"@ test public void   (  )  throws  exception  {  final  string old version header = ""@hd\tvn:1 . 3\tso:unsorted"" ;  final  file input sam =  file . create temp file ( "" view sam test . input . "" "" . sam"" )  ;  input sam . delete on exit (  )  ;  final  as"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\ViewSamTest.java,test intervals,"@ test public void   (  )  throws  exception  {  final  file input sam = new  file ( ""testdata / picard / sam / viewsam   intervals   test . sam"" )  ;  final  file input intervals file = new  file ( ""testdata / picard / sam / viewsam   intervals   test . "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\BedToIntervalListTest.java,do test,"private void   ( final  string input bed final  string header )  throws io exception  sam exception  {  final  file output file =  file . create temp file ( ""bed   to   interval   list   test . "" "" . interval   list"" )  ;  output file . delete on exit (  )  ;  final  bed to interval list program = new  bed to interval list (  )  ;  final  file input bed file = new  file ( test   data   dir input bed )  ;  program . input = input bed file ;  program . sequence   dictionary = new  file ( test   data   dir header )  ;  program . output = output file ;  program . unique = true ;  program . do work (  )  ;  io util . assert files equal ( new  file ( input bed file . get absolute path (  )   +  "" . interval   list"" )  output file )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\BedToIntervalListTest.java,test bed to interval list,"@ test ( data provider = ""  data provider"" )  public void test bed to interval list ( final  string input bed )  throws io exception  {  do test ( input bed ""header . sam"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\BedToIntervalListTest.java,test bed to interval list bad sequence dictionary,"@ test ( data provider = ""test bed to interval list sequence dictionary bad data provider"" expected exceptions =  { sam exception . class  picard exception . class }  )  public void   ( final  string dictionary )  throws io exception  {  do test ( ""seq   "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\BedToIntervalListTest.java,test bed to interval list data provider,"@ data provider public  object[][]   (  )  {  return new  object[][] {  { ""simple . bed"" }   { ""overlapping . bed"" }   { ""extended . bed"" }   { ""one   base   interval . bed"" }   { ""zero   base   interval . bed"" }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\BedToIntervalListTest.java,test bed to interval list out of bounds,"@ test ( data provider = ""  data provider"" expected exceptions =  picard exception . class )  public void test bed to interval list out of bounds ( final  string input bed )  throws io exception  {  do test ( input bed ""header . sam"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\BedToIntervalListTest.java,test bed to interval list out of bounds data provider,"@ data provider public  object[][]   (  )  {  return new  object[][] {  { ""end   after   chr . bed"" }   { ""end   before   chr . bed"" }   { ""missing   chr . bed"" }   { ""start   after   chr . bed"" }   { ""start   before   chr . bed"" }   { ""off   by   one   i"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\BedToIntervalListTest.java,test bed to interval list sequence dictionary,"@ test ( data provider = ""  data provider"" )  public void test bed to interval list sequence dictionary ( final  string dictionary )  throws io exception  {  do test ( ""seq   dict   test . bed"" dictionary )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\BedToIntervalListTest.java,test bed to interval list sequence dictionary bad data provider,"@ data provider public  object[][]   (  )  {  return new  object[][] {  { ""seq   dict   test . dictionary . bad"" }   { ""seq   dict   test . dictionary . bad . vcf"" }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\BedToIntervalListTest.java,test bed to interval list sequence dictionary data provider,"@ data provider public  object[][]   (  )  {  return new  object[][] {  { ""seq   dict   test . dictionary . interval   list"" }   { ""seq   dict   test . dictionary . fasta"" }   { ""seq   dict   test . dictionary . dict"" }   { ""seq   dict   test . dictionary"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\DelimitedTextFileWithHeaderIteratorTest.java,basic parsing test,"@ test public void   (  )  throws  exception  {  final  string[][] data = new  string[][] { new  string[] { ""foo"" ""bar"" ""splat"" }  new  string[] { ""1"" ""2"" ""3"" }  new  string[] { ""a"" ""b"" ""c"" }  new  string[] { ""foo"" ""bar"" ""splat"" }  }  ;  final  file tmp ="
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\DelimitedTextFileWithHeaderIteratorTest.java,parsing with column headers test,"@ test public void   (  )  throws  exception  {  final  string[] headers =  { ""string"" ""string2"" ""number"" }  ;  final  string[][] data = new  string[][] { headers new  string[] { ""1"" ""2"" ""3"" }  new  string[] { ""a"" ""b"" ""2"" }  new  string[] { ""foo"" ""bar"" """""
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\FifoBufferTest.java,test,"public void   ( final double megabytes )  throws io exception  {  final  file input file =  file . create temp file ( ""fifo   input . "" "" . foo"" )  ;  input file . delete on exit (  )  ;  final int n bytes =  ( int )  ( megabytes * 1024 * 1024 )  ;   {  final  random random = new  random ( n bytes )  ;  final  buffered output stream out = new  buffered output stream ( new  file output stream ( input file )  )  ;  final int bytes per write = 127 ;  final byte[] bytes = new byte[bytes per write] ;  for  ( int i = 0 ;  i  <  n bytes ;  i +  = bytes per write )   {  random . next bytes ( bytes )  ;  out . write ( bytes )  ;   }  out . close (  )  ;   }  final  md5 calculating input stream in = new  md5 calculating input stream ( new  file input stream ( input file )   (  file ) null )  ;  final  md5 calculating output stream out = new  md5 calculating output stream ( new  file output stream ( "" / dev / null"" )   (  file ) null )  ;  final  print stream out stream = new  print stream ( out )  ;  final  fifo buffer buffer = new  fifo buffer ( in out stream )  ;  buffer . buffer   size = 128 * 1024 * 1024 ;  buffer . do work (  )  ;  in . close (  )  ;  out . close (  )  ;  final  string input md5 = in . md5 (  )  ;  final  string output md5 = out . md5 (  )  ;   assert . assert equals ( output md5 input md5 ""md5s do not match between input and output . "" )  ;  input file . delete (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\FifoBufferTest.java,test fifo buffer,@ test public void   (  )  throws io exception  {  test ( 1 )  ;  test ( 2 )  ;  test ( 3 )  ;  test ( 4 )  ;  test ( 5 )  ;  test ( 6 )  ;  test ( 7 )  ;  test ( 8 )  ;  test ( 9 )  ;  test ( 10 )  ;  test ( 10 . 1345 )  ;  test ( 150 )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java, single end adapter,private   ( final  string name final  string three prime adapter )  {  this . name = name ;  this . three prime adapter = three prime adapter ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,create sam record with adapter sequence,private sam record   ( final int read length final  illumina adapter pair adapter pair final int adapter position )  {  final  string adapter string = adapter pair . get3 prime adapter in read order (  )  ;  final int replacement length =  math . min ( adapter string . length (  )  read length  -  adapter position )  ;  final  string adapter substring = adapter string . substring ( 0 replacement length )  ;  final  string read bases = replace substring ( make bogus read string ( read length )  adapter substring adapter position adapter substring . length (  )  )  ;  final sam record rec = new sam record ( null )  ;  rec . set read string ( read bases )  ;  return rec ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,get prime adapter,@ override public  string   (  )  {  return three prime adapter ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,get prime adapter bytes,@ override public byte[]   (  )  {  return  string util . string to bytes ( three prime adapter )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,get prime adapter bytes in read order,@ override public byte[]   (  )  {  return get3 prime adapter bytes (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,get prime adapter in read order,@ override public  string   (  )  {  return three prime adapter ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,get prime adapter,@ override public  string   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,get prime adapter bytes,@ override public byte[]   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,get prime adapter bytes in read order,@ override public byte[]   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,get prime adapter in read order,@ override public  string   (  )  {  throw new  unsupported operation exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,get clip paired test data,"@ data provider ( name = ""clip paired test data"" )  public  object[][]   (  )  {  return new  object[][] {  { "" basic positive paired test matching"" ""ctactggcgctgaaactgagcagccaagcagatcgg"" ""gcttggctgctcagtttcagcgccagtagagatcgg""  illumina adapter pair . ind"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,get clip test data,"@ data provider ( name = ""clip test data"" )  public  object[][]   (  )  {  final  string forward =  illumina adapter pair . paired   end . get3 prime adapter (  )  ;  final  string se   forward =  illumina adapter pair . single   end . get3 prime adapter "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,get name,@ override public  string   (  )  {  return name ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,make bogus read string,private static  string   ( final int len )  {  final  string builder builder = new  string builder ( len )  ;  final  map <  character  character >  next char = new  hash map <  character  character >  (  )  ;  next char . put ( 'a' 'c' )  ;  next char . put ( 'c' 'g' )  ;  next char . put ( 'g' 't' )  ;  next char . put ( 't' 'a' )  ;  for  ( char cur char = 'a' ;  true ;  cur char = next char . get ( cur char )  )   {  for  ( int i = 0 ;  i  <  6 ;   +  + i )   {  if  ( builder . length (  )   =  =  len )  return builder . to string (  )  ;  builder . append ( cur char )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,patch adapter subsequence into read,private static  string   ( final  string read final  string adapter final int length )  {  return replace substring ( read adapter . substring ( 0 length )  read . length (  )   -  length read . length (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,replace substring,private static  string   ( final  string s final  string replacement final int position final int chars to replace )  {  final  string builder sb = new  string builder ( s )  ;  sb . replace ( position position  +  chars to replace replacement )  ;  return sb . to string (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,test adapter in all read positions,"@ test ( data provider = ""  data provider"" )  public void test adapter in all read positions ( final int read length )  {  final int min adapter length = 6 ;  for  (  final  illumina adapter pair adapter pair :  illumina adapter pair . values (  )  )   { "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,test adapter in all read positions data provider,"@ data provider ( name = "" "" )  public  object[][] test adapter in all read positions data provider (  )  {  return new  object[][] {  { 100 }   { 36 }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,test adapter list truncation,"@ test ( data provider = ""  data provider"" )  public void test adapter list truncation ( final  illumina adapter pair adapter pair )  {  final int threshold for truncating adapter list = 20 ;  final int read length = 100 ;  final  adapter marker marker = "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,test adapter list truncation data provider,"@ data provider ( name = "" "" )  public  object[][] test adapter list truncation data provider (  )  {   object[][] ret = new  object[ illumina adapter pair . values (  )  . length][] ;  for  ( int i = 0 ;  i  <  ret . length ;   +  + i )   {  ret[i] = new"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,test adapter truncation,@ test public void   (  )  {  final  adapter marker marker = new  adapter marker ( 30  illumina util .  illumina adapter pair . indexed  illumina util .  illumina adapter pair . dual   indexed  illumina util .  illumina adapter pair . nextera   v2  illumi
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,test basic clip,"@ test ( data provider = ""clip test data"" )  public void   ( final  string test name final  string read final  string clip final int min match final double err rate final int expected )  {  final byte[] r =  ( read  =  =  null )   ?  null :  string util ."
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,test one sided match superseded by two sided match,@ test public void   (  )  {  final int read length = 36 ;  final int adapter length = 30 ;  final  string read1 = patch adapter subsequence into read ( make bogus read string ( read length )   illumina adapter pair . single   end . get3 prime adapter in 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,test paired end clip,"@ test ( data provider = ""clip paired test data"" )  public void   ( final  string test name final  string read1 final  string read2 final  adapter pair expected )  {  final sam record rec1 = new sam record ( new sam file header (  )  )  ;  rec1 . set read"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ClippingUtilityTest.java,test single end sam record clip,"@ test ( data provider = ""clip test data"" )  public void   ( final  string test name final  string read final  string clip final int min match final double err rate final int expected )  {  if  ( read  =  =  null )  return ;  final  single end adapter ada"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListScattererTest.java, testcase,private   ( final  interval list source final int scatter width final  interval list scatterer .  mode mode final  list <  interval list >  expected scatter )  {  this . source = source ;  this . expected scatter = expected scatter ;  this . scatter width = scatter width ;  this . mode = mode ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListScattererTest.java,compose interval list,"private static  interval list   ( final  interval list source final  string chromosome final int .  .  .  segments by pair )  {  final  interval list intervals = new  interval list ( source . get header (  )  )  ;  for  ( int i = 0 ;  i  <  segments by pair . length ;  i +  = 2 )   {  final  interval parent interval = lookup interval containing locus ( source chromosome segments by pair[i] )  ;  intervals . add ( new  interval ( ""1"" segments by pair[i] segments by pair[i  +  1] parent interval . is negative strand (  )  parent interval . get name (  )  )  )  ;   }  return intervals ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListScattererTest.java,lookup interval containing locus,private static  interval   ( final  interval list source final  string chromosome final int start index )  {  for  (  final  interval interval : source )   {  if  ( interval . get contig (  )  . equals ( chromosome )  && start index  >  =  interval . get start (  )  && start index  <  =  interval . get end (  )  )   {  return interval ;   }   }  throw new  no such element exception (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListScattererTest.java,test scatter,"@ test ( data provider = ""  testcases"" )  public void test scatter ( final  testcase tc )  {  final  interval list scatterer scatterer = new  interval list scatterer ( tc . mode )  ;  final  list <  interval list >  scatter = scatterer . scatter ( tc . so"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListScattererTest.java,test scatter testcases,@ data provider public static  object[][]   (  )  {  final  object[][] objects = new  object[testcases . size (  ) ][] ;  for  ( int i = 0 ;  i  <  objects . length ;  i +  +  )   {  objects[i] = new  object[] { testcases . get ( i )  }  ;   }  return obj
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListScattererTest.java,to string,"@ override public  string   (  )  {  return "" testcase { ""  +  ""scatter width = ""  +  scatter width  +  ""  mode = "" +  mode +  ' } ' ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IlluminaUtilTest.java,byte buffers size copy,public byte[][]   ( byte[][] bytes )  {  byte[][] out bytes = new byte[bytes . length][] ;  for  ( int i = 0 ;  i  <  bytes . length ;  i +  +  )   {  out bytes[i] = new byte[bytes[i] . length] ;   }  return out bytes ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IlluminaUtilTest.java,i tob,public static final byte[]   ( int[] int vals )  {  byte[] byte vals = new byte[int vals . length] ;  for  ( int i = 0 ;  i  <  byte vals . length ;  i +  +  )   {  byte vals[i] =  ( byte ) int vals[i] ;   }  return byte vals ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IlluminaUtilTest.java,performance test get tile from read name,"@ test public void   (  )  {  final int iterations = 5000000 ;  final long start time =  system . current time millis (  )  ;  for  ( int i = 0 ;  i  <  iterations ;   +  + i )   {  final  integer tile =  illumina util . get tile from read name ( ""300wfaa"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IlluminaUtilTest.java,read names,"@ data provider ( name = "" "" )  public  object[][] read names (  )  {  return new  object[][] { new  object[] { ""300wfaaxx:1:119:1024:978#0 / 1"" 119 }  new  object[] { ""300wfaaxx090909:1:1:1024:978#0 / 1"" 1 }  new  object[] { ""foo"" null }  new  object[] {"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IlluminaUtilTest.java,solexa qual str to phreds to phreds,"@ data provider ( name = ""solexa qual str to phreds"" )  public  object[][]   (  )  {  return new  object[][] { new  object[] { ""x@ axy""  +   (  ( char ) 156 )   +   (  ( char ) 157 )  +   (  ( char ) 0 )  +   (  ( char ) 1 )  +  "" ? "" new byte[][] { new b"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IlluminaUtilTest.java,test find tile in read name,"@ test ( data provider = ""read names"" )  public void   ( final  string read name final  integer tile )  {  final  integer other tile =  illumina util . get tile from read name ( read name )  ;   assert . assert equals ( other tile tile "" tile numbers do n"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListToBedTest.java,test convert to bed,"@ test public void   (  )  throws  exception  {  final  interval list to bed program = new  interval list to bed (  )  ;  final  file tmp =  file . create temp file ( ""interval   list   to   bed   test   output"" "" . bed"" )  ;  tmp . delete on exit (  )  ;"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\sam\util\SamTestUtil.java,count sam total record,public static long   ( final  file sam file )  {  final  sam reader reader =  sam reader factory . make (  )  . open ( sam file )  ;  assert reader . has index (  )  ;  long total = 0 ;  for  ( int i = 0 ;  i  <  reader . get file header (  )  . get sequence dictionary (  )  . size (  )  ;  i +  +  )   {  total +  = reader . indexing (  )  . get index (  )  . get meta data ( i )  . get aligned record count (  )  ;  total +  = reader . indexing (  )  . get index (  )  . get meta data ( i )  . get unaligned record count (  )  ;   }  return total ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,data test haplotype probabilities from sequence add to probs,"@ data provider ( name = ""data test missing contig in reference"" )  public  object[][]   (  )  {  return new  object[][] {  { false  liftover vcf . exit   code   when   contig   not   in   reference }   { true 0 }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,data test write original position,"@ data provider ( name = "" "" )  public  object[][] data test write original position (  )  {  return new  object[][] {  { false }   { true }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,get command line program name,public  string   (  )  {  return  liftover vcf . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,indel flip data,"@ data provider ( name = "" "" )  public  iterator <  object[] >  indel flip data (  )  {  final  allele  refcaa =  allele . create ( ""caa"" true )  ;  final  allele  refgtt =  allele . create ( ""gtt"" true )  ;  final  allele  refacgt =  allele . create ( ""a"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,indel flip data with original allele,"@ data provider ( name = "" "" )  public  iterator <  object[] >  indel flip data with original allele (  )  {  final  list <  object[] >  tests = new  array list <  >  (  )  ;  indel flip data (  )  . for each remaining ( x  -  >   {  if  ( x[2]  =  =  nul"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListToolsTest.java, actions test,@ data provider public  iterator <  object[] >    (  )  {  return  arrays . stream (  interval list tools .  action . values (  )  )  . map ( a  -  >  new  object[] { a }  )  . iterator (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListToolsTest.java,action and total bases data,@ data provider public  object[][]   (  )  {  return new  object[][] {  {  interval list tools .  action . concat 341 4 }   {  interval list tools .  action . union 201 2 }   {  interval list tools .  action . intersect 140 2 }   {  interval list tools . 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListToolsTest.java,action and total bases with invert data,@ data provider public  object[][]   (  )  {  final long total bases in dict =  interval list . from file ( second input )  . get header (  )  . get sequence dictionary (  )  . get reference length (  )  ;  final int total contigs in dict =  interval list
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListToolsTest.java,delete temp dirs,@ after test void   (  )  {  dirs to delete . for each (  test util::recursive delete )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListToolsTest.java,get command line program name,@ override public  string   (  )  {  return  interval list tools . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListToolsTest.java,test actions,"@ test ( data provider = ""action and total bases data"" )  public void   ( final  interval list tools .  action action final long bases final int intervals )  throws io exception  {  final  interval list il = tester ( action )  ;   assert . assert equals ("
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListToolsTest.java,test actions with invert,"@ test ( data provider = ""action and total bases with invert data"" )  public void   ( final  interval list tools .  action action final long bases final int intervals )  throws io exception  {  final  interval list il = tester ( action true )  ;   assert "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListToolsTest.java,test all actions,"@ test ( data provider = "" actions test"" )  public void   ( final  interval list tools .  action action )  throws io exception  {  final  file il out =  file . create temp file ( "" interval list tools"" ""interval   list"" )  ;  il out . delete on exit (  ) "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListToolsTest.java,test scatter,"@ test ( data provider = ""  testcases"" )  public void test scatter ( final  interval list scatterer test .  testcase tc )  throws io exception  {  final  file il out dir = io util . create temp dir ( "" interval list tools"" ""lists"" )  ;  dirs to delete . a"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListToolsTest.java,test scatter testcases,@ data provider public static  object[][]   (  )  {  final  object[][] objects = new  object[ interval list scatterer test . testcases . size (  ) ][] ;  for  ( int i = 0 ;  i  <  objects . length ;  i +  +  )   {  objects[i] = new  object[] {  interval l
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListToolsTest.java,test second input validation,@ test public void   (  )  {   interval list tools interval list tools = new  interval list tools (  )  ;   string[] errors = interval list tools . custom command line validation (  )  ;   assert . assert null ( errors )  ;  interval list tools . second  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\IntervalListToolsTest.java,tester,"private  interval list   (  interval list tools .  action action boolean invert )  throws io exception  {  final  file il out =  file . create temp file ( "" interval list tools"" ""interval   list"" )  ;  il out . delete on exit (  )  ;  final  list <  string >  args = new  array list <  >  (  )  ;  args . add ( ""action = ""  +  action . to string (  )  )  ;  args . add ( ""input = ""  +  scatterable )  ;  if  ( action . takes second input )   {  args . add ( ""second   input = ""  +  second input )  ;   }  else  {  args . add ( ""input = ""  +  second input )  ;   }  if  ( invert )   {  args . add ( ""invert = true"" )  ;   }  args . add ( ""output = ""  +  il out )  ;   assert . assert equals ( run picard command line ( args )  0 )  ;  return  interval list . from file ( il out )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,indel no flip data,"@ data provider ( name = "" "" )  public  iterator <  object[] >  indel no flip data (  )  {  final  variant context builder builder = new  variant context builder (  )  . source ( ""test1"" )  . chr ( ""chr1"" )  ;  final  variant context builder result   buil"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,left align alleles data,"@ data provider ( name = "" "" )  public  iterator <  object[] >  left align alleles data (  )  {  final  allele  refg =  allele . create ( ""g"" true )  ;  final  allele a =  allele . create ( ""a"" false )  ;  final  allele  refa =  allele . create ( ""a"" true"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,liftover reverse strand,"@ data provider ( name = "" "" )  public  object[][] liftover reverse strand (  )  {  return new  object[][] {  { ""test liftover biallelic indels . vcf"" 5 0 }   { ""test liftover multiallelic indels . vcf"" 0 2 }   { ""test liftover failing variants . vcf"" 3 0"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,no call and symbolic data,"@ data provider ( name = "" "" )  public  iterator <  object[] >  no call and symbolic data (  )  {  final  variant context builder builder = new  variant context builder (  )  . source ( ""test1"" )  . chr ( ""chr1"" )  ;  final  variant context builder result"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,snp with changed ref,"@ test ( data provider = "" "" )  public void snp with changed ref ( final  variant context source final  reference sequence reference final  variant context result )  {  final  lift over lift over = new  lift over ( positive   chain   file )  ;  final  int"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,teardown,@ after class public void   (  )  {  io util . delete directory tree ( output   data   path )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,test changing info fields,"@ test public void   (  )  {  final  string filename = ""test liftover failing variants . vcf"" ;  final  file lift output file = new  file ( output   data   path ""lift - delete - me . vcf"" )  ;  final  file reject output file = new  file ( output   data   "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,test changing tag arguments,"@ test public void   (  )  {  final  string filename = ""test liftover failing variants . vcf"" ;  final  file lift output file = new  file ( output   data   path ""lift - delete - me . vcf"" )  ;  final  file reject output file = new  file ( output   data   "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,test flip indel,"@ test ( data provider = ""indel flip data"" )  public void   ( final  variant context source final  reference sequence reference final  variant context result )  {  final  lift over lift over = new  lift over ( chain   file )  ;  final  interval original l"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,test flip indel with original alleles,"@ test ( data provider = ""indel flip data with original allele"" )  public void   ( final  variant context source final  reference sequence reference final  variant context result )  {  final  lift over lift over = new  lift over ( chain   file )  ;  final"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,test left align variants,"@ test ( data provider = ""left align alleles data"" )  public void   ( final  variant context source final  reference sequence reference final  variant context result )  {   variant context builder vcb = new  variant context builder ( source )  ;   liftove"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,test lift over no call and symbolic,"@ test ( data provider = ""no call and symbolic data"" )  public void   ( final  lift over lift over final  variant context source final  variant context result final boolean expect reversed )  {  final  interval target = lift over . lift over ( new  interv"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,test lift over simple indels,"@ test ( data provider = ""indel no flip data"" )  public void   ( final  lift over lift over final  reference sequence reference final  variant context source final  variant context result )  {  final  interval target = lift over . lift over ( new  interva"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,test missing contig in reference,"@ test ( data provider = ""data test missing contig in reference"" )  public void   ( final boolean warn on missing context final int expected return code )  {  final  file lift output file = new  file ( output   data   path ""lift - delete - me . vcf"" )  ; "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,test reverse complement failure does not error out,"@ test public void   (  )  {  final  variant context builder builder = new  variant context builder (  )  . source ( ""test"" )  . loc ( ""chr1"" 1 4 )  ;  final  allele original ref =  allele . create ( ""cccc"" true )  ;  final  allele original alt =  allele "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,test reverse complemented indels,"@ test ( data provider = ""liftover reverse strand"" )  public void   ( final  string filename final int expected passing final int expected failing )  {  final  file lift output file = new  file ( output   data   path ""lift - delete - me . vcf"" )  ;  final"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,test write original position,"@ test ( data provider = ""data test write original position"" )  public void   ( final boolean should write original position )  {  final  file lift output file = new  file ( output   data   path ""lift - delete - me . vcf"" )  ;  final  file reject output f"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,test write vcf with flipped alleles,"@ test public void   (  )  throws io exception  {  final  file lift output file = new  file ( output   data   path ""lift - delete - me . vcf"" )  ;  final  file reject output file = new  file ( output   data   path ""reject - delete - me . vcf"" )  ;  final "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverVcfTest.java,test write vcf with flipped alleles negative chain,"@ test public void   (  )  throws io exception  {  final  file lift output file = new  file ( output   data   path ""lift - delete - me . vcf"" )  ;  final  file reject output file = new  file ( output   data   path ""reject - delete - me . vcf"" )  ;  final "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverUtilsTest.java,alleles to string data,"@ data provider public  iterator <  object[] >    (  )  {  final  list <  object[] >  tests = new  array list <  >  (  )  ;  tests . add ( new  object[] {  arrays . as list (  allele . create ( ""a"" true )   allele . create ( ""g"" )  )   arrays . as list ( "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverUtilsTest.java,swap ref alt data,"@ data provider public  object[][]   (  )  {   string test name = ""test1"" ;  final  list <  object[] >  tests = new  array list <  >  (  )  ;   variant context builder builder = new  variant context builder ( test name ""chr1"" 2 2  arrays . as list (  refa"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverUtilsTest.java,test alleles to string,"@ test ( data provider = ""alleles to string data"" )  public void   ( final  list <  allele >  input final  list <  string >  output )  {   assert . assert equals (  liftover utils . alleles to string list ( input )  output )  ;   list <  allele >  restore"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\LiftoverUtilsTest.java,test swap ref alt,"@ test ( data provider = ""swap ref alt data"" )  public void   ( final  variant context swap me final  variant context expected )  {   vcf test utils . assert equals (  liftover utils . swap ref alt ( swap me annotations to swap annotations to drop )  expe"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MathUtilTest.java,assert equals,"private void   ( final double[] actual final double[] expected )  {   assert . assert equals ( actual . length expected . length "" arrays do not have equal lengths"" )  ;  for  ( int i = 0 ;  i  <  actual . length ;   +  + i )   {   assert . assert equals ( actual[i] expected[i] "" array differ at position ""  +  i )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MathUtilTest.java,divide double test cases,@ data provider public  object[][]   (  )  {  return new  object[][] { new  object[] { 15 . 0 3 . 0 5 . 0 }  new  object[] { 15 . 0 0 . 0 0 . 0 }  }  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MathUtilTest.java,divide method fail test cases,@ data provider public  object[][]   (  )  {  return new  object[][] { new  object[] { new double[] { 1 2 3 4 }  new double[] { 2 3 4 }  }  new  object[] { new double[] { 100 }  new double[] {  }  }  }  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MathUtilTest.java,divide method test cases,@ data provider public  object[][]   (  )  {  return new  object[][] { new  object[] { new double[] { 1 2 3 4 }  new double[] { 2 3 4  - 5 }  new double[] {  . 5 2 . 0  /  3 3 . 0  /  4  - 4 . 0  /  5 }  }  new  object[] { new double[] { 100 }  new double
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MathUtilTest.java,log math test,@ test public void   (  )  {   assert . assert equals (  math util . log   10   math . get log value ( 10 )  1d 0 . 00001d )  ;   assert . assert equals (  math util . log   10   math . get non log value ( 1 )  10d 0 . 00001d )  ;   assert . assert equals
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MathUtilTest.java,seq method test cases,@ data provider public  object[][]   (  )  {  return new  object[][] { new  object[] { 0d 5d 1d new double[] { 0 1 2 3 4 5 }  }  new  object[] { 0d 0 . 5d 0 . 1d new double[] { 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 }  }  new  object[] { 0d 0 . 5d 0 . 11d new do
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MathUtilTest.java,test divide,"@ test ( data provider = ""divide method test cases"" )  public void   ( final double[] numerators final double[] denominators final double[] expected )  {  assert equals ( divide ( numerators denominators )  expected )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MathUtilTest.java,test divide double,"@ test ( data provider = ""divide double test cases"" )  public void   ( final double numerator final double denominator final double expected )  {   assert . assert equals (  math util . divide ( numerator denominator )  expected )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MathUtilTest.java,test divide fail,"@ test ( data provider = ""divide method fail test cases"" expected exceptions =  runtime exception . class )  public void   ( final double[] lhs final double[] rhs )  {  divide ( lhs rhs )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MathUtilTest.java,test seq generation,"@ test ( data provider = ""seq method test cases"" )  public void   ( final double from final double to final double by final double[] expected )  {  final double[] actual =  math util . seq ( from to by )  ;   assert . assert equals ( actual . length expec"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\GraphUtilsTest.java,second test,@ test public void   (  )  {   graph utils .  graph <  integer >  graph = new  graph utils .  graph <  >  (  )  ;  graph . add edge ( 1 3 )  ;  graph . add edge ( 2 3 )  ;  graph . add edge ( 0 2 )  ;  graph . add edge ( 4 3 )  ;  graph . add edge ( 5 6 )
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\GraphUtilsTest.java,simple test,@ test public void   (  )  {   graph utils .  graph <  integer >  graph = new  graph utils .  graph <  >  (  )  ;  graph . add edge ( 5 6 )  ;  graph . add edge ( 5 8 )  ;  graph . add edge ( 7 9 )  ;  graph . add edge ( 7 8 )  ;  graph . add edge ( 4 2 )
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ScatterIntervalsByNsTest.java,get sequence,@ override public  reference sequence   ( final  string contig )  {  if  ( contig . equals ( record . get sequence name (  )  )  )   {  return new  reference sequence ( record . get sequence name (  )  0 reference string . get bytes (  )  )  ;   }  else  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ScatterIntervalsByNsTest.java,get sequence dictionary,@ override public sam sequence dictionary   (  )  {  return dictionary ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ScatterIntervalsByNsTest.java,get subsequence at,@ override public  reference sequence   ( final  string contig final long start final long stop )  {  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ScatterIntervalsByNsTest.java,is indexed,@ override public boolean   (  )  {  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ScatterIntervalsByNsTest.java,next sequence,@ override public  reference sequence   (  )  {  if  (  ! done )   {  done = true ;  return get sequence ( record . get sequence name (  )  )  ;   }  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ScatterIntervalsByNsTest.java,reset,@ override public void   (  )  {  done = false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ScatterIntervalsByNsTest.java,test segregate,"@ data provider ( name = "" "" )  public  object[][] test segregate (  )  {  return new  object[][] { new  object[] { ""nnnnnaaaaannnnnn"" 1  collection util . make list ( new  interval ( ""fake1"" 1 5 )  new  interval ( ""fake1"" 6 10 )  new  interval ( ""fake1"" "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ScatterIntervalsByNsTest.java,test segregate reference,"@ test ( data provider = ""test segregate"" )  public void   ( final  string reference string final int max nmer to merge final  list <  interval >  result )  throws  exception  {  final sam sequence record record = new sam sequence record ( ""fake1"" referen"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\ScatterIntervalsByNsTest.java,to string,@ override public  string   (  )  {  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MergingIteratorTest.java, queue backed iterator,  ( final  queue < t >  queue )  {  this . backing = queue . iterator (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MergingIteratorTest.java,compare,@ override public int   (  integer integer  integer integer2 )  {  return integer  -  integer2 ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MergingIteratorTest.java,has next,@ override public boolean   (  )  {  return backing . has next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MergingIteratorTest.java,next,@ override public t   (  )  {  return backing . next (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MergingIteratorTest.java,remove,@ override public void   (  )  {  backing . remove (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MergingIteratorTest.java,test iterators of uneven length,@ test public void   (  )  {  final  queue <  integer >  queue one = new  linked list <  integer >  (  )  ;  queue one . add ( 1 )  ;  queue one . add ( 3 )  ;  queue one . add ( 5 )  ;  queue one . add ( 7 )  ;  queue one . add ( 9 )  ;  queue one . add 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MergingIteratorTest.java,test ordering and completeness,@ test public void   (  )  {  final  queue <  integer >  queue one = new  linked list <  integer >  (  )  ;  queue one . add ( 1 )  ;  queue one . add ( 3 )  ;  queue one . add ( 5 )  ;  final  queue <  integer >  queue two = new  linked list <  integer >
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\MergingIteratorTest.java,test out of order iterators,@ test ( expected exceptions =  illegal state exception . class )  public void   (  )  {  final  queue <  integer >  queue one = new  linked list <  integer >  (  )  ;  queue one . add ( 1 )  ;  queue one . add ( 3 )  ;  final  queue <  integer >  queue t
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\QuerySortedReadPairIteratorUtilTest.java,test basic halfmapped read pair,"@ test public void   (  )  {  sam record set builder builder = new sam record set builder ( false sam file header .  sort order . queryname )  ;  builder . set read length ( read   length )  ;  builder . add pair ( ""halfmapped   paired"" 1 1 31 false true "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\QuerySortedReadPairIteratorUtilTest.java,test basic paired read,"@ test public void   (  )  {  sam record set builder builder = new sam record set builder ( false sam file header .  sort order . queryname )  ;  builder . set read length ( read   length )  ;  builder . add pair ( ""mapped   paired"" 1 1 31 )  ;   peekable"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\QuerySortedReadPairIteratorUtilTest.java,test basic unmapped read pair,"@ test public void   (  )  {  sam record set builder builder = new sam record set builder ( false sam file header .  sort order . queryname )  ;  builder . set read length ( read   length )  ;  builder . add unmapped pair ( ""unmapped   paired"" )  ;   peek"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\QuerySortedReadPairIteratorUtilTest.java,test fragment no read pair,"@ test public void   (  )  {  sam record set builder builder = new sam record set builder ( false sam file header .  sort order . queryname )  ;  builder . set read length ( read   length )  ;  builder . add frag ( ""mapped   frag   a"" 1 1 false )  ;  buil"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\RExecutorTest.java,test failingr script,"@ test public void   (  )  {   assert . assert true ( r executor . execute from classpath ( ""failing . r"" )   !  =  0 )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\RExecutorTest.java,test passingr script,"@ test public void   (  )  {   assert . assert true ( r executor . execute from classpath ( ""passing . r"" )   =  =  0 )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\RExecutorTest.java,testr script not found,"@ test ( expected exceptions =  illegal argument exception . class )  public void   (  )  {  r executor . execute from classpath ( ""asdlfjasl"" )  ;   assert . fail (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TabbedTextFileWithHeaderParserTest.java,basic parsing test,"@ test public void   (  )  throws  exception  {  final  string[][] data = new  string[][] { new  string[] { ""foo"" ""bar"" ""splat"" }  new  string[] { ""1"" ""2"" ""3"" }  new  string[] { ""a"" ""b"" ""c"" }  new  string[] { ""foo"" ""bar"" ""splat"" }  }  ;  final  file tmp ="
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TabbedTextFileWithHeaderParserTest.java,parsing with column headers test,"@ test public void   (  )  throws  exception  {  final  string[][] data = new  string[][] { new  string[] { ""1"" ""2"" ""3"" }  new  string[] { ""a"" ""b"" ""2"" }  new  string[] { ""foo"" ""bar"" """" }  }  ;  final  string[] headers =  { ""string"" ""string2"" ""number"" }  ;"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TestNGUtil.java,assert equal double arrays,"public static void   ( final double[] lhs final double[] rhs final double accuracy )  {   assert . assert not null ( lhs )  ;   assert . assert not null ( rhs )  ;  if  ( accuracy  <  =  0 )  throw new  illegal argument exception ( "" accuracy must be positive . "" )  ;   assert . assert equals ( lhs . length rhs . length "" arrays not same length: ""  +  lhs . length  +  "" vs .  "" +  rhs . length )  ;  for  ( int i = 0 ;  i  <  lhs . length ;   +  + i )   {   assert . assert true ( compare double with accuracy ( lhs[i] rhs[i] accuracy )  "" arrays disagree at position ""  +  i  +  "": "" +  lhs[i] +  "" vs .  "" +  rhs[i] +  "" .  "" )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TestNGUtil.java,assert greater than,"static public void   ( final double lhs final double rhs )  {   assert . assert true ( lhs  >  rhs  string . format ( "" expected inequality is not true: %g  >  %g"" lhs rhs )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TestNGUtil.java,assert less than,"static public void   ( final double lhs final double rhs )  {   assert . assert true ( lhs  <  rhs  string . format ( "" expected inequality is not true: %g  <  %g"" lhs rhs )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TestNGUtil.java,compare double with accuracy,"public static boolean   ( final double lhs final double rhs final double accuracy )  {  if  ( accuracy  <  =  0 )  throw new  illegal argument exception ( "" accuracy must be positive . "" )  ;  return abs ( lhs  -  rhs )   /   ( abs ( lhs )   +  abs ( rhs )   +  epsilon )   <  accuracy ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TestNGUtil.java,do meta test,"@ test ( data provider = ""testcases"" )  public void   ( final  test clazz testcase )  {  do test ( testcase )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\UnsignedTypeUtilTest.java,u byte data,"@ data provider ( name = "" "" )  public  object[][] u byte data (  )  {  return new  object[][] {  {  ( byte ) 0xff 255 }   {  ( byte ) 0xfe 254 }   {  ( byte ) 0x80 128 }   {  ( byte ) 0x7f 127 }   {  ( byte ) 0x70 112 }   {  ( byte ) 0x02 2 }   {  ( byte"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\UnsignedTypeUtilTest.java,u byte to int test,"@ test ( data provider = ""u byte data"" )  public void   ( final byte unsigned byte final int expected int )  {   assert . assert equals (  unsigned type util . u byte to int ( unsigned byte )  expected int )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\UnsignedTypeUtilTest.java,u byte to short test,"@ test ( data provider = ""u byte data"" )  public void   ( final byte unsigned byte final int expected int )  {  final short expected short =  ( short ) expected int ;   assert . assert equals (  unsigned type util . u byte to short ( unsigned byte )  expe"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\UnsignedTypeUtilTest.java,u int data,"@ data provider ( name = "" "" )  public  object[][] u int data (  )  {  return new  object[][] {  { 0xffffffff 4294967295l }   { 0xfffffffe 4294967294l }   { 0x81014000 2164342784l }   { 0x7fffffff 2147483647l }   { 0x10502100 273686784l }   { 0x00000002 2"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\UnsignedTypeUtilTest.java,u int to long test,"@ test ( data provider = ""u int data"" )  public void   ( final int unsigned int final long expected long )  {   assert . assert equals (  unsigned type util . u int to long ( unsigned int )  expected long )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\UnsignedTypeUtilTest.java,u short data,"@ data provider ( name = "" "" )  public  object[][] u short data (  )  {  return new  object[][] {  {  ( short ) 0xffff 65535 }   {  ( short ) 0xfffe 65534 }   {  ( short ) 0x8021 32801 }   {  ( short ) 0x7fff 32767 }   {  ( short ) 0x5545 21829 }   {  ( s"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\UnsignedTypeUtilTest.java,u short to int test,"@ test ( data provider = ""u short data"" )  public void   ( final short unsigned short final int expected int )  {   assert . assert equals (  unsigned type util . u short to int ( unsigned short )  expected int )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\AbstractVcfMergingClpTester.java,get contig position,"static  string   ( final  variant context context )  {  return context . get contig (  )   +  "" - ""  +   integer . to string ( context . get start (  )  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,get basic input parser data,"@ data provider ( name = ""basic input parser data"" )  private  object[][]   (  )  {  return new  object[][] {  { new  file ( test file1 )  }   { io util . open file for reading ( new  file ( test file1 )  )  }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,get file name,public  string   (  )  {  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,get leading white space data,"@ data provider ( name = ""leading white space data"" )  private  object[][]   (  )  {  return new  object[][] {  { new  file ( test file2 )  }   { io util . open file for reading ( new  file ( test file2 )  )  }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,get multi file parsing data,"@ data provider ( name = ""multi file parsing data"" )  private  object[][]   (  )  {  return new  object[][] {  { new  file ( test file1 )  new  file ( test file1 )  }   { io util . open file for reading ( new  file ( test file1 )  )  io util . open file f"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,get no grouping data,"@ data provider ( name = ""no grouping data"" )  private  object[][]   (  )  {  return new  object[][] {  { new  file ( test file3 )  }   { io util . open file for reading ( new  file ( test file3 )  )  }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,get tabbed data,"@ data provider ( name = ""tabbed data"" )  private  object[][]   (  )  {  return new  object[][] {  { new  file ( test file4 )  }   { io util . open file for reading ( new  file ( test file4 )  )  }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,get too many words data,"@ data provider ( name = ""too many words data"" )  private  object[][]   (  )  {  return new  object[][] {  { new  file ( test file1 )  }   { io util . open file for reading ( new  file ( test file1 )  )  }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,get word count calculation data,"@ data provider ( name = ""data"" )  private  object[][]   (  )  {  return new  object[][] {  { ""1\t2\t3"" false "" tabs with all fields filled . "" }   { ""1\t2\t"" false "" tabs with no final field . "" }   { ""\t2\t3"" false "" tabs with no first field . "" }   { """
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,is delimiter,protected boolean   ( final byte b )  {  for  ( int i = 0 ;  i  <  delimiters . length ;  i +  +  )   {  if  ( b  =  =  delimiters[i] )   {  return true ;   }   }  return false ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,read next line,protected byte[]   (  )  {  return new byte[0] ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,set delimiter,public void   (  string delim )  {  delimiters = delim . to char array (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,test multi file parsing,"@ test ( data provider = ""multi file parsing data"" )  public void   (  object file or stream1  object file or stream2 )  throws io exception  {   format util format = new  format util (  )  ;   list <  string >  expected = new  array list <  string >  (  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,test tabbed file parser,"@ test ( data provider = ""tabbed data"" )  public void   (  object file or stream )  {   tabbed input parser parser = file or stream instanceof  file  ?  new  tabbed input parser ( false  (  file ) file or stream )  : new  tabbed input parser ( false  (  i"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,test text file parser,"@ test ( data provider = ""basic input parser data"" )  public void   (  object file or stream )  throws io exception  {   format util format = new  format util (  )  ;   list <  string >  expected = new  array list <  string >  (  )  ;  if  ( file or strea"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,test text file parser leading whitespace,"@ test ( data provider = ""leading white space data"" )  public void   (  object file or stream )  {   basic input parser parser = file or stream instanceof  file  ?  new  basic input parser ( true  (  file ) file or stream )  : new  basic input parser ( tr"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,test text file parser no grouping,"@ test ( data provider = ""no grouping data"" )  public void   (  object file or stream )  {   basic input parser parser = file or stream instanceof  file  ?  new  basic input parser ( true  (  file ) file or stream )  : new  basic input parser ( true  (  i"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,test too many words,"@ test ( expected exceptions =  picard exception . class data provider = ""too many words data"" )  public void   (  object file or stream )  {   basic input parser parser = file or stream instanceof  file  ?  new  basic input parser ( true 3  (  file ) fil"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\util\TextFileParsersTest.java,test word count calculation,"@ test ( data provider = ""data"" )  public void   (  string line boolean group delimiters  string name )  {   word count test parser parser = new  word count test parser (  )  ;  parser . set delimiter ( ""\t "" )  ;  parser . set treat grouped delimiters as"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\CallingMetricAccumulatorTest.java,get singleton sample data,"@ data provider ( name = "" "" )  public  object[][] get singleton sample data (  )  {  final  list <  object[] >  retval = new  array list <  >  ( 10 )  ;  final  allele a ref =  allele . create ( ""a"" true )  ;  final  allele g =  allele . create ( ""g"" fal"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\CallingMetricAccumulatorTest.java,test get singleton sample,"@ test ( data provider = ""get singleton sample data"" )  public void   ( final  variant context vc final  string sample )  throws  exception  {   assert . assert equals (  calling metric accumulator . get singleton sample ( vc )  sample )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\AccumulateVariantCallingMetricsTest.java,check results,"private void   ( final  metrics file <  collect variant calling metrics .  variant calling detail metrics  comparable <  ?  >  >  detail final  metrics file <  collect variant calling metrics .  variant calling summary metrics  comparable <  ?  >  >  summary )  {  int parsed detail = 0 ;  for  (  final  collect variant calling metrics .  variant calling detail metrics metrics : detail . get metrics (  )  )   {  if  ( metrics . sample   alias . equals ( ""foo1"" )  )   {   assert . assert equals ( metrics . het   homvar   ratio 2 . 0 )  ;   assert . assert equals ( metrics . total   het   depth 30 )  ;   assert . assert equals ( metrics . total   snps 15 )  ;   assert . assert equals ( metrics . num   in   db   snp 10 )  ;   assert . assert equals ( metrics . novel   snps 5 )  ;   assert . assert equals ( metrics . filtered   snps 7 )  ;   assert . assert equals ( metrics . pct   dbsnp 0 . 666667 0 . 01 )  ;   assert . assert equals ( metrics . dbsnp   titv 2 . 333333 0 . 01 )  ;   assert . assert equals ( metrics . novel   titv 1 . 5 0 . 01 )  ;   assert . assert equals ( metrics . total   indels 9 )  ;   assert . assert equals ( metrics . novel   indels 3 )  ;   assert . assert equals ( metrics . filtered   indels 12 )  ;   assert . assert equals ( metrics . num   in   db   snp   indels 6 )  ;   assert . assert equals ( metrics . pct   dbsnp   indels 0 . 666667 0 . 01 )  ;   assert . assert equals ( metrics . dbsnp   ins   del   ratio 1 . 0 0 . 01 )  ;   assert . assert equals ( metrics . novel   ins   del   ratio 0 . 0 0 . 01 )  ;   assert . assert equals ( metrics . snp   reference   bias 0 . 466667 0 . 01 )  ;   assert . assert equals ( metrics . num   singletons 10 )  ;   }  else if  ( metrics . sample   alias . equals ( ""foo2"" )  )   {   assert . assert equals ( metrics . het   homvar   ratio 1 . 571429 )  ;   assert . assert equals ( metrics . total   het   depth 33 )  ;   assert . assert equals ( metrics . total   snps 18 )  ;   assert . assert equals ( metrics . num   in   db   snp 13 )  ;   assert . assert equals ( metrics . novel   snps 5 )  ;   assert . assert equals ( metrics . filtered   snps 5 )  ;   assert . assert equals ( metrics . pct   dbsnp 0 . 722222 0 . 01 )  ;   assert . assert equals ( metrics . dbsnp   titv 2 . 25 0 . 01 )  ;   assert . assert equals ( metrics . novel   titv 0 . 666667 0 . 01 )  ;   assert . assert equals ( metrics . total   indels 6 )  ;   assert . assert equals ( metrics . novel   indels 3 )  ;   assert . assert equals ( metrics . filtered   indels 6 )  ;   assert . assert equals ( metrics . num   in   db   snp   indels 3 )  ;   assert . assert equals ( metrics . pct   dbsnp   indels 0 . 5 0 . 01 )  ;   assert . assert equals ( metrics . dbsnp   ins   del   ratio 0 . 5 0 . 01 )  ;   assert . assert equals ( metrics . novel   ins   del   ratio 0 . 5 0 . 01 )  ;   assert . assert equals ( metrics . snp   reference   bias 0 . 696969 0 . 01 )  ;   assert . assert equals ( metrics . num   singletons 9 )  ;   }  else  {   assert . assert true ( false "" unexpected sample name in detailed metrics: ""  +  metrics . sample   alias )  ;   }  parsed detail +  +  ;   }   assert . assert equals ( parsed detail 2 "" did not parse enough detail metrics . "" )  ;  boolean parsed summary = false ;  for  (  final  collect variant calling metrics .  variant calling summary metrics metrics : summary . get metrics (  )  )   {   assert . assert equals ( metrics . total   snps 33 )  ;   assert . assert equals ( metrics . novel   snps 10 )  ;   assert . assert equals ( metrics . num   in   db   snp 23 )  ;   assert . assert equals ( metrics . filtered   snps 12 )  ;   assert . assert equals ( metrics . pct   dbsnp 0 . 696969 0 . 01 )  ;   assert . assert equals ( metrics . dbsnp   titv 2 . 285714 0 . 01 )  ;   assert . assert equals ( metrics . novel   titv 1 . 0 0 . 01 )  ;   assert . assert equals ( metrics . total   indels 15 )  ;   assert . assert equals ( metrics . novel   indels 6 )  ;   assert . assert equals ( metrics . num   in   db   snp   indels 9 )  ;   assert . assert equals ( metrics . filtered   indels 18 )  ;   assert . assert equals ( metrics . pct   dbsnp   indels 0 . 6 0 . 01 )  ;   assert . assert equals ( metrics . dbsnp   ins   del   ratio 0 . 8 0 . 01 )  ;   assert . assert equals ( metrics . novel   ins   del   ratio 0 . 2 0 . 01 )  ;   assert . assert equals ( metrics . snp   reference   bias 0 . 587302 0 . 01 )  ;   assert . assert equals ( metrics . num   singletons 19 )  ;  parsed summary = true ;   }   assert . assert true ( parsed summary "" did not parse summary metrics . "" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\AccumulateVariantCallingMetricsTest.java,shard data provider,"@ data provider ( name = "" "" )  public  object[][] shard data provider (  )  {  final  file file prefix1 = new  file ( test   data   dir ""merge test . shard1"" )  ;  final  file file prefix2 = new  file ( test   data   dir ""merge test . shard2"" )  ;  final"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\AccumulateVariantCallingMetricsTest.java,test merge,"@ test ( data provider = ""shard data provider"" )  public void   ( final  list <  file >  inputs )  throws io exception  {  final  file merged file prefix = new  file ( test   data   dir  +  ""merge test"" )  ;  final  file merged summary file = new  file ( "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\ByIntervalListVariantContextIteratorTest.java, by interval list variant context iterator test,public   (  )  {  this . header = getsam file header (  )  ;  this . dict = header . get sequence dictionary (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\ByIntervalListVariantContextIteratorTest.java,get reader,private vcf file reader   ( final  file file )  {  return new vcf file reader ( file true )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\ByIntervalListVariantContextIteratorTest.java,getsam file header,private sam file header   (  )  {  final vcf file reader reader = get reader ( ceu   trios   snps   vcf )  ;  final sam sequence dictionary dict = reader . get file header (  )  . get sequence dictionary (  )  ;  reader . close (  )  ;  final sam file header header = new sam file header (  )  ;  header . set sequence dictionary ( dict )  ;  return header ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\ByIntervalListVariantContextIteratorTest.java,test empty interval list,@ test public void   (  )  {  final  interval list interval list = new  interval list ( header )  ;  final vcf file reader reader = get reader ( ceu   trios   snps   vcf )  ;  final  iterator <  variant context >  iterator = new  by interval list variant 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\ByIntervalListVariantContextIteratorTest.java,test no overlap different contig,"@ test public void   (  )  {  final  interval list interval list = new  interval list ( header )  ;  interval list . add ( new  interval ( ""3"" 167166899 167166899 )  )  ;  final vcf file reader reader = get reader ( ceu   trios   snps   vcf )  ;  final  i"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\ByIntervalListVariantContextIteratorTest.java,test no variants,@ test public void   (  )  {  final  interval list interval list = new  interval list ( header )  ;  interval list . add ( new  interval ( this . dict . get sequence ( 0 )  . get sequence name (  )  1 100 )  )  ;  final vcf file reader reader = get reader
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\ByIntervalListVariantContextIteratorTest.java,test simple enclosing,"@ test public void   (  )  {  final  interval list interval list = new  interval list ( header )  ;  interval list . add ( new  interval ( ""12"" 68921962 68921962 )  )  ;  final vcf file reader reader = get reader ( ceu   trios   indels   vcf )  ;  final  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\ByIntervalListVariantContextIteratorTest.java,test simple overlap,"@ test public void   (  )  {  final  interval list interval list = new  interval list ( header )  ;  interval list . add ( new  interval ( ""2"" 167166899 167166899 )  )  ;  final vcf file reader reader = get reader ( ceu   trios   snps   vcf )  ;  final  i"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\ByIntervalListVariantContextIteratorTest.java,test variant overlapping multiple intervals is returned only once,"@ test public void   (  )  {  final  interval list interval list = new  interval list ( header )  ;  interval list . add ( new  interval ( ""12"" 68921962 68921962 )  )  ;  interval list . add ( new  interval ( ""12"" 68921964 68921964 )  )  ;  final vcf file"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\FixVcfHeaderTest.java,run fix vcf header,"private void   ( final int check firstn records final  file replacement header final boolean enforce sample samples )  throws io exception  {  final  fix vcf header program = new  fix vcf header (  )  ;  final  file output vcf =  vcf test utils . create temporary indexed file ( ""output . "" "" . vcf"" )  ;  program . input = input   vcf ;  program . output = output vcf ;  if  ( replacement header  =  =  null )   {  program . check   first   n   records = check firstn records ;   }  else  {  program . header = replacement header ;  program . enforce   same   samples = enforce sample samples ;   }   assert . assert equals ( program . instance main ( new  string[0] )  0 )  ;  io util . assert files equal ( output   vcf output vcf )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\FixVcfHeaderTest.java,setup,"@ before test void   (  )  throws io exception  {   file output   data   path = io util . create temp dir ( "" fix vcf header test"" null )  ;  output   data   path . delete on exit (  )  ;  final  file test data path = new  file ( ""testdata / picard / vcf "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\FixVcfHeaderTest.java,test fix vcf header,"@ test ( data provider = ""  data provider"" )  public void test fix vcf header ( final int check firstn records final  file replacement header final boolean enforce sample samples )  throws io exception  {  run fix vcf header ( check firstn records replace"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\FixVcfHeaderTest.java,test fix vcf header data provider,"@ data provider ( name = "" "" )  public  object[][] test fix vcf header data provider (  )  {  return new  object[][] {  {  - 1 header   vcf true }   {  - 1 header   vcf false }   {  - 1 header   vcf   with   extra   sample false }   {  - 1 null true }   {"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\FixVcfHeaderTest.java,test replace header with different samples error,@ test ( expected exceptions =  picard exception . class )  public void   (  )  throws io exception  {  run fix vcf header (  - 1 header   vcf   with   extra   sample true )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\filter\TestFilterVcf.java,good input vcfs,"@ data provider ( name = "" "" )  public  object[][] good input vcfs (  )  {  return new  object[][] {  { input }   { sites   only   input }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\filter\TestFilterVcf.java,quick javascript filter,"private  file   ( final  string content )  throws  exception  {  final  file out =  file . create temp file ( ""jsfilter"" "" . js"" )  ;  out . delete on exit (  )  ;  try  ( final  print writer pw = new  print writer ( out )  )  {  pw . println ( content )  ;   }  return out ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\filter\TestFilterVcf.java,slurp filters,private  list map <  string  string >    ( final  file vcf )  {  final  list map <  string  string >  map = new  list map <  >  (  )  ;  final vcf file reader in = new vcf file reader ( vcf false )  ;  for  (  final  variant context ctx : in )   {  if  ( ctx . is not filtered (  )  )  continue ;  for  (  final  string filter : ctx . get filters (  )  )   {  map . add ( ctx . getid (  )  filter )  ;   }   }  in . close (  )  ;  return map ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\filter\TestFilterVcf.java,sorted, < t extends  comparable >  sorted set < t >    (  set < t >  in )  {  return new  tree set <  >  ( in )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\filter\TestFilterVcf.java,test ab filtering,"@ test public void   (  )  throws  exception  {  final  set <  string >  fails =  collection util . make set ( ""tf2"" ""rs28566954"" ""rs28548431"" )  ;  final  file out = test filtering ( input "" . vcf . gz"" 0 . 4 0 0  double . max   value )  ;  final  list m"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\filter\TestFilterVcf.java,test combined filtering,"@ test public void   (  )  throws  exception  {  final  tree set <  string >  fails = new  tree set <  string >  (  collection util . make set ( ""rs13302979"" ""rs13303033"" ""rs2710876"" ""rs2799066"" ""rs28548431"" ""rs28566954"" ""rs71509448"" ""rs71628926"" ""tf2"" ) "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\filter\TestFilterVcf.java,test dp filtering,"@ test public void   (  )  throws  exception  {  final  set <  string >  fails =  collection util . make set ( ""rs71509448"" ""rs71628926"" ""rs13302979"" ""rs2710876"" )  ;  final  file out = test filtering ( input "" . vcf . gz"" 0 18 0  double . max   value )  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\filter\TestFilterVcf.java,test dp filtering to vcf,"@ test public void   (  )  throws  exception  {  final  set <  string >  fails =  collection util . make set ( ""rs71509448"" ""rs71628926"" ""rs13302979"" ""rs2710876"" )  ;  final  file out = test filtering ( input "" . vcf"" 0 18 0  double . max   value )  ;  fi"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\filter\TestFilterVcf.java,test filtering,"private  file   ( final  file vcf final  string output extension final double min ab final int min dp final int min gq final double max fs )  throws  exception  {  final  file out =  vcf test utils . create temporary indexed file ( ""filter vcf test . "" output extension )  ;  final  filter vcf filterer = new  filter vcf (  )  ;  filterer . create   index = true ;  filterer . input = vcf ;  filterer . output = out ;  filterer . min   ab = min ab ;  filterer . min   dp = min dp ;  filterer . min   gq = min gq ;  filterer . max   fs = max fs ;  final int retval = filterer . do work (  )  ;  if  ( retval  !  =  0 )   {  throw new  picard exception ( "" return value non - zero: ""  +  retval )  ;   }  return out ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\filter\TestFilterVcf.java,test filtering to vcf with no sequence dictionary,"@ test ( expected exceptions =  picard exception . class )  public void   (  )  throws  exception  {  final  file out =  file . create temp file ( ""filter vcf test . "" "" . vcf"" )  ;  out . delete on exit (  )  ;  final  filter vcf filterer = new  filter v"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\filter\TestFilterVcf.java,test fs filtering,"@ test ( data provider = ""good input vcfs"" )  public void   ( final  file input )  throws  exception  {  final  set <  string >  fails =  collection util . make set ( ""rs13303033"" ""rs28548431"" ""rs2799066"" )  ;  final  file out = test filtering ( input "" ."
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\filter\TestFilterVcf.java,test gq filtering,"@ test public void   (  )  throws  exception  {  final  set <  string >  fails =  collection util . make set ( ""rs71509448"" )  ;   {  final  file out = test filtering ( input "" . vcf . gz"" 0 0 20  double . max   value )  ;  final  list map <  string  stri"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\filter\TestFilterVcf.java,test java script,"@ test ( data provider = ""good input vcfs"" )  public void   ( final  file input )  throws  exception  {  final  file out =  vcf test utils . create temporary indexed file ( ""filter vcf testjs . "" "" . vcf"" )  ;  final  filter vcf filterer = new  filter vcf"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\filter\TestFilterVcf.java,test no filtering,"@ test ( data provider = ""good input vcfs"" )  public void   ( final  file input )  throws  exception  {  final  file out = test filtering ( input "" . vcf . gz"" 0 0 0  double . max   value )  ;  final vcf file reader in = new vcf file reader ( out false ) "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\CollectVariantCallingMetricsTest.java,test all hom refvcf,"@ test public void   (  )  throws io exception  {  final  file db snp file = new  file ( test   data   dir ""mini . dbsnp . vcf"" )  ;  final  file vcf file = new  file ( test   data   dir ""all hom ref . vcf"" )  ;  final  file indexed vcf file =  vcf test u"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\CollectVariantCallingMetricsTest.java,test metrics tiny,"@ test public void   (  )  throws io exception  {  final  file db snp file = new  file ( test   data   dir ""mini . dbsnp . vcf"" )  ;  final  file vcf file = new  file ( test   data   dir ""mini . vcf"" )  ;  final  file out file = new  file ( test   data   "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\CollectVariantCallingMetricsTest.java,test metrics tinygvcf,"@ test public void   (  )  throws io exception  {  final  file db snp file = new  file ( test   data   dir ""mini . dbsnp . vcf"" )  ;  final  file vcf file = new  file ( test   data   dir ""mini   gvcf . vcf"" )  ;  final  file out file = new  file ( test   "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceGA4GHSchemeTest.java,testgagh scheme,"@ test public void   (  )  throws  exception  {  final  genotype concordance counts concordance counts =  genotype concordance test . get genotype concordance counts ( ceu trio snps vcf ceu trio snps vcf ""na12878"" false null )  ;  concordance counts . val"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceGA4GHSchemeTest.java,testgagh scheme diff samples,"@ test public void   (  )  throws  exception  {  final  genotype concordance counts concordance counts =  genotype concordance test . get genotype concordance counts ( ceu trio snps vcf ceu trio snps vcf ""na12891"" false null )  ;  concordance counts . val"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceGA4GHSchemeTest.java,testgagh scheme diff samples with intervals,"@ test public void   (  )  throws  exception  {  final  genotype concordance counts concordance counts =  genotype concordance test . get genotype concordance counts ( ceu trio snps vcf ceu trio snps vcf ""na12891"" false interval list )  ;  concordance cou"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceGA4GHSchemeTest.java,testgagh scheme with intervals,"@ test public void   (  )  throws  exception  {  final  genotype concordance counts concordance counts =  genotype concordance test . get genotype concordance counts ( ceu trio snps vcf ceu trio snps vcf ""na12878"" false interval list )  ;  concordance cou"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceGA4GHSchemeWithMissingTest.java,test missing hom ref scheme with intervals,"@ test public void   (  )  {  final  genotype concordance counts concordance counts =  genotype concordance test . get genotype concordance counts ( nist truthvcf ceu triosnpsvcf ""na12878"" true interval list )  ;  concordance counts . validate counts agai"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\MergeVcfsTest.java,get program,@ override protected  command line program   (  )  {  return new  merge vcfs (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GatherVcfsTest.java, test gather files,"@ test ( data provider = ""vcfshards"" )  public void   ( final  list <  file >  input files final  file expected output final int expected ret val )  throws io exception  {  final  list <  string >  args = new  array list <  >  (  )  ;  final  file output "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GatherVcfsTest.java,get command line program name,@ override public  string   (  )  {  return  gather vcfs . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GatherVcfsTest.java,setup,"@ before class public void   (  )  throws io exception  {  final  file test   dir = new  file ( ""testdata / picard / vcf /  gather vcf"" )  ;  vcf =  vcf test utils . create temporary indexed vcf from input ( new  file ( test   dir ""input . vcf"" )  ""whole "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GatherVcfsTest.java,vcfshards,@ data provider public  object[][]   (  )  {  return new  object[][] {  {  arrays . as list ( shard1 shard2 shard3 )  vcf 0 }   {  arrays . as list ( shard1 shard2   bad shard3 )  vcf 1 }   {  arrays . as list ( shard1 shard3 shard2 )  vcf 1 }   {  arrays
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\processor\ByWholeContigTest.java,test,@ test public void   (  )  throws  exception  {  final  vcf file segment generator .  by whole contig segmenter =  vcf file segment generator .  by whole contig . get instance (  )  ;  int chunk count = 0 ;  for  (  final  vcf file segment variant context
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\processor\AccumulatorExecutorTest.java,accumulate,@ override public void   ( final  variant context vc )  {  observed variant context strings . add ( vc . to string (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\processor\AccumulatorExecutorTest.java,build,@ override public  variant processor .  accumulator   (  )  {  return new  variant processor .  accumulator (  )  {  @ override public void accumulate (  final  variant context vc )  {  observed variant context strings . add ( vc . to string (  )  )  ;   
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\processor\AccumulatorExecutorTest.java,result,@ override public  object   (  )  {  return null ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\processor\AccumulatorExecutorTest.java,test,@ test public void   (  )  throws  exception  {  final  set <  string >  actual variant context strings =  collections . synchronized set ( new  hash set <  string >  (  )  )  ;  for  (  final  file test vcf : test   vcfs )   {  for  (  final  variant con
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\processor\ThreadsafeTest.java,ensure same variants read as simple vcf file iterator,@ test public void   (  )  {  final  variant iterator producer .  threadsafe iterator factory = new  variant iterator producer .  threadsafe (  vcf file segment generator . by whole contig subdividing with width ( ten   million )   arrays . as list ( vcf 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\processor\ThreadsafeTest.java,ensure test data actually has wide variant at ten million,"@ test public void   (  )  {  final  joiner joiner =  joiner . on ( "":"" )  ;  final vcf file reader r = new vcf file reader ( vcf   with   multi   allelic   variant   at   position   10million )  ;   assert . assert equals ( joiner . join ( r . query ( ""1"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\processor\ThreadsafeTest.java,ensure unique variant observations especially multi allelic ones that appear at chunking boundaries,@ test public void   (  )  {  final  variant iterator producer .  threadsafe iterator factory = new  variant iterator producer .  threadsafe (  vcf file segment generator . by whole contig subdividing with width ( ten   million )   arrays . as list ( vcf 
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,assert metrics file equal,private void   ( final  file actual metrics file final  file expected metrics file )  throws  file not found exception  {  final  metrics file <  genotype concordance summary metrics  comparable <  ?  >  >  actual = new  metrics file <  genotype concordance summary metrics  comparable <  ?  >  >  (  )  ;  actual . read ( new  file reader ( actual metrics file )  )  ;  final  metrics file <  genotype concordance summary metrics  comparable <  ?  >  >  expected = new  metrics file <  genotype concordance summary metrics  comparable <  ?  >  >  (  )  ;  expected . read ( new  file reader ( expected metrics file )  )  ;   assert . assert true ( expected . are metrics equal ( actual )  )  ;   assert . assert true ( expected . are histograms equal ( actual )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,assert non zero counts agree,public static void   ( final  genotype concordance counts counter final  map <  truth and call states  integer >  expected count map )  {  for  (  final  truth state truth state :  truth state . values (  )  )   {  for  (  final  call state call state :  call state . values (  )  )   {   integer expected count = expected count map . get ( new  truth and call states ( truth state call state )  )  ;  if  ( expected count  =  =  null )  expected count = 0 ;   assert . assert equals ( counter . get count ( truth state call state )  expected count . int value (  )  )  ;   }   }   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,genotype concordance determine state data provider,"@ data provider ( name = "" "" )  public  object[][] genotype concordance determine state data provider (  )  {  final  object[][] original unit test data = new  object[][] {  {  aref  aref  truth state . hom   ref  aref  aref  call state . hom   ref }   { "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,get genotype concordance counts,"public static  genotype concordance counts   ( final  file truthvcf final  file callvcf final  string call sample final boolean missing sites flag  list <  file >  interval files )  {  final  file output base file name = new  file ( output   data   path ""actual gt conc"" )  ;  final  file output summary file = new  file ( output base file name . get absolute path (  )   +   genotype concordance . summary   metrics   file   extension )  ;  final  file output details file = new  file ( output base file name . get absolute path (  )   +   genotype concordance . detailed   metrics   file   extension )  ;  output summary file . delete on exit (  )  ;  output details file . delete on exit (  )  ;  final  genotype concordance genotype concordance = new  genotype concordance (  )  ;  genotype concordance . truth   vcf = truthvcf ;  genotype concordance . truth   sample = ""na12878"" ;  genotype concordance . call   vcf = callvcf ;  genotype concordance . call   sample = call sample ;  genotype concordance . missing   sites   hom   ref = missing sites flag ;  genotype concordance . intervals = interval files ;  genotype concordance . output = output base file name ;   assert . assert equals ( genotype concordance . instance main ( new  string[0] )  0 )  ;  return genotype concordance . get snp counter (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,get genotype concordance test file data,"@ data provider ( name = ""genotype concordance test file data"" )  public  object[][]   (  )  {  return new  object[][] {  { ceu   trios   snps   vcf ""na12878"" ceu   trios   snps   vcf ""na12878"" null null false false ceu   trios   snps   vs   ceu   trios  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,make unique list of alleles,private  list <  allele >    ( final  allele .  .  .  alleles )  {  final  set <  allele >  unique alleles = new  hash set <  allele >  (  )  ;  for  (  final  allele allele : alleles )   {  if  (  ! allele . equals (  allele . no   call )  )   {  unique alleles . add ( allele )  ;   }   }  if  (  ! unique alleles . contains (  aref )  )  unique alleles . add (  aref )  ;  return new  array list <  allele >  ( unique alleles )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,tear down,@ after class public void   (  )  {  io util . delete directory tree ( output   data   path )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,test genotype concordance,"@ test ( data provider = ""genotype concordance test file data"" )  public void   ( final  file vcf1 final  string sample1 final  file vcf2 final  string sample2 final  integer min gq final  integer min dp final boolean output all rows final boolean missing"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,test genotype concordance determine state,private void   ( final  variant context truth variant context final  truth state expected truth state final  variant context call variant context final  call state expected call state final int min gq final int min dp )  {  final  truth and call states truth and call states =  genotype concordance . determine state ( truth variant context truth   sample   name call variant context call   sample   name min gq min dp false )  ;   assert . assert equals ( truth and call states . truth state expected truth state )  ;   assert . assert equals ( truth and call states . call state expected call state )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,test genotype concordance determine state dp,@ test public void   (  )  throws  exception  {  final  list <  allele >  alleles normal = make unique list of alleles (  aref c )  ;  final  genotype gt normal =  genotype builder . create ( truth   sample   name  arrays . as list (  aref c )  )  ;  fina
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,test genotype concordance determine state filter,"@ test public void   (  )  throws  exception  {  final  set <  string >  filters = new  hash set <  string >  (  arrays . as list ( ""bad ! "" )  )  ;  final  list <  allele >  alleles1 = make unique list of alleles (  aref c )  ;  final  genotype gt1 =  ge"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,test genotype concordance determine state gq,@ test public void   (  )  throws  exception  {  final  list <  allele >  alleles normal = make unique list of alleles (  aref c )  ;  final  genotype gt normal =  genotype builder . create ( truth   sample   name  arrays . as list (  aref c )  )  ;  fina
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,test genotype concordance determine state null,@ test public void   (  )  throws  exception  {  final  list <  allele >  alleles = make unique list of alleles (  aref c )  ;  final  genotype gt1 =  genotype builder . create ( truth   sample   name  arrays . as list (  aref c )  )  ;  final  variant co
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,test ignore filter status,"@ test public void   (  )  throws  exception  {  final  file truth vcf path = new  file ( test   data   path . get absolute path (  )  ""nist   subset   3sites . vcf"" )  ;  final  file call vcf path = new  file ( test   data   path . get absolute path (  )"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,test no call variants,"@ test public void   (  )  {  final  genotype concordance genotype concordance = new  genotype concordance (  )  ;  genotype concordance . truth   vcf = new  file ( test   data   path ""mini . vcf"" )  ;  genotype concordance . truth   sample = ""na20801"" ; "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,test normalize alleles for indels,@ test public void   (  )  {  final  path truth vcf path =  paths . get ( test   data   path . get absolute path (  )  normalize   alleles   truth )  ;  final  path call vcf path =  paths . get ( test   data   path . get absolute path (  )  normalize   al
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,test normalize alleles for writingvcf,@ test public void   (  )  throws  file not found exception  {  final  file truth vcf path = new  file ( test   data   path . get absolute path (  )  normalize   no   calls   truth )  ;  final  file call vcf path = new  file ( test   data   path . get abs
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\GenotypeConcordanceTest.java,test spanning deletion,"@ test public void   (  )  throws  file not found exception  {  final  file truth vcf path = new  file ( test   data   path . get absolute path (  )  ""spanning deletion truth . vcf"" )  ;  final  file call vcf path = new  file ( test   data   path . get ab"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\processor\WidthLimitingDecoratorTest.java, segment,  ( final int start final int stop )  {  this . start = start ;  this . stop = stop ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\processor\WidthLimitingDecoratorTest.java,contig,"@ override public  string   (  )  {  return ""a"" ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\processor\WidthLimitingDecoratorTest.java,for vcf,@ override public  iterable <  vcf file segment >    ( final  file vcf )  {  return  collections . singleton (  (  vcf file segment ) entire thing )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\processor\WidthLimitingDecoratorTest.java,start,@ override public int   (  )  {  return start ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\processor\WidthLimitingDecoratorTest.java,stop,@ override public int   (  )  {  return stop ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\processor\WidthLimitingDecoratorTest.java,test for vcf,@ test public void   (  )  throws  exception  {  final  segment entire thing = new  segment ( 1 9942 )  ;  final  immutable list <  segment >  expected sub things =  immutable list . of ( new  segment ( 1 1000 )  new  segment ( 1001 2000 )  new  segment (
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\processor\WidthLimitingDecoratorTest.java,to string,"@ override public  string   (  )  {  return "" segment { ""  +  ""start = ""  +  start  +  ""  stop = "" +  stop +  ""  vcf = "" +  vcf (  )  +  ""  contig = "" +  contig (  )  +  ' } ' ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\processor\WidthLimitingDecoratorTest.java,vcf,"@ override public  file   (  )  {  return new  file ( ""b"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\MendelianViolations\FindMendelianViolationsTest.java,grep,"private int   ( final  file file final  string regex )  {  int results = 0 ;  final  pattern pattern =  pattern . compile ( "" . *""  +  regex  +  "" . *"" )  ;  try  ( final  line iterator impl li = new  line iterator impl ( new  ascii line reader ( io util . open file for reading ( file )  )  )  )  {  while  ( li . has next (  )  )   {  final  string line = li . next (  )  ;  if  ( pattern . matcher ( line )  . matches (  )  )   {  results +  +  ;   }   }   }  catch  (  final io exception e )   {  e . print stack trace (  )  ;   }  return results ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\MendelianViolations\FindMendelianViolationsTest.java,grep mv,"private int   ( final  file file final  string regex )  {  return grep ( file ""[ ; \t]mv = ""  +  regex  +  ""[ ; \t]"" )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\MendelianViolations\FindMendelianViolationsTest.java,test find medelian violations,"@ test public void   (  )  throws io exception  {  final  file vcf file = new  file ( test   data   dir ""ceu trio   plus   fake . vcf"" )  ;  final  file vcf index file = new  file ( test   data   dir ""ceu trio   plus   fake . vcf . idx"" )  ;  if  ( vcf fi"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\SamTestUtils.java,create indexed bam,"public static  file   ( final  file sam file final  file temp file prefix )  throws io exception  {  final  file output =  file . create temp file ( temp file prefix . get absolute path (  )  "" . bam"" )  ;  output . delete on exit (  )  ;  final  file index file = new  file ( output . get absolute path (  )   +  "" . bai"" )  ;  index file . delete on exit (  )  ;  final  sam reader in =  sam reader factory . make default (  )  . open ( sam file )  ;  sam file writer out = new sam file writer factory (  )  . set create index ( true )  . makebam writer ( in . get file header (  )  true output )  ;  in . iterator (  )  . stream (  )  . for each ( out::add alignment )  ;  out . close (  )  ;  in . close (  )  ;  return output ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\SplitVcfsTest.java,get command line program name,public  string   (  )  {  return  split vcfs . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\SplitVcfsTest.java,teardown,@ after class public void   (  )  {  io util . delete directory tree ( output   data   path )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\SplitVcfsTest.java,test split,"@ test public void   (  )  {  final  file indel output file = new  file ( output   data   path ""split - vcfs - test - indels - delete - me . vcf"" )  ;  final  file snp output file = new  file ( output   data   path ""split - vcfs - test - snps - delete - m"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\SortVcfsTest.java,get program,@ override protected  command line program   (  )  {  return new  sort vcf (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\SortVcfsTest.java,test presorted file,"@ test public void   (  )  throws io exception  {  final  file snp input file = new  file ( test   data   path ""ceu trio - snps . vcf"" )  ;  final  file output =  file . create temp file ( ""sort - presorted - test - output . "" "" . vcf"" )  ;  final  list <"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\SortVcfsTest.java,test scrambled snps and ordered indels,"@ test public void   (  )  throws io exception  {  final  file indel input file = new  file ( test   data   path ""ceu trio - indels . vcf"" )  ;  final  file snp input file = new  file ( test   data   path ""ceu trio - snps - scrambled . 1 . vcf"" )  ;  fina"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\SortVcfsTest.java,test scrambled snps and scrambled indels,"@ test public void   (  )  throws io exception  {  final  file indel input file = new  file ( test   data   path ""ceu trio - indels - scrambled . 1 . vcf"" )  ;  final  file snp input file = new  file ( test   data   path ""ceu trio - snps - scrambled . 1 ."
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\SortVcfsTest.java,test single scrambled file,"@ test public void   (  )  throws io exception  {  final  file snp input file = new  file ( test   data   path ""ceu trio - snps - scrambled . 1 . vcf"" )  ;  final  file output =  file . create temp file ( ""sort - single - scrambled - test - output . "" "" ."
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\SortVcfsTest.java,test two scrambled snp files,"@ test public void   (  )  throws io exception  {  final  file input file1 = new  file ( test   data   path ""ceu trio - snps - scrambled . 1 . vcf"" )  ;  final  file input file2 = new  file ( test   data   path ""vcf format test . scrambled . vcf"" )  ;  fi"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\SortVcfsTest.java,validate sorting results,private void   ( final  file output final int expected variant context count )  {  final vcf file reader output reader = new vcf file reader ( output false )  ;  final  variant context comparator output comparator = output reader . get file header (  )  . getvcf record comparator (  )  ;   variant context last = null ;  int variant context count = 0 ;  final  closeable iterator <  variant context >  iterator = output reader . iterator (  )  ;  while  ( iterator . has next (  )  )   {  final  variant context output context = iterator . next (  )  ;  if  ( last  !  =  null )   assert . assert true ( output comparator . compare ( last output context )   <  =  0 )  ;  last = output context ;  variant context count +  +  ;   }  iterator . close (  )  ;   assert . assert equals ( variant context count expected variant context count )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VariantContextComparatorTest.java,build variant context,"private static  variant context   ( final  string source final  string contig final long start )  {  final  collection <  allele >  alleles = new  array list <  allele >  (  )  ;  alleles . add (  allele . create ( ""aaaa"" true )  )  ;  alleles . add (  allele . create ( ""aagg"" false )  )  ;  return new  variant context builder ( source contig start start  +  3 alleles )  . make (  )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VariantContextComparatorTest.java,get ordered contig list,private static  list <  string >    ( final  variant context .  .  .  variant contexts )  {  final  linked hash set <  string >  contigs = new  linked hash set <  string >  (  )  ;  for  (  final  variant context context : variant contexts )   {  contigs . add ( context . get contig (  )  )  ;   }  return new  array list <  string >  ( contigs )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VariantContextComparatorTest.java,test combination one,"@ test public void   (  )  {  final  variant context context one = build variant context ( ""source"" ""one"" 100 )  ;  final  variant context context two = build variant context ( ""source"" ""two"" 150 )  ;  final  list <  string >  contigs = get ordered contig"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VariantContextComparatorTest.java,test combination two,"@ test public void   (  )  {  final  variant context context one = build variant context ( ""source"" ""one"" 150 )  ;  final  variant context context two = build variant context ( ""source"" ""two"" 100 )  ;  final  list <  string >  contigs = get ordered contig"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VariantContextComparatorTest.java,test contigs,"@ test public void   (  )  {  final  variant context context one = build variant context ( ""source"" ""one"" 100 )  ;  final  variant context context two = build variant context ( ""source"" ""two"" 100 )  ;  final  list <  string >  contigs = get ordered contig"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VariantContextComparatorTest.java,test identical,"@ test public void   (  )  {  final  variant context context one = build variant context ( ""source"" ""one"" 100 )  ;  final  list <  string >  contigs = get ordered contig list ( context one )  ;   assert . assert equals ( 0 new  variant context comparator "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VariantContextComparatorTest.java,test positions,"@ test public void   (  )  {  final  variant context context one = build variant context ( ""source"" ""one"" 100 )  ;  final  variant context context two = build variant context ( ""source"" ""one"" 150 )  ;  final  list <  string >  contigs = get ordered contig"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VariantContextComparatorTest.java,test throws on duplicate contig,"@ test ( expected exceptions =  illegal argument exception . class )  public void   (  )  {  final  list <  string >  contigs = new  array list <  string >  ( 3 )  ;  contigs . add ( ""one"" )  ;  contigs . add ( ""two"" )  ;  contigs . add ( ""one"" )  ;  new "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\UpdateVcfSequenceDictionaryTest.java,output fies,"@ data provider ( name = "" output files"" )  public static  object[][]   (  )  {  return new  object[][] {  { output   data   path  +  ""update vcf sequence dictionary test - delete - me . vcf"" }   { std   out   name }  }  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\UpdateVcfSequenceDictionaryTest.java,teardown,@ after class public void   (  )  {  io util . delete directory tree ( output   data   path )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\UpdateVcfSequenceDictionaryTest.java,test update vcf sequence dictionary,"@ test ( data provider = "" output files"" )  public void   ( final  string output file name )  throws io exception   no such field exception   illegal access exception  {   file input = new  file ( test   data   path ""vcf format test . vcf"" )  ;  final  fi"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VcfFormatConverterTest.java,compare files,private void   ( final  file file1 final  file file2 )  {   assert . assert true ( file1 . exists (  )  )  ;   assert . assert true ( file2 . exists (  )  )  ;   assert . assert equals ( file1 . length (  )  file2 . length (  )  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VcfFormatConverterTest.java,convert file,"private  file   ( final  file input final  string prefix final  string format )  {  final  file output file ;  try  {  output file =  file . create temp file ( prefix format )  ;   }  catch  (  final io exception ioe )   {  throw new  picard exception ( "" unable to create temp file ! "" )  ;   }  output file . delete on exit (  )  ;  new  file ( output file . get absolute path (  )   +   tribble . standard   index   extension )  . delete on exit (  )  ;  final  list <  string >  args = new  array list <  string >  (  arrays . as list ( ""input = ""  +  input . get absolute path (  )  ""output = ""  +  output file . get absolute path (  )  )  )  ;  if  ( vcf   gz . equals ( format )  )   {  args . add ( ""create   index = false"" )  ;   }  if  ( input . get name (  )  . ends with ( vcf   gz )  )   {  args . add ( ""require   index = false"" )  ;   }   assert . assert equals ( run picard command line ( args )  0 )  ;  return output file ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VcfFormatConverterTest.java,get command line program name,public  string   (  )  {  return  vcf format converter . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VcfFormatConverterTest.java,run back and forth test,"private void   ( final  file input final  string format final  string original format )  {  final  string temp prefix = ""back and forth"" ;  final  file back and forth = convert file ( input temp prefix format )  ;  final  file back and forth series2 = convert file ( back and forth temp prefix original format )  ;  compare files ( input back and forth series2 )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VcfFormatConverterTest.java,run like test,"private void   ( final  file input final  string format )  {  final  file output file = convert file ( input ""like test"" format )  ;  compare files ( input output file )  ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VcfFormatConverterTest.java,test bcf to bcf,@ test public void   (  )  {  run like test ( test   bcf bcf )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VcfFormatConverterTest.java,test bcf to vcf,@ test public void   (  )  {  run back and forth test ( test   bcf vcf bcf )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VcfFormatConverterTest.java,test vcf to bcf,@ test public void   (  )  {  run back and forth test ( test   vcf bcf vcf )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VcfFormatConverterTest.java,test vcf to vcf,@ test public void   (  )  {  run like test ( test   vcf vcf )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VcfFormatConverterTest.java,test vcf to vcf gz,@ test public void   (  )  {  run back and forth test ( test   vcf vcf   gz vcf )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VcfTestUtils.java,assert equals,"public static void   ( final  genotypes context actual final  genotypes context expected )  {  if  ( expected  =  =  null )   {   assert . assert null ( actual )  ;  return ;   }   assert . assert equals ( actual . get sample names ordered by name (  )  expected . get sample names ordered by name (  )  "" sample names differ"" )  ;  for  (  final  string name : expected . get sample names ordered by name (  )  )   {   assert . assert equals ( actual . get ( name )  . get alleles (  )  expected . get ( name )  . get alleles (  )  "" alleles differ for sample ""  +  name )  ;   assert . assert equals ( actual . get ( name )  . getad (  )  expected . get ( name )  . getad (  )  )  ;   assert . assert equals ( actual . get ( name )  . getpl (  )  expected . get ( name )  . getpl (  )  )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VcfTestUtils.java,assert vcf files are equal,"public static void   ( final  file actual final  file expected )  throws io exception  {  final  file indexed actual = create temporary indexed vcf from input ( actual ""assert"" )  ;  final  file indexed expected = create temporary indexed vcf from input ( expected ""assert"" )  ;  try  ( final vcf file reader vcf reader actual = new vcf file reader ( indexed actual )  ; final vcf file reader vcf reader expected = new vcf file reader ( indexed expected )  )  {   vcf test utils . assert equals ( vcf reader actual vcf reader expected )  ;   }   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VcfTestUtils.java,create temporary indexed file,"public static  file   ( final  string prefix final  string suffix )  throws io exception  {  final  file out =  file . create temp file ( prefix suffix )  ;  out . delete on exit (  )  ;   string index file extension = null ;  if  ( suffix . ends with ( ""vcf . gz"" )  )   {  index file extension = "" . tbi"" ;   }  else if  ( suffix . ends with ( ""vcf"" )  )   {  index file extension = "" . idx"" ;   }  else if  ( suffix . ends with ( "" . bam"" )  )   {  index file extension = "" . bai"" ;   }  if  ( index file extension  !  =  null )   {  final  file index out = new  file ( out . get absolute path (  )   +  index file extension )  ;  index out . delete on exit (  )  ;   }  return out ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VcfTestUtils.java,create temporary indexed vcf from input,"public static  file   ( final  file vcf file final  string temp file prefix final  string suffix )  throws io exception  {  final  string extension ;  if  ( suffix  !  =  null )   {  extension = suffix ;   }  else if  ( vcf file . get absolute path (  )  . ends with ( "" . vcf"" )  )   {  extension = "" . vcf"" ;   }  else if  ( vcf file . get absolute path (  )  . ends with ( "" . vcf . gz"" )  )   {  extension = "" . vcf . gz"" ;   }  else  {  extension = ""nope ! "" ;   }  if  (  ! extension . equals ( "" . vcf"" )  &&  ! extension . equals ( "" . vcf . gz"" )  )  throw new  illegal argument exception ( ""couldn't find a  . vcf or  . vcf . gz ending for input file ""  +  vcf file . get absolute path (  )  )  ;   file output = create temporary indexed file ( temp file prefix extension )  ;  final vcf file reader in = new vcf file reader ( vcf file false )  ;  final vcf header header = in . get file header (  )  ;  final  variant context writer out = new  variant context writer builder (  )  . set reference dictionary ( header . get sequence dictionary (  )  )  . set options (  enum set . of (  options . index   on   the   fly )  )  . set output file ( output )  . build (  )  ;  out . write header ( header )  ;  for  (  final  variant context ctx : in )   {  out . add ( ctx )  ;   }  out . close (  )  ;  in . close (  )  ;  return output ;   }  "
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VcfToIntervalListTest.java,get command line program name,public  string   (  )  {  return  vcf to interval list . class . get simple name (  )  ;   }  
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VcfToIntervalListTest.java,get vcf to interval list data,"@ data provider ( name = "" vcf to interval list data"" )  public  object[][]   (  )  {  return new  object[][] {  { new  file ( test   resource   dir ""small   m2   more   variants . vcf"" )  false 11  -  1  -  1 }   { new  file ( test   resource   dir ""smal"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\VcfToIntervalListTest.java,test excluding filtered,"@ test ( data provider = "" vcf to interval list data"" )  public void   ( final  file input file final boolean include filtered final int expected intervals size )  throws io exception  {  final  file output file =  file . create temp file ( ""vcftointerval"
C:\Users\User\Desktop\Thesis\picard\src\test\java\picard\vcf\processor\VcfFileSegmentGeneratorTest.java,ensure overlap exclusion test,"@ test public void   (  )  {  final  overlap detector <  interval >  one tiny interval detector = new  overlap detector <  interval >  ( 0 0 )  ;  final  interval the interval = new  interval ( ""1"" 5 10 )  ;  one tiny interval detector . add lhs ( the int"
